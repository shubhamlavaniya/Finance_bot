page_content,source,title
"Lost in Translation
May 2023
A report from
Gabriel Nicholas
Aliya Bhatia
Large Language Models in 
Non-English Content Analysis
GABRIEL NICHOLAS
Research Fellow at the Center for Democracy & Technology.
ALIYA BHATIA
Policy Analyst, Free Expression Project at the Center for 
Democracy & Technology.
The Center for Democracy & Technology (CDT) is the leading 
nonpartisan, nonprofit organization fighting to advance civil rights and",N/A,N/A
"civil liberties in the digital age. We shape technology policy, governance, 
and design with a focus on equity and democratic values. Established in 
1996, CDT has been a trusted advocate for digital rights since the earliest 
days of the internet. The organization is headquartered in Washington, 
D.C., and has a Europe Office in Brussels, Belgium.
A report from
Gabriel Nicholas and Aliya Bhatia
WITH CONTRIBUTIONS BY",N/A,N/A
"WITH CONTRIBUTIONS BY
Samir Jain, Mallory Knodel, Emma Llansó, Michal Luria, Nathalie Maréchal, Dhanaraj Thakur, and 
Caitlin Vogus.
ACKNOWLEDGMENTS 
We thank Pratik Joshi, Sebastin Santy, and Aniket Kesari for their invaluable feedback on the technical 
aspects of this report. We also thank Jacqueline Rowe, Damini Satija, and Ángel Díaz for their 
insightful comments and suggestions. The translation of our executive summary is made possible by",N/A,N/A
"Global Voices Translations and with the help of Iverna McGowan, Maria Villamar, Ophélie Stockhem, 
and Tomás Pomar. All views in this report are those of CDT. 
This work is made possible through a grant from the John S. and James L. Knight Foundation.
Suggested Citation: Nicholas, G. and Bhatia, A. (2023) Lost in Translation: Large Language Models 
in Non-English Content Analysis. Center for Democracy & Technology. https://cdt.org/insights/lost-",N/A,N/A
"in-translation-large-language-models-in-non-english-content-analysis/
References in this report include original links and links archived and shortened by the Perma.cc service. 
The Perma.cc links also contain information on the date of retrieval and archive. 
This report is licensed under a Creative Commons Attribution 4.0 International License.
Lost in Translation
Large Language Models in Non-
English Content Analysis
Lost in Translation
CDT Research
4
CDT Research
4
Contents",N/A,N/A
"CDT Research
4
CDT Research
4
Contents
Executive Summary
5
Introduction
8
I.	 Background
12
A. How Large Language Models Work
12
B. The Resourcedness Gap: Why the Largest Language 
Models are in English
15
C. Multilingual Language Models: Efforts to Bridge the 
Resourcedness Gap
19
II.	 Limitations of Language Models in English and 
Non-English Contexts
23
A. Concerns with Building and Deploying Large 
Language Models
23
B. Limitations of Multilingual Language Models
25",N/A,N/A
"25
III.	Recommendations
31
A. Companies
31
B. Researchers and Funders
33
C. Governments
36
Works Cited
39
5
Lost in Translation
Executive 
Summary
T
he internet is the primary source of information, economic 
opportunity, and community for many around the world. 
However, the automated systems that increasingly mediate our 
interactions online — such as chatbots, content moderation 
systems, and search engines — are primarily designed for and work far",N/A,N/A
"more effectively in English than in the world’s other 7,000 languages.
In recent years, large language models have become the dominant 
approach for building AI systems to analyze and generate language 
online, but again, they have been built primarily for the English 
language. A large language model (e.g., Open AI’s GPT-4, Meta’s 
LLaMa, Google’s PaLM) is a machine learning algorithm that scans 
enormous volumes of text to learn which words and sentences",N/A,N/A
"frequently appear near one another and in what context. Large language 
models can be adapted to perform a wide range of tasks across different 
domains. They are most known for being used to build chatbots, 
such as ChatGPT, but researchers and technology companies also 
use them for content analysis tasks, such as sentiment analysis, text 
summarization, and hate speech detection. Google, Meta, Microsoft, 
and other companies have already incorporated large language models",N/A,N/A
"into their core product functions, such as content moderation and 
search. Other vendors soon may incorporate them into automated 
decision-making systems, such as resume scanners.
Recently though, researchers and technology companies have attempted 
to extend the capabilities of large language models into languages other 
than English by building what are called multilingual language models. 
Instead of being trained on text from only one language, multilingual",N/A,N/A
"language models are trained on text from dozens or hundreds of 
languages at once. Researchers posit that multilingual language models 
infer connections between languages, allowing them to apply word 
associations and underlying grammatical rules learned from languages 
with more text data available to train on (in particular English) to 
those with less. In some applications, multilingual language models 
outperform models trained on only one language — for instance, a",N/A,N/A
"model trained on lots of text from lots of languages, including Hindi, 
might perform better in Hindi contexts than a model just trained on 
Hindi text.
Multilingual language models give technology companies a way to scale 
their AI systems to many languages at once, and some have already 
begun to integrate them into their products. Online service providers 
in particular have deployed multilingual language models to moderate 
Lost in Translation
CDT Research
6",N/A,N/A
"Lost in Translation
CDT Research
6
content: Meta uses a multilingual language model to detect harmful content on its 
platforms in over 100 languages; Alphabet’s Perspective API uses one to detect toxic 
content in eighteen different languages; Bumble uses one to detect and take action on 
unwanted sexual messages around the world.
Multilingual language models allow technologists to attempt to build models in languages",N/A,N/A
"for which they otherwise might not have enough digitized text. Languages vary widely 
in resourcedness, or the volume, quality, and diversity of text data they have available to 
train language models on. English is the highest resourced language by multiple orders of 
magnitude, but Spanish, Chinese, German, and a handful of other languages are sufficiently 
high resource enough to build language models in. Medium resource languages, with fewer",N/A,N/A
"but still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource 
languages, with almost no training data sets, such as Amharic, Cherokee, and Haitian 
Creole, have too little text for training their own large language models. Language data in 
low resource languages is also often of particularly poor quality: either it is mistranslated or 
even nonsensical language scraped from the internet, or is limited to sources with narrow",N/A,N/A
"domains, such as religious texts and Wikipedia. This gap in data availability between 
languages is known as the resourcedness gap.
Multilingual language models are designed to address these gaps in data availability by 
inferring semantic and grammatical connections between higher- and lower-resource 
languages, allowing the former to bootstrap the latter. However, this architecture 
raises its own concerns. Multilingual language models are still usually trained",N/A,N/A
"disproportionately on English language text and thus end up transferring values and 
assumptions encoded in English into other language contexts where they may not 
belong. For example, a multilingual model might associate the word “dove” in all 
languages with “peace” even though the Basque word for dove (“uso”) can be an insult. 
The disparity in available data also means multilingual language models work far better",N/A,N/A
"in higher resource languages and languages similar to them than lower resource ones. 
Model developers will sometimes try to fill in these gaps with machine-translated text, 
but translation errors may further compound language misrepresentation. And when 
multilingual language models do fail, their unintuitive connections between languages 
can make those problems harder to identify, diagnose, and fix.
Large language models’ general use in content analysis raises further concerns.",N/A,N/A
"Computational linguists argue that large language models are limited in their capacity 
to analyze forms of expression not included in their training data, meaning they may 
struggle to perform in new contexts. They may also reproduce any biases present in 
their training data. Often, this text is scraped from the internet, meaning that large 
language models may encode and reinforce dominant views expressed online.
Large Language Models in Non-English Content Analysis
7",N/A,N/A
"7
​Companies, researchers, and governments each have a role to play in protecting the 
public from the potential dangers of multilingual language model content analysis 
systems. To ensure better public accountability, companies that deploy large language 
models should always be transparent about how they use them and in which languages. 
Companies should deploy language models with narrow remits and adequate channels 
for human review.",N/A,N/A
"for human review.
Researchers and research funders meanwhile should invest in efforts to improve the 
use and performance of language models in languages other than English, in particular, 
to reduce failures that disparately impact speakers of lower-resourced languages. The 
best way to do this is by supporting language-specific research communities, who can 
promote the virtuous cycle of collecting data, curating datasets, training language",N/A,N/A
"models, publishing, and building applications. Local language speakers and context 
experts need to be part of each step of this process and also be curating the data and 
assessing the language models deployed by large, global online services.
Finally, governments need to be careful about how they use or encourage the use of 
large language models. Large language models should never power systems used to make",N/A,N/A
"high-stakes decisions without oversight, such as decisions about immigration status or 
healthcare, nor should governments mandate or inadvertently require by law the use of 
large language model-powered systems to moderate content from online services. Instead, 
governments should convene different stakeholders to align on what norms and guardrails 
should be around developing and deploying large language models.
Large language models in general and multilingual language models in particular",N/A,N/A
"have the potential to create new economic opportunities and improve the web for 
all. However, mis- or over-application of these technologies poses real threats to 
individuals’ rights, such as undermining their right to free expression by inaccurately 
taking down a person’s post on social media or their right to be free of discrimination 
by misinterpreting an individual’s job or visa application. Multilingual language",N/A,N/A
"models specifically can inadvertently further entrench the Anglocentrism they are 
intended to address. In light of these limitations, technology companies, researchers, 
and governments must consider potential human and civil rights risks when studying, 
procuring, developing, or using multilingual language models to power systems, in 
particular when they are used to make critical information available or play a role",N/A,N/A
"in decisions affecting people’s access to economic opportunities, liberty, or other 
important interests or rights.
Executive Summary
Lost in Translation
CDT Research
8
Introduction
D
espite the modern internet’s power to mobilize and connect 
people around the world, the web still does not reflect the 
linguistic diversity of its users. In particular, the automated 
systems that increasingly mediate our interactions online — 
such as chatbots, search engines, and content moderation systems —",N/A,N/A
"are built using and perform far better on English-language text than 
the world’s other 7,000 languages (Kornai, 2013; Sengupta, 2022). 
Individuals speaking languages other than English face barriers to 
expressing themselves freely online and may face greater challenges 
when it comes to accessing critical information, public services, and 
even asylum and safety (Torbati, 2019).
In the last few years, however, there have been rapid advancements in",N/A,N/A
"developing machine learning tools that can analyze content in a wide 
variety of languages and across different domains. Large language 
models, machine learning tools trained on enormous amounts of text 
to recognize patterns in language, power many of these systems. Large 
language models already underlie translation apps, search autocomplete, 
and chatbots such as ChatGPT. They are known for being adaptable to 
many different language tasks, and today, researchers and technologists",N/A,N/A
"are constantly on the lookout for new applications and contexts 
in which to deploy them. Since the late 2010s, major U.S.-based 
technology companies have mostly invested in building large language 
models that work primarily for English, such as Open AI’s GPT-4, 
Meta’s LLaMa, and Google’s PaLM.
Recently, companies and researchers have begun building and researching 
multilingual language models, large language models trained on text",N/A,N/A
"data from several different languages at once. Meta’s XLM-RoBERTa 
(XLM-R) for instance is trained on text from 100 languages (Meta AI, 
2019) at once. Google’s mBERT, a multilingual version of its popular 
BERT model, is trained on 104 languages. Researchers claim that these 
models extend the multifaceted capabilities of large language models to 
languages other than English, even to languages for which there is little or 
no text data for the model to learn from (Artetxe & Schwenk, 2019; Wu",N/A,N/A
"& Dredze, 2019).
Technology companies have their own interests in improving how 
well large language models work in different languages. Some may 
want to make their products available in multiple languages to gain a 
competitive edge in emerging and populous markets. Online services 
Large Language Models in Non-English Content Analysis
9
that host user-generated content may especially be interested in using multilingual",N/A,N/A
"language models to detect and take action on hate speech, disinformation, and other 
content that violates their policies or the law (Dulhanty et al., 2019). This is top of 
mind for services after facing criticism for not taking more aggressive action against 
content that incited violence and genocide in Ethiopia, Nigeria, and Myanmar, among 
others. Services have begun to deploy multilingual language models into their content",N/A,N/A
"moderation systems: Meta claims their XLM-R model can detect harmful content 
in all 100 languages it is trained on (Meta AI, 2021); Alphabet’s Perspective API uses 
a large language model to detect toxic content in eighteen different languages (Lees 
et al., 2022); Bumble uses one to detect rude and abusive messages in at least fifteen 
languages (Belloni, 2021). Technology companies are also repurposing these models to",N/A,N/A
"make health care information available and soon may reach into other domains as well 
(Lunden, 2023).
In the future, governments could also seek to use automated systems built using 
large language models to make information available, answer questions in languages 
spoken by their constituents (in the form of chatbots), or, more dangerously, analyze 
information to make critical decisions such as benefits allocation or refugee status 
determinations (Kinchin & Mougouei, 2022).",N/A,N/A
"determinations (Kinchin & Mougouei, 2022).
Still, studies show that even multilingual language models struggle to deal with the 
wide disparities between different languages in how much text data they have available 
to train and test language models. English has, by multiple orders of magnitude, more 
text data available than any other language and commands most of the attention of the 
natural language processing research community. The abundance of English language",N/A,N/A
"data stems from its position as the official or de facto language of international business, 
politics, and media, itself a legacy of British colonialism and American neocolonialism 
and the subsequent erasure of regional and indigenous languages. American technology 
companies have further entrenched English as the predominant language of the internet 
by rolling out early standards, coding languages, and social media platforms in English 
long before other languages.",N/A,N/A
"long before other languages.
The hegemony of English data means that most large language models, even 
multilingual ones, are built predominantly using Standard English language text and 
work best in Standard English language contexts. Spanish, Chinese, Arabic, and a few 
other “high resource” languages also have significant amounts of text data available, but 
many “medium resource” languages, such as Hindi and Portuguese, and “low resource”",N/A,N/A
"languages, such as Haitian Creole and Swahili, have hardly any data available at all, and 
multilingual language models perform much worse in those languages. This skewed 
emphasis fails to reflect the diversity of languages spoken by the world’s internet users 
and further perpetuates the dominance of the English language.
Introduction
Lost in Translation
CDT Research
10
Despite being deployed in real-world systems, multilingual language models have largely",N/A,N/A
"been absent from public discourse, particularly about digital rights and public policy, 
and have instead been relegated to computer science academia and tech company public 
relations. This paper seeks to address this gap by offering several resources to bolster 
policy discussions. Part I provides a simple technical explanation of how large language 
models work in general, why there is a gap in available data between English and other",N/A,N/A
"languages, and how multilingual language models attempt to bridge that gap. Part II 
accounts for the challenges of doing content analysis with large language models in 
general and multilingual language models in particular, namely:
1.	 Multilingual language models often rely on machine-translated text that can 
contain errors or terms native language speakers don’t actually use. 
2.	 When multilingual language models fail, their problems are hard to identify, 
diagnose, and fix.",N/A,N/A
"diagnose, and fix.
3.	 Multilingual language models do not and cannot work equally well in all languages.
4.	 Multilingual language models fail to account for the contexts of local language 
speakers.
Finally, Part III provides recommendations for companies, researchers, and 
policymakers to keep in mind when considering studying, developing, and deploying 
large and multilingual language models to do content analysis. These recommendations",N/A,N/A
"offer guidance concerning when large language models should or should not be 
deployed, how to improve their performance in non-English languages, and how to 
ensure better accountability and transparency to local language stakeholders.
Before proceeding, two notes on the terminology used in this primer. First, this paper 
focuses specifically on one category of applications for large language models: content 
analysis, or, the inference and extraction of information, themes, and concepts from",N/A,N/A
"text. The Center for Democracy & Technology (CDT) has written many times about 
the limitations of automated content analysis systems (Duarte et al., 2017; Shenkman 
et al., 2021) and the civil liberty risks they can pose, particularly in areas such as content 
moderation, student activity monitoring, hiring and more (Grant-Chapman et al., 
2021; Nicholas, 2022; Vallee & Duarte, 2019). Large language models are already deeply",N/A,N/A
"integrated into many of these technical systems, particularly content moderation, and will 
soon become part of many more. Public discourse about large language models has so far 
disproportionately focused on text generation, an important area but not the only one. 
Many of the shortcomings of large language models presented in this report also apply 
to text generation. As such, this report can be read as a primer on some of the limits of",N/A,N/A
"generative AI systems as well. However, we choose to focus on content analysis for this 
report because of the potential dangers associated with using these models to host and 
make information available and the impacts on free expression rights.
Large Language Models in Non-English Content Analysis
11
Second, this paper focuses on how multilingual language models perform in languages 
other than English. We use the shorthand of “non-English languages” for easy reading",N/A,N/A
"and because it is the terminology used in the machine learning and policy literature. 
We recognize the irony that this term centers the English language and misleadingly 
implies all other languages are a monolith. Where possible, we elaborate upon the types 
of languages we are writing about and make distinct references to specific languages and 
cultural contexts that will elude models trained primarily in English. In some instances,",N/A,N/A
"we think the term “non-English” captures the sheer Anglocentrism of many of these 
models well by articulating the limited scope in which they are trained and tested.
Introduction
Lost in Translation
CDT Research
12
I. Background
A. How Large Language Models Work
Natural language processing (NLP) is a subfield of artificial intelligence 
and linguistics concerned with building computer systems that can 
process and analyze language. NLP underlies many technologies we",N/A,N/A
"encounter every day — spellcheck, voice assistants like Siri or Alexa, 
resume scanners, language translators, and automated hate speech 
detection tools, to name a few. Until only a few years ago, when 
technologists wanted to teach a computer to perform a given NLP task, 
they would build a system specifically tailored to that task. To create a 
spam detection system for instance, a technologist might gather many 
emails, mark which ones are and are not spam, use some of those emails to",N/A,N/A
"train an algorithm and use others to test how well that algorithm works.
Today though, the field has fundamentally reoriented itself around 
repurposing large language models to solve nearly every problem. 
A language model is a mathematical function trained to solve a text 
prediction task like the following, “Given a sequence of words, predict 
what word will likely come next.” For example, a language model might be 
given the phrase “I was a bad student, I used to skip ____,” and generate",N/A,N/A
"as an output that there is a high percent chance the missing word is 
“class,” a low percent it is “rope,” and a near zero percent it is “clamoring.”
The distribution of language that the model learns in the process can 
easily be repurposed to many different language tasks. The most often 
discussed application is text generation: conversational agents like 
ChatGPT can repurpose this text prediction task to answer questions, 
summarize text, and generate overall “human”-sounding speech.",N/A,N/A
"However, chatbots are just one application of large language models. 
Once a large language model is built, it can be further trained on a 
smaller dataset to improve its performance in a specific task, a process 
called fine-tuning. Today, for example, a developer building a spam 
detection system might take a general large language model already 
built by someone else — say Google’s BERT — and fine-tune it to the 
specific task of spam detection using a handful of emails already labeled",N/A,N/A
"spam or not spam. By building it on top of a language model, the spam 
detection system will do a better job of detecting spam that doesn’t 
perfectly match the language available in the email dataset.
Language models are not new. Computational linguists have used 
statistical models to try to infer rules about language since the 1980s 
(Nadkarni et al., 2011) and have used “neural networks” (an algorithm 
loosely modeled on how neurons connect in the brain) to do so since",N/A,N/A
"the early 2010s (Mikolov et al., 2013). What is new though is their 
Large Language Models in Non-English Content Analysis
13
largeness. Early language models could not be trained on as much data, since they had 
to read text in sequence, a process that could not be sped up by using more computing 
power. These early language models struggled to analyze words within the broader 
context of a sentence or document: for instance, one fine-tuned to detect suicidal",N/A,N/A
"ideation might have difficulty distinguishing between expressions of self-harm (“I 
just wish I was dead”) and humor (“omg I’m dead”). But in 2017, Google researchers 
released a paper on a new architecture called transformers, which allowed language 
models to train on lots of data at the same time, in parallel rather than in sequence 
(Vaswani et al., 2017). These transformer-based language models could ingest so much",N/A,N/A
"data simultaneously that they could learn associations between entire sequences of 
words, not just individual words. Instead of being shown just {“dead”}, the model 
would see a word in its entire context, {“dead”, [“omg”, “I’m”, “_____”]}, thus creating 
a much richer representation of language. Today, the only limit on the size of a language 
model — how much data it ingests and how many connections it makes between",N/A,N/A
"different sequences of words (i.e. parameters) — is how much data one can find and 
how much developers are willing to spend on processing power.
The output a language model produces is called a representation space, a map of the 
sequences of words that commonly appear near one another in the training text. For 
example, the phrases “It’s so cold outside!” and “I better wear a jacket” may be near one 
another in a language model’s representation space, since those sentences often appear",N/A,N/A
"close to one another in writing. This kind of proximity can lead to language models 
inferring patterns within language that can then help them conduct tasks that it is not 
explicitly trained in. In this case, sentences about cold weather being mapped near each 
other mean the large language model could be trained to detect whether a given phrase 
is about temperature.
With enough data, a large language model may have such a rich and multifaceted",N/A,N/A
"representation of a language that it can learn to do new tasks with only a few, or even 
zero examples to fine-tune on. For instance, the spam detection system described earlier 
could be built with little to no spam to fine-tune on. This capability is called “few-shot” 
or “zero-shot learning” and is one of the greatest promises of large language models, so 
much so that the original GPT-3 white paper is entitled “Language Models are Few-
Shot Learners” (Brown et al., 2020).",N/A,N/A
"Shot Learners” (Brown et al., 2020).
Importantly though, large language models only learn the distribution of language, not 
its meaning (Bender & Koller, 2020). In the previous “cold” example, the model has not 
learned that when one is cold, one puts on a jacket or anything about the deeper meanings 
of “cold” and “jacket,” only that the words often appear near one another. If one of the 
documents a large language model trains on is a humorous blogpost about the best shorts",N/A,N/A
"to wear in cold temperatures, the model could just as easily learn that “shorts” and “cold” 
are related. Similarly, if a model is trained only on very formal language data, it may never 
learn that “nippy” or “brick” (New York City slang) can refer to cold as well.
I. Background
Lost in Translation
14
Technologists often try to address these shortcomings by training language models 
on more and more data. If a model is exposed to more data, the idea is that it will be",N/A,N/A
"familiar with more contexts, and outliers like the ironic cold-weather shorts blogpost 
will be outweighed by more representative data. This has led to ballooning in the size 
of large language models. BERT, a popular open-source model built by Google in 
2018, was trained on 800 million words from free books and 2.5 billion words from 
English Wikipedia (Devlin et al., 2019). Two years later, OpenAI released its closed",N/A,N/A
"source GPT-3, which was trained on half a trillion mostly-English words crawled from 
the internet (Brown et al., 2020). Google’s PaLM, released in 2022, trained on 780 
billion words, mostly from English-language websites and social media conversations 
(Chowdhery et al., 2022). As models have grown in size, so have the computation costs 
of training them. While BERT costs a few thousand dollars in computing power to",N/A,N/A
"train from scratch and is often trained by academics to build new topic- or language-
specific models (Izsak et al., 2021), GPT-3 and PaLM-sized models cost millions or 
tens of millions of dollars to train (Sharir et al., 2020). Future models will only be 
more expensive, leaving only the most well-off companies able to afford to build them 
(Bommasani et al., 2021).
Figure 1. Language model 
representation space. A langauge model’s 
reprsentation space, collapsed into two",N/A,N/A
"reprsentation space, collapsed into two 
dimensions. In reality, these models often 
have thousands or tens of thousands of 
dimensions.
Source: (Amer, 2022)
Lost in Translation
14
When is 
Boxing Day?
What is the date 
of Boxing Day?
How many species 
of sharks are there?
How many species of the 
Great White shark are there?
It’s so cold 
outside!
I better wear 
a jacket.
Large Language Models in Non-English Content Analysis
15",N/A,N/A
"15
Models are expensive to initially train, but once built, their representations are relatively 
cheap to use and be fine-tuned for different tasks. Thus, many technologists simply 
use pretrained large language models built by others (usually large companies, with the 
expertise and resources) instead of paying to create their own. The few big pretrained 
models that exist have thus become a sort of infrastructure, known as “foundation",N/A,N/A
"models” (Bommasani et al., 2021). This gives many technologists access to the state of 
the art capabilities, but it also creates a single point of failure for the sector as a whole: 
if a foundation model has a problem, it will persist across many applications. And these 
models are so large and complicated that even when they are open source, researchers 
cannot understand the underlying logic they use to come up with individual decisions.",N/A,N/A
"Many of the largest and most advanced of these foundation models — such as 
OpenAI’s GPT-4, Google’s PaLM, and Meta’s LLaMa — are trained primarily on 
English language data. In the next section, we explore one reason why that may be: the 
resourcedness gap.
B. The Resourcedness Gap: Why the Largest 
Language Models are in English
English is the closest thing there is to a global lingua franca. It is the dominant language",N/A,N/A
"in science, popular culture, higher education, international politics, and global 
capitalism; it has the most total speakers and the third-most first-language speakers 
(Ethnologue, 2023b). It is the primary language spoken on the internet, accounting 
for 63.7% of websites, despite being spoken by only 16% of the world’s population 
(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic",N/A,N/A
"superiority: rather it is the colonial and neocolonial legacy of nearly three hundred 
years of the preeminent global superpower speaking English — first Great Britain, 
then the United States. The British government prioritized the English language 
through official language policies to facilitate trade and in an attempt to “modernize” 
its colonies, and as British, and later American trade became globally dominant, so too",N/A,N/A
"did English (Corradi, 2017; Phillipson, 1992). Prioritization of the English language 
came at the expense of other regional and indigenous languages and accelerated 
language endangerment and economic marginalization, which still impedes digital 
investment into these languages worldwide (Rowe, 2022; S. Zhang et al., 2022). 
American companies continue to perpetuate the dominance of the English language in 
a new more insidious form, by making online services available to global users without",N/A,N/A
"comparable investment into the languages they speak (Amrute et al., 2022; Kupfer & 
Muyumba, 2022).
I. Background
Lost in Translation
CDT Research
16
As a result of these forces, English also dominates the field of natural language 
processing, and there is vastly more raw text data available in English than in any other 
language by orders of magnitude (Joshi et al., 2020). English has the most digitized 
books and patents, the largest Wikipedia, and the biggest internet presence. English is",N/A,N/A
"also by far the language paid the most attention by the global NLP research community. 
It is so hegemonic within the field that NLP papers about the English language 
typically do not even mention the language in the title or abstract (Bender, 2019). As 
Figure 2 shows, even among NLP papers that do mention a language in the abstract, 
English is mentioned over ten times as often as the next most mentioned language, 
German (ACL Rolling Review Dashboard, 2022).",N/A,N/A
"German (ACL Rolling Review Dashboard, 2022).
This wealth of data and research makes it significantly easier to build large language 
models in English than in any other language. More raw text data, also known as 
unlabeled data, means more data for the model to be trained on; more research means 
that there are more datasets annotated with information, also known as labeled data, 
that can be used to test how well models complete different types of language tasks.",N/A,N/A
"This creates a virtuous cycle for English-language NLP — more labeled and unlabeled 
data leads to more research attention, which leads to increased demand for labeled and 
unlabeled data, and so on.
English is the prime example of a high resource language, a language for which a lot of 
high-quality data resources exist. Though it has the most data available of any language 
(English could be called an “extremely” high resource language), there are six other",N/A,N/A
"languages that could be considered high resource — the official UN languages list, 
minus Russian, plus Japanese (see Table 1). There are also a few dozen medium resource 
languages, such as Urdu, Italian, and Tagalog, with another one or two orders of 
magnitude less data, or about one hundredth or one-thousandth of available English data. 
The rest of the world’s 6,000 plus languages can be considered low resource or extremely",N/A,N/A
"low resource, with only small amounts of written text available (Joshi et al., 2020).
Resourcedness can vary within languages as well. Languages such as Arabic and Spanish 
differ so much between dialects that many are mutually incomprehensible, even if 
they mostly use the same written form. Languages can also have different sociolects, 
varying across different social groups, identity groups, and contexts (e.g. formal versus",N/A,N/A
"informal). Regional dialects and sociolects can vary in degrees of difference from 
having different vocabulary and grammatical structures (e.g. Australian English or 
African American English versus Standard American English) to make extensive use of 
borrowed words from other languages (e.g. Nigerian English, Indian English), to fully 
hybrid bilingual dialects (e.g. Spanglish, Hinglish). However, the available digitized",N/A,N/A
"text of language often doesn’t reflect the full spectrum of variation that exists within a 
language. (Bergman & Diab, 2022). Data scraped from the internet in particular over-
indexes Standard English spoken by younger people in developed countries (Luccioni 
& Viviano, 2021). Other languages have just as much dialectical diversity as English and 
also likely over-index on certain dialects.
Large Language Models in Non-English Content Analysis
17
Figure 2. Languages mentioned in",N/A,N/A
"17
Figure 2. Languages mentioned in 
paper abstracts. Top most mentioned 
languages in abstracts of papers published 
by the Association for Computational 
Linguistics, May 2022-January 2023.
Source: (Santy et al., 2023)
Paper Abstracts
Languages with less data available also often have lower quality data available, either 
because it is mislabeled or otherwise not representative of how people actually speak 
the language. This is particularly true with web-crawled data, a key data source for",N/A,N/A
"large language models (Khan & Hanna, 2023). Non-English language data scraped 
from the internet is more often machine translated, scanned from an image, or both, 
and each of those processes introduces opportunities for error (Dodge et al., 2021). 
Low- and medium-resource language data on the internet is more often pornographic, 
nonsensical, or non-linguistic content (Kreutzer et al., 2022). It is also often labeled as",N/A,N/A
"the incorrect language – around 95% of the time for many low resource languages – 
because automatic language identification works much more poorly with insufficient 
data, thus creating a circular problem (Caswell et al., 2020). Languages with the worst 
quality web data are disproportionately those written in non-Latin scripts (e.g. Urdu, 
Japanese, Arabic) and those spoken in the Global South (e.g. African languages,",N/A,N/A
"minority languages in the Middle East, non-Mandarin Chinese languages) (Kreutzer et 
al., 2022).
17
0
200
300
100
English
Korean
Indonesian
Thai
French
Greek
Turkish
Finnish
German
Spanish
Swahili
Classical Chinese
Hindi
Hebrew
Polish
Italian
Kinyarwanda
Arabic
Russian
Talugu
Dutch
Japanese
Vietnamese
Portuguese
Latin
Marathi
311
27
18
16
16
16
16
13
10
7
7
7
6
5
5
5
4
4
4
4
4
3
3
3
3
3
I. Background
Lost in Translation
CDT Research
18",N/A,N/A
"I. Background
Lost in Translation
CDT Research
18
Low resource languages also tend to have data that comes from a less diverse set of 
sources. The clean data that does exist often comes from places such as Wikipedia, the 
Bible, and parliamentary proceedings, particularly in large language models that depend 
on drawing parallels between low and high resource languages (see III.B and III.C) 
(Nekoto et al., 2020). None of these data sources is representative of a language as a",N/A,N/A
"whole. For example, there is a significant gender gap when it comes to who contributes 
to Wikipedia, with studies finding that the percentage of women who edit Wikipedia 
articles remains “dismally low” (Callahan & Herring, 2011; Vitulli, 2018), and it 
doesn’t reflect a more casual style of speech. Some text on Wikipedia is also machine-
translated — Cebuano, Swedish, and Waray for instance are some of the Wikipedia",N/A,N/A
"languages with the most articles, but most are translated by the same bot (Lokhov, 
2021). The Bible is similarly its own unique domain, unrepresentative of language at 
large, but is overrepresented in the training data for non-English large language models. 
This can lead to errors in the tone and substance of language. For example, for a period 
of time, running a word repeated enough times through Google translate produced a",N/A,N/A
"religious-sounding text: the word “dog” pasted two dozen times and translated from 
Maori to English produced text about Jesus’ return at the end of days (Christian, 2018).
The resourcedness of a language is often out of sync with the number of speakers or 
internet users that language has. Hindi, Bengali, and Indonesian are medium-resource 
languages yet each has hundreds of millions of speakers (Joshi et al., 2020). Guaraní,",N/A,N/A
"an Indigenous language spoken by most of the ~7 million-person population of 
Paraguay, hardly has any data resources at all (Góngora et al., 2021). Fula, a language 
spoken by tens of millions of West Africans, also has few data sets (Nguer et al., 2020). 
Despite over 600 million internet users across the African continent, nearly all African 
languages remain low-resourced.
Table 1. Categories of language 
resourcedness. Languages divided into 
different levels of resourcedness, according",N/A,N/A
"different levels of resourcedness, according 
to labeled and unlabeled datasets available 
as of 2020.
Source: (Joshi et al., 2020)
Resourcedness
Languages
Number of Languages
Number of Speakers
Extremely High Resource
English
1
1.1B
High Resource
Arabic, French, Japanese, German, 
Spanish, Mandarin
6
2.7B
Medium Resource
Dutch, Vietnamese, Korean, 
Portuguese, Hindi, Slovak, Hebrew, 
Indonesian, Afrikaans, Bengali, etc.
Dozens
2.7B
Low Resource
Haitian Creole, Tigrinya, Swahili,",N/A,N/A
"Low Resource
Haitian Creole, Tigrinya, Swahili, 
Bavarian, Cherokee, Zulu, Burmese, 
Telugu, Maltese, Amharic, etc.
Hundreds
0.5B
Extremely Low Resource
Dahalo, Warlpiri, Popoloca, 
Wallisian, Bora, etc.
Thousands
1.1B
Lost in Translation
18
Large Language Models in Non-English Content Analysis
19
Many scholars have worked to try to close this resourcedness gap between high and low 
resource languages. Individual NLP communities have formed around many languages in",N/A,N/A
"order to kickstart and perpetuate the virtuous cycle of research attention and benchmark 
development, including collectives such as IndoNLP for languages spoken in Indonesia 
and Masakhane for African languages (Cahyawijaya et al., 2022; Nekoto et al., 2020; Orife 
et al., 2020), and conferences such as the Association for Computational Linguistics’ 
low resource language track, and AmericasNLP for indigenous languages (ACL, 2021;",N/A,N/A
"AmericasNLP, 2022; Masakhane, n.d.). Tech companies have also sought to expand the 
number of language models their models work in, in part by creating more data sets, 
including with projects like Facebook’s No Language Left Behind project and Google’s 
1000 Languages Initiative (NLLB Team et al., 2022; Vincent, 2022). DARPA even 
funded the Low Resource Languages for Emergent Incidents (LORELEI) program in 
2014 to improve translation about emergency incidents into low resource languages",N/A,N/A
"(Corvey, 2014). But the gaps between English, other high resource languages, and low 
resource languages remain large and are growing exponentially greater by the day, at least 
in terms of available, raw digitized data.
The response by the NLP community has not just been to collect more language 
data but also to employ technical tricks to help language models squeeze the most 
performance out of the little data they have. In the next section, we discuss the primary",N/A,N/A
"technical architecture developers use to do this: multilingual language models.
C. Multilingual Language Models: Efforts to 
Bridge the Resourcedness Gap
In English, most large language models are monolingual, meaning that they train mostly 
on data from one language. Researchers have also built monolingual models in non-
English languages: for instance, the architecture for Google’s BERT model — one of 
the most popular and cheapest to train — has been utilized for French (CamemBERT),",N/A,N/A
"Italian (AlBERTo), Arabic (AraBERT), Dutch (BERTje), Basque (BERTeus), Maltese 
(BERTu), and Swahili (SwahBERT), to name a few (Agerri et al., 2020; Antoun et al., 
2020; de Vries et al., 2019; G. Martin et al., 2022; L. Martin et al., 2020; Micallef et al., 
2022; Polignano et al., 2019). However, in general, these monolingual models perform 
worse in their respective languages than the best English models do in English because 
they don’t have as much data to train on.",N/A,N/A
"they don’t have as much data to train on.
This lack of data manifests in different ways depending on the specific task a model is 
fine-tuned to perform. Some language model capabilities — usually ones that depend 
on fact retrieval — improve linearly with size. For instance, the more data a language 
model is exposed to, the better it is at answering trivia questions or reformatting 
data (Srivastava et al., 2022). Other capabilities — usually ones with multiple steps 
I. Background",N/A,N/A
"I. Background
Lost in Translation
CDT Research
20
or components — exhibit a “breakthrough” behavior, where once a model reaches a 
certain size, it improves sharply at the task. For instance, language models typically are 
unable to write code or add three digit numbers until they train on a certain amount 
of data, at which point their performance improves dramatically (Ganguli et al., 2022). 
Low and extremely low resource languages often do not have enough data to train a",N/A,N/A
"large language model at all, but medium and even high resource languages may not 
have the hundreds of millions, or billions of words of text data necessary to achieve the 
breakthroughs that English can (Y. Zhang et al., 2021).
Besides technical limitations, companies may not be interested in deploying a different 
monolingual model for every language their product is available in for business reasons 
as well. Maintaining and debugging one large language model for each language",N/A,N/A
"introduces costs that scale per language introduced, introducing complexity and 
additional overhead costs. Companies that seek to expand into new global markets 
will likely try to keep their costs fixed by reusing as much infrastructure as possible, 
including language models.
Therefore, instead of using monolingual models to do NLP tasks in non-English 
languages, researchers and developers most often use multilingual language models,",N/A,N/A
"such as Google’s mBERT and Meta’s XLM-R, which are trained on texts from 
many different languages at once. Like their monolingual counterparts, multilingual 
language models are trained on a fill-in-the-blank task. However, by training on text 
from several different languages, multilingual language models can, at least in theory, 
infer connections between languages, acting as a sort of bridge between high and low 
resource languages, allowing the former to bootstrap the latter.",N/A,N/A
"For instance, imagine that an Indian climate change researcher wants to use a language 
model to collect all Hindi-language tweets about the weather. A monolingual language 
model trained on just Hindi text may not have enough data to have seen the words 
“thaand” (“cold” in Hindi) and “shaal” or (“shawl” in Hindi) appear near one another 
in text, so it may miss that tweets to the effect of “Main Agast mein shaal pahanta",N/A,N/A
"hoon” (“I put a shawl on in August”) is a sentence about cold weather.1 A multilingual 
model, trained on data from English, Hindi, and many other languages may have seen 
text where “thaand” appears near “cold,” “shaal” appears near “shawl,” and “cold” 
appears near “shawl,” thereby allowing the model to infer that “thaand” and “shaal” are 
interrelated terms.
Multilingual language models are usually not trained on equal volumes of data from",N/A,N/A
"each language: mBERT for instance is trained on 15.5 GB of English text but as little 
as 10 MB of Yoruba text (Wu & Dredze, 2020). Even BLOOM, a popular multilingual 
model by BigScience with a particular focus on language representation, has 30% of its 
1	  Transliterated into Roman script for ease of reading for an English-language reader.
Large Language Models in Non-English Content Analysis
21
Figure 3. Monolingual vs multilingual 
language model representation",N/A,N/A
"language model representation 
space. A visualization of a monolingual 
and a multilingual langauge model’s 
representation space, collapsed into three 
dimensions.
Source: (Schwenk, 2019) 
training text in English (BigScience Workshop et al., 2023). In large part, this is because 
of the lack of available data in these languages, which come disproportionately from 
Wikipedia and religious texts, as discussed earlier (see Part I.C).",N/A,N/A
"Just as a monolingual language model can be fine-tuned to work better on an individual 
task, a multilingual language model can be fine-tuned to work better in an individual 
language. Imagine for instance a developer who wants to use a multilingual language 
model to detect Indonesian election disinformation on social media. One way they 
could do it is by using an out-of-the-box multilingual model, such as BLOOM, and",N/A,N/A
"fine-tuning it by showing examples of false narratives circulated in Indonesian related 
to the local election. This likely would not work very well though, since BLOOM has 
only been exposed to a limited amount of data on Indonesian text — only 1.2% of its 
training data is in Indonesian (BigScience Workshop et al., 2023). Another better way 
to do it, if the developer has access to more Indonesian language data, would be first to",N/A,N/A
"fine-tune the model on additional Indonesian text (essentially, continuing to learn the 
fill-in-the-missing-word task, but this time just in Indonesian) and then further fine-
tuning it on the task election disinfo detection using that dataset.
Model developers though do not always have enough text data to sufficiently fine-
tune a multilingual model to work in a specific language. To make up for this, they 
often use imperfect machine-translated text. The two main methods of incorporating",N/A,N/A
"translated text are called translate-train or translate-test methods. With translate-train, 
a multilingual language model is fine-tuned on data that has been translated from 
(usually) English into a desired lower resource language (Conneau & Lample, 2019). 
With translate-test, a (usually) English monolingual language model is fine-tuned 
on data translated from the desired language into English, and all testing data gets 
translated into English as well (Artetxe, Labaka, et al., 2020).",N/A,N/A
"I. Background
21
The tree is green.
The tree is green.
El árbol es verde.
Monolingual model
It is cold today.
Multlingual model
I put on a shawl.
I like to sing. 
I like to sing. 
J’aime chanter. 
Aaj bohut thaand hai.
Main ek shaal pahanta hoon.
I put on a shawl.
It is cold today.
Lost in Translation
CDT Research
22
Imagine, for example, a developer building a language model to detect terrorist content 
in the Basque language with a handful of examples of terrorist content in Basque",N/A,N/A
"but not enough Basque text data to properly fine-tune a language model. With the 
translate-train approach, a developer would take a large volume of English text data, 
machine translate it into Basque, use that data to fine-tune a pretrained multilingual 
language model, and then further fine-tune it to the task of terrorist content detection 
using the native Basque data. With translate-test, a developer would fine-tune a",N/A,N/A
"pretrained English language model on data translated from Basque to English, and 
then further fine-tune it by translating the terrorist content data they have into English. 
Subsequently, to analyze Basque text, it would first have to be translated into English 
before being evaluated by the model. Reliance on translated data raises many concerns, 
as discussed in Part II.C.1.
However, translated texts can help multilingual language models learn connections",N/A,N/A
"between languages. By feeding a model parallel texts — for instance, explicitly 
informing it that “baahar bohut thand hai” and “It’s so cold outside” have the same 
meaning — it can better extrapolate other language parallels as well (e.g. NLLB Team et 
al., 2022; Reid & Artetxe, 2022). Multilingual language models can learn connections 
between languages without explicit labeling, instead inferring relationships between",N/A,N/A
"languages on its own through borrowed words, numbers, and URLs (Pires et al., 2019). 
In general, NLP researchers understand little about why it is that multilingual language 
models can be effectively fine-tuned to work in languages that they have relatively little 
data for (Conneau, Khandelwal, et al., 2020; Pires et al., 2019; Wu & Dredze, 2019). 
Some argue that it is because multilingual language models have inferred language-",N/A,N/A
"agnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder, 
et al., 2020; Chi et al., 2020; Conneau, Wu, et al., 2020; Tsvetkov et al., 2016). Others 
say that multilingual language models are just effective imitators (Bender et al., 2021; 
Lauscher et al., 2020). The debate is impossible to fully resolve because of the overall 
complexity and opacity of large language models, but so far evidence suggests that at",N/A,N/A
"best, the linguistic universals they learn are limited to narrow semantic and syntactic 
domains (Libovický et al., 2019; Wu & Dredze, 2019), such as learning plural/singular 
verb agreement across multiple languages (de Varda & Marelli, 2023). But even if a model 
can infer syntactic or semantic commonalities between languages, such inferences will 
not necessarily help it manage more complex, context-dependent tasks (Choi et al., 2021).",N/A,N/A
"For instance, in some languages, multilingual language models do no better than random 
guessing at detecting hate speech (Lin et al., 2022). As will be discussed in the next section, 
these are hardly the only limits of multilingual language models.
23
Lost in Translation
II. Limitations of 
Language Models 
in English and Non-
English Contexts T
he press, technology companies, and social media are abuzz 
about the potential of large language models. In this section,",N/A,N/A
"however, we discuss the shortcomings of these models, 
particularly as they operate in non-English language contexts. 
In the first section, we discuss general concerns with building and 
deploying large language models. These concerns apply both to the 
English and non-English contexts. In the second section, we look at the 
problems more specifically raised by multilingual language models.
A. Concerns with Building and 
Deploying Large Language Models
1. LARGE LANGUAGE MODELS ARE BOUND BY",N/A,N/A
"1. LARGE LANGUAGE MODELS ARE BOUND BY 
LANGUAGE THEY HAVE SEEN BEFORE AND STRUGGLE 
TO PERFORM IN NEW CONTEXTS.
A large language model does not understand language; instead, it makes 
probabilistic inferences about text based on the distribution of language 
within the data it is trained on. Bender and Koller argue that this means 
language models are limited to contexts they have encountered before 
and struggle greatly in those they have not (2020). NLP researchers have",N/A,N/A
"already proven this is the case in generative AI by demonstrating several 
unintuitive outcomes: for instance, language models are better able to 
perform mathematical operations with numbers that appear frequently 
in written language (e.g., multiplying numbers by 24), than numbers 
that appear infrequently (e.g. multiplying numbers by 23) (Razeghi 
et al., 2022). Large language models may exhibit similar limitations in 
content analysis as well. For instance, if a large language model were",N/A,N/A
"used to analyze a candidate’s resume, it may struggle to account for 
lesser-known companies or newer skill sets without up-to-date, domain-
specific data to fine-tune on. These tasks are reliant on in-context 
knowledge and without domain-specific training, i.e. training an off-
the-shelf large language model with text relevant to the task at hand, 
these models are likely to perform poorly and their purported domain-
agnostic abilities should garner skepticism (Duarte et al., 2017).",N/A,N/A
"Lost in Translation
CDT Research
24
2. LARGE LANGUAGE MODELS REPRODUCE THE BIASES, VALUES, 
AND HARMS OF THE DATA THEY TRAIN ON.
Large language models are built using vast quantities of text scraped from the internet 
and exhibit all the biases and limitations of their data source (Okerlund et al., 2022). 
Some commonly used datasets, such as Common Crawl, include large volumes of 
hate speech and sexually explicit content (Luccioni & Viviano, 2021). Other problems",N/A,N/A
"are more nefarious. For example, researchers found that when GPT-3 generated 
completions for the prompt “Two Muslims walked into a___,” 66% of completions 
included violent language, three times more than for other religious groups (Abid et 
al., 2021). Others have found similar entrenched biases against people with disabilities, 
for example inferring negative sentiment from sentences that include disability-related 
terms (Hutchinson et al., 2020).",N/A,N/A
"terms (Hutchinson et al., 2020).
Though technologists often try to pull out explicitly harmful data from training 
sets, models can still reify harms, such as referring to “women doctors” or calling 
undocumented immigrants “illegals” (Bender et al., 2021). Removing these instances 
of harmful data from training datasets, which are disproportionately outsourced 
to underpaid staff around the world, also imposes labor and psychological burdens 
(Williams et al., 2022).",N/A,N/A
"(Williams et al., 2022). 
Even if datasets are rid of specific examples of harmful text, they will nonetheless 
contain values and assumptions that are encoded into the language we speak and the 
dominant perspectives that exist in many pieces of written text, particularly government 
documents or state-run media pieces that may make up the bulk of text available for 
low resource languages (Bender et al., 2021). Many machine learning researchers fail to",N/A,N/A
"consider these problems in their work — one study found that 98% of machine learning 
papers mention no negative potential of the technologies they are describing (Birhane 
et al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, “Feeding AI systems 
on the world’s beauty, ugliness, and cruelty, but expecting it to reflect only the beauty 
is a fantasy” (2021). When these problems exist in any particularly popular foundation",N/A,N/A
"model, they proliferate across many different applications built on top of that model.
3. THE DATA LARGE LANGUAGE MODELS TRAIN ON RAISE 
COPYRIGHT AND PRIVACY CONCERNS.
Legal experts also raise concerns about copyright and ownership of text that make up 
the vast quantities of data that train and distinguish large models (Ebers et al., 2022; 
Okerlund et al., 2022). Getty Images has sued the creators of Stable Diffusion, an AI",N/A,N/A
"tool that creates images based on written prompts, claiming that the toolscraped Getty’s 
databases of proprietary images and photos without permission (Vincent, 2023a). Legal 
questions about ownership of text and whether scraping proprietary text is lawful (e.g., 
because it constitutes fair use) or not remain unanswered (Kublik, n.d.).
Large Language Models in Non-English Content Analysis
25
II. Limitations of Language Models in English and Non-English Contexts",N/A,N/A
"Some datasets that large language models train on are likely to capture examples of 
language from sites such as social media, raising personal data privacy concerns. There 
is a high possibility that in gathering exchanges from social media networks, training 
datasets inadvertently contain private and even sensitive information, which increases 
the risk of models leaking details like names, phone numbers, or addresses from the data 
on which they’re trained (Carlini et al., 2021, 2023).",N/A,N/A
"4. TRAINING LARGE LANGUAGE MODELS COULD HAVE A 
SIGNIFICANT ENVIRONMENTAL IMPACT.
Finally, there are increasing concerns about the environmental cost of producing large 
language models. Scholars and advocates have raised concerns about the environmental 
impact of training these models, particularly the largest ones with billions of 
parameters, due to their intense computation requirements (Crawford, 2021; Okerlund",N/A,N/A
"et al., 2022). There is preliminary research attempting to quantify the energy impacts 
of computation at this scale (Kaack et al., 2022), but some early estimates suggest that 
training a single BERT model, one that serves as the foundation for some multilingual 
language models, requires as much energy as a trans-American flight (Strubell et al., 
2019). Large language models, like GPT-3, require thousands of times more (Heikkilä,",N/A,N/A
"2022). Png writes that these costs may be concentrated in poorer countries, where 
server farms and raw materials required to build necessary infrastructure are often 
located (2022).
B. Limitations of Multilingual Language Models
1. MULTILINGUAL LANGUAGE MODELS OFTEN RELY ON MACHINE-
TRANSLATED TEXT THAT CAN CONTAIN ERRORS OR TERMS NATIVE 
LANGUAGE SPEAKERS DON’T ACTUALLY USE.
Incorporating machine-translated data into the training and fine-tuning of multilingual",N/A,N/A
"language models creates various opportunities for the model to malfunction. 
Multilingual language models that depend on translation may struggle to build 
accurate representations of words or concepts which have different connotations in 
different languages. For instance, in English, “dove” is a term associated with peace, but 
its equivalent in Basque, “uso,” is an emasculating insult. A translation-based cross-",N/A,N/A
"lingual model that does not train on the word “uso” used in its native context could 
potentially fail to see it used in a call for violence since the English mapping is so closely 
associated with “peace.”
Lost in Translation
CDT Research
26
Another issue is what NLP practitioners call the “translationese” problem (Yu et al., 
2022) — that is, machine-translated language materially differs from how human",N/A,N/A
"native speakers naturally use language (Bizzoni et al., 2020; Teich, 2003). In generative 
AI, translationese can result in mono- or multilingual language models simplifying 
or overcomplicating sentences, producing repeated words, using too common or too 
uncommon words, borrowing too much or too little from the original language, and 
other patterns of speech native speakers would not use (Volansky et al., 2015). These",N/A,N/A
"mistakes are not consistent between languages or systems, so it would be difficult for 
models to be able to systematically root them out, though some argue that it is possible 
(Yu et al., 2022).
The problems of machine translation spread beyond models that intentionally train on 
it. The web is filled with machine-translated text, and models that train on web-scraped 
data will inadvertently encounter a lot of it, particularly in low resource languages",N/A,N/A
"(Kreutzer et al., 2022). For instance, a lot of the Catalan data that exists on the web, 
particularly on websites using the .cat top-level domain, is translated using Google 
Translate, even on official government websites (Pym et al., 2022). Even benchmarks to 
test how well multilingual language models work in high and low resource languages are 
often translated from another language, leaving researchers with less of a sense of how",N/A,N/A
"well these models work on language as spoken by native speakers. For instance, OpenAI 
tested GPT-4’s capabilities in 26 languages, but using only benchmarks translated from 
English (OpenAI, 2023).
2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE 
CONTEXTS OF LOCAL LANGUAGE SPEAKERS.
As discussed earlier, large language models only work well in contexts similar to 
contexts of the data they are trained on. A language model trained on legal texts,",N/A,N/A
"for instance, will perform much better on law-related tasks than medical tasks 
or interpreting the Quran (Koehn & Knowles, 2017). This poses a problem for 
multilingual language models, which, particularly in low resource languages, are trained 
on text that is translated from other language contexts or comes from a few distinctive 
contexts, such as Wikipedia and the Bible. Multilingual language models that are not",N/A,N/A
"trained on large volumes of text from native speakers of a given language will more 
often fail at tasks that require knowledge of an individual speaker’s local context, such 
as hate speech detection and resume scanning (Lin et al., 2022).
Imagine, for example, a multilingual language model fine-tuned to detect anti-
Muslim content in Assamese, a low-resource language with fifteen million speakers, 
predominantly in northeast India (Ethnologue, 2023a). Assamese and Bengali are both",N/A,N/A
"medium resource languages, so a multilingual model may draw connections between 
the two. However, anti-Muslim hate speech is very closely tied to historical events and 
the specific political conditions of Assam. For instance, the term “Bangladeshi Muslim,” 
Large Language Models in Non-English Content Analysis
27
II. Limitations of Language Models in English and Non-English Contexts
neutral in many other languages and contexts, is a hate speech dog whistle in Assamese",N/A,N/A
"because it casts Assamese Muslims as foreigners (a concept that is itself closely tied to the 
Indian government’s repatriation efforts) (Avaaz, 2019). A multilingual model neither 
trained on extensive native Assamese text nor explicitly trained by a language expert would 
likely not be able to capture this hyperlocal distinction.
Multilingual language models work by transferring between language contexts, but that",N/A,N/A
"transfer often means simply that the context of higher resource languages overwrites 
lower resource ones. Spanish, for instance, tends to use more adjectives and analogies 
describing extreme situations than English, so a sentiment detection algorithm that 
transfers linguistic properties over from English may mischaracterize Spanish text as 
having a stronger emotional valence than it would to a native speaker (Stadthagen-",N/A,N/A
"Gonzalez et al., 2017). This structure transfer can also bring the biases of a source 
language into a target language (Savoldi et al., 2021). For instance, if a language without 
gender pronouns, such as Hungarian or Yoruba, is mapped onto a language with 
gendered third-person pronouns, such as English or French, the language model could 
force gender associations and biases of the gendered language onto the non-gendered",N/A,N/A
"one, as often occurs in translation (Prates et al., 2020) (see Figure 4).
Figure 4. Google Translate from 
Hungarian to English. A screenshot of 
Google Translate, circa 2020, showing how 
the multilingual language models project 
gender onto genderless languages.
Source: (Prates et al., 2020)
27
Lost in Translation
CDT Research
28
3. MULTILINGUAL LANGUAGE MODELS DO NOT AND CANNOT WORK 
EQUALLY WELL IN ALL LANGUAGES.",N/A,N/A
"EQUALLY WELL IN ALL LANGUAGES.
Multilingual language models not only do not work equally well in all languages but 
they cannot, since the more languages a multilingual model is trained on, the less it 
can capture unique traits of any specific languages. This problem is called the curse 
of multilinguality (Lauscher et al., 2020). Large language model developers are thus 
forced to trade off performance between disparate languages; making a model work",N/A,N/A
"better in Hindi for example, may come at a cost to its performance in English. In 
practice, when technology companies must choose which languages to deprioritize 
within their multilingual language models, they may be incentivized to have them 
be languages where speakers tend to be less wealthy, have less political power, or live 
outside of the company’s priority markets, thus exacerbating the resourcedness gap they 
are designed to address.",N/A,N/A
"are designed to address.
In general, semantic and syntactic similarity to a high resource language protects 
from the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al. 
tested mBERT on languages it had not explicitly trained on before and found that it 
worked better in Swiss German (related to German, a high resource language), than 
it did in Estonian (a Uralic language, like medium resource languages Hungarian and",N/A,N/A
"Finnish), than it does Uyghur (a Turkic language, distant from any high or medium 
resource language, with four alphabets) (2021). In general, multilingual language 
models struggle with languages written in non-Latin scripts (Pires et al., 2019; Ruder 
et al., 2021), language isolates (languages etymologically distinct from all other 
languages, such as Basque), and families of languages less connected to those of high",N/A,N/A
"resource languages. This threatens to create a poor-get-poorer dynamic for languages 
that are only similar to other low resource languages, as is the case with many widely 
spoken African languages including Swahili, Amharic, and Kabyle (Joshi et al., 2020). 
This dynamic further strengthens the post-colonial structural inequality discussed 
throughout this report.
Multilingual language models are also forced to trade off between languages in the",N/A,N/A
"vocabulary they use. Large language models train on the problem of predicting the next 
word in a sentence. If a model is trying to guess the word to fill in “Today I feel ___,” it 
will have a harder time doing so if it has to choose between ten million possible words 
from any language instead of just a few hundred thousand English words. The total 
number of words a language model has to choose from is called its vocabulary size. The",N/A,N/A
"larger a model’s vocabulary size, the more different possible words it can generate and 
recognize, but also the more computational resources it takes to train. Multilingual 
language models use all kinds of shortcuts to get their vocabulary size down. For instance, 
Large Language Models in Non-English Content Analysis
29
they will often transliterate languages into Latin scripts or train the model to guess the",N/A,N/A
"next subword (e.g. breaking “tasks” into “ta” and “##sks”) or letter instead of the full 
word, thus collapsing the barrier between languages (Tay et al., 2022; C. Wang et al., 
2020). These shortcuts cut down on costs, but they also reduce a model’s ability to 
capture semantic relationships between words, thus degrading its performance overall.
Vocabulary is often decided by how frequently different words, subwords, and",N/A,N/A
"letters appear in a model’s training text, and since multilingual language models are 
trained mostly on English data, their vocabularies will skew towards English as well. 
A multilingual model may have a relatively obscure word like “riposte” in its English 
vocabulary, but be may missing common words in other high resource languages (e.g., 
“escritorio” in Spanish), common subwords in medium resource languages, (e.g., “tzv”",N/A,N/A
"in Hebrew), and entire letters in low resource languages (e.g., a character that appears in 
Tigrinya but not other Ge’ez-based scripts). This inferior representation makes models 
perform worse in a variety of tasks, and makes content analysis systems far easier to trick 
by doing things like changing white space, using typos, or in the case of toxic content 
detection, adding common, positive words like “love” (Gröndahl et al., 2018; Lees et al., 
2022).",N/A,N/A
"2022).
4. WHEN MULTILINGUAL LANGUAGE MODELS FAIL, THEIR 
PROBLEMS ARE HARD TO IDENTIFY, DIAGNOSE, AND FIX.
NLP practitioners depend on benchmarks to determine both how well a language 
model performs at specific tasks and how close it is in general to achieving “natural 
language understanding” (Bender & Koller, 2020). This latter type of benchmarking 
is very difficult in all languages, since it is hard to generalize about a language model’s",N/A,N/A
"capabilities from only a handful of disparate tests (Raji et al., 2021). However, the 
challenges of both types of benchmarks are exacerbated in the multilingual context. 
The disparities in NLP research attention and labeled data between languages mean 
that there are far more benchmarks and tasks that can be used to test models in English 
than in other languages, particularly low resource ones. Models developed to operate in",N/A,N/A
"non-English contexts are still usually tested with benchmarks translated from English 
which, as discussed earlier, is often markedly different from the target language.
The alternative to translation is hiring people local to the contexts a model is being 
applied to and paying them to create data sets and develop benchmarks. This works 
particularly well for models built to do a specific task in a specific language (Nguyen,",N/A,N/A
"2020; Tattle, n.d.), but is very expensive and resource intensive to scale up for models 
meant to work in many languages and contexts. It also raises challenging questions 
for detecting bias in language models (Talat et al., 2022) and performing inherently 
II. Limitations of Language Models in English and Non-English Contexts
Lost in Translation
CDT Research
30
political tasks, such as content moderation. For instance, a social media company trying",N/A,N/A
"to create a dataset of inflammatory content posted in Bosnia and Herzegovina needs 
people who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian, 
Montenegrin, and Macedonian) but also unbiased in those conflicts, all in a country 
that lacks media pluralism or a strong civil society sector (Article 19, 2022). Scaling this 
to every geopolitical problem discussed in all languages on a given online service is a 
daunting, if not impossible, task.",N/A,N/A
"daunting, if not impossible, task.
When problems with multilingual language models can be found, it is often difficult 
to determine why they are occurring. Large language models are already opaque, even 
to those who develop them — neural networks, the core technology underlying large 
language models, are known for being particularly obtuse and for representing language 
in a way that doesn’t map cleanly onto human-understandable concepts (Nicholas,",N/A,N/A
"2020). However, multilingual language models are particularly opaque because they 
make unintuitive, hard-to-trace connections between languages. Take for instance, 
this case from an NLP paper: the Google researchers behind the Perspective API, a 
model for detecting “toxic” content, found that their model flagged tweets that used 
the Italian word “sfiga” (which roughly translates to “bad luck”) as hate speech because",N/A,N/A
"two of the three examples included in the training dataset that contained the subword 
“sfiga” were labeled as hate speech (“sfigati” is an insult meaning “loser”) (Lees et 
al., 2020). If this were a multilingual model that had mapped Italian learnings onto 
Turkish analysis, perhaps sentences with the equivalent Turkish word for “unlucky” 
(“şanssız”) would also be flagged as hate speech. Even if researchers had access to all the",N/A,N/A
"data used to train that multilingual model, it would be extremely difficult to locate and 
fix this bug without knowing Italian or understanding how the model had mapped 
these relationships.
31
Lost in Translation
III. Recommendations E
fforts to improve language models’ performance in various 
languages and contexts are exciting, as they may boost 
connectivity and information exchange for billions of users 
around the world. However, language models are limited in their",N/A,N/A
"capabilities, and employing them too widely, without safeguards, or for 
the wrong kinds of tasks has the potential to raise civil liberties concerns 
and erect new barriers (Maundu, 2023). Unthinking deployment 
of large language models may impede peoples’ ability to access 
information, employment, and public benefits, with disparate impacts 
for individuals in the Global South where many of the low resource 
languages are spoken. We should be cautious about the rapid adoption",N/A,N/A
"of these technologies, especially as building blocks for other types of 
automation in high-stakes arenas like content moderation, employment 
software, and resource allocation.
In this section, we offer recommendations for companies, researchers, and 
governments to take into consideration as they build, study, and regulate 
large language models, particularly in non-English language contexts.
A. Companies
TECHNOLOGY COMPANIES SHOULD DISCLOSE WHEN, 
HOW, AND IN WHAT LANGUAGES THEY USE LARGE",N/A,N/A
"HOW, AND IN WHAT LANGUAGES THEY USE LARGE 
LANGUAGE MODELS.
To better understand the problems and challenges with deploying large 
language models in different languages, researchers and the public need 
to know where to look. Companies that incorporate language models 
into their technical systems should always disclose how they are using 
them, which languages they are using them in, and what languages they 
have been trained on. Currently, the approach of many companies to AI",N/A,N/A
"transparency consists of trumpeting the capabilities of their AI systems 
in blog posts and press releases, and, for a few larger firms, releasing 
research versions of their language models that still differ from the ones 
they use in production. Despite publishing on AI and pushing the field 
forward, technology companies tend to hold information about their 
production AI systems, even basic information about what languages 
they are used in, close to the chest.
Lost in Translation",N/A,N/A
"Lost in Translation
CDT Research
32
Academics and civil society have written extensively about how technology companies, 
particularly online service providers, could offer better transparency and accountability 
for their AI systems, including language models. The Santa Clara Principles, a set of 
principles developed and revised by global civil society groups, provides examples of 
the types of disclosures companies can make about their content moderation policies",N/A,N/A
"and processes (2021). Groups like BigScience also pave the way, exemplifying the type 
of documentation other model-developers can publish about their content analysis 
systems, including model cards, transparency reports, and other avenues to disclose 
more information about the linguistic makeup of a model’s training data (e.g. what 
languages it has trained on, how much data from each language, where those datasets",N/A,N/A
"come from). Better transparency creates opportunities for external actors to more 
immediately identify potential risks and impacts on users and for technology companies 
to mitigate the potential dangers of deploying large language models in English and 
non-English contexts.
WHEN DEPLOYED, LARGE LANGUAGE MODELS SHOULD BE 
ACCOMPANIED BY ADEQUATE REMEDIAL CHANNELS AND 
MECHANISMS THAT ENSURE INDIVIDUALS CAN APPEAL OUTCOMES 
AND DECISIONS MADE BY THESE SYSTEMS.",N/A,N/A
"AND DECISIONS MADE BY THESE SYSTEMS.
Because of the complexities of human speech and the error-prone nature of automated 
tools, decision-making systems built on top of large language models should be used 
within narrow remits and with adequate remedial channels for users encountering 
them. Those remedial channels and processes should have human reviewers with 
the same language proficiencies that their systems are deployed in. Language- and",N/A,N/A
"context-specific remedial channels are particularly important for allowing users to 
appeal decisions made by online services, especially when those decisions either restrict 
their expression or access to information or fundamentally determine their access 
to economic or social rights like the right to housing, education, and social security 
(United Nations Human Rights Office of the High Commissioner, n.d.).
Technology companies can also offer accountability at a system level, not just the",N/A,N/A
"level of individual decisions. One way to do this is to conduct and publish human 
rights impact assessments at the different phases of the language model’s life cycle 
— development, testing, deployment, and evaluation (Prabhakaran et al., 2022). 
Publishing human rights impact assessments will also aid in other actors’ decisions 
when procuring these systems to conduct tasks in different domains and contexts. In",N/A,N/A
"particular, these human rights impact assessments should consider the disparate risks 
to different language speakers in advance of a model being deployed in those languages. 
Online service providers can provide transparency by disclosing the systems and 
languages they use large language models in. 
Large Language Models in Non-English Content Analysis
33
III. Recommendations
COMPANIES SHOULD INVEST IN IMPROVING LANGUAGE MODEL 
PERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN",N/A,N/A
"LANGUAGE AND CONTEXT EXPERTS.
Recently, an arms race has begun between Google and Meta to see who can include 
more languages in their multilingual language model. Meta’s “No Language Left 
Behind” initiative trained a model on over 200 languages (NLLB Team et al., 2022); 
months later, Google one upped Meta with its “1,000 Languages Initiative” (Vincent, 
2022). This race puts a premium on the number of languages the model trains on,",N/A,N/A
"rather than how well it works in each language. In particular, it is unclear how these 
models will handle the “curse of multilinguality,” where, as explained in II.B.3, the 
more languages a model trains on, the less it can capture the idiosyncrasies of each 
language. It is also unclear how these companies define a model “working” in any of 
these languages.
Companies building large language models should not just focus on the number of",N/A,N/A
"languages their model is trained on but the quality of its performance in each language. 
In part, that means better benchmarks, but benchmarks can only go so far. To evaluate 
the full range of potential applications and pitfalls that could come with applying a 
language model in a specific language context, it is necessary to involve language experts, 
civil society, local experts, heritage and language preservation advocates, linguists, and",N/A,N/A
"human rights experts. These actors are crucial to ensuring that labeled training datasets 
adequately capture the nuances and variations of a given language. Many organizations 
are already doing this type of work. Uli is an example of this, where two India-based 
nonprofit organizations — Tattle and Centre for Internet & Society — convened a 
range of gender, gender-based violence, communal violence, and other language experts",N/A,N/A
"to annotate training datasets in Indian English, Tamil, and Hindi to build a tool capable 
of parsing sentiment and toxicity on Twitter. Other researchers have also pointed to 
using annotators to label training datasets as a way to equip models with the ability to 
parse variations in the speech of a certain language (Bergman & Diab, 2022; Nkemelu 
et al., 2022). 
B. Researchers and Funders
RESEARCH FUNDERS SHOULD INVEST IN SPECIFIC NLP LANGUAGE 
COMMUNITIES TO KICKSTART THE VIRTUOUS CYCLE OF",N/A,N/A
"COMMUNITIES TO KICKSTART THE VIRTUOUS CYCLE OF 
DEVELOPMENT.
Developing NLP capabilities in any language is a cyclical process, and for high resource 
languages — particularly English — that cycle is virtuous. When a language has lots 
of clean, human-annotated datasets, researchers and developers are better equipped 
to build models and benchmarks to test models in that language. More models and 
Lost in Translation
CDT Research
34",N/A,N/A
"Lost in Translation
CDT Research
34
benchmarks lead to more publications, conferences, and real-world use cases. And 
finally, increased demand for research and software in a language drives demand for 
more datasets. For low resource languages, however, the virtuous cycle is hard to 
kickstart. Without tools, annotators, and financial investment earmarked for different 
language communities, NLP researchers cannot create the datasets needed to build",N/A,N/A
"models or benchmarks, and even if they could, they face difficulties publishing or 
getting attention for their work in popular journals and conferences. The most 
prestigious NLP publications focus disproportionately on English; languages without 
their own self-sustaining NLP communities end up to a handful of specialized outlets.
Investments into non-English NLP should particularly focus on creating self-sustaining",N/A,N/A
"scholarly NLP communities, and doing this requires investing in all levels at once. The 
groups that are best set up to properly allocate these investments are the language- and 
geography-specific NLP research communities that have cropped up over the years, 
such as such as Masakhane, AmericasNLP, ARBML, and others who can convene 
practitioners around common goals to advance the field (Alyafeai & Al-Shaibani, 2020;",N/A,N/A
"AmericasNLP, 2022; Orife et al., 2020). These communities know what kind of data 
sets should be built, which community actors are needed to properly vet them, and 
what kind of competitions and conferences should be run to keep the virtuous cycles 
going. One model for how this can work is exemplified by EVALITA, an event hosted 
by the Italian Association for Computational Linguistics. In it, researchers first submit",N/A,N/A
"data sets for new language tasks, such as identifying misogyny or dating documents. 
Then, researchers compete to train models to perform those tasks the best. Finally, 
those results get published, thus generating interest and attention toward Italian NLP 
and ensuring researchers continue to build tools for the language (Basile et al., 2020).
Private companies can contribute not only by financially supporting these efforts",N/A,N/A
"but by sharing more of the non-English datasets they use to train their large language 
models, both for transparency and to support research. Large tech companies have 
already shared the code for training many of their multilingual language models 
— Meta’s XLM-R and Google’s mBERT are the subjects of most multilingual 
model research in publication — and disclosed the data they train them on — 
CommonCrawl, and Wikipedia and BooksCorpus, respectively. However, the models",N/A,N/A
"that Google, Meta, OpenAI, and other large companies use in their products train on 
other, proprietary, language data. Companies should share more of their training data, 
both for public accountability and to bolster research.
Large language models have by and large been built by private companies, but private 
incentives may be at odds with developing these models in safe and equitable ways. 
Government investment into non-English large language model research could lead",N/A,N/A
"to improvements in areas private companies may be underinvesting in (Mazzucato, 
2014). DARPA’s late 2010’s LORELEI project, aimed at spurring research into low 
Large Language Models in Non-English Content Analysis
35
III. Recommendations
resource languages to improve translation for humanitarian efforts, is a good first step, 
but further government incentives could help assure that NLP researchers invest in 
a broad range of approaches and languages, rather than focus disproportionately on",N/A,N/A
"English. BigScience’s BLOOM is a good example of how large language models can 
be developed in the open and with public support. The French government is one of 
many funders which has allowed BLOOM to remain open to inquiry by other NLP 
practitioners. The multilingual language model was trained using ROOTs, a 1.6TB 
multilingual dataset that is clearly documented and available for NLP practitioners to 
analyze (Laurençon et al., 2022).
RESEARCHERS SHOULD FOCUS ON MEASURING AND ADDRESSING",N/A,N/A
"THE IMPACTS OF LARGE LANGUAGE MODELS.
Technologists understand little about the internal logic of how large language models 
operate and therefore have a difficult time predicting when they make mistakes, 
what the effects of these mistakes will be, and how to fix them. Multilinguality only 
exacerbates this problem. Better tools are needed to interrogate large language models, 
particularly multilingual language models, about why they make the decisions and",N/A,N/A
"mistakes they do, and how to fix them.
In particular, the increased use of multilingual language models has the potential to 
help and harm language communities. Enabling greater digital participation amongst 
a language community raises something that researchers call the “Janus-face nature 
of digital participation” (NLLB Team et al., 2022): it allows more to participate and 
benefit from the digital economy, however, it may also expose more people to the harms",N/A,N/A
"present online, often without their consultation and consent (Hao, 2022; Toyama, 
2015). More research on the effects and externalities of the increased use of language 
models and specifically multilingual language models must grapple with the impacts 
these tools have on different linguistic communities, linguistic preservation and 
diversity efforts, and access to opportunity for all. 
Different actors have different roles to play here. Civil society has a role in documenting",N/A,N/A
"the impacts of these models and imagining what these “better” models should look like. 
There are many open questions around the types of problems that need automated 
solutions, what more representative datasets might look like, how to manage the tradeoffs 
between languages, how large language models affect linguistic preservation efforts, and 
what the rights implications are of using large language models, among other things.",N/A,N/A
"Academics and corporate researchers have a role in better defining the contexts and tasks 
these models hope to address, and developing quantitative and qualitative methods to 
evaluate these desired normative values. And companies that deploy language models 
can provide researchers more transparency into how their models work, what data they 
are trained on, and in what situations they use them so researchers can better tailor their",N/A,N/A
"research to reflect what is happening in real-world systems.
Lost in Translation
CDT Research
36
C. Governments
GOVERNMENTS SHOULD CAUTION AGAINST USING AUTOMATED 
DECISION-MAKING SYSTEMS THAT RELY ON LARGE LANGUAGE 
MODELS TO MAKE HIGH-STAKES DECISIONS.
Many governments have deployed or are considering deploying systems that use natural 
language processing technology as part of AI systems to make high-impact decisions,",N/A,N/A
"such as determining immigration status or selecting judicial cases to try (Patel et al., 
2020; Rionda & Mejia, 2021). Vendors who build these systems may soon follow the 
larger industry trend of incorporating large language models since they are relatively 
cheap to build and easy to adapt as requirements change. However, as discussed 
throughout this paper, large language models are a relatively novel technology that has",N/A,N/A
"technical limitations. These tools pose serious civil liberty concerns that are magnified 
in non-English contexts and when used to make decisions that may affect a person’s 
livelihood. For instance, if a large language model is used as the basis of an algorithm 
to evaluate affordable housing applications and the text that large language model was 
trained on exhibits anti-Muslim bias, the resulting affordable housing algorithm may",N/A,N/A
"disproportionately deny Muslims’ applications. Relying on large language models to 
make high-stakes decisions can have outsized, negative impacts on individuals’ lives, 
impeding safety and access to economic opportunities.
Governments should therefore never rely solely on automated systems that incorporate 
large language models to make high-risk decision-making areas, such as pretrial risk 
assessment, allocation of social services, and immigration status. Policymakers should",N/A,N/A
"consider the impact on rights and access to services when procuring new tools and 
vendors to build these systems and conduct and disclose any assessments conducted 
on these systems. They should also be cautious when adopting these systems for 
information sharing services, such as chatbots about social services or that provide 
healthcare information, and test them extensively in every language in which they are 
deployed, and never use them to entirely replace human intermediaries.",N/A,N/A
"GOVERNMENTS SHOULD NOT MANDATE OR INADVERTENTLY 
REQUIRE BY LAW THE USE OF AUTOMATED CONTENT ANALYSIS 
SYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.
Governments around the world are increasingly pressuring online service providers to 
limit content they find to be inaccurate or harmful, such as misinformation related to 
health care, or preemptively monitor online speech which may incite violence. Given",N/A,N/A
"the scale of content available on social media and other services, this has driven an 
interest amongst governments to mandate that online service providers use automated 
content analysis systems to detect or remove content they deem as “illegal” or harmful 
to their constituents.
Large Language Models in Non-English Content Analysis
37
III. Recommendations
This is ill-advised. Mandating the use of automated content moderation technologies",N/A,N/A
"or requiring companies to take down content in a limited time period (effectively 
requiring the use of automated technologies) opens the door for the overbroad removal 
of speech. Large language models, especially in non-English language contexts, are not 
a magical technology that can perfectly distinguish between “good” and “bad” speech. 
At best, they are an imprecise technology that fails to understand the context of speech",N/A,N/A
"— for instance, when an individual uses a slur versus when a journalist documents 
the use of a slur by that individual. At worst, they are tools that can be appropriated 
by governments to squash dissent and freedom of expression. Efforts to persuade tech 
companies to improve their automated systems, clarify their policies, introduce more 
accountability, and promote parity between languages are all welcome, but requiring",N/A,N/A
"companies to adopt certain technologies is not an effective way to achieve those ends.
INTERNATIONAL AND MULTILATERAL STANDARDS BODIES, 
REGULATORY AGENCIES, AND OTHERS SHOULD CONVENE 
MULTI-STAKEHOLDER DISCUSSIONS ABOUT STANDARDS AND 
GUARDRAILS FOR THE DEVELOPMENT AND USE OF LARGE 
LANGUAGE MODELS.
The norms around when and how multilingual language models should be deployed 
are very much in flux. Those norms so far have mostly been established implicitly by",N/A,N/A
"technology companies in the ways they build and deploy these models, but trends in 
these norms may be at odds with the public interest. For instance, OpenAI revealed 
some information about the training data they used for GPT-3 but almost nothing 
about GPT-4; Open AI co-founder Ilya Sutskever described having shared information 
about GPT-3’s training data as “just not wise” and something the company would 
unlikely do again (Vincent, 2023b).",N/A,N/A
"unlikely do again (Vincent, 2023b).
Companies should not have a monopoly on the norms around language models. 
Governmental and nongovernmental convening bodies need to organize and push back 
to establish counter-norms that better serve the public’s interests. This field is early on 
enough that these bodies should discuss what positive outcomes even look like. Users 
affected by the deployment of large language models need to be at the table for those",N/A,N/A
"conversations. Government agencies and multilateral organizations (e.g. the Internet 
Engineering Task Force, United Nations) can play a coordinating role to get together 
the relevant stakeholders to come up with such standards.
There are also larger questions to reckon with when it comes to the use of large 
language models in non-English contexts. At once, companies are increasingly 
deploying multilingual language models to bridge the gap between the functionality in",N/A,N/A
"English and other languages across a myriad of tasks, such as harmful content detection, 
sentiment analysis, and content scanning. However, as we show in this paper, these 
multilingual systems are relatively new and perform inconsistently across languages. 
Lost in Translation
CDT Research
38
If deployed prematurely and without guardrails, these models pose real risks to 
individuals around the world and in particular their ability to express themselves freely.",N/A,N/A
"These risks have the potential to compound existing challenges in the information 
environment for individuals in Western democracies where there are real vacuums of 
available information in languages other than English and in countries in the Global 
South where there are already real threats to the free expression and exchange of 
information posed by majoritarian and institutional powers (Golebiewski & boyd,",N/A,N/A
"2018). Alternatively, companies may decide to only roll out systems that have been 
fine-tuned for English and wait until there is enough data and tooling available for non-
English language tools — something that will take an enormous amount of financial 
investment, time, effort, and rare consensus — further entrenching the digital divide 
and Anglocentrism present online. Both scenarios are lose-lose for all speakers on the",N/A,N/A
"web. This is a wicked problem and the current incentives are at play to build bigger 
models, and with more languages. Multi-stakeholder bodies are much better positioned 
than companies to determine when the risks associated with building larger, more 
multilingual language models are worth taking.
Large Language Models in Non-English Content Analysis
39
Works Cited
Abid, A., Farooqi, M., & Zou, J. (2021). Large language models associate Muslims with violence. Nature Machine",N/A,N/A
"Intelligence, 3(6), Article 6. [perma.cc/HK4B-3AAQ]
ACL. (2021, August 3). ACL 2022 Theme Track: “Language Diversity: from Low-Resource to Endangered 
Languages.” ACL. [perma.cc/F2YW-QZBP]
ACL Rolling Review Dashboard. (2022). Papers Mentioning >0 Languages. [perma.cc/EQU9-5CWQ]
Agerri, R., Vicente, I. S., Campos, J. A., Barrena, A., Saralegi, X., Soroa, A., & Agirre, E. (2020). Give your Text 
Representation Models some Love: The Case for Basque. Proceedings of the 12th Conference on Language",N/A,N/A
"Resources and Evaluation, 4781–4788. [perma.cc/R2DA-GGQZ]
Alyafeai, Z., & Al-Shaibani, M. (2020). ARBML: Democratizing Arabic Natural Language Processing Tools. 
Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS), 8–13. [perma.cc/4TFY-E9EJ]
Amer, M. (2022, July 13). Large Language Models and Where to Use Them: Part 2. Cohere. [perma.cc/CRT5-
HDX8]
AmericasNLP. (2022, December 7). Second Workshop on NLP for Indigenous Languages of the Americas",N/A,N/A
"(AmericasNLP). [perma.cc/SC88-9WGF]
Amrute, S., Singh, R., & Guzmán, R. L. (2022). A Primer on AI in/from the Majority World. Data & Society. 
[perma.cc/SR8B-J2L9]
Antoun, W., Baly, F., & Hajj, H. (2020). AraBERT: Transformer-based Model for Arabic Language 
Understanding. Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a 
Shared Task on Offensive Language Detection, 9–15. [perma.cc/X5VJ-JKXQ]",N/A,N/A
"Artetxe, M., Labaka, G., & Agirre, E. (2020). Translation Artifacts in Cross-lingual Transfer Learning. Proceedings 
of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 7674–7684. 
[perma.cc/MZY5-DL83]
Artetxe, M., Ruder, S., & Yogatama, D. (2020). On the Cross-lingual Transferability of Monolingual 
Representations. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 
4623–4637. [perma.cc/7WMN-5QPR]",N/A,N/A
"4623–4637. [perma.cc/7WMN-5QPR]
Artetxe, M., & Schwenk, H. (2019). Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual 
Transfer and Beyond. Transactions of the Association for Computational Linguistics, 7, 597–610. [perma.cc/
LB6R-GH9K]
Article 19. (2022). Bridging the Gap: Local voices in content moderation. Bosnia and Herzegovina. [perma.cc/ASU5-
ST4N]
Avaaz. (2019). Megaphone for Hate: Disinformation and Hate Speech on Facebook During Assam’s Citizenship",N/A,N/A
"Count. Avaaz. [perma.cc/5MXS-7P7N]
Lost in Translation
40
Lost in Translation
CDT Research
Basile, V., Maro, M. D., Croce, D., & Passaro, L. (2020, December 17). EVALITA 2020: Overview of the 7th 
Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Seventh Evaluation 
Campaign of Natural Language Processing and Speech Tools for Italian, Online. [perma.cc/76EK-EJQ8]",N/A,N/A
"Belloni, M. (2021, December 8). Multilingual message content moderation at scale. Bumble Tech. [perma.cc/
RL2A-L2BD]
Bender, E. (2019, September 15). The #BenderRule: On Naming the Languages We Study and Why It Matters. 
The Gradient. [perma.cc/J3ZM-A5UP]
Bender, E., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can 
Language Models Be Too Big? 🦜. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and",N/A,N/A
"Transparency, 610–623. [perma.cc/3KLC-TBUY]
Bender, E., & Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of 
Data. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5185–5198. 
[perma.cc/TN3W-5NTC]
Bergman, A., & Diab, M. (2022). Towards Responsible Natural Language Annotation for the Varieties of Arabic. 
Findings of the Association for Computational Linguistics: ACL 2022, 364–371. [perma.cc/Q37M-8F2Y]",N/A,N/A
"BigScience Workshop, Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A. 
S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., 
Sagot, B., Muennighoff, N., … Wolf, T. (2023). BLOOM: A 176B-Parameter Open-Access Multilingual 
Language Model (arXiv:2211.05100). arXiv. [perma.cc/2K4Z-F5U7]
Birhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., & Bao, M. (2022). The Values Encoded in Machine",N/A,N/A
"Learning Research. 2022 ACM Conference on Fairness, Accountability, and Transparency, 173–184. 
[perma.cc/9GNB-JHQ5]
Birhane, A., & Prabhu, V. U. (2021). Large image datasets: A pyrrhic win for computer vision? 2021 IEEE Winter 
Conference on Applications of Computer Vision, 1536–1546. [perma.cc/Q8LP-THYK]
Bizzoni, Y., Juzek, T. S., España-Bonet, C., Dutta Chowdhury, K., van Genabith, J., & Teich, E. (2020). How",N/A,N/A
"Human is Machine Translationese? Comparing Human and Machine Translations of Text and Speech. 
Proceedings of the 17th International Conference on Spoken Language Translation, 280–290. [perma.
cc/4DTZ-DVKC]
Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosselut, 
A., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K.,",N/A,N/A
"Davis, J. Q., Demszky, D., … Liang, P. (2021). On the Opportunities and Risks of Foundation Models. 
Stanford Center for Research on Foundation Models. [perma.cc/3TKJ-UM2F]
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., 
Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., 
Wu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. Advances in Neural",N/A,N/A
"Information Processing Systems, 33, 1877–1901. [perma.cc/7EES-WDAB]
Cahyawijaya, S., Lovenia, H., Aji, A. F., Winata, G. I., Wilie, B., Mahendra, R., Wibisono, C., Romadhony, A., 
Vincentio, K., Koto, F., Santoso, J., Moeljadi, D., Wirawan, C., Hudi, F., Parmonangan, I. H., Alfina, 
I., Wicaksono, M. S., Putra, I. F., Rahmadani, S., … Purwarianti, A. (2022). NusaCrowd: Open Source 
Initiative for Indonesian NLP Resources (arXiv:2212.09648). arXiv. [perma.cc/UQ3Y-4LKW]
41",N/A,N/A
"41
Large Language Models in Non-English Content Analysis
Works Cited
Callahan, E. S., & Herring, S. C. (2011). Cultural bias in Wikipedia content on famous persons. Journal of the 
American Society for Information Science and Technology, 62(10), 1899–1915. [perma.cc/2S8K-YEJK]
Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., & Zhang, C. (2023, February 1). Quantifying 
Memorization Across Neural Language Models. The Eleventh International Conference on Learning",N/A,N/A
"Representations. [perma.cc/678U-9PAQ]
Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., 
Erlingsson, U., Oprea, A., & Raffel, C. (2021). Extracting Training Data from Large Language Models 
(arXiv:2012.07805). arXiv. [perma.cc/58MA-VWRZ]
Caswell, I., Breiner, T., van Esch, D., & Bapna, A. (2020). Language ID in the Wild: Unexpected Challenges on",N/A,N/A
"the Path to a Thousand-Language Web Text Corpus. Proceedings of the 28th International Conference on 
Computational Linguistics, 6588–6608. [perma.cc/8RFD-DTUK]
Chi, E. A., Hewitt, J., & Manning, C. D. (2020). Finding Universal Grammatical Relations in Multilingual BERT. 
Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5564–5577. 
[perma.cc/8LNR-VNY9]",N/A,N/A
"[perma.cc/8LNR-VNY9]
Choi, H., Kim, J., Joe, S., Min, S., & Gwon, Y. (2021). Analyzing Zero-shot Cross-lingual Transfer in Supervised 
NLP Tasks (arXiv:2101.10649). arXiv. [perma.cc/NEB9-8THZ]
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., 
Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N.,",N/A,N/A
"Prabhakaran, V., … Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways. Google Research. 
[perma.cc/NZ7N-6GPB]
Christian, J. (2018, July 20). Why Is Google Translate Spitting Out Sinister Religious Prophecies? Vice. [perma.
cc/8YQU-NUFM]
Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., Grave, E., Ott, M., 
Zettlemoyer, L., & Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale.",N/A,N/A
"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 8440–8451. 
[perma.cc/2MP6-9W3J]
Conneau, A., & Lample, G. (2019). Cross-lingual Language Model Pretraining. Advances in Neural Information 
Processing Systems, 32. [perma.cc/N7EE-JM83]
Conneau, A., Wu, S., Li, H., Zettlemoyer, L., & Stoyanov, V. (2020). Emerging Cross-lingual Structure in 
Pretrained Language Models. Proceedings of the 58th Annual Meeting of the Association for Computational",N/A,N/A
"Linguistics, 6022–6034. [perma.cc/3NHR-G7Y4]
Corradi, A. (2017, April 25). The Linguistic Colonialism of English. Brown Political Review. [perma.cc/5M3M-
9EMN]
Corvey, W. (2014). Low Resource Languages for Emergent Incidents. Defense Advanced Research Projects Agency. 
[perma.cc/4FDR-M3YC]
Crawford, K. (2021). Atlas of AI: Power, politics, and the planetary costs of artificial intelligence. Yale University 
Press.
42
Lost in Translation
CDT Research",N/A,N/A
"Press.
42
Lost in Translation
CDT Research
de Varda, A. G., & Marelli, M. (2023). Data-driven Cross-lingual Syntax: An Agreement Study with Massively 
Multilingual Models. Computational Linguistics, 1–39. [perma.cc/7LQP-EEBQ]
de Vries, W., van Cranenburgh, A., Bisazza, A., Caselli, T., van Noord, G., & Nissim, M. (2019). BERTje: A Dutch 
BERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]
Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional",N/A,N/A
"Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American 
Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long 
and Short Papers), 4171–4186. [perma.cc/E46R-UYDE]
Dodge, J., Sap, M., Marasović, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., & Gardner, M. (2021). 
Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. Proceedings",N/A,N/A
"of the 2021 Conference on Empirical Methods in Natural Language Processing, 1286–1305. [perma.
cc/3GC6-UEWJ]
Duarte, N., Llansó, E., & Loup, A. C. (2017). Mixed Messages? The Limits of Automated Social Media Content 
Analysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]
Dulhanty, C., Deglint, J. L., Daya, I. B., & Wong, A. (2019, November 26). Taking a Stance on Fake News: Towards 
Automatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance",N/A,N/A
"Detection. NeurIPS 2019, Vancouver. [perma.cc/P5JD-5AD9]
Ebers, M., Poncibò, C., & Zou, M. (Eds.). (2022). Contracting and Contract Law in the Age of Artificial 
Intelligence. Hart Publishing. [perma.cc/G4XR-VYNL]
Eronen, J., Ptaszynski, M., & Masui, F. (2023). Zero-shot cross-lingual transfer language selection using linguistic 
similarity. Information Processing & Management, 60(3), 103250. [perma.cc/S78N-C9MR]",N/A,N/A
"Ethnologue. (2023a). Assamese. Ethnologue, Languages of the World. [perma.cc/BE78-H3PN]
Ethnologue. (2023b). Statistics. Ethnologue, Languages of the World. [perma.cc/H27U-44TK]
Ganguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones, A., Joseph, N., Kernion, J., Mann, 
B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Elhage, N., Showk, S. E., Fort, S., Hatfield-Dodds,",N/A,N/A
"Z., Johnston, S., … Clark, J. (2022). Predictability and Surprise in Large Generative Models. 2022 ACM 
Conference on Fairness, Accountability, and Transparency, 1747–1764. [perma.cc/C8YH-6LMA]
Golebiewski, M., & boyd, danah. (2018). Data Voids: Where Missing Data Can Easily Be Exploited. Data & 
Society. [perma.cc/HE5A-7QTJ]
Góngora, S., Giossa, N., & Chiruzzo, L. (2021). Experiments on a Guarani Corpus of News and Social Media.",N/A,N/A
"Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the 
Americas, 153–158. [perma.cc/N6S5-4PGN]
Grant-Chapman, H., Laird, E., & Venzke, C. (2021). Student Activity Monitoring Software Research Insights and 
Recommendations. Center for Democracy & Technology. [perma.cc/FY8G-WC2P]
Gröndahl, T., Pajola, L., Juuti, M., Conti, M., & Asokan, N. (2018). All You Need is “Love”: Evading Hate Speech",N/A,N/A
"Detection. Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security, 2–12. [perma.cc/
T6P5-FRX5]
43
Large Language Models in Non-English Content Analysis
Works Cited
Hao, K. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. [perma.
cc/54U3-KU5C]
Heikkilä, M. (2022, November 14). We’re getting a better idea of AI’s true carbon footprint. MIT Technology 
Review. [perma.cc/8PWZ-ESJK]",N/A,N/A
"Review. [perma.cc/8PWZ-ESJK]
Hutchinson, B., Prabhakaran, V., Denton, E., Webster, K., Zhong, Y., & Denuyl, S. (2020). Social Biases in NLP 
Models as Barriers for Persons with Disabilities. Proceedings of the 58th Annual Meeting of the Association 
for Computational Linguistics, 5491–5501. [perma.cc/8FGR-P3FA]
Izsak, P., Berchansky, M., & Levy, O. (2021). How to Train BERT with an Academic Budget. Proceedings of the",N/A,N/A
"2021 Conference on Empirical Methods in Natural Language Processing, 10644–10652. [perma.cc/8MPG-
W2QE]
Joshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The State and Fate of Linguistic Diversity and 
Inclusion in the NLP World. Proceedings of the 58th Annual Meeting of the Association for Computational 
Linguistics, 6282–6293. [perma.cc/82HQ-EH65]
Kaack, L. H., Donti, P. L., Strubell, E., Kamiya, G., Creutzig, F., & Rolnick, D. (2022). Aligning artificial",N/A,N/A
"intelligence with climate change mitigation. Nature Climate Change, 12(6), Article 6. [perma.cc/7C4S-
X2LH]
Khan, M., & Hanna, A. (2023). The Subjects and Stages of AI Dataset Development: A Framework for Dataset 
Accountability. Ohio State Technology Law Journal, 19. [perma.cc/XLG3-AP2J]
Kinchin, N., & Mougouei, D. (2022). What Can Artificial Intelligence Do for Refugee Status Determination? A 
Proposal for Removing Subjective Fear. International Journal of Refugee Law. [perma.cc/3KER-DZ5R]",N/A,N/A
"Koehn, P., & Knowles, R. (2017). Six Challenges for Neural Machine Translation. Proceedings of the First 
Workshop on Neural Machine Translation, 28–39. [perma.cc/9WSQ-HQJY]
Kornai, A. (2013). Digital Language Death. PLOS ONE, 8(10), e77056. [perma.cc/MMZ8-C9VH]
Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A., Subramani, N., Sokolov, 
A., Sikasote, C., Setyawan, M., Sarin, S., Samb, S., Sagot, B., Rivera, C., Rios, A., Papadimitriou, I., Osei,",N/A,N/A
"S., Suarez, P. O., … Adeyemi, M. (2022). Quality at a Glance: An Audit of Web-Crawled Multilingual 
Datasets. Transactions of the Association for Computational Linguistics, 10, 50–72. [perma.cc/YZ7B-
Q7PN]
Kublik, V. (n.d.). EU/US Copyright Law and Implications on ML Training Data. Valohai. [perma.cc/LD3Z-
RVW7]
Kupfer, M., & Muyumba, J. (2022). Language & Coloniality: Non-Dominant Languages in the Digital Landscape. 
Pollicy. [perma.cc/PM8N-Y9YW]",N/A,N/A
"Pollicy. [perma.cc/PM8N-Y9YW]
Laurençon, H., Saulnier, L., Wang, T., Akiki, C., Moral, A. V. del, Scao, T. L., Werra, L. V., Mou, C., Ponferrada, 
E. G., Nguyen, H., Frohberg, J., Šaško, M., Lhoest, Q., McMillan-Major, A., Dupont, G., Biderman, 
S., Rogers, A., Allal, L. B., Toni, F. D., … Jernite, Y. (2022, October 31). The BigScience ROOTS Corpus: 
A 1.6TB Composite Multilingual Dataset. Thirty-sixth Conference on Neural Information Processing",N/A,N/A
"Systems Datasets and Benchmarks Track. [perma.cc/QS7B-YNYU]
44
Lost in Translation
CDT Research
Lauscher, A., Ravishankar, V., Vulić, I., & Glavaš, G. (2020). From Zero to Hero: On the Limitations of Zero-
Shot Language Transfer with Multilingual Transformers. Proceedings of the 2020 Conference on Empirical 
Methods in Natural Language Processing (EMNLP), 4483–4499. [perma.cc/ZJ3R-95JM]
Lees, A., Sorensen, J., & Kivlichan, I. (2020). Jigsaw @ AMI and HaSpeeDe2: Fine-Tuning a Pre-Trained",N/A,N/A
"Comment-Domain BERT Model. In V. Basile, D. Croce, M. Maro, & L. C. Passaro (Eds.), EVALITA 
Evaluation of NLP and Speech Tools for Italian—December 17th, 2020 (pp. 40–47). Accademia University 
Press. [perma.cc/9D4M-RSCL]
Lees, A., Tran, V. Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., & Vasserman, L. (2022). A New Generation 
of Perspective API: Efficient Multilingual Character-level Transformers. Proceedings of the 28th ACM",N/A,N/A
"SIGKDD Conference on Knowledge Discovery and Data Mining, 3197–3207. [perma.cc/5K82-WG8J]
Libovický, J., Rosa, R., & Fraser, A. (2019). How Language-Neutral is Multilingual BERT? (arXiv:1911.03310). 
arXiv. [perma.cc/96RW-WXBL]
Lin, X. V., Mihaylov, T., Artetxe, M., Wang, T., Chen, S., Simig, D., Ott, M., Goyal, N., Bhosale, S., Du, J., 
Pasunuru, R., Shleifer, S., Koura, P. S., Chaudhary, V., O’Horo, B., Wang, J., Zettlemoyer, L., Kozareva, Z.,",N/A,N/A
"Diab, M., … Li, X. (2022). Few-shot Learning with Multilingual Generative Language Models. Proceedings 
of the 2022 Conference on Empirical Methods in Natural Language Processing, 9019–9052. [perma.
cc/5QY9-97G5]
Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper 
Blog. [perma.cc/WDL2-TF53]
Luccioni, A., & Viviano, J. (2021). What’s in the Box? An Analysis of Undesirable Content in the Common Crawl",N/A,N/A
"Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 
11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182–189. 
[perma.cc/2QQU-NRPB]
Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient 
conversations into action. TechCrunch. [perma.cc/MK55-SV54]",N/A,N/A
"Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings 
of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: 
Human Language Technologies, 303–313. [perma.cc/3ZP6-V6AJ]
Martin, L., Muller, B., Suárez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, É. V., Seddah, D., & Sagot, B. 
(2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the",N/A,N/A
"Association for Computational Linguistics, 7203–7219. [perma.cc/76EU-4LTM]
Masakhane. (n.d.). Masakhane. Retrieved December 21, 2022. [perma.cc/A7SA-ALPM]
Maundu, C. (2023, February 21). How language denies people access to public information. Nation. [perma.
cc/8C4B-JS3Y]
Mazzucato, M. (2014). The entrepreneurial state: Debunking public vs. private sector myths (Revised edition). 
Anthem Press.",N/A,N/A
"Anthem Press.
Meta AI. (2019, November 7). XLM-R: State-of-the-art cross-lingual understanding through self-supervision. 
Meta AI. [perma.cc/J55N-4MV5]
45
Large Language Models in Non-English Content Analysis
Works Cited
Micallef, K., Gatt, A., Tanti, M., van der Plas, L., & Borg, C. (2022). Pre-training Data Quality and Quantity for a 
Low-Resource Language: New Corpus and BERT Models for Maltese. Proceedings of the Third Workshop",N/A,N/A
"on Deep Learning for Low-Resource Natural Language Processing, 90–101. [perma.cc/QY8V-9Q6H]
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013, September 6). Efficient Estimation of Word Representations 
in Vector Space. International Conference on Learning Representations. [perma.cc/T869-PDX4]
Muller, B., Anastasopoulos, A., Sagot, B., & Seddah, D. (2021). When Being Unseen from mBERT is just the 
Beginning: Handling New Languages With Multilingual Language Models. Proceedings of the 2021",N/A,N/A
"Conference of the North American Chapter of the Association for Computational Linguistics: Human 
Language Technologies, 448–462. [perma.cc/J5MH-QDW3]
Nadkarni, P. M., Ohno-Machado, L., & Chapman, W. W. (2011). Natural language processing: An introduction. 
Journal of the American Medical Informatics Association : JAMIA, 18(5), 544–551. [perma.cc/72PK-
UGK9]
Nekoto, W., Marivate, V., Matsila, T., Fasubaa, T., Fagbohungbe, T., Akinola, S. O., Muhammad, S., Kabongo",N/A,N/A
"Kabenamualu, S., Osei, S., Sackey, F., Niyongabo, R. A., Macharm, R., Ogayo, P., Ahia, O., Berhe, M. 
M., Adeyemi, M., Mokgesi-Selinga, M., Okegbemi, L., Martinus, L., … Bashir, A. (2020). Participatory 
Research for Low-resourced Machine Translation: A Case Study in African Languages. Findings of the 
Association for Computational Linguistics: EMNLP 2020, 2144–2160. [perma.cc/5BVM-LUMM]
Nguer, E. M., Lo, A., Dione, C. M. B., Ba, S. O., & Lo, M. (2020). SENCORPUS: A French-Wolof Parallel",N/A,N/A
"Corpus. Proceedings of the Twelfth Language Resources and Evaluation Conference, 2803–2811. [perma.cc/
NBE7-QCZW]
Nguyen, T. (2020, November 27). Why fake news is so hard to combat in Asian American communities. Vox. 
[perma.cc/45GF-UUEC]
Nicholas, G. (2020). Explaining Algorithmic Decisions. Georgetown Law Technology Review, 4(711), 20. [perma.
cc/UD7D-HF6F]
Nicholas, G. (2022). Shedding Light on Shadowbanning. Center for Democracy & Technology. [perma.cc/D2TS-
Y92D]",N/A,N/A
"Y92D]
Nkemelu, D., Shah, H., Essa, I., & Best, M. L. (2023). Tackling Hate Speech in Low-resource Languages with 
Context Experts. International Conference on Information & Communication Technologies and 
Development, Washington, USA. [perma.cc/5QK7-GTMR]
NLLB Team, Costa-jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, 
J., Licht, D., Maillard, J., Sun, A., Wang, S., Wenzek, G., Youngblood, A., Akula, B., Barrault, L., Gonzalez,",N/A,N/A
"G. M., Hansanti, P., … Wang, J. (2022). No Language Left Behind: Scaling Human-Centered Machine 
Translation (arXiv:2207.04672). arXiv. [perma.cc/LZH5-DMUA]
Okerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M., & Parthasarathy, S. (2022). What’s 
in the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them. 
University of Michigan. [perma.cc/8SXE-RSYE]
OpenAI. (2023). GPT-4 Technical Report (arXiv:2303.08774). arXiv. [perma.cc/6ACB-LZYC]
46",N/A,N/A
"46
Lost in Translation
CDT Research
Orife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., Ali, J. T., Abbott, J., Marivate, V., 
Kabongo, S., Meressa, M., Murhabazi, E., Ahia, O., van Biljon, E., Ramkilowan, A., Akinfaderin, A., 
Öktem, A., Akin, W., Kioko, G., … Bashir, A. (2020). Masakhane—Machine Translation For Africa 
(arXiv:2003.11529). arXiv. [perma.cc/84Z4-S7AZ]",N/A,N/A
"(arXiv:2003.11529). arXiv. [perma.cc/84Z4-S7AZ]
Patel, F., Levinson-Waldman, R., Koreh, R., & DenUyl, S. (2020). Social Media Monitoring. Brennan Center for 
Justice. [perma.cc/N5LF-ZKP2]
Phillipson, R. (1992). Linguistic Imperialism. Oxford University Press.
Pires, T., Schlinger, E., & Garrette, D. (2019). How Multilingual is Multilingual BERT? Proceedings of the 57th 
Annual Meeting of the Association for Computational Linguistics, 4996–5001. [perma.cc/4DPF-LWWX]",N/A,N/A
"Png, M.-T. (2022). At the Tensions of South and North: Critical Roles of Global South Stakeholders in AI 
Governance. 2022 ACM Conference on Fairness, Accountability, and Transparency, 1434–1445. [perma.cc/
Z7HD-3T4A]
Polignano, M., Basile, P., Degemmis, M., Semeraro, G., & Basile, V. (2019). AlBERTo: Italian BERT Language 
Understanding Model for NLP Challenging Tasks Based on Tweets. Sixth Italian Conference on 
Computational Linguistics, Bari, Italy. [perma.cc/RBY9-4JHJ]",N/A,N/A
"Prabhakaran, V., Mitchell, M., Gebru, T., & Gabriel, I. (2022). A Human Rights-Based Approach to Responsible AI 
(arXiv:2210.02667). arXiv. [perma.cc/R97H-WQSK]
Prates, M., Avelar, P., & Lamb, L. (2020). Assessing gender bias in machine translation: A case study with Google 
Translate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]
Pym, A., Ayvazyan, N., & Prioleau, J. M. (2022). Should raw machine translation be used for public-health",N/A,N/A
"information? Suggestions for a multilingual communication policy in Catalonia. Just. Journal of Language 
Rights & Minorities, Revista de Drets Lingüístics i Minories, 1(1–2), 71–99. [perma.cc/HSA8-TB3F]
Raji, D., Denton, E., Bender, E. M., Hanna, A., & Paullada, A. (2021). AI and the Everything in the Whole 
Wide World Benchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and 
Benchmarks, 1. [perma.cc/EX84-X9BQ]",N/A,N/A
"Benchmarks, 1. [perma.cc/EX84-X9BQ]
Razeghi, Y., Logan IV, R. L., Gardner, M., & Singh, S. (2022). Impact of Pretraining Term Frequencies on Few-
Shot Numerical Reasoning. Findings of the Association for Computational Linguistics: EMNLP 2022, 
840–854. [perma.cc/SMG9-BSKV]
Reid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning 
(arXiv:2212.10173). arXiv. [perma.cc/83GW-CVXX]",N/A,N/A
"(arXiv:2212.10173). arXiv. [perma.cc/83GW-CVXX]
Richter, F. (n.d.). English Is the Internet’s Universal Language. Statista Infographics. Retrieved December 14, 
2022, from [perma.cc/WW7B-7X37]
Rionda, V. P. S., & Mejia, J. C. U. (2021). PretorIA y la automatización del procesamiento de causas de derechos 
humanos. Derechos Digitales and Dejusticia. [perma.cc/65MQ-X484]
Rowe, J. (2022, March 2). Marginalised languages and the content moderation challenge. Global Partners Digital.",N/A,N/A
"[perma.cc/GU4K-5HBE]
47
Large Language Models in Non-English Content Analysis
Works Cited
Ruder, S., Constant, N., Botha, J., Siddhant, A., Firat, O., Fu, J., Liu, P., Hu, J., Garrette, D., Neubig, G., & 
Johnson, M. (2021). XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation. 
Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 10215–10245. 
[perma.cc/W4TJ-SGTB]",N/A,N/A
"[perma.cc/W4TJ-SGTB]
Santa Clara Principles. (2021). Santa Clara Principles on Transparency and Accountability in Content Moderation. 
Santa Clara Principles. [perma.cc/T623-AVW6]
Santy, S., Kummerfeld, J., & Rubio, H. (2023). Languages mentioned in Paper Abstracts. ACL Rolling Review. 
[perma.cc/EQU9-5CWQ]
Savoldi, B., Gaido, M., Bentivogli, L., Negri, M., & Turchi, M. (2021). Gender Bias in Machine Translation.",N/A,N/A
"Transactions of the Association for Computational Linguistics, 9, 845–874. [perma.cc/9K3F-5VBZ]
Schwenk, H. (2019, January 22). LASER natural language processing toolkit—Engineering at Meta. Meta AI. 
[perma.cc/46JG-AZ4T]
Sengupta, P. B., Claudia Pozo, Anasuya. (2022, March 31). Does the internet speak your language? Launching the 
first-ever State of the Internet’s Languages report. Whose Knowledge? [https://perma.cc/9KCX-M863]",N/A,N/A
"Sharir, O., Peleg, B., & Shoham, Y. (2020). The Cost of Training NLP Models: A Concise Overview 
(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]
Shenkman, C., Thakur, D., & Llansó, E. (2021). Do You See What I See? Capabilities and Limits of Automated 
Multimedia Content Analysis. Center for Democracy & Technology. [perma.cc/W85T-HQQF]
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A.,",N/A,N/A
"Garriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. 
W., Safaya, A., Tazarv, A., … Wu, Z. (2022). Beyond the Imitation Game: Quantifying and extrapolating the 
capabilities of language models (arXiv:2206.04615). arXiv. [perma.cc/278S-ZJV9]
Stadthagen-Gonzalez, H., Imbault, C., Pérez Sánchez, M. A., & Brysbaert, M. (2017). Norms of valence and 
arousal for 14,031 Spanish words. Behavior Research Methods, 49(1), 111–123. [perma.cc/7FWX-Z3JD]",N/A,N/A
"Strubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. 
Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3645–3650. 
[perma.cc/9P4Y-J4HT]
Talat, Z., Névéol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., 
Radev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D., & Wal, O. van der. (2022). You",N/A,N/A
"reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. Proceedings of 
BigScience Episode #5, 26–41. [perma.cc/3ECR-4E7U]
Tattle. (n.d.). Uli. [perma.cc/4AB2-D4GX]
Tay, Y., Tran, V. Q., Ruder, S., Gupta, J., Chung, H. W., Bahri, D., Qin, Z., Baumgartner, S., Yu, C., & Metzler, D. 
(2022, February 23). Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. 
International Conference on Learning Representations 2022. [perma.cc/YRL4-E7DT]",N/A,N/A
"Teich, E. (2003). Cross-Linguistic Variation in System and Text: A Methodology for the Investigation of 
Translations and Comparable Texts. In Cross-Linguistic Variation in System and Text. De Gruyter Mouton. 
[perma.cc/L8A8-RH8B]
48
Lost in Translation
CDT Research
Torbati, Y. (2019, September 26). Google Says Google Translate Can’t Replace Human Translators. Immigration 
Officials Have Used It to Vet Refugees. ProPublica. [perma.cc/ZUN6-LHA5]",N/A,N/A
"Toyama, K. (2015). Geek heresy: Rescuing social change from the cult of technology. PublicAffairs.
Tsvetkov, Y., Sitaram, S., Faruqui, M., Lample, G., Littell, P., Mortensen, D., Black, A. W., Levin, L., & Dyer, 
C. (2016). Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation 
Learning. Proceedings of the 2016 Conference of the North American Chapter of the Association for 
Computational Linguistics: Human Language Technologies, 1357–1366. [perma.cc/4RES-KFNM]",N/A,N/A
"United Nations Human Rights Office of the High Commissioner. (n.d.). ​Economic, social and cultural rights. 
OHCHR. [perma.cc/Y6MK-SZZ4]
Vallee, H. Q. la, & Duarte, N. (2019). Algorithmic Systems in Education: Incorporating Equity and Fairness When 
Using Student Data. Center for Democracy and Technology. [perma.cc/CC89-ZVNV]
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017,",N/A,N/A
"December 5). Attention Is All You Need. Advances in Neural Information Processing Systems. [perma.
cc/2ZDX-Z796]
Vincent, J. (2022, November 2). Google plans giant AI language model supporting world’s 1,000 most spoken 
languages. The Verge. [perma.cc/3Y48-X7WV]
Vincent, J. (2023a, January 17). Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its 
content. The Verge. [perma.cc/4CXS-3WNN]",N/A,N/A
"content. The Verge. [perma.cc/4CXS-3WNN]
Vincent, J. (2023b, March 15). OpenAI co-founder on company’s past approach to openly sharing research: “We were 
wrong.” The Verge. [perma.cc/DPL6-4PD2]
Vitulli, M. A. (2018). Writing Women in Mathematics Into Wikipedia. Notices of the American Mathematical 
Society, 65(03), 330–334. [perma.cc/X73F-AZPM]
Volansky, V., Ordan, N., & Wintner, S. (2015). On the features of translationese. Digital Scholarship in the",N/A,N/A
"Humanities, 30(1), 98–118. [perma.cc/7F8S-3YXK]
Wang, C., Cho, K., & Gu, J. (2020). Neural Machine Translation with Byte-Level Subwords. Proceedings of the 
AAAI Conference on Artificial Intelligence, 34(05), Article 05. [perma.cc/5DL7-XSSP]
Wang, Z., K, K., Mayhew, S., & Roth, D. (2020). Extending Multilingual BERT to Low-Resource Languages. 
Findings of the Association for Computational Linguistics: EMNLP 2020, 2649–2656. [perma.cc/ZNC8-
C9E7]",N/A,N/A
"C9E7]
Williams, A., Miceli, M., & Gebru, T. (2022). The Exploited Labor Behind Artificial Intelligence. Noēma. [perma.
cc/GE8H-7SUN]
Wu, S., & Dredze, M. (2019). Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT. Proceedings 
of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International 
Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 833–844. [perma.cc/EJ3G-MFYN]",N/A,N/A
"Wu, S., & Dredze, M. (2020). Are All Languages Created Equal in Multilingual BERT? Proceedings of the 5th 
Workshop on Representation Learning for NLP, 120–130. [perma.cc/5E6X-NNAA]
49
Large Language Models in Non-English Content Analysis
Works Cited
Yu, S., Sun, Q., Zhang, H., & Jiang, J. (2022). Translate-Train Embracing Translationese Artifacts. Proceedings of 
the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 362–
370. [perma.cc/7F8C-EYM6]",N/A,N/A
"370. [perma.cc/7F8C-EYM6]
Zhang, S., Frey, B., & Bansal, M. (2022, April 25). How can NLP Help Revitalize Endangered Languages? A Case 
Study and Roadmap for the Cherokee Language. Proceedings of the 60th Annual Meeting of the Association 
for Computational Linguistics (Volume 1: Long Papers). ACL 2022, Dublin, Ireland. [perma.cc/2XF2-
2GDC]
Zhang, Y., Warstadt, A., Li, X., & Bowman, S. R. (2021). When Do You Need Billions of Words of Pretraining",N/A,N/A
"Data? Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 
11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 1112–1125. 
[perma.cc/43ZK-2ZXC]
cdt.org
cdt.org/contact
202-637-9800
@CenDemTech
Center for Democracy & Technology
1401 K Street NW, Suite 200
Washington, D.C. 20005",N/A,N/A
"CEDILLE:
A LARGE AUTOREGRESSIVE LANGUAGE MODEL IN FRENCH
Martin Müller∗
Florian Laurent∗
Cedille AI1
hello@cedille.ai
ABSTRACT
Scaling up the size and training of autoregressive language models has enabled novel ways of solving
Natural Language Processing tasks using zero-shot and few-shot learning. While extreme-scale
language models such as GPT-3 offer multilingual capabilities, zero-shot learning for languages",N/A,N/A
"other than English remain largely unexplored. Here, we introduce Cedille, a large open source
auto-regressive language model, speciﬁcally trained for the French language. Our results show that
Cedille outperforms existing French language models and is competitive with GPT-3 on a range
of French zero-shot benchmarks. Furthermore, we provide an in-depth comparison of the toxicity
exhibited by these models, showing that Cedille marks an improvement in language model safety",N/A,N/A
"thanks to dataset ﬁltering.
1
Introduction
Large autoregressive language models have drawn wide
attention due to their zero-shot and few-shot capabilities,
allowing them to be used for a wide variety of Natural Lan-
guage Processing tasks without the need for task-speciﬁc
ﬁnetuning or annotation data [1, 2]. Additionally, previ-
ous work highlights the improved sample and compute
efﬁciency of larger models, generally justifying the move
towards larger models [3].",N/A,N/A
"towards larger models [3].
Although large language models, such as GPT-3 [2], have
been trained on multilingual corpuses, the performance on
NLP tasks may vary signiﬁcantly between languages. As-
sessing zero-shot performance in non-English languages
is challenging due to the limited number of human-curated
benchmarks available. However, with the exception of re-
cent work in machine translation [4], multilingual models
generally perform worse than mono- or bilingual language
models [5].",N/A,N/A
"models [5].
Monolingual autoregressive language models in French
have previously been proposed. GPT-fr [6] and PAGnol [7]
have been trained on ﬁltered versions of Common Crawl2
and CCNet [8], respectively. Both works highlight the im-
portance of deduplicating and ﬁltering of pre-training data
and use decoder-only transformer architectures, closely
following the GPT models with model sizes reaching 1B
and 1.5B parameters, respectively. It’s worth noting that",N/A,N/A
"these works do not directly compare performance against
extreme-scale large multilingual models, such as GPT-3,
in particular with regard to zero-shot tasks.
Previous work on the various encoding biases in large lan-
guage models highlights the importance of dataset curation
and documentation [9, 10]. Experiments conducted on
GPT-3 (which has been trained on 570GB of text data
from Common Crawl) show that the model may gener-
ate toxic sentences even when prompted with non-toxic",N/A,N/A
"text [11]. Although applying ﬁltering of training data using
automated toxicity scores may introduce classiﬁer-speciﬁc
biases [12], this technique remains more effective than
∗Authors contributed equally, order is random
1Coteries SA, EPFL Innovation Park, Lausanne, Switzerland
2https://commoncrawl.org/
arXiv:2202.03371v1  [cs.CL]  7 Feb 2022
decoder-based detoxiﬁcation using methods such as swear
word ﬁlters, PPLM [13], soft prompt tuning [14] or toxicity
control tokens [15].",N/A,N/A
"control tokens [15].
As a consequence of the aforementioned risks, the trend
towards larger models coincides with a trend to not release
models publicly. Controlling access to large language mod-
els may protect against certain bad actors but also limits
reproducibility and research efforts to mitigate the negative
properties of such models. In a push for building models in
the open, EleutherAI, a grassroot collective of researchers,
released GPT-J [16], a 6B parameter English language",N/A,N/A
"model. This model was trained on the Pile [20], a 825GB
text corpus by the same collective.
The contributions of this paper are as follows: (1) We intro-
duce Cedille, an openly available French language model
built on GPT-J, which is capable of achieving competitive
zero-shot performance against existing French language
models and GPT-3. (2) We release the toxicity scores
of the complete French C4 dataset, and (3) we provide a
comparison of Cedille’s toxicity to other language models",N/A,N/A
"(including GPT-3).
2
Methods
2.1
Model architecture
Our model architecture is identical to GPT-J [16]. GPT-J
uses a similar transformer architecture to the one used in
6.7B GPT-3 with three main differences: (1) No sparse
attention patterns were used; (2) the dimension of the atten-
tion head was increased from 128 to 256; and (3) Rotary
positional embeddings [17] were used instead of sinusoidal
embeddings. See Table 1 for more details.
Number of parameters
6,053,381,344
Number of layers N
28",N/A,N/A
"6,053,381,344
Number of layers N
28
Model dimensions dmodel
4096
Feed-forward dimension dff
16,384
Number of attention heads nheads
16
Head dimension dhead
256
Context size
2048
Vocab size
50,257
Table 1: Cedille model details.
2.2
Training data
Cedille is trained on a ﬁltered version of the French part
of the multilingual C4 (mC4) dataset [18], which contains
332M documents or 1.1TB of uncompressed text. mC4 is
extracted from 71 Common Crawl snapshots (years 2013",N/A,N/A
"to 2020) and uses CLD33, a small feed-forward neural net-
work, for language identiﬁcation. mC4 ﬁltered out pages
of less than three lines of at least 200 characters.
We apply two different forms of ﬁltering to the dataset 1)
toxicity ﬁltering using the Detoxify model [19] and 2) loss
ﬁltering using the FlauBERT model [20]. For both ﬁltering
steps we compute the metric on a per document level of the
entire base dataset. In some cases chunking the documents",N/A,N/A
"into splits of 1200 characters was necessary due to the
ﬁxed context size of the used models. Chunks smaller than
600 characters were not evaluated. The predictions were
run on TPU v3-8 machines with 8-fold data parallelism
each.
Each percentile as well as the tails of both the loss and the
toxicity distribution were sampled and manually inspected
to ﬁnd suitable cut-off values for ﬁltering. The inspection
of these samples revealed that both toxicity and loss values",N/A,N/A
"were appropriate4. We removed documents correspond-
ing to a toxicity score higher than 0.5, corresponding to
0.25% of the content (0.8M documents). For the loss ﬁl-
tering we considered the loss distribution of each of the
2048 ﬁles and removed documents below a 0.2 percentile
loss (corresponding to a loss value of roughly 4.5) and
above an absolute loss value of 10. This corresponded to
a removal of roughly 20% of all documents (66M docu-",N/A,N/A
"ments). The combined ﬁltering led to a ﬁnal training set of
265M documents, which corresponds to roughly 773GB
of uncompressed text.
The text was then run through the fix_text method of
the Python library ftfy [21] using NFKC normalization
and encoded using the unmodiﬁed GPT-2 tokenizer. Docu-
ments were simply concatenated and split into samples of
2049 tokens. The ﬁnal training set yielded a total of 130M
samples corresponding to 268B tokens.
2.3
Training process",N/A,N/A
"2.3
Training process
Cedille was trained starting from the ofﬁcial GPT-J model
checkpoint using the mesh-transformer-jax codebase [22].
Training was conducted on a v3-128 TPU VM using 16-
fold data parallelism and 8-fold model sharding. For all
our experiments we used an effective batch size of 256.
We used a linear warmup of 42k steps up to a peak learning
rate of 5e-5 and a cosine decay to 1e-5. Weight decay was
set to 0.1. Cedille was trained for 150k steps, which corre-",N/A,N/A
"sponds to 0.3 epochs on the training set or 78.7B tokens.
The starting and ﬁnal training perplexities were 6.13 and
3.89, respectively. During training we monitored the loss
on a dataset of French news stories published too recently
to be part of the training data.
3https://github.com/google/cld3
4Despite the positive visual inspection a bug in the loss computation was discovered much later in the analysis. Further investiga-",N/A,N/A
"tion revealed that roughly 10% of samples were wrongly included in the ﬁnal dataset as a result. Although it cannot be fully ruled
out we do not believe that a systematic bias was introduced.
2
2.4
Evaluation
Zero-shot performance was evaluated using a forked ver-
sion of the lm-evaluation-harness codebase [23]. In par-
ticular, we added a different way of evaluating perplexity
using strides (see section 3.1), implemented the various
benchmarks discussed in this work, and integrated the",N/A,N/A
"mesh-transformer-jax library (for evaluating checkpoints
on TPUs) and the Pagnol model families. Benchmarking
was conducted on v3-8 TPU VMs and on A100 GPUs.
Toxicity evaluation was conducted using a modiﬁed ver-
sion of the real-toxicity-prompts codebase5. The main
difference is the use of the Detoxify model in order
to predict toxicity (see section 4).
Our adapted code-
base is available at https://github.com/coteries/
real-toxicity-prompts.
3
Tasks
3.1
Perplexity
Model
#params
Byte-PPL",N/A,N/A
"3
Tasks
3.1
Perplexity
Model
#params
Byte-PPL
Token-PPL
GPT-3 (ada)
1.3Ba
1.930
7.952
GPT-3 (babbage)
6.7B
1.973
6.447
GPT-3 (curie)
13B
1.809
5.082
GPT-3 (davinci)
175B
1.656
3.993
GPT-J
6.05B
1.746
5.797
Cedille
6.05B
1.646
3.932
Pagnol (small)
124M
1.852
17.802
Pagnol (medium)
335M
1.775
14.623
Pagnol (large)
773M
1.725
12.791
GPT-fr (base)
1B
2.090
11.882
Table 2: Byte-level and token-level perplexity scores on the
WikiText-fr benchmark (lower is better).",N/A,N/A
"WikiText-fr benchmark (lower is better).
aOpenAI hasn’t ofﬁcially disclosed the size of the models
provided by their API, however recent experiments suggest the
mapping presented in the table [24].
Zero-shot perplexity was evaluated on the test subset of
the WikiText-fr6 dataset [6], containing articles from the
French Wikipedia which are part of the “quality articles” or
“good articles” categories, similar to the English WikiText-
103 dataset [25]. The test set contains 589k words or 3.7M",N/A,N/A
"characters of cleaned French text from 60 articles. We eval-
uated perplexity by concatenating the text without further
preprocessing and using a sliding window approach [26]
with a stride of 512 tokens. Therefore models with a con-
text window of 1024 tokens (GPT-fr, Pagnol) had 512
tokens of context, whereas models with a context window
of 2048 tokens had 1536 tokens of context. Table 2 shows
the summed log likelihoods both normalized by number",N/A,N/A
"of characters and by number of tokens. Note that the
token-level perplexity for GPT-fr and Pagnol is not directly
comparable to the other models, as they are not using the
(English) GPT-2 tokenizer.
Cedille achieves the lowest perplexity score out of the an-
alyzed models, clearly outcompeting existing French lan-
guage models and narrowly outcompeting GPT-3 (davinci).
Unsurprisingly, models with larger context windows gen-
erally perform better at this task. It is noteworthy that the",N/A,N/A
"test dataset is likely contained in the training data as no
dataset-speciﬁc ﬁltering of the training data was conducted
as part of this work.
3.2
Summarization
We evaluated the summarization capabilities on the Orange-
Sum benchmark, as introduced in the BARThez work [27]
as a French equivalent of XSum [28]. The benchmark con-
tains news articles published between February 2011 and
September 2020, scraped from the French website “Orange
Actu”. The models were given the news article in the test",N/A,N/A
"subset using the following prompt:
{article text}\nPour résumer :
The models were tasked to generate 100 tokens using top-k
of 2 and a temperature of 1, following the methodology
in [1]. We used greedy decoding (top-k = 1) for GPT-3,
since at the time of this work being conducted, the API
didn’t allow for other top-k values. When the prompt ex-
ceeded the context window of the model it was left-side
truncated. The output was then clipped to contain at most 3",N/A,N/A
"sentences (using simplistic sentence splitting at the period
character). Table 3 shows the ROUGE score [29] of the
output compared to the title of the corresponding articles.
Model
R1
R2
RL
GPT-3 (ada)
13.95
4.75
11.59
GPT-3 (babbage)
4.62
1.76
3.86
GPT-3 (curie)
5.28
2.21
4.42
GPT-3 (davinci)
15.49
5.82
13.05
GPT-J
14.46
4.72
11.68
Cedille
14.74
4.83
11.86
Pagnol (small)
8.52
1.61
7.24
Pagnol (medium)
8.98
1.86
7.55
Pagnol (large)
9.19
1.85
7.71
GPT-fr (base)
10.15
2.60
8.27",N/A,N/A
"9.19
1.85
7.71
GPT-fr (base)
10.15
2.60
8.27
Table 3: Performance of summarization in French. Shown are
the ROUGE scores on the OrangeSum dataset (higher is better).
Generally, we observed some variance due to the non-
greedy sampling procedure. However, computational limi-
5https://github.com/allenai/real-toxicity-prompts
6https://huggingface.co/datasets/asi/wikitext_fr
3
tations and cost made it difﬁcult to estimate this variance.
We also observed that the choice of the preﬁx (“Pour ré-",N/A,N/A
"sumer :”) strongly inﬂuences the scores. Some of the
evaluated models are also more likely to generate bullet
point summaries, rather than a single sentence, which may
again lead to different sentence splitting. This may ex-
plain the increased score for GPT-3 (ada) compared to
larger GPT-3 models. Nevertheless, the scores provided
in Table 3 give some rough indication of summarization
performance.
3.3
Question Answering (QA)
Question answering (QA) was evaluated on FQuAD",N/A,N/A
"Question answering (QA) was evaluated on FQuAD
(French Question Answering Dataset) [30], a dataset in-
spired by the English SQuAD equivalent [31]. The models
were evaluated on the validation subset, which contains
3188 human-curated question-answer pairs, based on 768
high-quality French Wikipedia articles.
Model
F1
Exact match (%)
GPT-3 (ada)
19.09
4.48
GPT-3 (babbage)
26.16
8.81
GPT-3 (curie)
39.49
17.84
GPT-3 (davinci)
-
-
GPT-J
26.14
6.96
Cedille
34.59
12.23
Pagnol (small)
10.66
0.43",N/A,N/A
"Cedille
34.59
12.23
Pagnol (small)
10.66
0.43
Pagnol (medium)
13.80
0.84
Pagnol (large)
17.67
2.72
GPT-fr (base)
15.15
2.03
Table 4: Question-answering F1 and exact match scores in
French on the FQuAD benchmark (higher is better).
The models were evaluated using the SQuAD v2 met-
ric [31], which also takes into consideration “no answer”
probabilities, i.e. cases when no answer to a particular
question is possible given the context. The models were",N/A,N/A
"tasked to generate 100 tokens and at most 1 sentence using
greedy sampling and the following prompt:
Titre:
{title}\nContexte:
{context}\n\n
Question:
{question}\n\nRéponse:
The “no answer” probabilities were calculated against the
string:
{prompt} Sans réponse.
However, all questions in the evaluated data contained
exactly one answer.
The results in Table 4 show that GPT-3 is very competitive
on this task, with GPT-3 (curie) outperforming Cedille",N/A,N/A
"and all other evaluated models. GPT-3 (davinci) was not
evaluated on this task for cost reasons, as OpenAI did not
support our request for funding at the time of writing. The
results may be contrasted to a ﬁnetuned version of Camem-
BERT [32] which yields F1 of 88% and best match of 78%
on this dataset [30].
3.4
Translation
Zero-shot translation was evaluated for the language pair
English and French on the WMT14 dataset [33]. Tradi-
tionally, such benchmarks are evaluated using the BLEU",N/A,N/A
"score [34]. The datasets contains 3003 samples each and
are provided by the sacrebleu library [35]. The zero-shot
task is formulated using the following pattern:
{source_lang} phrase:
{text}\n{target_lang}
phrase:
Where source_lang and target_lang are French and
English, respectively, depending on the direction. Greedy
sampling is used to generate 256 tokens. The output was
clipped to at most 1 sentence.
Cedille outperforms other models for the direction English",N/A,N/A
"to French, highlighting the strong French writing capabil-
ities (see Table 5). Likewise, GPT-3 (davinci) performs
better for the French to English direction. Monolingual
models, such as Pagnol and GPT-fr perform worse at this
task presumably due to the limited amount of English that
was part of their pretraining data. Often, smaller models
were unable to follow the instructions and simply repeated
the context in the given language. As opposed to summa-",N/A,N/A
"rization and question-answering benchmarks, the target is
generally not part of the context, therefore simply repeating
the input normally results in a low score.
As of 2021, dedicated neural machine translation solutions,
such as Very Deep Transformers, reach 46.4 BLEU for
English to French translation [36].
Model
BLEU (en→fr)
BLEU (fr→en)
GPT-3 (ada)
2.71
16.64
GPT-3 (babbage)
3.20
24.56
GPT-3 (curie)
13.45
27.15
GPT-3 (davinci)
20.40
27.70
GPT-J
14.71
26.06
Cedille
24.89
20.59
Pagnol (small)",N/A,N/A
"14.71
26.06
Cedille
24.89
20.59
Pagnol (small)
0.76
1.20
Pagnol (medium)
1.07
1.48
Pagnol (large)
1.06
3.47
GPT-fr (base)
1.47
1.57
Table 5: BLEU scores for ranslation on WMT14 for the English-
French language pair (higher is better).
4
Toxicity analysis
In order to evaluate the toxicity of the model we closely
followed the work conducted in [11]. We studied the case
4
of unprompted (i.e. conditioned only on a start-of-sentence
token) and prompted generation.",N/A,N/A
"token) and prompted generation.
The original work in [11] used the Perspective API, a ser-
vice that uses machine learning classiﬁers to estimate the
perceived toxicity of text. In this work, we employ the
Detoxify tool [19] instead. We made this choice as the
underlying models used by Perspective evolve with time
and are not released publicly, which limits experimental
reproducibility.
Detoxify assigns a toxicity score between 0 and 1, with 1",N/A,N/A
"denoting “a very hateful, aggressive, or disrespectful com-
ment”. We refer to content with a score > 0.5 as “toxic”.
We use the “multilingual” Detoxify model from release
v0.4.0, and compare the toxicity of Cedille output to 3
other models: GPT-2 (117M), GPT-3 (davinci), GPT-J and
GPT-fr (base).
4.1
Unprompted toxicity
For the unprompted toxicity we analyze the expected max-
imum toxicity, i.e. the expected worst-case toxicity score
given N unprompted generations. Figure 1 shows boot-",N/A,N/A
"strap estimates (1000 iterations) of the expected maximum
toxicity for N generations with variance bounds as shades.
In this setting, Cedille consistently generates content with
lower expected maximum toxicity than GPT-2, GPT-J, and
GPT-3. After 100 generations, this value is under 0.5 for
GPT-fr and Cedille (0.41 and 0.48, respectively), which
means that the worst content from these models is not
expected to be toxic. This is in contrast with the other",N/A,N/A
"models, for which maximum expected toxicity values are
0.64, 0.54 and 0.56.
After 10K generations, Cedille and GPT-fr are the only
models for which the expected worst outputs don’t reach
a toxicity level of 1.0 We expect all other models to have
at least one output that is maximally toxic as detected by
Detoxify. Generally the two models that perform best are
GPT-fr and Cedille, which were both trained on carefully
ﬁltered datasets, pointing to the importance of dataset cu-",N/A,N/A
"ration when considering the safety of language models.
Without any conditioning, the multilingual models almost
exclusively generate English content: this is the case of
GPT-2, GPT-J and GPT-3. However, with the Detoxify
model being multilingual, the toxicity scores remain com-
parable.
4.2
Prompted toxicity
For prompted toxicity we used a set of 50 French prompts
with values of toxicity spanning the full range, with a mean
of 0.34. The set of prompts was selected randomly from",N/A,N/A
"the RealToxicityPrompt dataset and manually translated
from English to French by a French native speaker. We
used a smaller number of prompts than in [11] due to lim-
ited computing resources. The French prompts cause the
multilingual models (GPT-2, GPT-J and GPT-3) to gener-
ate French content. For each prompt, each model generates
50 completions. We used nucleus sampling with p = 0.9
to generate up to 20 tokens per continuation, following the
protocol from [11].",N/A,N/A
"protocol from [11].
Table 6 shows two properties: 1) the expected maximum
toxicity over 25 generations (with standard deviations in
parentheses) and 2) the empirical probability of generating
toxic text at least once among 25 generations.
Model
Exp. max tox.
Prob. toxicity
GPT-2a
0.63 (0.23)
0.66
GPT-3 (davinci)
0.68 (0.27)
0.74
GPT-J
0.73 (0.26)
0.78
Cedille
0.66 (0.27)
0.72
GPT-fr (base)
0.73 (0.27)
0.78
Table 6: Toxicity of prompted generations.",N/A,N/A
"0.78
Table 6: Toxicity of prompted generations.
aUpon manual inspection, it appeared that GPT-2 is unable
to generate sensible French content, and as such the resulting
toxicity values can’t be compared to other models.
For both properties, Cedille outperforms the other models.
We can see again that Cedille is less toxic than GPT-J,
indicating that the training not only improved the model’s
French capabilities, but also increased its safety.
5
Conclusions",N/A,N/A
"5
Conclusions
In this work we introduced Cedille, a large auto-regressive
French language model.
Our work shows that mono-
lingual models such as Cedille, can be competitive com-
pared to extreme scale multilingual language models, i.e.
GPT-3. Compared to existing French language models,
Cedille is capable of performing well on zero-shot natural
language understanding tasks and reaches a new state-of-
the-art perplexity score on the French WikiText corpus.",N/A,N/A
"Lastly, our approach of toxicity ﬁltering of the training
data led to a decrease in both maximum toxicity as well as
the likelihood of toxic output.
As a result of the ﬁnetuning approach starting from GPT-J,
Cedille has been exposed to a large amount of both English
and French language data from the Pile and French mC4.
This combination allows for competitive zero-shot trans-
lation scores for the French-English language pair. Early
experiments indicate that ﬁnetuning an existing English",N/A,N/A
"language model and adapting it to French is more efﬁcient
even with considerable compute and data investments (see
appendix).
Given the scarcity of high-quality human-curated datasets
in non-English languages it is especially challenging to
provide a fair comparison of language models. For the
zero-shot benchmarks we observed a high degree of sen-
sitivity towards evaluation settings such as preﬁxes, sam-
pling parameters, and type of evaluation metric. The scores
5
10
100
1K
10K",N/A,N/A
"5
10
100
1K
10K
Number of Generations
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Expected Maximum Toxicity
GPT-2
GPT-3
GPT-J
GPT-fr
Cedille
Figure 1: Unprompted expected maximum toxicity against increasing numbers of generations.
should therefore only be considered as a rough guidance
and model performance may be highly task speciﬁc. In this
work we haven’t provided performance metrics for other
NLP tasks such as text classiﬁcation or word sense disam-",N/A,N/A
"biguation. Furthermore, this work focused on zero-shot
evaluation, ignoring few-shot or ﬁnetuning approaches.
Apart from training larger models, a possible path for-
ward is to deduplicate training data. This method has been
shown to improve end-task performance signiﬁcantly [8,
37] but was not conducted as part of this work. In order to
further reduce language model toxicity, a possible direc-
tion is the integration of human feedback in the training",N/A,N/A
"process in order to reduce toxic output generation [38].
Data availability.
Cedille is available under the MIT
License on the Hugging Face model hub:
https:
//huggingface.co/Cedille/fr-boris, and on our
GitHub repository: https://github.com/coteries/
cedille-ai. Regarding the French mC4 toxicity scores
and toxicity analysis code, please refer to: https://
github.com/coteries/real-toxicity-prompts.
Funding.
This work was funded by, and conducted at,",N/A,N/A
"This work was funded by, and conducted at,
Coteries SA7. The model was trained on Cloud TPUs pro-
vided by Google’s TPU Research Cloud program.
Acknowledgments.
We thank Sébastien Flury and
François Bochatay for their guidance and feedback. Tiago
Castanheiro, Flavien Bonvin and Livio Gamassia imple-
mented the web-based Playground used to evaluate the
model. Tiago Castanheiro, Flavien Bonvin, Sacha To-
ufani, Livio Gamassia, and Kasper Andkjaer tested out",N/A,N/A
"multiple versions of the model. Sébastien Von Roth de-
signed the Cedille logo as well as the visual design of the
Playground and Cedille website8. Sonja Dossenbach as-
sembled the dataset of recent French news. We are grateful
to EleutherAI for publicly releasing the GPT-J model and
offering us support on their Discord server9. We thank the
TPU Research Cloud team for their access to Cloud TPUs
and their support.
References
[1]
Alec Radford et al. “Language models are unsu-",N/A,N/A
"Alec Radford et al. “Language models are unsu-
pervised multitask learners”. In: OpenAI blog 1.8
(2019), p. 9.
[2]
Tom B Brown et al. “Language models are few-
shot learners”. In: arXiv preprint arXiv:2005.14165
(2020).
[3]
Jared Kaplan et al. “Scaling laws for neu-
ral
language
models”.
In:
arXiv
preprint
arXiv:2001.08361 (2020).
[4]
Chau Tran et al. “Facebook AI WMT21 news
translation task submission”. In: arXiv preprint
arXiv:2108.03265 (2021).
[5]",N/A,N/A
"arXiv:2108.03265 (2021).
[5]
Naveen Arivazhagan et al. “Massively multilingual
neural machine translation in the wild: Findings and
challenges”. In: arXiv preprint arXiv:1907.05019
(2019).
7https://coteries.com
8https://cedille.ai
9https://discord.gg/zBGx3azzUn
6
[6]
Antoine Simoulin and Benoit Crabbé. “Un mod-
èle Transformer Génératif Pré-entrainé pour le _
français”. In: Traitement Automatique des Langues
Naturelles. ATALA. 2021, pp. 245–254.
[7]
Julien Launay et al. “PAGnol: An Extra-Large",N/A,N/A
"[7]
Julien Launay et al. “PAGnol: An Extra-Large
French Generative Model”. In: arXiv preprint
arXiv:2110.08554 (2021).
[8]
Guillaume Wenzek et al. “Ccnet: Extracting high
quality monolingual datasets from web crawl data”.
In: arXiv preprint arXiv:1911.00359 (2019).
[9]
Emily M Bender et al. “On the Dangers of Stochas-
tic Parrots: Can Language Models Be Too Big?”
In: Proceedings of the 2021 ACM Conference on
Fairness, Accountability, and Transparency. 2021,
pp. 610–623.
[10]",N/A,N/A
"pp. 610–623.
[10]
Isaac Caswell et al. “Quality at a glance: An au-
dit of web-crawled multilingual datasets”. In: arXiv
preprint arXiv:2103.12028 (2021).
[11]
Samuel Gehman et al. “RealToxicityPrompts: Evalu-
ating neural toxic degeneration in language models”.
In: arXiv preprint arXiv:2009.11462 (2020).
[12]
Johannes Welbl et al. “Challenges in detox-
ifying language models”. In: arXiv preprint
arXiv:2109.07445 (2021).
[13]
Sumanth Dathathri et al. “Plug and play language",N/A,N/A
"Sumanth Dathathri et al. “Plug and play language
models: A simple approach to controlled text gener-
ation”. In: arXiv preprint arXiv:1912.02164 (2019).
[14]
Brian Lester, Rami Al-Rfou, and Noah Constant.
“The power of scale for parameter-efﬁcient prompt
tuning”. In: arXiv preprint arXiv:2104.08691
(2021).
[15]
Nitish Shirish Keskar et al. “Ctrl: A conditional
transformer language model for controllable gener-
ation”. In: arXiv preprint arXiv:1909.05858 (2019).
[16]",N/A,N/A
"[16]
Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6
Billion Parameter Autoregressive Language Model.
https : / / github . com / kingoflolz / mesh -
transformer-jax. May 2021.
[17]
Jianlin Su et al. “Roformer: Enhanced transformer
with rotary position embedding”. In: arXiv preprint
arXiv:2104.09864 (2021).
[18]
Linting Xue et al. “mT5: A massively multilin-
gual pre-trained text-to-text transformer”. In: arXiv
preprint arXiv:2010.11934 (2020).
[19]
Laura Hanu and Unitary team. Detoxify. https:",N/A,N/A
"Laura Hanu and Unitary team. Detoxify. https:
//github.com/unitaryai/detoxify. 2020.
[20]
Hang Le et al. “Flaubert: Unsupervised language
model pre-training for french”. In: arXiv preprint
arXiv:1912.05372 (2019).
[21]
Robyn Speer. ftfy. Zenodo. Version 5.5. 2019. DOI:
10.5281/zenodo.2591652. URL: https://doi.
org/10.5281/zenodo.2591652.
[22]
Ben Wang. Mesh-Transformer-JAX: Model-Parallel
Implementation of Transformer Language Model
with JAX. https://github.com/kingoflolz/",N/A,N/A
"with JAX. https://github.com/kingoflolz/
mesh-transformer-jax. May 2021.
[23]
Leo Gao et al. A framework for few-shot language
model evaluation. Version v0.0.1. Sept. 2021. DOI:
10.5281/zenodo.5371628. URL: https://doi.
org/10.5281/zenodo.5371628.
[24]
Leo Gao. On the Sizes of OpenAI API Models.
https://blog.eleuther.ai/gpt3- model-
sizes/. May 2021.
[25]
Stephen Merity et al. “Pointer sentinel mixture mod-
els”. In: arXiv preprint arXiv:1609.07843 (2016).
[26]",N/A,N/A
"[26]
Perplexity of ﬁxed-length models. https : / /
huggingface . co / docs / transformers /
perplexity. Accessed: 2022-02-04.
[27]
Moussa Kamal Eddine, Antoine J-P Tixier, and
Michalis Vazirgiannis. “BARThez: a skilled pre-
trained french sequence-to-sequence model”. In:
arXiv preprint arXiv:2010.12321 (2020).
[28]
Shashi Narayan, Shay B Cohen, and Mirella La-
pata. “Don’t give me the details, just the sum-
mary! topic-aware convolutional neural networks",N/A,N/A
"mary! topic-aware convolutional neural networks
for extreme summarization”. In: arXiv preprint
arXiv:1808.08745 (2018).
[29]
Chin-Yew Lin. “Rouge: A package for automatic
evaluation of summaries”. In: Text summarization
branches out. 2004, pp. 74–81.
[30]
Martin d’Hoffschmidt et al. “FQuAD: French
question answering dataset”. In: arXiv preprint
arXiv:2002.06071 (2020).
[31]
Pranav Rajpurkar et al. “SQuAD: 100,000+ ques-
tions for machine comprehension of text”. In: arXiv",N/A,N/A
"preprint arXiv:1606.05250 (2016).
[32]
Louis Martin et al. “CamemBERT: a tasty
french
language
model”.
In:
arXiv
preprint
arXiv:1911.03894 (2019).
[33]
Ondˇrej Bojar et al. “Findings of the 2014 workshop
on statistical machine translation”. In: Proceedings
of the ninth workshop on statistical machine trans-
lation. 2014, pp. 12–58.
[34]
Kishore Papineni et al. “Bleu: a method for auto-
matic evaluation of machine translation”. In: Pro-
ceedings of the 40th annual meeting of the Associa-",N/A,N/A
"tion for Computational Linguistics. 2002, pp. 311–
318.
[35]
Matt Post. “A Call for Clarity in Reporting BLEU
Scores”. In: Proceedings of the Third Conference
on Machine Translation: Research Papers. Belgium,
Brussels: Association for Computational Linguis-
tics, Oct. 2018, pp. 186–191. URL: https://www.
aclweb.org/anthology/W18-6319.
[36]
Xiaodong Liu et al. “Very deep transformers for
neural machine translation”. In: arXiv preprint
arXiv:2008.07772 (2020).
[37]",N/A,N/A
"arXiv:2008.07772 (2020).
[37]
Katherine Lee et al. “Deduplicating training data
makes language models better”. In: arXiv preprint
arXiv:2107.06499 (2021).
[38]
Long Ouyang et al. Training language models to
follow instructions with human feedback. https://
openai.com/blog/instruction-following/.
Jan. 2022.
7
SUPPLEMENTARY MATERIAL
1
Experiments training from scratch
Given the amount of compute and data available, training from scratch rather than ﬁnetuning was considered. We",N/A,N/A
"experimented training Cedille from scratch using both the GPT-2 tokenizer (Cedille-fs-GPT2, vocab size 50,400) and
the GPT-fr tokenizer (Cedille-fs-GPTfr, vocab size 50.000) for 60k steps using a peak learning rate of 1.2e-4 end
learning rate 1.2e-5, and 7281 warm-up steps. These two variants are therefore only trained on one third of the data
compared to the released Cedille model (150k steps). In order to have a fair comparison we show the result of Cedille",N/A,N/A
"after the same amount of steps (Cedille-60k). All models were trained on the same ﬁltered mC4 dataset, as described in
this work.
As shown in Table S1, Cedille-60k outperforms the from-scratch variants on the WikiText-fr benchmark. However,
due to compute limitations we did not run the variants for longer than 60k steps and it is possible that we could’ve
reached similar performance after 150k steps. Furthermore, both variants perform similarly, even though they are using",N/A,N/A
"a different tokenizer. Due to the variants performing very similarly, we conclude that even though a dedicated French
tokenizer is a lot more efﬁcient at encoding French text compared to the GPT-2 tokenizer, its beneﬁt with regard to
end-task performance was minimal in our experiments.
Model
PPL (byte)
PPL (token)
GPT-J
1.746
5.797
Cedille-60k
1.673
4.112
Cedille-fs-GPT2
1.794
4.972
Cedille-fs-GPTfr
1.775
6.856",N/A,N/A
"1.794
4.972
Cedille-fs-GPTfr
1.775
6.856
Table S1: Byte-level and token-level perplexities for the WikiText-fr benchmark. Cedille-60k is the Cedille model at checkpoint 60k
(out of 150k), Cedille-fs-GPT2 and Cedille-fs-GPTfr are models trained for 60k steps on the same dataset, but with random weight
initialization.
8",N/A,N/A
"arXiv:2305.06530v1  [cs.CL]  11 May 2023
AfricaNLP workshop at ICLR2022
HOW GOOD ARE COMMERCIAL LARGE LANGUAGE
MODELS ON AFRICAN LANGUAGES?
Jessica Ojo
Masakhane
jessicaojo19@gmail.com
Kelechi Ogueji
Masakhane
kelechi.ogueji@uwaterloo.ca
ABSTRACT
Recent advancements in Natural Language Processing (NLP) has led to the pro-
liferation of large pretrained language models. These models have been shown to
yield good performance, using in-context learning, even on unseen tasks and lan-",N/A,N/A
"guages. They have also been exposed as commercial APIs as a form of language-
model-as-a-service, with great adoption. However, their performance on African
languages is largely unknown. We present a preliminary analysis of commercial
large language models on two tasks (machine translation and text classiﬁcation)
across eight African languages, spanning different language families and geo-
graphical areas. Our results suggest that commercial language models produce",N/A,N/A
"below-par performance on African languages. We also ﬁnd that they perform bet-
ter on text classiﬁcation than machine translation. In general, our ﬁndings present
a call-to-action to ensure African languages are well represented in commercial
large language models, given their growing popularity.
1
INTRODUCTION
Large language models have risen to the fore of Natural Language Processing (NLP). These models",N/A,N/A
"have been shown to achieve state-of-the-art performances on several tasks. More recently, focus has
shifted from the pretrain-ﬁnetune paradigm (Howard & Ruder, 2018; Devlin et al., 2019; Liu et al.,
2019; Raffel et al., 2020) to in-context learning (Brown et al., 2020; Lin et al., 2021; Wei et al.,
2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al., 2023). In-context
learning proves that prompting large language models with some task-speciﬁc examples allows them",N/A,N/A
"perform well on test examples of that task, all without updating the model’s parameters. This has
led to reduced computation costs and has made it possible to create language-models-as-a-service
(Sun et al., 2022), in the form of commercial Application Programming Interfaces (APIs). Com-
mercial language models have become very prevalent. For context, the recently released ChatGPT1
amassed 100 million users2 in two months, making it the fastest growing consumer app in recent",N/A,N/A
"history. Given their dominance and inevitable continual rise, it is important to understand how these
models perform on African languages. Hence, we present a preliminary effort to close this gap by
evaluating two commercial large language models using in-context learning on African languages.
Evaluation is performed on two tasks - text classiﬁcation and machine translation. Our experiments,
spanning 8 African languages from different language families and geographical locations, suggests",N/A,N/A
"that commercial language models do not perform well on African languages. In particular, we note
a large disparity in performance, depending on the evaluation task - models perform better on text
classiﬁcation than machine translation. Our work sheds light on the need to ensure the inclusion
of African languages in the development of commercial language models, given their inevitable
adoption in our daily lives.
1https://chat.openai.com/",N/A,N/A
"1https://chat.openai.com/
2https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-faste
1
AfricaNLP workshop at ICLR2022
2
RELATED WORK
2.1
IN-CONTEXT LEARNING
The use of pretrained language models has become the de-facto approach to solving natural language
processing (NLP) tasks. Previous models such as BERT (Devlin et al., 2019), RoBERTa (Liu et al.,
2019) and T5 (Raffel et al., 2020) largely follow a pretrain-ﬁnetune setting (Howard & Ruder,",N/A,N/A
"2018). In this method, the pretrained model is ﬁnetuned on a downstream task, such as text classi-
ﬁcation, and then used for that task. While this works very well, it has several downsides. For one,
ﬁnetuned models are usually task-speciﬁc and this means one has to maintain separate models for
separate tasks. Furthermore, the growing size of pretrained language models (Kaplan et al., 2020)
means that it is becoming increasingly expensive to ﬁnetune such gigantic models. One solution",N/A,N/A
"that has proven popular in recent times is in-context learning (Brown et al., 2020; Schick & Sch¨utze,
2021; Wei et al., 2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al.,
2023). The core idea behind this method is to enable pretrained language models learn from ex-
amples within the context. In this setting, a user prompts a pretrained language model with a few
labelled examples of a task following a speciﬁc pattern, and unlabelled examples that need to be pre-",N/A,N/A
"dicted on (Wei et al., 2022c; Liu et al., 2022; Wei et al., 2022b). In-context learning can also work
in a zero-shot setting where no labelled examples are included in the prompt. In-context learning
works surprisingly well and is very efﬁcient since there is no update to the model’s parameters. As
a result, computation costs are signiﬁcantly reduced and it becomes possible to expose language
models as a service (Sun et al., 2022). Commercial APIs are heavily reliant on in-context learning",N/A,N/A
"as this is the primary method through which users interact 3 with the models4.
2.2
MULTILINGUAL IN-CONTEXT LEARNING
Large language models have proven successful in multilingual settings.
Lin et al. (2021) train
several multilingual models, of which the largest one (7.5B parameters) sets a state-of-the-art in
few-shot learning on more than 20 languages. Their model outperforms GPT3 on several mul-
tilingual tasks. Muennighoff et al. (2022) perform multitask prompted ﬁnetuning on multilingual",N/A,N/A
"pretrained language models and observe impressive zero-shot generalization to tasks in unseen lan-
guages. Following ﬁndings from Blevins & Zettlemoyer (2022) that non-English dataset present in
the pretraining corpora of English language models explains their surprising cross-lingual ability,
Chowdhery et al. (2022) deliberately introduce non-English corpora (≈22%) into the pretraining
corpora of their PaLM model and achieve impressive few-shot multilingual performance. Shi et al.",N/A,N/A
"(2022) evaluate GPT3 and PaLM on a newly introduced grade school mathematics multilingual
benchmark. They ﬁnd that using prompts with intermediate reasoning steps in English consistently
led to competitive or better results than those written in the native language of the question. They
also set a new state-of-the-art on a common-sense reasononing multilingual benchmark, XCOPA
(Ponti et al., 2020), using few-shot examples. Zhao & Sch¨utze (2021) show that prompting yields",N/A,N/A
"better cross-lingual transfer in few-shot settings than ﬁnetuning and in-language training of multilin-
gual natural language inference. Furthermore, Winata et al. (2021) evaluate the multilingual ability
of GPT (Radford et al., 2019) and T5 (Raffel et al., 2020) models on multi-class text classiﬁcation,
and ﬁnd that they work well on non-English languages given a few English examples. Concurrent
work (Jiao et al., 2023) evaluate ChatGPT on machine translation and ﬁnd that, while it is compet-",N/A,N/A
"itive with other commercial translation APIs such as Google translate5, it is less robust on other
domains such as biomedical. Another concurrent work (Zhang et al., 2023) conducts a study on
the performance of GLM (Zeng et al., 2022) on machine translation. They note several interesting
ﬁndings on the effect of prompt template, examples and language. Despite the plethora of works
on multilingual prompting, little to no African languages are usually contained in the evaluation",N/A,N/A
"sets of nearly all of these works. When present, they are often obtained by translating the existing
datasets of other languages (Yu et al., 2022) This method has been shown to contain artifacts that
can inﬂate the performance of models evaluated on such datasets (Artetxe et al., 2020). Our work is
orthogonal to all of this works because we focus solely on commercial language model APIs, given
their prevalence. The closest to our work is concurrent by Abott et al. (2023), who evaluate GPT",N/A,N/A
"3https://platform.openai.com/docs/guides/completion/prompt-design
4https://docs.cohere.ai/docs/prompt-engineering
5https://translate.google.com/
2
AfricaNLP workshop at ICLR2022
3.5 on Named Entity Recognition and Machine Translation on only isiZulu. However, our work is
different from this as we compare two commercial APIs in the evaluation of text classiﬁcation and
Machine Translation across 8 African language.
3
METHODOLOGY
3.1
DATASETS",N/A,N/A
"3
METHODOLOGY
3.1
DATASETS
Evaluation is done on two tasks - text classiﬁcation and machine translation.
3.1.1
TEXT CLASSIFICATION
We use the news topic classiﬁcation datasets from Hedderich et al. (2020) and Alabi et al. (2022).
We select the Hausa (hau) language from Hedderich et al. (2020) which has 5 categories. Pretrained
language models have been shown to work very well on this dataset in both few and zero-shot",N/A,N/A
"settings. The dataset from Alabi et al. (2022) covers ﬁve languages, out of which we select four
- Nigerian Pidgin (pcm), Malagasay (mlg), and Somali (som), isiZulu (zul). Each language has 5
categories, except Somali which has 6. For both datasets, we use the train, validation and test splits
as released by the authors. We select these languages because they cover different language families
and geographical areas.
3.1.2
MACHINE TRANSLATION",N/A,N/A
"and geographical areas.
3.1.2
MACHINE TRANSLATION
We use the MAFAND-MT machine translation dataset from Adelani et al. (2022) which covers 16
African languages. Running translation on commercial APIs is cumbersome and expensive, hence
we select 5 languages from the 16. The ﬁve languages are isiZulu (zul), Yoruba (yor), Nigerian
Pidgin (pcm), Swahili (Swa) and Lugala (lug). We use the splits as released by the authors.
3.2
MODELS",N/A,N/A
"3.2
MODELS
Two commercial APIs6 are considered: ChatGPT7 and Cohere8. We consider both these APIs be-
cause they are arguably the most popular ones9. ChatGPT is based on the Instruct-GPT models
(Ouyang et al., 2022). It is optimized for conversations and has been shown to be capable of sev-
eral NLP tasks including text classiﬁcation, machine translation, question answering, and so on.
We use Cohere’s multilingual model10 which is based on their multilingual embedding model11.",N/A,N/A
"The embedding model supports 100 languages, including 15 African languages. All the languages
we consider, except Nigerian Pidgin, are supported by the model. However, given the linguistic
proximity of Nigerian Pidgin to English (Faraclas, 2008; Ogueji & Ahia, 2019; Chang et al., 2020;
Ahia & Ogueji, 2020a; Lent et al., 2021; 2022), the model should be able to perform well on the
dataset.
3.3
PROMPTING AND EVALUATION",N/A,N/A
"dataset.
3.3
PROMPTING AND EVALUATION
We describe our prompting and evaluation approaches for text classiﬁcation and machine translation.
3.3.1
TEXT CLASSIFICATION
For Cohere, we use the Classify12 endpoint and follow the format speciﬁed in the API documenta-
tion13. When using ChatGPT, we design several prompts ourselves and we also ask ChatGPT for
6Experiments were run between January 22, 2023 and February 5, 2023.
7https://chat.openai.com/
8https://www.cohere.ai",N/A,N/A
"7https://chat.openai.com/
8https://www.cohere.ai
9https://venturebeat.com/uncategorized/openai-rival-cohere-launches-language-model-api/
10https://docs.cohere.ai/changelog/multilingual-support-for-coclassify
11https://docs.cohere.ai/docs/multilingual-language-models
12https://api.cohere.ai/classify
13https://docs.cohere.ai/reference/classify
3
AfricaNLP workshop at ICLR2022
the best prompt for classiﬁcation, following concurrent work (Jiao et al., 2023). We perform some",N/A,N/A
"initial evaluation of the prompts and select the best one.
Our best prompt is shown below:
Given the following news headlines and their categories:
Text:
{Sentence}
Category:
{Label}
Please classify the following news headlines into one of:
{Label List}.
Text:
{Sentence}
Category:
Where Sentence is the news headline to be classiﬁed, Category is the news topic, and LabelList
is a comma separated list of all unique labels for that language.",N/A,N/A
"For both models, we supply two example demonstrations per category from the training set. We
randomly sample 100 samples from the test set for each language and evaluate on this. Both demon-
strations and evaluation are done across two random seeds, such that we sample distinct demonstra-
tions and test samples for each language with each random seed. We report the average F1 score for
each language across both seeds. It should be noted that we decide to evaluate on a subset of the test",N/A,N/A
"set because of the tedious nature of obtaining results ChatGPT.
3.3.2
MACHINE TRANSLATION
We do not use Cohere for machine translation because its generation API currently supports only
English14. ChatGPT is used for all our machine translation evaluations. Preliminary results from
comparing few-shot to zero-shot translations on Nigerian Pidgin suggested no noticeable difference.
Hence, we perform all translations in a zero-shot manner because of the tedious nature and low-",N/A,N/A
"throughput of obtaining results from ChatGPT.
We use the prompt used in concurrent work (Jiao et al., 2023) which is shown below:
Please provide the [TGT] translation for these sentences:
{Sentence}
{Sentence}
Where T GT is the target language to be translated into, and Sentence is a sentence to be translated.
We sample 100 sentences from the test set of each language and evaluate translating this to and from",N/A,N/A
"English. We report the BLEU score (Papineni et al., 2002) which is calculated using SacreBLEU
(Post, 2018).
It has been shown that English prompts perform better, on average, than in-language prompts
(Lin et al., 2021; Shi et al., 2022), so we do not explore prompting in the target language for both
tasks.
4
RESULTS
4.1
TEXT CLASSIFICATION
Results are reported in table 1. As we can see, both commercial models fall well below the current",N/A,N/A
"state of the art. Surprisingly, Cohere’s multilingual embedding model is the worst performer, despite
supporting almost all the languages evaluated on. Nigerian Pidgin has the highest score in the Cohere
results. This is most likely as a result of its close linguistic relationship with English language, which
usually makes up a signiﬁcant portion of the pretraining corpora of pretrained language models",N/A,N/A
"(Wenzek et al., 2020; Gao et al., 2020; Laurenc¸on et al., 2022). ChatGPT is the best performing
commercial model, and it gets above average F1 scores on all languages. Similar to Cohere, Hausa
14https://docs.cohere.ai/docs/generation-card#technical-notes
4
AfricaNLP workshop at ICLR2022
Table 1: Text Classiﬁcation Results: We report the F1 scores for the commercial models. We also
report the current state of the art result obtained from Alabi et al. (2022). Best results per language",N/A,N/A
"are in bold.
Language
Cohere
ChatGPT
Current SOTA
Hausa (hau)
43.2
77.9
91.2
Malagasay (mlg)
35.0
51.1
67.3
Nigerian Pidgin (pcm)
48.8
73.4
82.2
Somali (som)
28.4
51.3
79.9
isiZulu (zul)
24.8
54.8
79.6
and Nigerian Pidgin possess the highest F1 scores. The details of ChatGPT’s pretraining corpora
and exact training methods are unknown, so it is hard to hypothesize a reason for its relatively
good performance. However, it is very likely that its pretraining corpora contains non-English text.",N/A,N/A
"Furthermore, multilinguality has been shown to be a part of possible emergent abilities of large
language models (Wei et al., 2022b), so the performance is not entirely surprising. Overall, both
commercial models fall signiﬁcantly short of the current state of the art. While ChatGPT is the
better performer, Cohere’s performance is especially surprising since it has been trained on almost
all of the evaluated languages15.
4.2
MACHINE TRANSLATION",N/A,N/A
"4.2
MACHINE TRANSLATION
Results are reported in table 2. ChatGPT has very poor performance on machine translation, ob-
taining BLEU scores of less than 1.0 on all languages. This is very surprising given its good per-
formance on text classiﬁcation. Our results agree with concurrent work (Abott et al., 2023) which
ﬁnds that GPT 3.5 obtains a BLEU score of 0 on Zulu to English translation. Our ﬁndings are",N/A,N/A
"also somewhat similar to (Jiao et al., 2023), which reports signiﬁcantly worse performance on Ro-
manian, a relatively low-resource language, than on higher-resource languages like English and
German. While the BLEU scores are too low to draw conclusions from, ChatGPT seems to perform
better when translating into English than from it. This agrees with previous works (Belinkov et al.,
2017; Bugliarello et al., 2020) which show that it is harder to translate into morphologically rich",N/A,N/A
"languages, like African ones, than morphologically poor ones like English. In general, our results
suggest that ChatGPT is not good enough for translation involving African languages. It also sug-
gests that ChatGPT performs better on sequence classiﬁcation tasks than it does on text generation
tasks for African languages.
5
ERROR ANALYSIS
We take a closer look at some errors made by the model on machine translation. Speciﬁcally, we",N/A,N/A
"focus on two languages - Yoruba and Nigerian Pidgin - because they are understood by the authors.
For each language, we randomly select 3 samples and discuss their predictions.
5.1
YORUBA TRANSLATIONS
Samples are shown in table 4. Looking at sample 1, ChatGPT mistranslates “B´ı omi b´a gb´on´a
ju b´ı ´o s.e ye. lo.” which means “When water becomes too hot” to “Water is poured into the con-
tainer”. Furthermore, the English to Yoruba translation is completely wrong and riddled with a lot",N/A,N/A
"of misspellings and grammatical errors. In sample 3, ChatGPT gets the translations wrong and also
transposes the words “ob`ınrin” (woman) and “ok`unrin” (man) in the translations. One notable ob-
servation across English to Yoruba translations is that ChatGPT does not always include diacritics
in its Yoruba predictions. Overall, ChatGPT does a really poor job in translating in either direc-
tion. The hallucinatory nature of the model predictions is evident, as all translations barely have any",N/A,N/A
"correlation with the original sentences.
15https://txt.cohere.ai/multilingual/
5
AfricaNLP workshop at ICLR2022
Table 2: Machine Translation Results: We report the BLEU scores of the translations from ChatGPT.
We also report the current state of the art result obtained from Adelani et al. (2022)
and NLLB Team et al. (2022). Best results per language are in bold.
Translation Direction
ChatGPT
Current SOTA
Lug→Eng
0.16
30.9
Eng→Lug
0.13
25.8
Pcm→Eng
0.22
45.2
Eng→Pcm
0.20
35.0
Swa→Eng
0.18
39.3",N/A,N/A
"0.22
45.2
Eng→Pcm
0.20
35.0
Swa→Eng
0.18
39.3
Eng→Swa
0.15
30.7
Yor→Eng
0.10
24.4
Eng→Yor
0.12
14.4
Zul→Eng
0.31
40.3
Eng→Zul
0.26
22.9
5.2
NIGERIAN PIDGIN TRANSLATIONS
Samples are shown in table 3. Looking at the Nigerian Pidgin sentences, we can see the language’s
linguistic similarity with English. Interestingly, while the ChatGPT predictions yield low BLEU
scores, they are somewhat semantically similar to the ground truth. However, there notable errors",N/A,N/A
"made across board. For example, focusing on the Nigerian Pidgin to English predictions in sample
2, there are tense errors. Also, the model seems to misunderstand what “numbers” refers to in the
input text, as its prediction indicates it confuses it for the number of goals. Furthermore, across
all samples, the model seems to be poor at translating certain English words to Nigerian Pidgin
words, such as “The” to “Di”, so it always retains the original English word. In general, while the",N/A,N/A
"predictions in both directions for all samples have notable issues, they are more semantically similar
to the ground truth than the BLEU scores suggests. This highlights the drawbacks of automatic
metrics based on N-gram overlap.
6
CONCLUSION
We have presented a preliminary analysis of commercial language models on African languages.
Joshi et al. (2020) note that over 90% of the world’s 7000+ languages are under-studied by the NLP",N/A,N/A
"community. Despite the 2000+ spoken languages and over 1 billion people in Africa16, its languages
make up a signiﬁcant portion of the under-studied languages (Blasi et al., 2022). While there have
been several efforts (∀et al., 2020; Ahia & Ogueji, 2020b; Adelani et al., 2021; Ogueji et al., 2021;
NLLB Team et al., 2022; Alabi et al., 2022; Dossou et al., 2022; Adebara et al., 2022) to close this",N/A,N/A
"gap, there is still a lot of work to be done. This is even more pertinent given the rapid commercial
adoption of large scale language models. Our ﬁndings suggest that these models do not perform
well on African languages. In particular, there seems to be performance disparity, depending on the
task evaluated. Although our work reports what is, to the best of our knowledge, the ﬁrst evaluation
of commercial language models on African languages, we note that this only a preliminary study",N/A,N/A
"that needs to be further advanced. Future works could focus on more advanced prompting methods
such as chain-of-thought (Wei et al., 2022c) and pivot prompting (Jiao et al., 2023), evaluation of
more test samples and a wider variety of tasks. While our ﬁnding may be impacted by the sampled
16https://en.wikipedia.org/wiki/Demographics_of_Africa
6
AfricaNLP workshop at ICLR2022
Table 3: Examples of Nigerian Pidgin translation using ChatGPT
Sample 1
Sample 2
Sample 3
Nigerian Pid-
gin Sentence",N/A,N/A
"Sample 2
Sample 3
Nigerian Pid-
gin Sentence
Commission head, Simon
Byabakama,
assure
di
nation on top live TV
for
Thursday
evening
afta polls don close say
result don dey enter for
di national tally centre
despite
di
nationwide
internet blackout
Di goal be give Eyimba
some hope as dem kontinu
to press for plunty nomba
to secure a point at least
Na im inauguartion be
di ﬁrst time wey elected
leaders dey handova give
each oda for Niger history
for over 60 years wey dem
don get independence, but",N/A,N/A
"don get independence, but
di attack from jihadist and
some kind plan to do coup
don spoil di celebrate.
English Sen-
tence
Commission head, Simon
Byabakama, assured the
nation on live TV on
Thursday
evening
after
polls closed that results
were arriving at the na-
tional tally centre despite
the
nationwide
internet
blackout.
The goal gave Enyimba
some hope as they contin-
ued to press in numbers to
at least secure a point
His inauguration marks
the
ﬁrst
handover
be-
tween
elected
leaders",N/A,N/A
"the
ﬁrst
handover
be-
tween
elected
leaders
in Niger’s 60-year post-
independence
history,
but jihadist attacks and
an
alleged
attempted
coup have overshadowed
ceremonies.
ChatGPT
Translation
Pcm→Eng
Commission head, Simon
Byabakama, assured the
nation on live TV on
Thursday
evening
after
the polls had closed that
the results were entering
the national tally center
despite the nationwide in-
ternet blackout.
The goal was to give Ey-
imba some hope as they
continue to press for a suf-",N/A,N/A
"continue to press for a suf-
ﬁcient number of goals to
secure at least one point.
The inauguration marked
the
ﬁrst
time
in
over
60 years of independence
that elected leaders have
handed
power
to
each
other in Niger’s history,
but attacks by jihadists
and plans for a coup have
disrupted the celebrations
ChatGPT
Translation
Eng→Pcm
Simon Byabakama wey
dey head the Commis-
sion, e talk for TV on
Thursday night after elec-
tion close say the result
don dey reach the centre
where dem dey count the",N/A,N/A
"don dey reach the centre
where dem dey count the
result even though inter-
net all over the place dey
cut.
The goal give Enyimba
some hope as dem still
dey press wey full force to
ﬁt get at least one point.
The day wey dem swear
am
for
ofﬁce,
na
the
ﬁrst time wey leader wey
get vote go hand over to
another leader since 60
years after independence
for Niger but the attacks
wey the bad people wey
dey carry gun dey do, and
the way wey dem try put
eye for the power no gree
am to happen make e no",N/A,N/A
"eye for the power no gree
am to happen make e no
dey sweet for the day.
test data, the use of the BLEU automatic metric (Callison-Burch et al., 2006; Mathur et al., 2020;
Freitag et al., 2020), prompting template and prompting examples, it nonetheless presents a call-to-
action to ensure African languages are well represented in the age of commercial large language
models.
7
AfricaNLP workshop at ICLR2022
Table 4: Examples of Yoruba translation using ChatGPT
Sample 1
Sample 2
Sample 3",N/A,N/A
"Sample 1
Sample 2
Sample 3
Yoruba Sen-
tence
B´ı omi b´a gb´on´a ju b´ı ´o s.e
ye. lo. (t`ab´ı b´ı ´o b´a tut`u j`u)
`awo.n iy`un y´o`o l`e ew`e omi
— t´ı y´o`o s´ı p`ad´an`u o.wo. t`o
´o ´n ﬁo`unje. n`u ´un.
K´ı ´o t´o de `e´er´oo `ago. n´a`a,
erin os. `u me.e.f`a n´a`a ti lu
ok`un.
`Ike.l`u t´ı ´o ko.
lu `awo.n
ob`ınrin wo.ny´ı (`ati `awo.n
o.k`unrin
kan)
ror`o
b´ı
e.ranko e.h`ann`a.
English Sen-
tence
When water becomes too
hot (or too cold) the corals
expel the algae — and",N/A,N/A
"expel the algae — and
with it, its main source of
food.
Before his arrival at the
camp, the six-month-old
was snared in a wire trap.
The
attacks
on
these
women (and some men)
are vicious and inhuman.
ChatGPT
Translation
Yor→Eng
Water is poured into the
container (or it is ﬁlled)
until the container is full -
when it overﬂows, the ex-
cess water is poured out.
If you do not pay attention
to your work, the work of
others will be affected.
The
tradition
requires
men to cover their heads",N/A,N/A
"The
tradition
requires
men to cover their heads
(and sometimes women
too) in public places.
ChatGPT
Translation
Eng→Yor
Ti omi ba n mu ki i fe.e.
(tabi ki i fe.e.) awo.n corals
ni wo.n ﬁomi omi po. - ati
ni ito.ju re., iru ibe.re. ti a n
pa.
Bayi o ti gba lo. si ibeere,
o.mo. to.lo.ti si igba ni a ti
dara ju o.nu.
`Id´am`o
ge.ge.
b´ı
i
`awo.
n
o.mo.-`om`o-w´e
(`ati
n´ı
k`ok`or`o)
n`ıy´ın
ni
`aj`ın`a
`ıw´ej`u `ıto.lo.mo. w´aj`u.
REFERENCES
Jade
Abott,
Bonaventure
Dossou,
and
Rooweither
Mbuya.",N/A,N/A
"Abott,
Bonaventure
Dossou,
and
Rooweither
Mbuya.
Com-
paring
africa-centric
models
to
openai’s
gpt3.5,
2023.
URL
https://lelapa.ai/comparing-africa-centric-models-to-openais-gpt3-5-2/.
Ife Adebara, AbdelRahim Elmadany, Muhammad Abdul-Mageed, and Alcides Alcoba In-
ciarte.
Serengeti:
Massively multilingual language models for africa, 2022.
URL
https://arxiv.org/abs/2212.10785.
David Adelani, Jesujoba Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter,",N/A,N/A
"Dietrich Klakow, Peter Nabende, Ernie Chang, Tajuddeen Gwadabe, Freshia Sackey, Bonaven-
ture F. P. Dossou, Chris Emezue, Colin Leong, Michael Beukman, Shamsuddeen Muhammad,
Guyo Jarso, Oreen Yousuf, Andre Niyongabo Rubungo, Gilles Hacheme, Eric Peter Wairagala,
Muhammad Umair Nasir, Benjamin Ajibade, Tunde Ajayi, Yvonne Gitau, Jade Abbott, Mo-
hamed Ahmed, Millicent Ochieng, Anuoluwapo Aremu, Perez Ogayo, Jonathan Mukiibi, Fa-",N/A,N/A
"toumata Ouoba Kabore, Godson Kalipe, Derguene Mbaye, Allahsera Auguste Tapo, Victoire
Memdjokam Koagne, Edwin Munkoh-Buabeng, Valencia Wagner, Idris Abdulmumin, Ayodele
Awokoya, Happy Buzaaba, Blessing Sibanda, Andiswa Bukula, and Sam Manthalu. A few thou-
sand translations go a long way! leveraging pre-trained models for African news translation. In
Proceedings of the 2022 Conference of the North American Chapter of the Association for Com-",N/A,N/A
"putational Linguistics: Human Language Technologies, pp. 3053–3070, Seattle, United States,
July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.223.
URL https://aclanthology.org/2022.naacl-main.223.
David Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D’souza, Julia Kreutzer, Constan-
tine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, Stephen",N/A,N/A
"Mayhew, Israel Abebe Azime, Shamsuddeen H. Muhammad, Chris Chinenye Emezue, Joyce
8
AfricaNLP workshop at ICLR2022
Nakatumba-Nabende, Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau, Derguene Mbaye, Je-
sujoba Alabi, Seid Muhie Yimam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani, Rubungo An-
dre Niyongabo, Jonathan Mukiibi, Verrah Otiende, Iroro Orife, Davis David, Samba Ngom,
Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chia-",N/A,N/A
"maka Chukwuneke, Nkiruka Odu, Eric Peter Wairagala, Samuel Oyerinde, Clemencia Siro, To-
bius Saul Bateesa, Temilola Oloyede, Yvonne Wambui, Victor Akinode, Deborah Nabagereka,
Maurice Katusiime, Ayodele Awokoya, Mouhamadane MBOUP, Dibora Gebreyohannes, Henok
Tilaye, Kelechi Nwaike, Degaga Wolde, Abdoulaye Faye, Blessing Sibanda, Orevaoghene
Ahia, Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo,
Adewale Akinfaderin, Tendai Marengereke, and Salomey Osei.",N/A,N/A
"MasakhaNER: Named En-
tity Recognition for African Languages.
Transactions of the Association for Computational
Linguistics, 9:1116–1131, 10 2021.
ISSN 2307-387X.
doi: 10.1162/tacl a 00416.
URL
https://doi.org/10.1162/tacl_a_00416.
Orevaoghene Ahia and Kelechi Ogueji. Towards supervised and unsupervised neural machine trans-
lation baselines for nigerian pidgin. ArXiv, abs/2003.12660, 2020a.
Orevaoghene Ahia and Kelechi Ogueji.
Towards supervised and unsupervised neural ma-",N/A,N/A
"Towards supervised and unsupervised neural ma-
chine translation baselines for nigerian pidgin.
CoRR, abs/2003.12660, 2020b.
URL
https://arxiv.org/abs/2003.12660.
Jesujoba O. Alabi, David Ifeoluwa Adelani, Marius Mosbach, and Dietrich Klakow.
Adapting
pre-trained language models to African languages via multilingual adaptive ﬁne-tuning. In Pro-
ceedings of the 29th International Conference on Computational Linguistics, pp. 4336–4349,",N/A,N/A
"Gyeongju, Republic of Korea, October 2022. International Committee on Computational Lin-
guistics. URL https://aclanthology.org/2022.coling-1.382.
Mikel Artetxe, Gorka Labaka, and Eneko Agirre.
Translation artifacts in cross-lingual
transfer learning.
In Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 7674–7684, Online, November 2020. Asso-
ciation for Computational Linguistics.
doi:
10.18653/v1/2020.emnlp-main.618.
URL",N/A,N/A
"doi:
10.18653/v1/2020.emnlp-main.618.
URL
https://aclanthology.org/2020.emnlp-main.618.
Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do neural
machine translation models learn about morphology? In Proceedings of the 55th Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 861–872, Vancou-
ver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1080.",N/A,N/A
"URL https://aclanthology.org/P17-1080.
Damian Blasi, Antonios Anastasopoulos, and Graham Neubig. Systematic inequalities in language
technology performance across the world’s languages. In Proceedings of the 60th Annual Meet-
ing of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5486–5505,
Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.
acl-long.376. URL https://aclanthology.org/2022.acl-long.376.",N/A,N/A
"Terra Blevins and Luke Zettlemoyer. Language contamination helps explain the cross-lingual capa-
bilities of english pretrained models, 2022. URL https://arxiv.org/abs/2204.08110.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,",N/A,N/A
"Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz
Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei.
Language models are few-shot learners.
In
H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural
Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL",N/A,N/A
"https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Pap
Emanuele Bugliarello, Sabrina J. Mielke, Antonios Anastasopoulos, Ryan Cotterell, and Naoaki
Okazaki. It’s easier to translate out of English than into it: Measuring neural translation difﬁculty
by cross-mutual information. In Proceedings of the 58th Annual Meeting of the Association for
9
AfricaNLP workshop at ICLR2022
Computational Linguistics, pp. 1640–1649, Online, July 2020. Association for Computational",N/A,N/A
"Linguistics. URL https://www.aclweb.org/anthology/2020.acl-main.149.
Chris Callison-Burch, Miles Osborne, and Philipp Koehn. Re-evaluating the role of Bleu in ma-
chine translation research. In 11th Conference of the European Chapter of the Association for
Computational Linguistics, pp. 249–256, Trento, Italy, April 2006. Association for Computa-
tional Linguistics. URL https://aclanthology.org/E06-1032.
Ernie Chang,
David Ifeoluwa Adelani,
Xiaoyu Shen,
and Vera Demberg.
Unsuper-",N/A,N/A
"Xiaoyu Shen,
and Vera Demberg.
Unsuper-
vised pidgin text generation by pivoting english data and self-training, 2020.
URL
https://arxiv.org/abs/2003.08272.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,
Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam",N/A,N/A
"Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James
Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-
skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin
Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret
Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,",N/A,N/A
"Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-
nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas
Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,
2022. URL https://arxiv.org/abs/2204.02311.
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan",N/A,N/A
"Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu,
Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pel-
lat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao,
Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,
Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-ﬁnetuned language
models, 2022. URL https://arxiv.org/abs/2210.11416.",N/A,N/A
"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
BERT: Pre-training of
deep bidirectional transformers for language understanding. In Proceedings of the 2019 Con-
ference of the North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Min-
nesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL
https://www.aclweb.org/anthology/N19-1423.",N/A,N/A
"https://www.aclweb.org/anthology/N19-1423.
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun,
Jingjing Xu, Lei Li, and Zhifang Sui.
A survey for in-context learning, 2023.
URL
https://arxiv.org/abs/2301.00234.
Bonaventure F. P. Dossou, Atnafu Lambebo Tonja, Oreen Yousuf, Salomey Osei, Abigail Oppong,
Iyanuoluwa Shode, Oluwabusayo Olufunke Awoyomi, and Chris Chinenye Emezue. Afrolm: A",N/A,N/A
"self-active learning-based multilingual pretrained language model for 23 african languages, 2022.
Nicholas Faraclas. Nigerian pidgin english: morphology and syntax. Varieties of English: Africa,
South and Southeast Asia, 4:340–367, 2008.
∀, Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa, Tajudeen Kolawole,
Taiwo Fagbohungbe, Solomon Oluwole Akinola, Shamsuddee Hassan Muhammad, Salomon",N/A,N/A
"Kabongo, Salomey Osei, et al. Participatory research for low-resourced machine translation:
A case study in african languages. Findings of EMNLP, 2020.
Markus Freitag, David Grangier, and Isaac Caswell.
BLEU might be guilty but refer-
ences are not innocent.
In Proceedings of the 2020 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), pp. 61–71, Online, November 2020. As-
sociation for Computational Linguistics.
doi:
10.18653/v1/2020.emnlp-main.5.
URL",N/A,N/A
"doi:
10.18653/v1/2020.emnlp-main.5.
URL
https://aclanthology.org/2020.emnlp-main.5.
10
AfricaNLP workshop at ICLR2022
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason
Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile:
An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.
Michael A. Hedderich, David Adelani, Dawei Zhu, Jesujoba Alabi, Udia Markus, and Diet-
rich Klakow.",N/A,N/A
"rich Klakow.
Transfer learning and distant supervision for multilingual transformer mod-
els: A study on African languages.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP), pp. 2580–2591, Online, November 2020.
Association for Computational Linguistics.
doi: 10.18653/v1/2020.emnlp-main.204.
URL
https://www.aclweb.org/anthology/2020.emnlp-main.204.
Jeremy Howard and Sebastian Ruder.
Universal language model ﬁne-tuning for text clas-
siﬁcation.",N/A,N/A
"siﬁcation.
In Proceedings of the 56th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1:
Long Papers), pp. 328–339, Melbourne, Australia, July
2018. Association for Computational Linguistics.
doi:
10.18653/v1/P18-1031.
URL
https://aclanthology.org/P18-1031.
Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. Is chatgpt a good
translator? a preliminary study, 2023. URL https://arxiv.org/abs/2301.08745.",N/A,N/A
"Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. The state and
fate of linguistic diversity and inclusion in the NLP world.
In Proceedings of the 58th An-
nual Meeting of the Association for Computational Linguistics, pp. 6282–6293, Online, July
2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.560. URL
https://aclanthology.org/2020.acl-main.560.
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,",N/A,N/A
"Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language
models. CoRR, abs/2001.08361, 2020. URL https://arxiv.org/abs/2001.08361.
Hugo Laurenc¸on, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral,
Teven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo Gonz´alez Ponferrada, Huu
Nguyen, J¨org Frohberg, Mario ˇSaˇsko, Quentin Lhoest, Angelina McMillan-Major, G´erard",N/A,N/A
"Dupont, Stella Biderman, Anna Rogers, Loubna Ben allal, Francesco De Toni, Giada Pis-
tilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa,
Paulo Villegas, Tristan Thrush, Shayne Longpre, Sebastian Nagel, Leon Weber, Manuel Romero
Mu˜noz, Jian Zhu, Daniel Van Strien, Zaid Alyafeai, Khalid Almubarak, Vu Minh Chien, Itziar
Gonzalez-Dios, Aitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz Suarez, Aaron Gokaslan, Shamik",N/A,N/A
"Bose, David Ifeoluwa Adelani, Long Phan, Hieu Tran, Ian Yu, Suhas Pai, Jenny Chim, Vio-
lette Lepercq, Suzana Ilic, Margaret Mitchell, Sasha Luccioni, and Yacine Jernite.
The big-
science ROOTS corpus: A 1.6TB composite multilingual dataset.
In Thirty-sixth Confer-
ence on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL
https://openreview.net/forum?id=UoEw6KigkUn.
Heather
Lent,
Emanuele
Bugliarello,
Miryam
de
Lhoneux,
Chen
Qiu,
and
Anders
Søgaard.",N/A,N/A
"Miryam
de
Lhoneux,
Chen
Qiu,
and
Anders
Søgaard.
On language models for creoles.
In Proceedings of the 25th Confer-
ence on Computational Natural Language Learning, pp. 58–71, Online, November 2021.
Association for Computational Linguistics.
doi:
10.18653/v1/2021.conll-1.5.
URL
https://aclanthology.org/2021.conll-1.5.
Heather Lent, Kelechi Ogueji, Miryam de Lhoneux, Orevaoghene Ahia, and Anders Søgaard. What",N/A,N/A
"a creole wants, what a creole needs. In Proceedings of the Thirteenth Language Resources and
Evaluation Conference, pp. 6439–6449, Marseille, France, June 2022. European Language Re-
sources Association. URL https://aclanthology.org/2022.lrec-1.691.
Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle
Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh",N/A,N/A
"Koura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva,
Mona T. Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual language
models. CoRR, abs/2112.10668, 2021. URL https://arxiv.org/abs/2112.10668.
11
AfricaNLP workshop at ICLR2022
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen.
What makes good in-context examples for GPT-3?
In Proceedings of Deep Learn-
ing Inside Out (DeeLIO 2022):",N/A,N/A
"ing Inside Out (DeeLIO 2022):
The 3rd Workshop on Knowledge Extraction and Inte-
gration for Deep Learning Architectures, pp. 100–114, Dublin, Ireland and Online, May
2022. Association for Computational Linguistics.
doi: 10.18653/v1/2022.deelio-1.10.
URL
https://aclanthology.org/2022.deelio-1.10.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pre-",N/A,N/A
"training approach. arXiv preprint, abs/1907.11692, 2019.
Nitika Mathur, Timothy Baldwin, and Trevor Cohn. Tangled up in BLEU: Reevaluating the eval-
uation of automatic machine translation evaluation metrics.
In Proceedings of the 58th An-
nual Meeting of the Association for Computational Linguistics, pp. 4984–4997, Online, July
2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.448. URL
https://aclanthology.org/2020.acl-main.448.",N/A,N/A
"https://aclanthology.org/2020.acl-main.448.
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le
Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,
Edward Raff, and Colin Raffel. Crosslingual generalization through multitask ﬁnetuning, 2022.
URL https://arxiv.org/abs/2211.01786.",N/A,N/A
"URL https://arxiv.org/abs/2211.01786.
NLLB Team, Marta R. Costa-juss`a, James Cross, Onur C¸ elebi, Maha Elbayad, Kenneth Heaﬁeld,
Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler
Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez,
Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shan-
non Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela",N/A,N/A
"Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm´an, Philipp Koehn, Alexandre Mourachko,
Christophe Ropers, Saﬁyyah Saleem, Holger Schwenk, and Jeff Wang. No language left behind:
Scaling human-centered machine translation, 2022.
Kelechi Ogueji and Orevaoghene Ahia. PidginUNMT: Unsupervised Neural Machine Translation
from West African Pidgin to English. ArXiv, abs/1912.03444, 2019.
Kelechi Ogueji, Yuxin Zhu, and Jimmy Lin.
Small data?
No Problem!
exploring the vi-",N/A,N/A
"Small data?
No Problem!
exploring the vi-
ability of pretrained multilingual language models for low-resourced languages.
In Pro-
ceedings of the 1st Workshop on Multilingual Representation Learning, pp. 116–126, Punta
Cana, Dominican Republic, November 2021. Association for Computational Linguistics. URL
https://aclanthology.org/2021.mrl-1.11.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,",N/A,N/A
"Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob
Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul
Christiano, Jan Leike, and Ryan Lowe.
Training language models to follow instruc-
tions with human feedback.
In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.
URL
https://openreview.net/forum?id=TG8KACxEON.",N/A,N/A
"URL
https://openreview.net/forum?id=TG8KACxEON.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
Bleu: a method for auto-
matic evaluation of machine translation.
In Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics, pp. 311–318, Philadelphia, Pennsylvania, USA,
July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL
https://aclanthology.org/P02-1040.",N/A,N/A
"https://aclanthology.org/P02-1040.
Edoardo Maria Ponti, Goran Glavaˇs, Olga Majewska, Qianchu Liu, Ivan Vuli´c, and Anna Korhonen.
XCOPA: A multilingual dataset for causal commonsense reasoning. In Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 2362–2376,
Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.
emnlp-main.185. URL https://aclanthology.org/2020.emnlp-main.185.
12
AfricaNLP workshop at ICLR2022",N/A,N/A
"12
AfricaNLP workshop at ICLR2022
Matt
Post.
A
call
for
clarity
in
reporting
BLEU
scores.
In
Proceedings
of
the Third Conference on Machine Translation:
Research Papers,
pp. 186–191, Bel-
gium,
Brussels,
October
2018.
Association
for
Computational
Linguistics.
URL
https://www.aclweb.org/anthology/W18-6319.
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language
models are unsupervised multitask learners, 2019.",N/A,N/A
"models are unsupervised multitask learners, 2019.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed
text-to-text transformer.
Journal of Machine Learning Research, 21(140):1–67, 2020.
URL
http://jmlr.org/papers/v21/20-074.html.
Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine",N/A,N/A
"Chafﬁn, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker,
Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De-
bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,
Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,
Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le",N/A,N/A
"Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. Multitask prompted
training enables zero-shot task generalization. In International Conference on Learning Repre-
sentations, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.
Timo Schick and Hinrich Sch¨utze. It’s not just size that matters: Small language models are also few-
shot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Asso-",N/A,N/A
"ciation for Computational Linguistics: Human Language Technologies, pp. 2339–2352, Online,
June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.185.
URL https://aclanthology.org/2021.naacl-main.185.
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi,
Hyung Won Chung,
Yi Tay,
Sebastian Ruder, Denny Zhou, Dipanjan Das,
and Ja-
son Wei.
Language models are multilingual chain-of-thought reasoners, 2022.
URL",N/A,N/A
"URL
https://arxiv.org/abs/2210.03057.
Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. Black-box tuning for
language-model-as-a-service. In Proceedings of ICML, 2022.
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester,
Nan Du, Andrew M. Dai, and Quoc V Le.
Finetuned language models are zero-
shot learners.
In International Conference on Learning Representations, 2022a.
URL
https://openreview.net/forum?id=gEZrGCozdqR.",N/A,N/A
"URL
https://openreview.net/forum?id=gEZrGCozdqR.
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani
Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto,
Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.
Emergent abilities of large lan-
guage models. Transactions on Machine Learning Research, 2022b. ISSN 2835-8856. URL
https://openreview.net/forum?id=yzkSU5zdwD. Survey Certiﬁcation.",N/A,N/A
"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H.
Chi,
Quoc V Le,
and Denny Zhou.
Chain of thought prompting elicits reasoning
in large language models.
In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022c.
URL
https://openreview.net/forum?id=_VjQlMeSB_J.
Guillaume
Wenzek,
Marie-Anne
Lachaux,
Alexis
Conneau,
Vishrav
Chaudhary,
Fran-
cisco Guzm´an, Armand Joulin, and Edouard Grave.",N/A,N/A
"cisco Guzm´an, Armand Joulin, and Edouard Grave.
CCNet:
Extracting high qual-
ity monolingual datasets from web crawl data.
In Proceedings of the 12th Lan-
guage Resources and Evaluation Conference, pp. 4003–4012, Marseille, France, May
2020. European Language Resources Association.
ISBN 979-10-95546-34-4.
URL
https://www.aclweb.org/anthology/2020.lrec-1.494.
13
AfricaNLP workshop at ICLR2022
Genta Indra Winata, Andrea Madotto, Zhaojiang Lin, Rosanne Liu, Jason Yosinski, and Pascale",N/A,N/A
"Fung. Language models are few-shot multilingual learners. In Proceedings of the 1st Workshop
on Multilingual Representation Learning, pp. 1–15, Punta Cana, Dominican Republic, Novem-
ber 2021. Association for Computational Linguistics.
doi: 10.18653/v1/2021.mrl-1.1. URL
https://aclanthology.org/2021.mrl-1.1.
Xinyan Velocity Yu, Akari Asai, Trina Chatterjee, Junjie Hu, and Eunsol Choi. Beyond counting
datasets: A survey of multilingual dataset construction and necessary resources. In Findings of",N/A,N/A
"EMNLP, 2022.
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan
Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang
Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. Glm-130b: An open bilingual pre-trained model.
arXiv preprint arXiv:2210.02414, 2022.
Biao Zhang, Barry Haddow, and Alexandra Birch. Prompting large language model for machine
translation: A case study, 2023. URL https://arxiv.org/abs/2301.07069.",N/A,N/A
"Mengjie Zhao and Hinrich Sch¨utze.
Discrete and soft prompting for multilingual models.
In
Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process-
ing, pp. 8547–8555, Online and Punta Cana, Dominican Republic, November 2021. As-
sociation for Computational Linguistics.
doi:
10.18653/v1/2021.emnlp-main.672.
URL
https://aclanthology.org/2021.emnlp-main.672.
14",N/A,N/A
"Natural Language Processing using Hadoop and KOSHIK 
Hong Shi, Emre Erturk  
Eastern Institute of Technology, New Zealand 
 
Abstract 
Natural language processing, as a data analytics related technology, is used widely in many 
research areas such as artificial intelligence, human language processing, and translation. At 
present, due to explosive growth of data, there are many challenges for natural language",N/A,N/A
"processing. Hadoop is one of the platforms that can process the large amount of data required for 
natural language processing. KOSHIK is one of the natural language processing architectures, and 
utilizes Hadoop and contains language processing components such as Stanford CoreNLP and 
OpenNLP. This study describes how to build a KOSHIK platform with the relevant tools, and provides 
the steps to analyze wiki data. Finally, it evaluates and discusses the advantages and disadvantages",N/A,N/A
"of the KOSHIK architecture, and gives recommendations on improving the processing performance.  
1. Introduction 
1.1. Natural Language Processing 
Natural language processing (NLP) is a technique to analyze readable text that is generated by 
humans for artificial intelligence, language processing, and translation (Behzadi, 2015). In order to 
accurately analyze the text, there are some methods for NLP to use in order to deal with the",N/A,N/A
"challenges such as the collection and storage of the text corpus, and analysis. NLP techniques also 
gain experience and benefits through research in linguistics, computational statics, artificial 
intelligence, machine learning and other sciences (Behzadi, 2015). However, at present, because 
of the information explosion, the use of traditional NLP faces many challenges such as the volume 
of structured and unstructured data, velocity of processing data, accuracy of the results. In addition,",N/A,N/A
"there are many slangs and ambiguous expressions used on social media networks, which give NLP 
pressure to analyze the meanings, which may also be hard for some people. Moreover, people 
nowadays heavily depend on search engines like Google and Bing (which use NLP as their core 
technique) in their daily study, work, and entertainment. All of these factors encourage computer 
scientists and researchers to find more robust, efficient and standardized solutions for NLP.  
1.2. Big Data",N/A,N/A
"1.2. Big Data 
Big Data is designed as generic platform to resolve the issues of volume, velocity, variety, 
veracity and value in data analytics (IBM, 2012). The data is collected from different sources, for 
example, daily logs, social media, and business transactions. Big Data demands the ability to hoard 
large amounts of data. With advanced storage technologies, the data size could be as high as",N/A,N/A
"terabytes (1012 bytes), petabytes (1015 bytes) and exabytes (1018 bytes). Furthermore, research on 
NLP often overlaps with research on or the use of Big Data platforms. Big Data handles all types of 
formats which are structured and unstructured. The structured data is readable and well-designed 
that is commonly stored in traditional relationship databases. Unstructured data does not have a 
predefined format. This type of data can be found in, for example, emails, images, and videos. Big",N/A,N/A
"Data is widely used in business forecasts, scientific research, analysis of social issues, healthcare, 
and meteorology. While promoting advances in NLP, it is also important to be aware of ethical 
issues around the potential misuse and dual-use of big data and NLP tools (Hovy & Spruit, 2016). 
1 
 
Some of these issues can be very interesting for information technology students to debate and 
learn more about (Erturk, 2013).  
1.3. Hadoop",N/A,N/A
"learn more about (Erturk, 2013).  
1.3. Hadoop 
Hadoop is a application created using Java, and provides a set of tools to do data processing 
which includes data storage, access, analysis (White, 2012). According to White (2012), the main 
components in Hadoop are HDFS (Hadoop distributed file system) and MapReduce. HDFS is solid 
and fault-tolerant, and provides a Java-based API that integrates with MapReduce to process the",N/A,N/A
"large data in parallel using a cluster of servers (Taylor, 2010). As Murthy, Padmakar and Reddy (2015) 
observed, traditional relational databases, which store structured data, could also be used together 
with Hadoop HDFS with full database management systems (DBMS) features. MapReduce is 
created with inspiration from the theory published by Google, and it provides functions that split 
large set of data computing into small computing tasks (White, 2012).",N/A,N/A
"1.4. Natural Language Processing on Hadoop 
Idealy, Hadoop, with the features of distributed storage system, multi-tasks processing system, 
generic platform and open source, can be used for NLP research. There are many papers discussing 
the solutions which utilize Hadoop for NLP. For example, HDFS is used in the research of Markham, 
Kowolenko and Michaelis (2015) to manage large amount of unstructured data, which was",N/A,N/A
"collected from the Internet with Hadoop tools. Idris, Hussain, Siddiqi, Hassan, Bilal and Lee (2015) 
designed a system named MRPack which gives an end-to-end MapReduce processing model for 
text processing, which includes a job task for NLP. MRPack shows it has better performance in data 
accessing, data managing and data writing, as well as less programming work and demanding for 
I/O management (Idris et al., 2015).",N/A,N/A
"I/O management (Idris et al., 2015). 
This study reviews KOSHIK, a Hadoop based framework which has been developed from the 
paper written by Exner and Nugues (2014). Then it gives the findings for what Hadoop components 
this framework used, and recommendations to improve the NLP performance. Finally, it shows the 
steps to test KOSHIK.  
2. Literature Review 
2.1. Introduction 
It is described that “KOSHIK is a framework for batch-oriented large scale-processing and",N/A,N/A
"querying of unstructured natural language documents. In particular, it builds on the Hadoop 
ecosystem and takes full advantage of the data formats and tools present in this environment to 
achieve its task” (Exner & Nugues, 2014, p. 463). KOSHIK tries to resolve the common challenges 
in NLP such as volume, velocity, and variety by adopting Hadoop for the system infrastructure, 
using a batch-oriented annotation model to continually add annotations and enabling a generic",N/A,N/A
"algorithm platform to analyze the variety of text (Exner & Nugues, 2014). It is also argued that 
before developing KOSHIK, there were many other NLP frameworks such as MULTEXT, GATE, and 
UIMA, which were important for document retrieval, indexing, and querying of processed 
information applications (Exner & Nugues, 2014). 
2 
 
2.2. KOSHIK Architecture 
 
Figure 1. An overview of the KOSHIK architecture. (Exner & Nugues, 2014).",N/A,N/A
"Exner and Nugues (2014) stated that “KOSHIK supports a variety of NLP tools implemented 
atop of the Hadoop distributed computing framework. The requirements on KOSHIK were driven 
by the desire to support scalability, reliability, and a large number of input formats and processing 
tasks”. KOSHIK supports different kinds of documents such as CoNLL-X, CoNLL 2008 and 2009 and 
Wikipedia dump files (Exner & Nugues, 2014; Buchholz and Marsi, 2006; Surdeanu et al., 2008). In",N/A,N/A
"order to analyze different kinds of language, KOSHIK involves a large set of filters, tokenizers, 
taggers, parsers, and coreference solvers through several language specific NLP tools such as 
OpenNLP, Mate Tools, Stanford CoreNLP, etc. (Exner & Nugues, 2014). With the developed 
annotation model in KOSHIK, this framework could simplify the process of content processors, 
which only require computing resource focus on the input and output of annotated documents 
(Exner & Nugues, 2014).",N/A,N/A
"(Exner & Nugues, 2014). 
KOSHIK utilizes Hadoop as its distributed computing framework, which not only used for a 
better performance on large corpus analysis, but also for the division and distribution of a set of 
documents, management of processing jobs, and to get the process result (Exner & Nugues, 2014). 
Pig and Hive which are core members of Hadoop ecosystem are adopted into this framework to 
manage the workflows for processing large data-sets and easily query information by SQL-like",N/A,N/A
"language respectively (Exner & Nugues, 2014). 
3. Key Terms 
After evaluating this paper, Hive and Pig which are data querying components of Hadoop, and 
OpenNLP and Stanford CoreNLP which are NLP process tools are identified for future research. 
According to Thusoo et al. (2009), Hive is a data warehouse infrastructure built based on 
Hadoop for providing data summarization, query, and analysis. It could be used to deal with large",N/A,N/A
"distributed data such as HDFS and traditional file systems like FAT, NTFS and exFat (Thusoo et al., 
2009). In addition, HiveQL, a SQL-like language, is created to query data on Hadoop which will 
translate the query to MapReduce jobs for high performance (Thusoo et al., 2009). 
 
3 
 
The Pig is a high-level declarative querying language inspired by SQL which will translate the 
query to MapReduce jobs (Pis Olston, Reed, Srivastava, Kumar & Tomkins, 2008). According to",N/A,N/A
"Gates et al. (2009), there are many data analysis projects which adopted Pig because it is easy to 
learn and use, and could quickly implement different versions of algorithms. 
Lingad, Karimi and Yin (2013) found that “OpenNLP is a Java based library for various natural 
language processing tasks, such as tokenization, part-of-speech (POS) tagging, and named entity 
recognition. For named entity recognition, it trains a Maximum Entropy model using the",N/A,N/A
"information from the whole document to recognize entities in documents”. Although OpenNLP 
provides many functions for NLP, the model to process the document should be considered that 
Verspoor (2012) argued that OpenNLP has low quality to divide sentence into parts, but it could 
improve the performance by using annotator. 
Stanford CoreNLP is a NLP tool and utilizes annotation to analyse text that it provides most of",N/A,N/A
"the common core NLP steps, from tokenization through to coreference resolution (Manning, 2014). 
It is also described that Stanford CoreNLP provides a complete toolkit and tools for grammatical 
analysis, accurate analysis, and supports different kinds of languages (Manning, 2014).  
4. Testing KOSHIK 
4.1. Preparing the Hardware Environment 
According to Exner and Nugues (2014), KOSHIK runs on Hadoop with Hive, and requires other",N/A,N/A
"NLP process libraries (OpenNLP, Mate and Stanford CoreNLP). The experimental environment 
(including hardware, software, and test data) used in this paper is described in the following tables.  
 
Hardware Environment 
Hardware 
Description 
CPU 
INTEL i5 quad cores 2.7Ghz  
Hard disk 
SATA 500G 
Memory 
DDR3 16G 
Graphic Card 
NVidia 940 
Network 
1G LAN 
 
Software Environment 
Operation 
System/application/library 
Version 
Operation System 
Centos 6.7 
KOSHIK 
1.01 
JAVA 
1.80 
Hadoop",N/A,N/A
"Centos 6.7 
KOSHIK 
1.01 
JAVA 
1.80 
Hadoop 
2.60 
Hive 
1.1.0 
Cloudera 
5.70 
Hue 
3.90 
VirtualBox 
5.0.20 
Stanford CoreNLP 
3.6 
OpenNLP 
1.5.0 
Mate 
 
 
Test Data 
Item 
Description 
Wiki Data 
12GB English wiki data. 
 
4 
 
In this test environment, Cloudera Quickstart VM is utilized to quickly construct the software 
environment. According to Cloudera (2016), Cloudera Quickstart VM is a virtual machine which",N/A,N/A
"installed most of the applications related to Hadoop such as Hive, Spark, HBase. One benefit to use 
this virtual machine is that it has already configured Hadoop and integrated with Hive, HBase and 
Hue, which is a management tool for applications in Hadoop ecosystem (Cloudera, 2016). 
Therefore, it is an ideal platform for researching and making proof of concept. 
4.2. Preparing the Software 
4.2.1. Download software and wiki data",N/A,N/A
"4.2.1. Download software and wiki data 
The following table list the download links for the required software. 
Software 
Link 
KOSHIK 
https://github.com/peterexner/KOSHIK 
Cloudera Quickstart VM 
http://www.cloudera.com/downloads/quickstart_vms/5-
7.html 
VirtualBox 
https://www.virtualbox.org/wiki/Downloads 
Stanford CoreNLP 
http://nlp.stanford.edu/software/corenlp.shtml 
OpenNLP 
http://opennlp.sourceforge.net/models-1.5/ 
Mate 
https://code.google.com/p/mate-tools/downloads/list",N/A,N/A
"WikiData 
https://dumps.wikimedia.org/enwiki/20160501/enwiki-
20160501-pages-articles.xml.bz2 
 
4.2.2. Configure software 
The following table describes steps to configure the required software. 
Software 
Step Description 
VirtualBox 
1. Unzip Cloudera Quickstart VM. 
2. Import the unzipped Cloudera Quickstart 
VM into VirtualBox. 
KOSHIK required libraries 
1. Create a folder anywhere named model. 
2. Create a folder named is2 in model folder 
and put downloaded files CoNLL2009-ST-",N/A,N/A
"and put downloaded files CoNLL2009-ST-
English-ALL.anna-3.3.lemmatizer.model, 
CoNLL2009-ST-English-ALL.anna-
3.3.parser.model, CoNLL2009-ST-English-
ALL.anna-3.3.postagger.model in it. 
3. Create a folder named lth in model folder 
and put downloaded file CoNLL2009-ST-
English-ALL.anna-3.3.srl-4.1.srl.model in 
it. 
4. Create a folder named opennlp in model 
folder and put downloaded file en-
sent.bin in it. 
5. Compress the model folder to model.zip. 
Virtual Machine.",N/A,N/A
"Virtual Machine. 
1. Start virtual machine. 
2. Create a folder named koshik_test. 
3. Copy 
enwiki-20160501-pages-
articles.xml.bz2 to koshik_test folder. 
4. Copy downloaded KOSHIK to koshik_test 
folder. 
5. Copy model.zip to koshik_test folder. 
Hadoop 
1. Under koshik_test folder, copy enwiki-
20160501-pages-articles.xml.bz2 
to 
Hadoop file system. 
5 
 
 
4.3. Testing 
The following show the steps to test KOSHIK to analyze the WIKI data. Steps 4, 5, and 6 are similar",N/A,N/A
"to those mentioned by Nugues (2014).  
 
Step 
Description 
Command 
1 
Import WIKI data 
into KOSHIK. 
hadoop jar Koshik-1.0.1.jar se.lth.cs.koshik.util.Import -input 
/enwiki-20160501-pages-articles.xml -inputformat wikipedia -
language eng -charset utf-8 -output /enwiki_avro 
2 
Start KOSHIK map-
reduce 
jobs 
to 
analyze the data. 
hadoop jar Koshik-1.0.1.jar se.lth.cs.koshik.util.EnglishPipeline -D 
mapred.reduce.tasks=12 -D mapred.child.java.opts=-Xmx8G -",N/A,N/A
"archives model.zip -input /enwiki_avro -output 
/enwiki_semantic 
3 
Import 
the 
analyzed 
result 
into 
Hive 
for 
querying. 
CREATE EXTERNAL TABLE koshikdocs ROW FORMAT SERDE 
'org.apache.hadoop.hive.serde2.avro.AvroSerDe' 
STORED 
AS 
INPUTFORMAT 
'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat' 
OUTPUTFORMAT 
'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat' 
LOCATION 
'/hivetablekoshik' 
TBLPROPERTIES('avro.schema.url'='hdfs:///AvroDocument.avsc');",N/A,N/A
"LOAD DATA INPATH '/enwiki_semantic/*.avro' INTO TABLE 
koshikdocs; 
4 
Query number of 
analyzed articles. 
SELECT count(identifier) from koshikdocs; 
SELECT count(key) FROM (SELECT explode(ann) AS (key,value) 
FROM 
(SELECT 
ann 
FROM 
koshikdocs 
LATERAL 
VIEW 
explode(annotations.features) annTable as ann) annmap) 
decmap WHERE key='POSTAG' AND value LIKE 'NN%'; 
5 
Query number of 
sentences 
SELECT 
count(ann) 
FROM 
koshikdocs 
LATERAL 
VIEW",N/A,N/A
"count(ann) 
FROM 
koshikdocs 
LATERAL 
VIEW 
explode(annotations.layer) annTable as ann WHERE ann LIKE 
'%Sentence'; 
6 
Query number of 
nouns. 
SELECT count(key) FROM (SELECT explode(ann) AS (key,value) 
FROM (SELECT ann FROM koshikdocs LATERAL VIEW 
explode(annotations.features) annTable as ann) annmap) 
decmap WHERE key='POSTAG' AND value LIKE 'NN%'; 
 
5. Findings: Advantages and Disadvantages of KOSHIK",N/A,N/A
"KOSHIK provides an architecture which utilizes Hadoop and related tools as well as individual 
NLP tools and language models, and simplifies the construction of a whole NLP system. By adopting 
this architecture, people who work with an NLP system could focus on their own professional areas. 
For example, linguists could focus on creating effective language models to improve the accuracy 
of NLP, while algorithm designers could provide high performance NLP analysis components. When",N/A,N/A
"KOSHIK uses the sentence detection component from Mate and Stanford, it has the potential to 
process other human languages in the future, if the NLP tools continue to add new language 
models. Another advantage is that KOSHIK supports different kinds of document types, and it is 
given related APIs to expand the compatible document types. Moreover, with HDFS, KOSHIK has 
the ability to analyze a large sets of data with high input and output performance. The data",N/A,N/A
"processing can be passed on to MapReduce, which will provide more computing power as required.  
Currently, KOSHIK has not yet become a mature product that is ready to be used by businesses. 
6 
 
First, it lacks support and documentation, and the learning curve for this tool is high. For example, 
this tool utilizes the language models of Mate, OpenNLP and Stanford CoreNLP. However, there are 
too many components for the user to discern which one KOSHIK is using for a particular task.",N/A,N/A
"Perhaps only its developers can see it from the source code. Secondly, since the last recorded 
change of code, this tool has not been maintained regularly, and there has not been any update 
for almost two years. It is uncertain whether this tool will have more functions and a stable version. 
6. Conclusions 
Natural language processing plays an important role in search engines, speech to text",N/A,N/A
"conversion tools, intelligent assistants, and artificial intelligence. It will continue to influence the 
user experience on the internet. With more and more data generated, there will be different kinds 
of data processed on Big Data platforms. Hadoop provides useful tools and has a mature ecosystem 
which is ideal for natural language processing. There are already some research reports, and 
software tools for natural language processing utilizing Hadoop. KOSHIK is one that provides an",N/A,N/A
"NLP architecture which utilizes Hadoop and Hive to process large amount of data. It is friendly for 
developers and linguists because it can separate these two types of work and allow each of them 
to focus on their own areas, thereby increasing the performance of NLP system. The architecture 
of KOSHIK is expandable; so it provides APIs to add new functions for the system. By utilizing 
OpenNLP, Mate and Stanford CoreNLP, KOSHIK supports different types of natural language",N/A,N/A
"processing. Documentation for KOSHIK is required to learn this tool, and to enable other 
developers to contribute toward it. However, because the source code has not been updated for a 
while, it is not ready for business use, but rather for personal testing and development. 
7. Recommendations 
Based on the architecture of KOSHIK and the process speed of large data, this architecture 
could increase processing speed by adopting Spark and GPU processing.",N/A,N/A
"Spark is a cluster computing system maintained by Apache and it supports in-memory 
computing. This can improve the data analysis speed as high as possible, compared to the original 
MapReduce method in Hadoop (Zaharia, Chowdhury, Franklin, Shenker & Stoica, 2010). Based on 
the test results of Zaharia et al. (2010) where they used Spark to analyze a 39 GB wiki data, the 
query time using Spark was 0.5 to 1 second. The Hadoop query took 35 seconds; therefore, Spark",N/A,N/A
"is much faster than Hadoop.  
At present, GPUs are successfully integrated into Hadoop and MapReduce frameworks which 
could increase the data processing speed (Yadav, Bhadoria & Suri, 2015). In addition, Yadav, 
Bhadoria and Suri (2015) found that there are some libraries such as JCUDA and Java Aparapi that 
provide APIs to interact with GPUs and extract better performance from them to support high 
performance computing within Hadoop. 
 
 
 
7 
 
References",N/A,N/A
"7 
 
References 
Behzadi, F. (2015). Natural language processing and machine learning: A review. 
International Journal of Computer Science and Information Security, 13(9), 101-
106.  
Cloudera. (2016). Overview of Cloudera and the Cloudera Documentation Set. 
Retrieved from 
http://www.cloudera.com/documentation/enterprise/latest/topics/introduction
.html. 
Erturk, E. (2013). The impact of intellectual property policies on ethical attitudes",N/A,N/A
"toward internet piracy. Knowledge Management: An International Journal, 
12(1), 101-109.  
Exner, P., & Nugues, P. (2014). KOSHIK: A large-scale distributed computing 
framework for NLP. In 3rd International Conference on Pattern Recognition 
Applications and Methods, 463-470. 
Gates, A. F., Natkovich, O., Chopra, S., Kamath, P., Narayanamurthy, S. M., Olston, 
C., ... & Srivastava, U. (2009). Building a high-level dataflow system on top of",N/A,N/A
"Map-Reduce: The Pig experience. Proceedings of the VLDB Endowment, 2(2), 
1414-1425. 
Hashem, I. A. T., Yaqoob, I., Anuar, N. B., Mokhtar, S., Gani, A., & Khan, S. U. (2015). 
The rise of “big data” on cloud computing: Review and open research issues. 
Information Systems, 47, 98-115. 
Hovy, D., & Spruit, S. (2016). The Social Impact of Natural Language Processing. 
Annual Meeting of the Association for Computational Linguistics, Berlin, 
Germany.",N/A,N/A
"Germany.  
IBM (2012). What is big data. Retrieved from http://www-
01.ibm.com/software/data/bigdata/what-is-big-data.html. 
Idris, M., Hussain, S., Siddiqi, M. H., Hassan, W., Bilal, H. S., & Lee, S. (2015). MRPack: 
Multi-algorithm execution using compute-intensive approach in MapReduce. 
PLoS One, 10(8). http://dx.doi.org/10.1371/journal.pone.0136259. 
Lingad, J., Karimi, S., & Yin, J. (2013). Location extraction from disaster-related",N/A,N/A
"microblogs. In Proceedings of the 22nd international conference on World Wide 
Web companion, 1017-1020. 
Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., & McClosky, D. 
(2014, June). The Stanford CoreNLP Natural Language Processing Toolkit. ACL 
(System Demonstrations), 55-60. 
Markham, S. K., Kowolenko, M., & Michaelis, T. L. (2015). Unstructured text analytics 
to support new product development decisions. Research Technology 
Management, 58(2), 30-38.",N/A,N/A
"Management, 58(2), 30-38.  
Mell, P. & Grance, T. (2011). The NIST Definition of Cloud Computing: 
Recommendations of the National Institute of Standards and Technology. 
Retrieved from 
http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf. 
8 
 
Murthy, B. V. R., Padmakar, V., & Reddy, M. A. (2015). Hadoop architecture and its 
functionality. International Journal of Computer Science and Information 
Security, 13(4), 97-103.",N/A,N/A
"Security, 13(4), 97-103.  
Nugues, P. (2014). Question answering and the development of the Hajen system. 
Retrieved from 
http://cst.ku.dk/projekter/semantikprojekt/arrangementer/information/Copenh
ague20141103.pdf  
Olston, C., Reed, B., Srivastava, U., Kumar, R., & Tomkins, A. (2008, June). Pig latin: a 
not-so-foreign language for data processing. In Proceedings of the 2008 ACM 
SIGMOD international conference on Management of data, 1099-1110.",N/A,N/A
"Taylor, R. C. (2010). An overview of the Hadoop/MapReduce/HBase framework and 
its current applications in bioinformatics. BMC Bioinformatics, 11. 
http://dx.doi.org/10.1186/1471-2105-11-S12-S1. 
Thusoo, A., Sarma, J. S., Jain, N., Shao, Z., Chakka, P., Anthony, S., ... & Murthy, R. 
(2009). Hive: a warehousing solution over a map-reduce framework. 
Proceedings of the VLDB Endowment, 2(2), 1626-1629. 
Verspoor, K., Cohen, K. B., Lanfranchi, A., Warner, C., Johnson, H. L., Roeder, C., . . .",N/A,N/A
"Hunter, L. E. (2012). A corpus of full-text journal articles is a robust evaluation 
tool for revealing differences in performance of biomedical natural language 
processing tools. BMC Bioinformatics, 13, 207. http://dx.doi.org/10.1186/1471-
2105-13-207. 
White, T. (2012). Hadoop: The definitive guide. O'Reilly Media: Sepastopol, USA. 
Zaharia, M., Chowdhury, M., Franklin, M. J., Shenker, S., & Stoica, I. (2010). Spark: 
Cluster Computing with Working Sets. HotCloud, 10, 10-10.",N/A,N/A
"NLI4DB: A Systematic Review of Natural Language
Interfaces for Databases
Mengyi Liu and Jianqiu Xu*
Nanjing University of Aeronautics and Astronautics, Nanjing, China
{liumengyi,jianqiu}@nuaa.edu.cn
Abstract
As the demand for querying databases in all areas of life continues to grow, researchers have devoted signifi-
cant attention to the natural language interface for databases (NLIDB). This paper presents a comprehensive sur-",N/A,N/A
"vey of recently proposed NLIDBs. We begin with a brief introduction to natural language processing techniques,
executable database languages and the intermediate representation between natural language and executable lan-
guage, and then provide an overview of the translation process from natural language to executable database
language. The translation process is divided into three stages: (i) natural language preprocessing, (ii) natural",N/A,N/A
"language understanding, and (iii) natural language translation. Traditional and data-driven methods are utilized
in the preprocessing stage. Traditional approaches rely on predefined rules and grammars, and involve techniques
such as regular expressions, dependency parsing and named entity recognition. Data-driven approaches depend
on large-scale data and machine learning models, using techniques including word embedding and pattern link-",N/A,N/A
"ing. Natural language understanding methods are classified into three categories: (i) rule-based, (ii) machine
learning-based, and (iii) hybrid. We then describe a general construction process for executable languages over
relational and spatio-temporal databases. Subsequently, common benchmarks and evaluation metrics for trans-
forming natural language into executable language are presented, and methods for generating new benchmarks",N/A,N/A
"are explored. Finally, we summarize the classification, development, and enhancement of NLIDB systems, and
discuss deep language understanding and database interaction techniques related to NLIDB, including (i) us-
ing LLM for Text2SQL tasks, (ii) generating natural language interpretations from SQL, and (iii) transforming
speech queries into SQL.
Keywords: Natural language interface for database, Semantic parsing, Structured language, Query processing
1
Introduction",N/A,N/A
"1
Introduction
In today’s data-driven world, databases are the backbone of a number of applications, from social media plat-
forms to financial systems. However, accessing and querying these vast repositories of information often requires
specialized knowledge of query languages such as SQL, which can be a significant barrier for non-expert users,
limiting their ability to harness the full potential of the data at their fingertips. The advent of natural language",N/A,N/A
"interface (NLI) has the potential to eliminate the interaction barrier between users and terminals [130]. The
integration of natural language processing (NLP) and database technology represents an intriguing avenue for
future research. There are systems that facilitate the transformation of natural language into structured language
[141, 22], provide the natural language description for query execution plans [139, 23], and transform SQL into
natural language [40, 132].",N/A,N/A
"natural language [40, 132].
Imagine a world where anyone, regardless of technical proficiency, can effortlessly interact with complex
databases using everyday language. This vision is becoming a reality through the development of natural language
*Corresponding author.
1
arXiv:2503.02435v1  [cs.DB]  4 Mar 2025
Who is the director of
""Inglourious Basterds""?
Natural Language Query
SELECT  DISTINCT p.*
FROM  movie m, person p, directing d
WHERE m.id = d.movieId AND person.id = d.directorId",N/A,N/A
"AND m.title = ""Inglourious Basterds""
Translated Executable Language
NLIDB
Manual
Processing
Figure 1: Example of translating a natural language into an executable language
Natural language preprocessing
Natural language understanding
Natural language translation
Natural Language Query
Executable Database Language
NLIDB
 Methods
Techniques involved
Examples of NLIDBs
traditional
named entity recognition,
dictionary generation, regular
expression, dependency parsing
PRECISE, Querix, QuestIO,",N/A,N/A
"PRECISE, Querix, QuestIO,
gAnswer, MEANS, NL2CM, 
ATHENA, SQLizer, NALMO
data-driven
word embedding, pattern linking
IRNet, xDBTagger 
Methods
Techniques involved
Examples of NLIDBs
rule-based
semantic accessibility,
intermediate query language
PRECISE, NaLIX, DaNaLIX, NaLIR, NL2CM,
ATHENA, NALMO, ezNL2SQL
machine learning-based
statistical machine translation, 
encoder-decoder frameworks
Seq2SQL, DialSQL, SyntaxSQLNet, DBTagger,
IRNet, SpatialNLI, ValueNet, SV2-SQL
hybrid",N/A,N/A
"IRNet, SpatialNLI, ValueNet, SV2-SQL
hybrid 
intermediate query language,
encoder-decoder frameworks
TypeSQL, NALMO, Veezoo, GAR, CatSQL, 
GENSQL, NALSpatial, xDBTagger
database elements + SELECT,
FROM, WHERE parts
join condition + WHERE clause
participating relations + FROM clause
query type
operators
the executable language
relational database
spatio-temporal
database
key semantic information
segmentation, 
part-of-speech tagging
Figure 2: A summary of translation techniques",N/A,N/A
"Figure 2: A summary of translation techniques
interface for databases (NLIDB), which aims to transform a natural language query (NLQ) into an executable
language, as illustrated in Figure 1. Users tend to favor an interactive interface that allows them to confirm the
accuracy and precision of the generated structured language [95]. The NLIDB enables users to avoid the necessity
of possessing expertise in structured query languages and database schema, thereby significantly streamlining the",N/A,N/A
"efforts of users and enhancing the benefits of utilizing databases [70]. The initial NLIDBs, including BASEBALL,
LUNAR, LADDER, Chat-80, and ASK, were released in rapid succession [2]. Subsequently, NLIDBs have
emerged and are primarily utilized in relational databases (e.g., GENSQL [44] and CatSQL [48]), spatial domains
(e.g., SpatialNLI [80, 141] and NALSpatial [89]), RDF question and answer (e.g., Querix [69] and TEQUILA
[64]), and XML databases (e.g., NaLIX [84, 85] and DaNaLIX [81]).",N/A,N/A
"Despite years of research, the landscape of NLIDB is fraught with challenges [9, 82]. The inherent ambiguity
and variability of natural language make NLIDB difficult to ensure accurate query interpretation. Additionally,
understanding the structure and semantics of different databases adds another layer of complexity. Furthermore,
achieving real-time performance while maintaining high accuracy in query translation remains an ongoing chal-",N/A,N/A
"lenge. While large language models (LLMs) offer new avenues for querying databases using natural language,
the training and reasoning of such models necessitate a substantial amount of computational resources, which
may prove challenging to implement in resource-limited scenarios [97]. Moreover, the decision-making process
of LLMs is frequently opaque and lacks interpretability, making it difficult to ascertain whether the generated",N/A,N/A
"query results align with the user’s intent [126]. These obstacles underscore the need for continued research and
development to refine NLIDB.
2
In light of these observations, this systematic review explores the current state of NLIDB, examining the var-
ious approaches and technologies that have been proposed to connect natural language with database querying,
named NLI4DB. The aim of this survey is to offer a comprehensive overview that serves as both a valuable ref-",N/A,N/A
"erence for researchers and a practical guide for practitioners aiming to implement effective NLIDB solutions.
NLI4DB presents a thorough examination of the NLIDB subject, categorizing the work into subtopics and pro-
viding in-depth analysis for each one. The translation process from natural language to executable language is
divided into three stages: (i) natural language preprocessing, (ii) natural language understanding, and (iii) nat-",N/A,N/A
"ural language translation. The three-stage division provides physical independence by separating the physical
arrangement of data from the semantics of queries [113]. The techniques for the translation are shown in Figure
2.
(i) Natural language preprocessing generally involves the construction of dedicated data dictionaries for the
domain using stemming extraction and synonym techniques. Part-of-speech tagging and word segmentation are",N/A,N/A
"then performed on the input natural language. Methods used in the preprocessing stage include traditional and
data-driven. Traditional approaches rely on predefined rules and grammars for domain-specific text processing,
and involve techniques such as regular expressions, dependency parsing and named entity recognition (NER).
Data-driven approaches depend on large-scale data and machine learning models for complex or variable text",N/A,N/A
"processing, using techniques such as word embedding and pattern linking.
(ii) Natural language understanding has rule-based, machine learning-based, and hybrid approaches. Rule-
based systems can only deal with knowledge bases of specific domains, whose semantic understanding processes
either define the concept of semantic accessibility or translate the NLQ into an intermediate representation that",N/A,N/A
"can describe the semantics and relationships in an accessible manner. Machine learning-based systems employ
a variety of techniques to parse text, including unsupervised approaches, question-and-answer supervised learn-
ing, statistical machine translation techniques, encoder-decoder frameworks with recurrent neural networks, and
combinations of deterministic algorithms and machine learning. Hybrid approaches combine rules and machine
learning techniques to maximize their benefits.",N/A,N/A
"learning techniques to maximize their benefits.
(iii) Natural language translation uses distinctive algorithms to map processed key semantic information to
corresponding structured language components. To build the SQL, the database elements matched by the NLQ are
placed in the appropriate locations in the SELECT, FROM, and WHERE parts. In the event that a query involves
multiple relations, it is necessary to include the join condition and the names of the participating relations in the",N/A,N/A
"WHERE and FROM clause, respectively. In the process of building an executable language of a spatio-temporal
database, the query type of the input NLQ is initially identified. The operators required to build the executable
language are then determined according to the query type. Finally, the key semantic information obtained from
the natural language understanding stage is integrated to form an executable language.",N/A,N/A
"The existing survey [2] related to NLIDB focuses on the comparative analysis of the entire natural language
interface system. Affolter et al. [2] divide NLIs into four groups: (i) keyword-based systems, (ii) pattern-based
systems, (iii) parsing-based systems, and (iv) grammar-based systems. For each group, they provide an overview
of representative systems and describe the most illustrative one in detail. In addition, they systematically compare",N/A,N/A
"24 recently developed NLIDBs on the basis of the sample world designed in the paper. Each system is evaluated
using 10 example questions to show the advantages and disadvantages.
Compared with Affolter et al. [2], we divide the system translation process into three steps and focus on
the comparative analysis of each step. We investigate the recently developed NLIDB systems and divide the",N/A,N/A
"translation process into three stages: (i) natural language preprocessing, (ii) natural language understanding,
and (iii) natural language translation. We classify natural language preprocessing techniques into traditional
and data-driven. Natural language understanding methods are then analyzed in three categories: (i) rule-based,
(ii) machine learning-based, and (iii) hybrid. Next, we provide a comprehensive outline of the construction",N/A,N/A
"process of executable languages for relational and spatio-temporal databases. Finally, we present commonly used
benchmarks and evaluation metrics, and describe the classification, development, and enhancement of NLIDBs.
3
Table 1: Frequently used notations
Name
Abbreviation
Natural language interface for database
NLIDB
Natural language interface
NLI
Natural language query
NLQ
Natural language processing
NLP
Named entity recognition
NER
Large language model
LLM
First-order logic
FOL",N/A,N/A
"Large language model
LLM
First-order logic
FOL
Automatic speech recognition
ASR
sequence-to-sequence
seq2seq
The rest of the paper is structured as follows. Section 2 furnishes the background concerning NLIDB, in-
cluding natural language processing techniques, executable database languages and intermediate representation
languages. Section 3 describes the generation of executable database languages in terms of three stages: (i) nat-",N/A,N/A
"ural language preprocessing, (ii) natural language understanding and (iii) natural language translation. Section
4 summarizes 11 popular benchmarks for transforming NLQ into SQL and 3 evaluation metrics, including re-
sponse time, translatability, and translation precision, and explores the methods for generating new benchmarks.
Section 5 analyzes the classification, development and enhancement of NLIDBs. Section 6 discuss deep language",N/A,N/A
"understanding and database interaction techniques related to NLIDB, including (i) using LLM for Text2SQL tasks,
(ii) generating natural language interpretations from SQL, and (iii) transforming speech queries into SQL. Sec-
tion 7 explores the open problems of NLIDB and concludes the survey. Table 1 summarizes the frequently used
notations.
2
Background: NLP techniques and query languages
We introduce the background related to NLIDB, including natural language processing techniques, executable",N/A,N/A
"database languages, and intermediate representation languages.
2.1
Natural language processing techniques
NLP is an interdisciplinary discipline that integrates several fields such as linguistics, computer science, and math-
ematics, and aims to make computers capable of understanding, processing and generating natural language text
or speech. Through segmentation, lexical annotation, and syntactic analysis, NLP provides structured processing",N/A,N/A
"of text to achieve semantic understanding and information extraction. The application areas of NLP cover machine
translation, sentiment analysis, information retrieval, and dialogue systems, providing people with an intelligent
and convenient way of language interaction.
A Brief History. The earliest research on natural language processing is machine translation. In 1950, Alan
Turing proposed the ultimate test for determining the arrival of truly “intelligent” machines, which is generally",N/A,N/A
"regarded as the inception of the idea of NLP [96]. From the 1950s to the 1970s, the rule-based method was
used to process natural language, which was based on grammatical rules and formal logic. In the 1970s, the
statistic-based method gradually supplanted the rule-based method. At this juncture, NLP built on mathematical
models and statistic made a substantial breakthrough and was applied to practical applications. From 2008 to the",N/A,N/A
"present, researchers have introduced deep learning to NLP in response to the achievements in image recognition
and speech recognition.
The NLP techniques commonly used in NLIDBs are as follows.
(i) Part of speech tagging refers to assigning the correct part of speech to each word in the segmented text,
4
(a) Part of speech tagging
(b) Lemmatization
(c) Named entity recognition
DT
All
det
acl
NNS
movies
VBG
starring
NNP
Brad
compound
NNP
Pitt
IN
from
case
CD
2000
IN
until
case
CD
2010
.
.
obj",N/A,N/A
"from
case
CD
2000
IN
until
case
CD
2010
.
.
obj
obl
obl
punct
(d) Dependency parsing
Figure 3: Processing natural language using Stanford CoreNLP
determining whether each word is a noun, verb, or adjective. In NLIDB, part of speech tagging facilitates the
identification of the grammatical roles of individual words in natural language queries, leading to an accurate
comprehension of users’ intent. Taking the natural language query “All movies starring Brad Pitt from 2000 until",N/A,N/A
"2010.” as an example, the result of part of speech tagging using Stanford CoreNLP is shown in Figure 3(a). In the
figure, DT = determiner; NNS = plural noun; VBG = the gerund or present participle of a verb; NNP = singular
proper noun; IN = preposition or subordinating conjunction; CD = cardinal number.
(ii) Lemmatization is the process of reducing the different forms of a word to the original form. In NLIDB,",N/A,N/A
"lemmatization is beneficial in unifying words of various tenses and morphs in natural language queries into base
forms in order to match the content in the database. Taking the natural language query “All movies starring Brad
Pitt from 2000 until 2010.” as an example, the result of lemmatization using Stanford CoreNLP is shown in Figure
3(b).
(iii) Named entity recognition is the procedure of identifying entities with specific meanings in natural lan-",N/A,N/A
"guage text [114]. Generally, the recognized entities can be categorized into three primary groups (entity, temporal,
and numeric) and seven subgroups (PERSON, ORGANIZATION, LOCATION, TIME, DATE, MONEY, and
PERCENT). NER in NLIDB enables the identification of entities involved in a natural language query to locate
the topic and scope of the query. Taking the natural language query “All movies starring Brad Pitt from 2000 until",N/A,N/A
"2010.” as an example, the result of NER using Stanford CoreNLP is shown in Figure 3(c).
(iv) Dependency parsing involves analyzing the dependencies between words in natural language sentences.
A binary asymmetric relationship between words is called dependency, which is described as an arrow from the
head (the subject to be modified) to the dependent (the modifier). Dependency parsing in NLIDB facilitates the",N/A,N/A
"understanding of grammatical relationships between words in NLQs, so that the structure and meaning of the
query can be accurately understood. Taking the natural language query “All movies starring Brad Pitt from 2000
until 2010.” as an example, the result of dependency parsing using Stanford CoreNLP is illustrated in Figure 3(d).
In the figure, punct = punctuation; obl = oblique nominal; obj = object; det = determiner; acl = clausal modifier of
noun; case = case marking.",N/A,N/A
"noun; case = case marking.
With the vigorous development of NLP technology, a number of NLP tools are appearing [114]. These tools
can perform basic tasks, including dependency parsing, named entity recognition, lemmatization, and part of
5
speech tagging, each of which has distinct advantages and disadvantages. The following is a list of the established
open source natural language processing tools.",N/A,N/A
"open source natural language processing tools.
(i) NLTK is a natural language processing toolkit using Python as the programming language. NLTK has
complete functions and realizes many of the functional components in natural language processing, such as named
entity recognition, sentence structure analysis, part-of-speech tagging, and text classification [13]. Born for the
academic field, NLTK is suitable for study and research. The disadvantage is that NLTK has a slower processing",N/A,N/A
"speed than other tools.
(ii) spaCy, a commercial open source software, is an industrial-grade natural language processing software
programmed in Python and Cython languages [45]. spaCy, which follows NLTK, includes pre-trained statistical
models and word vectors. spaCy can break down text into semantic units like articles, words and punctuation, and
support named entity recognition. spaCy is characterized by fast and accurate syntax analysis, and comprehensive",N/A,N/A
"functions ranging from simple part-of-speech tagging to advanced deep learning.
(iii) Stanford CoreNLP is a tool set developed by Stanford University using the Java programming language.
Stanford CoreNLP supports a variety of natural languages and has rich interfaces for programming languages that
can be used without Java [91]. Stanford CoreNLP is an efficient tool created by high-level research institutions",N/A,N/A
"and is widely used in scientific research and experiments, but may incur additional costs in production systems.
Stanford CoreNLP may not be the best choice for industry.
(iv) TextBlob is an extension to NLTK, which provides an easier way to use the functionality of NLTK [57].
TextBlob supports sentiment analysis, tokenization, part-of-speech tagging, and text classification. One of the
advantages is that TextBlob can be used in production environments where performance requirements are not too",N/A,N/A
"high. TextBlob can be applied in a wide range of scenarios, especially for small projects.
2.2
Executable database languages
The output of NLIDB is an executable database language, and we present executable languages over relational
data, RDF data, and spatial data.
2.2.1
Query language for relational data
The standard executable query language for relational data is SQL. Such a language is a general-purpose, ex-",N/A,N/A
"tremely powerful relational database language whose functions are not limited to querying, but also include creat-
ing database schema, inserting and modifying data, and defining and controlling database security integrity [29].
Following the establishment of SQL as an international standard language, numerous database manufacturers have
released SQL-compatible software, including both database management systems and interfaces. Consequently,",N/A,N/A
"SQL serves as the universal data access language and standard interface for most databases, fostering a shared
foundation for interoperability among different database systems. SQL has become the mainstream language in
the database field which is of great significance.
SQL provides the SELECT statement for querying data, which has flexible usage and rich functionality. The
SELECT statement can perform simple single-table queries as well as complex join queries and nested queries,",N/A,N/A
"whose general format is:
SELECT [ALL|DISTINCT] <target column expression> [alias] [,<target column expression> [alias]]
FROM <table name or view name> [,<table name or view name>] | (SELECT statement) [AS] <alias>
[WHERE <conditional expression>]
[GROUP BY <column name 1> [HAVING <conditional expression>]]
[ORDER BY <column name 2> [ASC|DESC]];
The purpose of the SELECT statement is to find the tuples that satisfy the conditions specified in the FROM clause,",N/A,N/A
"which may be a basic table, view, or derived table ,according to the conditional expression in the WHERE clause.
6
The attribute value in the tuple is then selected on the basis of the target column expression in the SELECT clause
to form the result table. When a GROUP BY clause is present, the output is organized by the value of <column
name 1>, where tuples sharing identical attribute column values are grouped together. Aggregation functions are",N/A,N/A
"usually applied to each group. When the GROUP BY clause is accompanied by a HAVING clause, the output
will only include groups that satisfy the specified conditions. If an ORDER BY clause is present, the result table
is sorted in ascending or descending order according to the values of <column name 2>.
2.2.2
Query language for RDF data
The complete designation of RDF is Resource Description Framework, which is a data model designed to represent",N/A,N/A
"information about resources on the Internet. The data model typically describes a fact composed of three parts
known as a triple, including (i) a subject, (ii) a predicate, and (iii) an object. An RDF graph contains multiple
triples. RDF documents are written in XML to offer a standardized method for describing information. RDF is
intended for computer applications to read and understand, rather than for visual presentation to web users.",N/A,N/A
"SPARQL is a specialized query language and data retrieval protocol designed for RDF, which stands for
SPARQL Protocol and RDF Query Language [24]. SPARQL is a query language over RDF graphs, where the
database is represented as a collection of “subject-predicate-object” triples. Although RDF data is inferential,
SPARQL does not have an inference query function. SPARQL is tailored for managing data stored in RDF",N/A,N/A
"format, enabling both retrieval and manipulation. SPARQL is composed of the following components.
• The PREFIX clause is employed to declare a prefix with the objective of simplifying the use of URIs. The
declaration of the prefix is optional.
• The SELECT clause serves the purpose of specifying the variables returned by a query.
• The WHERE clause is utilized to match data in RDF graphs. The clause contains one or more triple patterns
that are employed to indicate the conditions of a query.",N/A,N/A
"• The FILTER clause is designed to conditionally filter the results of a query. The clause can include boolean
expressions to limit the set of results matched by the WHERE clause.
The fundamental query types of SPARQL are as follows [101].
SELECT query is the most frequently used type of query, whose function is to select variables and return a
result set. A table is typically generated as the outcome of a SELECT query, which includes the variables that",N/A,N/A
"meet the query’s criteria along with their corresponding values.
CONSTRUCT query is used to generate a new RDF graph by utilizing the query pattern. In contrast to
tabular results, the CONSTRUCT query produces an RDF graph that is constructed from the matching data of the
query pattern.
ASK query is designed to ascertain the existence of RDF data that satisfies the query pattern. The ASK query",N/A,N/A
"provides a response in the form of a boolean value (true or false) to indicate the presence or absence of a match.
DESCRIBE query is employed to obtain the detailed description of resources. The description is determined
by the query engine and typically consists of triples that are directly related to the resource.
Each query type employs a WHERE clause to limit the scope of the query. Nevertheless, in the context of",N/A,N/A
"DESCRIBE queries, the inclusion of a WHERE clause is not mandatory. To illustrate, the subsequent query
retrieves people from the data set who are above the age of 24:
PREFIX info: <http://somewhere/peopleInfo#>
SELECT ?resource
WHERE
{
?resource info:age ?age .
FILTER (?age >= 24)
}
7
Table 2: Operators to query spatial data
Operator
Signature
Meaning
distance
point | line | region × point | line | region →real
Compute the distance between two spa-
tial objects.
direction
point × point →real",N/A,N/A
"tial objects.
direction
point × point →real
Compute the direction between two
points.
size
line →real
Return the length of a line.
area
region →real
Return the area of a region.
intersects
line | region × line | region →bool
TRUE, if both arguments intersect.
intersection
point | line | region × point | line | region →T, where
T is point if point is one of the arguments, otherwise
T is the argument having the smaller dimension
Intersection of two spatial objects.
distancescan",N/A,N/A
"Intersection of two spatial objects.
distancescan
rtree × relation × object × int →stream
Compute the integer k nearest neigh-
bors for a query object.
In this query, the “?” symbol represents a variable, followed by the variable name. The middle of the “<>”
symbol is the URI that describes the resource address. The “info:age” in the above query is a URI shorthand
and stands for “<http://somewhere/peopleInfo#age>”. The FILTER keyword is employed to impose limitations",N/A,N/A
"on the outcomes that are retrieved. In addition, RDF is semi-structured data, and different entities in RDF may
have distinct properties. SPARQL is capable of querying information that exists in RDF. However, when querying
information that does not exist, SPARQL does not show a failure and does not return any results. The OPTIONAL
keyword can then be used to signify that the query is optional, indicating that the query will return a result if the",N/A,N/A
"entity has the attribute, and a null value otherwise. The FILTER keyword can also be used in conjunction with the
OPTIONAL keyword.
2.2.3
Query language for spatial data
The increasing reliance on geographic information systems in many aspects of people’s production and life has
led to a significant increase in the demand for spatial data query in all walks of life. The popularity of spatial",N/A,N/A
"applications has brought great attention to spatial databases [55]. In databases, fundamental data types utilized for
the representation and manipulation of spatial objects include point, line, and region. The common operators to
query spatial data are shown in Table 2.
Mature systems for storing and managing spatial data include Esri’s ArcGIS, PostGIS, Google Earth Engine,
GRASS GIS, and SECONDO [56]. As an illustration, SECONDO is a freely available platform created for",N/A,N/A
"the purpose of organizing and examining spatial and temporal data. The basic commands of SECONDO are as
follows.
query <value expression>. The command evaluates the given value expression and subsequently displays
the result to the user.
let <identifier> = <value expression>. The command initially evaluates the provided value expression in a
manner analogous to the preceding command. In contrast to the previous command, the results of the evaluation",N/A,N/A
"are not immediately displayed but rather stored in an object named identifier. If the object already exists in the
database, the command will result in an error.
delete <identifier>. The command removes the object named identifier from the current database, and is
typically utilized in conjunction with the second command.
When an expert or system developer writes the executable query language for SECONDO, one needs to com-",N/A,N/A
"prehensively understand the intricate relationship between data flow and operators. The rel2stream operator trans-
forms a relation into a stream of tuples, as shown in Figure 4. The stream2rel operator, in contrast, converts a
stream of tuples into a relation. Among the fundamental operators of SECONDO, the filter operator is the most
8
a stream of tuples
city (Name:String, GeoData:Region)
Name
GeoData
Nanjing
Zhenjiang
Yangzhou",N/A,N/A
"Name
GeoData
Nanjing
Zhenjiang
Yangzhou
(Nanjing,         ), (Zhenjiang,              ), (Yangzhou,         ), ...
rel2stream
stream2rel
a stream of tuples
filter
Name = ""Nanjing""
(Nanjing,        )
Figure 4: Functions of the operators rel2stream, stream2rel and filter in SECONDO
frequently utilized. Similar to the SELECT keyword in SQL, the function of the filter operator is to extract in-",N/A,N/A
"formation from data that satisfies specific conditions. The SELECT keyword operates on a two-dimensional table
structure to query, filter, and project data by specifying columns and conditions. The filter operator works on a
stream of tuples, followed by a filter condition. The tuples that match the condition are then collected and out-
putted as a stream. For example, the following executable language will output all information about Nanjing in
the relation city in SECONDO.",N/A,N/A
"the relation city in SECONDO.
query city rel2stream filter [.Name = “Nanjing”] stream2rel;
During the execution of the query, the rel2stream operator first transforms the relation city into a stream of tuples,
then the filter operator extracts the tuple named “Nanjing” from the stream, and finally the stream2rel operator
converts the tuple into a relation from the stream.
2.3
Intermediate representation languages",N/A,N/A
"2.3
Intermediate representation languages
The intermediate representation language in NLIDB is designed to accommodate the semantic discrepancies and
diversity between natural language and executable database language, thus improving the translation accuracy,
flexibility and maintainability of the system [7]. The intermediate representation serves as a translator between
natural language and executable language, mapping complex natural language structures to a unified semantic",N/A,N/A
"representation for the purpose of efficient subsequent query processing and execution. By decoupling NLQ from
the underlying database query language, the intermediate representation language makes the NLIDB system flex-
ible, portable, and adaptable to various database types and query requirements. The design of the intermediate
representation considers several factors, such as:
(i) The intermediate representation should convey the query request that the user wishes to submit to the",N/A,N/A
"database, rather than the full meaning of the user’s input.
(ii) To facilitate subsequent translation into the executable language of the database, the intermediate repre-
sentation should be unambiguous.
(iii) To make re-development easier, the intermediate representation should be reusable.
Popular intermediate representations are parse trees [78], first-order logic [121], OQL [113], query sketch
[153], SemQL [53], and NatSQL [50].",N/A,N/A
"[153], SemQL [53], and NatSQL [50].
Parse tree. The syntactic structure of a query in natural language is closely tied to the design of a parse tree.
The tree structure is typically applied to represent the hierarchical and structural relationships of the query. Each
node in a parse tree indicates a grammatical unit (e.g., phrase, word group, and vocabulary), while edges indicate
grammatical relations (e.g., modification and conjunction) between these grammatical units. The nodes and edges",N/A,N/A
"on the parse tree can be labeled with semantic information to identify the semantic roles and constraints present
in the query, providing important information for subsequent query processing.
First-order logic. When transforming an NLQ into first-order logic (FOL), words and phrases in the natural
language are first mapped to predicates, constants, variables, and logical connectives in FOL to represent entities,
9",N/A,N/A
"9
attributes, and relations in the query. Subsequently, on the basis of the syntactic structure of the NLQ, the syntax
tree or syntax graph of the FOL representation is constructed to capture the semantic relations and logical struc-
tures in the query. Finally, the topics, conditions, and operations in the query are identified and converted into
logical expressions in FOL to denote the constraints and operational requirements of the query.",N/A,N/A
"When converting the natural language query “Find the names and salaries of all employees older than 30.”
into a first-order logic representation, predicates and constants are defined as follows.
Employee(x): x is an employee
Name(x, n): the name of employee x is n
Age(x, a): the age of employee x is a
Salary(x, s): the salary of employee x is s
The query condition is expressed as ∀x(Employee(x) ∧Age(x, a) ∧a > 30). The query result is expressed",N/A,N/A
"as ∃n, s(Name(x, n) ∧Salary(x, s)). The complete first-order logic representation is obtained by combining
the condition and result of the query.
∀x(Employee(x) ∧Age(x, a) ∧a > 30) ∧∃n, s(Name(x, n) ∧Salary(x, s))
OQL is built on an ontology knowledge graph, where words and phrases in natural language queries are
associated with concepts, attributes and relations within the ontology knowledge graph. The semantic information",N/A,N/A
"of natural language queries is captured through semantic representations and query patterns to effectively interact
with the database. OQL grammars permit the expression of complex aggregation, union and nested queries. OQL
queries operate upon individual concepts, with each concept being assigned an alias as specified in the FROM
clause of the query.
Query sketch is a form of SQL with natural language hints. Taking the NLQ “Find the number of papers in",N/A,N/A
"OOPSLA 2010.” as an example, the query sketch is as follows.
SELECT count(?[papers]) FROM ??[papers] WHERE ? = “OOPSLA 2010”;
In the query sketch, the symbols “??” and “?” represent an unspecified table and an unspecified column, respec-
tively. Hints for the corresponding gaps are indicated by words enclosed in square brackets. As an illustration, the
first hint in the sketch suggests that the symbol “?” has a similar semantic meaning to the term papers.",N/A,N/A
"SemQL is designed as a tree structure that not only constrains the search space during synthesis, but also main-
tains the same structural characteristics as SQL. In SemQL queries, the GROUP BY, HAVING, and FROM clauses
in SQL are removed, and the conditions from the WHERE and HAVING clauses are consistently represented in
the Filter sub-tree. Furthermore, in the later inference phase, domain knowledge is utilized to deterministically",N/A,N/A
"infer implementation details from SemQL queries. For instance, the columns included the GROUP BY clause of
SQL are typically present in the SELECT clause.
NatSQL retains the core functionality of SQL while streamlining the structure of SQL to align more closely
with the syntax of natural language. NatSQL keeps only the SELECT, WHERE, and FROM clauses, omitting
the JOIN ON, HAVING, and GROUP BY clauses. Additionally, NatSQL does not require nested sub-queries or",N/A,N/A
"aggregation operators, and employs a single SELECT clause. In the case of the natural language query “Which
film has more than 5 actors and less than 3 in the inventory?”, the SQL and NatSQL are as follows.
SQL: SELECT T1.title FROM film AS T1 JOIN film actor AS T2 ON T1.film id = T2.film id GROUP BY
T1.film id HAVING count(*) > 5 INTERSECT SELECT T1.title FROM film AS T1 JOIN inventory AS T2 ON
T1.film id = T2.film id GROUP BY T1.film id HAVING count(*) < 3;",N/A,N/A
"NatSQL: SELECT film.title WHERE count(film actor.*) > 5 and count(inventory.*) < 3;
10
Table 3: Natural language preprocessing for NLIDBs
NLIDB
Year
Underlying datatype
Segmentation
Part of speech
NER
Dictionary generation
Regular expression
Dependency parsing
Word Embedding
Pattern Linking
PRECISE [107]
2003
relational data
✓
✓
✓
✓
Querix [69]
2006
ontology
✓
✓
✓
QuestIO [27]
2008
ontology
✓
✓
✓
gAnswer [60]
2013
RDF data
✓
MEANS [1]
2015
RDF data
✓
✓
NL2CM [6, 5]
2015
RDF data
✓
✓
✓",N/A,N/A
"RDF data
✓
✓
NL2CM [6, 5]
2015
RDF data
✓
✓
✓
NL2TRANQUYL [16]
2015
relational data
✓
ATHENA [113]
2016
relational data
✓
✓
✓
✓
SQLizer [153]
2017
relational data
✓
✓
✓
TEQUILA [64]
2018
RDF data
✓
✓
✓
MyNLIDB [28]
2019
relational data
✓
✓
✓
IRNet [53]
2019
relational data
✓
✓
NLMO [145]
2020
moving objects
✓
✓
✓
✓
✓
NALMO [144, 143]
2021
moving objects
✓
✓
✓
✓
✓
NALSD [88]
2023
spatial data
✓
✓
✓
✓
NALSpatial [89]
2023
spatial data
✓
✓
✓
✓
xDBTagger [132]
2024
relation data
✓
✓
✓
✓
3",N/A,N/A
"✓
✓
xDBTagger [132]
2024
relation data
✓
✓
✓
✓
3
Generation of executable database languages
The generation of executable database languages can be divided into three stages: (i) natural language preprocess-
ing, (ii) natural language understanding, and (iii) natural language translation. In stage (i), the system performs a
preliminary analysis of the raw natural language query in order to prepare for the subsequent stage of natural lan-",N/A,N/A
"guage understanding. In stage (ii), the system performs semantic parsing and understanding of the preprocessed
natural language query to extract the semantic details and intent of the query. In stage (iii), the system converts
the comprehended natural language into a language that can be executed within the database.
3.1
Natural language preprocessing
Prior to the semantic understanding and translation of natural language queries, preprocessing is performed using",N/A,N/A
"traditional and data-driven methods. In order to preprocess natural language queries, the recently developed
NLIDBs utilize techniques as illustrated in Table 3.
The preprocessing process of many NLIDBs commences with the construction of a dedicated data dictionary
for the domain. The extraction process of domain knowledge exerts a profound influence on the portability of the
system. In addition, the semantic parsing component needs to accurately comprehend NLQ with the assistance",N/A,N/A
"of the dictionary, and the extraction process of domain knowledge will impact the availability of the NLIDB. The
primary goal of the extraction technique is to minimize the burden on system users while enhancing the capacity
to automatically generate a dictionary. The extraction process is primarily reliant on stemming and synonym
techniques. The system then needs to perform word segmentation and part-of-speech tagging on the input natural",N/A,N/A
"language. This process necessitates the utilization of natural language processing tools. When choosing the tool,
the high accuracy of the segmentation and part-of-speech tagging results should be considered first, followed
by the speed of processing. Furthermore, the query must be oriented to database information, and the relevant
11
Table 4: Rules for parsing natural language queries
Rules
Typical NLIDBs
Parse tree
PRECISE [107], NaLIX [84, 85], Querix [69], DaNaLIX [81], gAnswer [60],",N/A,N/A
"NaLIR [78, 77, 79], NL2TRANQUYL [16], Unnamed method [65], MyNLIDB
[28]
Ontology
QuestIO [27], ATHENA [113], FINESSE [63], Unnamed method [41], CNL-
RDF-Query [58], ATHENA++ [115], Unnamed method [4]
Semantic graph
Unnamed method [168], MEANS [1], NL2CM [6, 5]
Template matching
SQLizer [153], Unnamed method [3], LogicalBeam [11]
Pattern matching
SODA [15]
Context-free grammar
TR Discover [121]
Semantic grammar
Unnamed method [49]",N/A,N/A
"Semantic grammar
Unnamed method [49]
statements used in the query request are closely related to the database to be used. Therefore, part-of-speech
tagging is often employed in conjunction with named entity recognition and data dictionary.
Traditional preprocessing methods rely on predefined rules and grammars, involving techniques including
NER, regular expressions, and dependency parsing. NLMO performs segmentation and entity recognition using",N/A,N/A
"a natural language processing toolkit spaCy, and sets regular expressions for temporal information extraction.
ATHENA utilizes the TIMEX annotator to detect all temporal intervals mentioned in the text, and the Stan-
ford Numeric Expressions annotator to pinpoint all tokens containing numerical values. ATHENA employs the
Stanford Dependency Parser to identify the dependency relationship in the context of the GROUP BY clause.",N/A,N/A
"PRECISE utilizes the Charniak parser for the precise parsing of questions and the extraction of token relation-
ships from the resulting parse tree. NL2CM employs dependency parsing and part-of-speech tagging techniques.
NL2TRANQUYL analyzes the input natural language using the Stanford Parser, resulting in constituency and
dependency parses.
Data-driven preprocessing methods depend on large-scale data and machine learning models, and the tech-",N/A,N/A
"niques used include word embedding and pattern linking. Word2Vec and GloVe are word embedding models
that are able to represent words as points in a sequential vector space, thereby capturing the semantic relation-
ships between words. These vectors can be employed for calculating semantic similarity and extracting features.
xDBTagger utilizes a pre-trained word embedding model to convert tokens into a 300-dimensional vector repre-",N/A,N/A
"sentation. IRNet performs schema linking by connecting the natural language with the database schema, aiming
to identify the specific columns and tables referenced in the natural language. The columns are then assigned
different types according to the manner mentioned in the question.
3.2
Natural language understanding
Three principal technical approaches to understand natural language are (i) rule-based, (ii) machine learning-",N/A,N/A
"based, and (iii) hybrid. Based on the techniques, the process of natural language understanding for the recently
developed NLIDBs is summarized. We provide three timelines describing the research on rule-based, machine
learning-based, and hybrid approaches, as shown in Figure 5.
3.2.1
Rule-based methods
The semantic parsing of mature NLIs is predominantly based on rules. The systems require specific rules to parse",N/A,N/A
"natural language queries, including parse tree, ontology, semantic graph, template matching, pattern matching,
context-free grammar, and semantic grammar, as shown in Table 4. Rule-based systems can only deal with knowl-
edge bases in fixed domains and are generally not portable to other knowledge bases. In order to enhance the
accuracy of semantic understanding, systems are typically constrained by limitations in their ability to support
12
2014
NaLIR
2015
NL2CM
2016
ATHENA
2017
NLQ/A
2018",N/A,N/A
"2014
NaLIR
2015
NL2CM
2016
ATHENA
2017
NLQ/A
2018
TEQUILA
2020
ATHENA++
2021
EXAQT
NL2TRANQUYL
DialSQL
SQLizer
2003
PRECISE
2005
NaLIX
2007
DaNaLIX
2006
Querix
2009
QUICK
(to be continued)
2019
MyNLIDB
ezNL2SQL
2008
QuestIO
2013
gAnswer
TR Discover
MEANS
SPARKLIS
NLMO
(a) Rule-based methods
2020
RYANSQL
2022
Auto-Query
2021
ValueNet
SP-CNN
2017
Seq2SQL
2019
IRNet
2018
SyntaxSQLNet
COMBINE
2023
DTE
2024
SV2-SQL
IKnow-SQL
SpatialNLI
DialSQL
BiBERT-SQL
DBTagger
MIE",N/A,N/A
"SpatialNLI
DialSQL
BiBERT-SQL
DBTagger
MIE
(b) Machine learning-based methods
2022
Veezoo
2021
NALMO
2018
TypeSQL
2023
GAR
2024
xDBTagger
CatSQL
GENSQL
NALSpatial
NALSD
(c) Hybrid methods based on rule and machine learning
Figure 5: Timelines of the research progress of techniques for understanding natural language
natural language features, such as grammar and vocabulary [144]. PRECISE [107] elucidates the notion of se-",N/A,N/A
"mantic tractability and delineates a specific subset of natural language that can be accurately converted into SQL.
However, natural language queries that cannot be processed semantically will be rejected by PRECISE. NaLIX
[84, 85] restricts natural language queries to a regulated subset according to a predetermined grammar. DaNaLIX
[81] is constructed on NaLIX and employs domain knowledge for query translation. Domain knowledge is en-",N/A,N/A
"capsulated within a collection of regulations that map terms with domain meaning in the parse tree to terms that
can be understood by a generic system such as NaLIX. The domain adapter within DaNaLIX assesses the current
domain expertise and modifies the parse tree with related rules. NaLIR [78, 77, 79] identifies nodes within the
language parse tree that have the potential to correspond to SQL components resulting from the preprocessing",N/A,N/A
"step, and represents semantic coverage as a subset of the parse tree. Such a tree explicitly corresponds to SQL
and serves as a query tree, which mediates between NLQ and SQL. To comprehend the challenge of integrating
individual and collective knowledge, NL2CM first uses RDF to represent individual and general knowledge. Indi-
vidual expression detectors are then used to distinguish between individual and general query components, which",N/A,N/A
"are created through a declarative selection schema in conjunction with a specialized vocabulary. ATHENA uses
domain-specific ontology to transform the natural language input into an intermediate language on the ontology.
The intermediate language is then used to describe the semantic entities in the domain, as well as the relationships
between the entities. Ontology provides richer semantic information than relational schema, including inheritance
13",N/A,N/A
"13
and membership. By reasoning about the ontology, ATHENA demonstrates the capability to effectively discern
and capture the intentions of users. However, ATHENA is highly sensitive to changes and interpretations of user
queries [99]. Both the NLIDB system described in the paper [116] and ATHENA++ [115] are extensions of
ATHENA. They combine linguistic analysis with deep domain reasoning to translate complex join and nested",N/A,N/A
"SQL. NL2TRANQUYL [16] is a system designed for the planning of journeys within a complex multi-modal
transportation system, taking into account a number of constraints, including the minimization of journey time,
distance and cost. NL2TRANQUYL utilizes the ontology comprising a range of concepts to store and model re-
lated information, and generates knowledge graphs to determine the relationships between them. To discover and",N/A,N/A
"process temporal information in NLQ, TEQUILA decomposes the detected temporal problems and rewrites the
generated sub-problems. These papers [60, 168] utilize the Stanford Parser to generate dependency trees and ex-
tract semantic relations from the parsed data. Subsequently, a semantic query graph is constructed by connecting
these semantic relations to depict the user’s query intent. Querix [69] examines the syntax of natural language us-",N/A,N/A
"ing a syntactic analyzer, which is only effective when the natural language components are complete. Incomplete
components may result in inaccurate results, which could compromise the accuracy of the final results.
An optimal NLIDB enables users to formulate intricate queries on the database system and retrieve precise
information with minimal exertion. Consequently, a number of systems incorporate user interaction during the",N/A,N/A
"process of comprehending semantics. NaLIX and DialSQL [54] adjust the query during following user engage-
ments to revise the parse tree, however, the revision frequently necessitates a high number of user interactions.
DaNaLIX acquires domain knowledge through the interaction that occurs between the user and the system in an
automated manner. In addition to elucidating the user on the query processing procedure, NaLIR also presents a",N/A,N/A
"spectrum of interpretations for the user to select from, thus alleviating the user’s need to address potential misun-
derstandings. NaLIR is capable of detecting the parse tree, thereby enabling users to modify the parse tree directly,
rather than reformulating the natural language query. NaLIR can provide recommendations to users for revising
their queries in instances where the natural language queries fall beyond the semantic boundaries. QUICK [162]",N/A,N/A
"improves user interactions by utilizing keyword search to enrich the expressiveness of semantic queries. In practi-
cal application, QUICK assists users in determining the specific intent behind natural language through a series of
iterative refinement steps following the initial submission of a keyword-based question. NLQ/A [166] enhances
the user interaction component in order to more effectively address the issue of ambiguity. SPARKLIS [46] em-",N/A,N/A
"ploys a sequential process consisting of three stages in order to guarantee the thoroughness of user input during
searches for concepts, entities or modifiers. While interacting with the system may result in the user feeling con-
strained, slowed down, and less natural when entering a query, SPARKLIS provides guidance and safety through
intermediate answers and suggestions [2]. In order to reduce user involvement during the disambiguation process,",N/A,N/A
"ATHENA utilizes the extensive semantic data within the ontology to produce a prioritized list of explanations,
and employs a ranking algorithm that is intuitive and relies on ontology metrics to determine the most appropriate
explanation.
3.2.2
Machine learning-based methods
As the usage of statistical learning methods continues to expand, there has been a growing interest in conducting
semantic analysis on sentences through a variety of forms of supervision. Pasupat and Liang [102] employ",N/A,N/A
"question-and-answer format to provide guidance in responding to intricate natural language queries presented
within semi-structured tables. The paper [105] represents the inaugural attempt to develop a semantic parsing
model through unsupervised learning [66]. Artzi and Zettlemoyer [8] solicit feedback during the conversation to
determine the meaning of the user’s statements. In a domain where no training examples are available, Wang et al.",N/A,N/A
"[146] demonstrate the successful development of a semantic parser. Their approach comprises two key elements:
(i) a builder and (ii) a domain-general grammar. Wong and Mooney [150] utilize statistical machine translation
technology for the purpose of accomplishing semantic parsing tasks.
14
Table 5: NLIDBs with encoder-decoder frameworks
NLIDB
Year
Encoder
Decoder
DialSQL [54]
2018
Encode
dialogue
history
using
RNN networks
Decode errors and candidate se-
lections
SyntaxSQLNet [159]
2018",N/A,N/A
"lections
SyntaxSQLNet [159]
2018
Table-aware column encoder
Syntax tree-based decoder
Unnamed method [87]
2020
Encode NLQs and table headers
using XLNet [155]
The parsing layer splices the vec-
tor
ValueNet [19]
2021
Extension of IRNet’s encoder
LSTM architecture and multiple
pointer networks
Unnamed method [30]
2021
The encoder of LSTM
The decoder of LSTM
MIE [138]
2021
Multi-integrated
encoder
with
three integrated modules
No decoder
Auto-Query [100]
2022
The encoder of RATSQL [137]",N/A,N/A
"Auto-Query [100]
2022
The encoder of RATSQL [137]
SmBoP [112]
STAMP [51]
2023
The encoder of T5
The decoder of T5
Unnamed method [154]
2023
The encoder of Transformer
The decoder of Transformer
In recent times, there has been a growing utilization of encoder-decoder frameworks that rely on recurrent
neural networks for semantic parsing, as demonstrated in Table 5. Many systems combine machine learning and",N/A,N/A
"deterministic algorithms to generate structured languages [93]. This method allows the direct acquisition of the
correlation between natural language and the semantic representation, eliminating the need for an intermediate
representation like a parse tree [66]. Mapping natural language directly to the semantic representation can reduce
the dependence of rule-based semantic parsing models on preset vocabulary, templates, and hand-generated fea-",N/A,N/A
"tures. Machine learning-based models are not limited to specific knowledge bases or logical formal expressions,
thus enabling the implementation of natural language interfaces that support cross-knowledge bases or cross-
languages. Wang et al. [140, 142] propose a cross-domain NLI, which translates the marked natural language
into the intermediate representation of the target query type by building a cross-domain multilingual sequence-",N/A,N/A
"to-sequence (seq2seq) model. Symbols inserted into the natural language query are utilized to substitute the data
elements present in the intermediate query. However, this method is a supervised machine learning model whose
effectiveness is closely related to the quality of the training data. To ensure the accuracy of semantic understand-
ing, a substantial quantity of training data must be provided to the model. A number of researchers employ a",N/A,N/A
"synthetic data generator as a solution to the challenge of having a restricted amount of training data available.
The paper [159] introduces SyntaxSQLNet, which can generate NLQ data sets for cross-domain SQL single-table
operations, solely as a means of augmenting the training set. The method outlined in the paper [149] encompasses
single-table and multi-table join queries of SQL, and can be utilized as either an augmentation or as a standalone",N/A,N/A
"training data set. In terms of model training, the rule-based method is more effective than the neural network-
based method, which requires more training parameters and takes longer to establish the model, consuming more
memory space.
One of the earliest examples of machine learning-based systems is demonstrated in the paper [161]. This work
utilizes a deterministic shift-reduce parser and develops a learning algorithm called CHILL to learn the governing",N/A,N/A
"rules of parsing on the basis of inductive logic programming techniques. The corpus is trained using the CHILL
method to build the parser. Instead of learning dictionaries, this approach assumes that a dictionary is created
in advance that pairs words with semantic content rather than grammar. The paper [163] translates the mean-
ing of natural language sentences into lambda calculus encoding. The paper [163] outlines a learning algorithm",N/A,N/A
"whose input is a collection of sentences identified as lambda calculus expressions, and applies the method to the
task of learning NLIDB to build a parser. While providing considerable flexibility, encoder-decoder frameworks
frequently lack the ability to interpret and understand combinations of meaning [66]. The method employed by
Cheng et al. [25] involves the construction of the intermediate structure in two stages, which facilitates a com-",N/A,N/A
"prehensive understanding of the model’s learning process. Similarly, the paper [39] also produces an intermediate
15
template that presents the final output in a preliminary format, thereby facilitating the subsequent decoding pro-
cess. Yin and Neubig [157] address the issue of insufficient training data by incorporating explicit constraints
for decoders through the utilization of target language syntax. The approach enables the model to concentrate",N/A,N/A
"on parsing, directed by established grammar rules. Xiao et al. [151] utilize the grammar model as prior knowl-
edge, requiring the creation of a derivation tree while adhering to the constraints imposed by the grammar. The
approach in the paper [74] can significantly outperform the Seq2Tree model from the aforementioned paper [38]
by verifying that the decoder’s forecasts adhere to the type constraints outlined in the type constraint grammar.",N/A,N/A
"This suggests that satisfying type constraints and good formatting are equally important when generating logical
expressions. SpatialNLI [80, 141] is a natural language interface for the spatial field that employs the seq2seq
model to understand the semantic structure of natural language, while utilizing an external spatial understanding
model to identify the meaning of spatial entities. Subsequently, the spatial semantics learned from the spatial",N/A,N/A
"understanding model are integrated into natural language problems, thereby reducing the necessity of acquiring
specific spatial semantics. SpatialNLI represents a pioneering system that integrates an external spatial semantic
comprehension model to optimize the effectiveness of the principal seq2seq model. The paper [129] uses a tree
model to analyze the target entity in natural language, and employs a tree-structured LSTM to understand the",N/A,N/A
"problem. The paper [62] adjusts the neural sequence model to directly convert natural language into SQL, thus
circumventing the intermediate query language representation. Then the user feedback is utilized to mark error
queries, which are directly used to improve the model. The complete feedback loop does not necessitate the use
of any intermediate language representation and is not limited to a specific domain. This method offers the benefit",N/A,N/A
"of enabling the rapid and straightforward construction of a semantic parser from scratch, and the performance of
the parser improves as user feedback increases. The encoder of ValueNet [19] is an extension of the encoder of
IRNet [53], receiving not only details regarding the database schema, but also extracted value candidates from the
database content.
3.2.3
Hybrid methods based on rule and machine learning",N/A,N/A
"Hybrid methods based on rule and machine learning
Hybrid methods integrate rules and machine learning techniques to capitalize on the respective strengths of each,
thereby enhancing the ability of the system to understand and process NLQs [72]. Table 6 enumerates the rep-
resentative systems that employ the hybrid approach. Hybrid approaches are highly flexible and adaptable, as
they can utilize rules for tasks with explicit rules as well as machine learning models for complex and ambiguous",N/A,N/A
"semantic tasks. In addition, hybrid methods can flexibly incorporate new rules or train new machine learning
models as needed to accommodate the requirements of diverse domains and tasks, and are highly scalable [135].
TypeSQL [158], like SQLNet [152], is built on sketches and formats translation tasks as slot-filling problems.
The difference is that TypeSQL employs type information to enhance the understanding of entities and numbers",N/A,N/A
"in NLQs. TypeSQL assigns a type to each word, such as entity, column, number and date, within the knowledge
graph. Subsequently, two bidirectional LSTM networks are utilized to encode the words in the NLQ with the
corresponding column names and types. Finally, the LSTM output hidden states are leveraged to forecast the
slot values within the SQL sketch. NALMO is a natural language interface for moving objects. To understand",N/A,N/A
"NLQs, NALMO employs an entity extraction algorithm to obtain entity information, including time, location and
the number of nearest neighbors. A pre-constructed corpus is then trained using LSTM to determine the query
type. Veezoo [75] uses a range of techniques, including temporal expression parsing, entity linking, and relation
extraction, to identify key information in NLQs. The information is then extended and combined using predefined",N/A,N/A
"rules to generate multiple candidate intermediate representations. Finally, Veezoo utilizes a machine learning
model to score these intermediate representations in order to select the most probable interpretation of the NLQ.
The process of data preparation in GAR [42] commences with a collection of sample SQLs that are tailored to a
specific database. For a given NLQ, GAR searches for the NLQs generated during data preparation and employs",N/A,N/A
"a learning-to-rank model to identify the most relevant query, which is then used to obtain the translation result.
16
Table 6: NLIDBs based on rules and machine learning techniques
NLIDB
Year
Rule
Machine learning technique
Unnamed method
[52]
2012
Generate candidate SQLs via rules and
heuristic weighting schemes
Reorder candidate SQLs using the SVM
sorter
TypeSQL [158]
2018
Assign a type to each word to under-
stand the entity
Encode using bidirectional LSTM
NALMO
[144, 143]
2021
Semantic",N/A,N/A
"NALMO
[144, 143]
2021
Semantic
grammar
and
template
matching
Identify the query type using LSTM
Veezoo [75]
2022
Knowledge graph
Score intermediate representations using
machine learning models
GAR [42]
2023
Parse tree
Find the matching expression for NLQ
using a learn-to-rank model
GENSQL [44]
2023
Capture the structure of the database
with sample SQLs
Find the matching expression for NLQ
using a learn-to-rank model
CatSQL [48]
2023
Template matching
The decoder of Transformer. Train the",N/A,N/A
"The decoder of Transformer. Train the
model using Adam [71]
NALSpatial [89]
2023
Semantic
grammar
and
template
matching
Identify the query type using LSTM
NALSD [88]
2023
Semantic
grammar
and
template
matching
Identify the query type using LSTM
xDBTagger [132]
2024
Semantic graph
Bidirectional recurrent neural network
The learning-to-rank model learns to rank the semantic similarities from NLQs to generated NLQs and then finds",N/A,N/A
"the best matching expression for a given NLQ. GENSQL [44], a generative NLIDB, utilizes a given example SQL
from the database (e.g., from query logs) to comprehend the unique structure and semantics of a given database,
thereby guaranteeing precise translation outcomes. The fundamental model used in GENSQL for converting nat-
ural language to SQL is GAR. CatSQL [48] is a method for the generation of SQL that makes use of sketches. In",N/A,N/A
"addition, semantic constraints are merged into the neural network-driven SQL generation procedure for semantic
refinement. CatSQL sketches are templates with keywords and slots. CatSQL employs a deep learning algorithm
to populate vacant slots in order to generate the ultimate SQL. The deep learning algorithm is developed to focus
on the generation of essential NLQ-related information, with the objective of filling the gaps without requiring the",N/A,N/A
"explicit generation of keywords like SELECT, FROM, and WHERE.
Hybrid approaches based on rules and machine learning offer several advantages, including flexibility, accu-
racy, and scalability. Nevertheless, such approaches present certain challenges, such as complexity, dependence
on data, and tuning difficulties [68]. Hybrid methods require the simultaneous management and maintenance of",N/A,N/A
"rule engines and machine learning models, including rule definition, feature engineering, and model training, and
thus have high complexity [52]. Furthermore, the rules and machine learning models utilized in hybrid approaches
may encounter parameter tuning problems, which necessitate a significant investment of time and effort for opti-
mization and debugging, thus increasing the costs associated with the development and maintenance of the system.",N/A,N/A
"During the design and implementation of natural language interfaces, it is essential to take a comprehensive view
of the advantages and challenges involved, and to make trade-offs and choices in accordance with the specific
needs.
3.3
Natural language translation
The natural language translation stage employs the semantic information derived from the natural language un-
derstanding stage, subsequently integrating the underlying structure of the database to transform the input natural",N/A,N/A
"language into the corresponding executable language. A prevalent approach for translation is to employ com-
plex algorithms and machine learning models to generate structured language based on the domain knowledge
of the underlying database and the semantic representation of natural language [83]. Most established NLIDBs
17
Parsed NLQ
Number of
query relations
Database elements
Database elements
Join conditions and
involved relations
SELECT, FROM, WHERE
SELECT, FROM, WHERE
WHERE, FROM
SQL
1
>1",N/A,N/A
"SELECT, FROM, WHERE
WHERE, FROM
SQL
1
>1
Figure 6: General build process for SQL
construct queries by query combination, mapping key information expressed in natural languages to correspond-
ing components in structured languages. We examine the process of natural language translation in recently
developed NLIDBs, and summarize the general construction process of executable languages for relational and
spatio-temporal databases.",N/A,N/A
"spatio-temporal databases.
The general build process for SQL is illustrated in Figure 6 and further elaborated in the subsequent two cases.
(i) When querying a single relation, it is only necessary to place the database elements matched by NLQ in the
correct positions in the SELECT, FROM, and WHERE parts, respectively. Then, SQL can be composed directly.
(ii) When querying multiple relations, the join condition and the names of the participating relations need to",N/A,N/A
"be included in the WHERE and FROM clauses, respectively. Additionally, it is necessary to determine whether
the join path is unique. If only one join path is available, SQL can be generated directly. Otherwise, a query
is typically generated for each possible join path, and then the most probable one is selected according to the
corresponding algorithm.
In recent years, there has been significant interest in NLI for spatio-temporal databases [26]. Temporal and",N/A,N/A
"spatial concepts are derived from the natural language description using symbolic representations in order to depict
spatio-temporal features and their relationships [14, 106]. Due to the particularity and expressiveness of spatio-
temporal problems, executable query languages over spatio-temporal databases are quite different from SQL.
Consequently, the method employed for the construction of SQL cannot be directly applied to the generation of",N/A,N/A
"executable languages over spatio-temporal databases. The general process for the construction of an executable
language for a spatio-temporal database is shown in Figure 7. Preliminary parsing of the input natural language
query is performed to obtain semantic information including key entities and query types. Subsequently, the
operators necessary to construct the executable language are determined according to the type of query. Finally,",N/A,N/A
"key entities and operators are combined according to certain rules to compose an executable database language.
Taking the range query over spatial data as an example, the key entities involved include spatial relations and
locations. The operator intersects will return all objects in the relation that intersect the location if the spatial
attribute of the relation and the data type of the location are both line or region. Conversely, the operator intersects",N/A,N/A
"will return all objects in the relation that lie within the location if the spatial attribute of the relation is point and
the data type of the location is region.
Different DBMSs and structured languages offer a range of clauses and operators for various queries. ATHENA
employs a mapping strategy that correlates the ontology with the database schema in order to convert the interme-
diate query language utilized in the ontology into SQL. The system described in the paper [63] extends ATHENA",N/A,N/A
"to access multiple structured backends, which is achieved through the automated translation of the intermediate
18
Parsed NLQ
Key semantic
information
Query type
Key entities
Operator
Query
combination
Executable language
Mapping rules
Figure 7: General construction process for executable languages over spatio-temporal data
query language into the specific structured query language utilized by these backend stores. NLPQC [124] is",N/A,N/A
"capable of processing queries formulated using predefined domain-specific templates. Querix selectively isolates
specific elements from the syntactic tree in order to align acquired knowledge with the knowledge base, thereby
obtaining the final outcome. NL2CM leverages crowd intelligence by converting audience queries into OASSIS-
QL (an extended version of SPARQL). NaLIR utilizes the structure of the user-validated query tree to produce",N/A,N/A
"the suitable structure in the SQL statement and determine the join path. In order to ascertain whether the target
SQL contains aggregate functions or sub-queries, NaLIR initially identifies function nodes or quantifier nodes
in the query tree and subsequently generates SQL statements based on the identified conditions. The paper [52]
employs lexical dependencies found in the question and database metadata to build a reasonable collection of",N/A,N/A
"SELECT, WHERE, and FROM clauses that enhance the quality of meaningful joins. The paper [52] combines
clauses through a rule and heuristic weighting scheme, and then generates a sorted list of candidate SQLs, demon-
strating that full semantic interpretation can be avoided by relying on a simple SQL generator. This method can
be employed iteratively to address intricate issues necessitating nested SELECT commands. Finally, this paper",N/A,N/A
"[52] applies the re-ranker to reorder the list of questions and SQL candidate pairs with the aim of enhancing the
accuracy of the system. TEQUILA uses a standard KB-QA system to evaluate the sub-questions from the se-
mantic understanding part individually. The results of the sub-questions are then combined with the reasoning
to calculate the answer to the full question. NL2TRANQUYL translates English requests into formal TRAN-",N/A,N/A
"QUYL [17] queries using the knowledge graph generated by the semantic comprehension component. The traffic
query language TRANQUYL for travel planning follows the conventional SQL structure of “SELECT, FROM,
WHERE”. NALMO supports five distinct types of moving object queries, including (i) time interval queries, (ii)
range queries, (iii) nearest neighbor queries, (iv) trajectory similarity queries, and (v) join queries. In the query",N/A,N/A
"translation process, NALMO first constructs a corpus comprising the five query types, collectively referred to as
MOQ. Then the LSTM neural network is used for training, resulting in a model that is capable of accurately iden-
tifying the specific type of query. Finally, the appropriate operators are selected according to the query type, and
the entity information extracted by the semantic parsing component is combined to build the executable language
for SECONDO.
4
NL2SQL benchmarks",N/A,N/A
"for SECONDO.
4
NL2SQL benchmarks
We presents 11 frequently used benchmarks for transforming NLQ into SQL and three evaluation metrics, explor-
ing the methods for generating new benchmarks.
4.1
Existing benchmarks
The details of NLQ and executable language pairs for common domains are presented in Table 7. The majority
of existing benchmarks are utilized in the domain of relational databases to transform natural language query into",N/A,N/A
"SQL (NL2SQL). The comparison of fields and types of SQL supported by the benchmarks for NL2SQL is shown
in Table 8. We can conclude that GeoQuery and Spider support the most types of SQL, while WikiSQL supports
19
Table 7: Examples of NLQ and executable language pairs for common domains
Domain
Examples of NLQ and executable language pairs
Relational database
NLQ: How many CFL teams are from York College?
SQL:
SELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”
Spatial domain",N/A,N/A
"Spatial domain
NLQ1: What is the population of San Antonio?
Lambda expression:
answer(A,population(B,A),const(B,cityid(San Antonio)))
NLQ2: Could you tell me what parks are in the center?
Executable language:
query park feed filter [.GeoData ininterior center] consume;
Moving Objects
NLQ: Where did the train 7 go at 8am?
Executable language:
query Trains feed filter [.Id = 7] filter [.Trip present [const instant value “2020-11-",N/A,N/A
"20-8:00”]] extend [Pos: val (.Trip atinstant [const instant value “2020-11-20-8:00”])]
project [Id, Line, Pos] consume;
Trip planning
NLQ: Can I walk to 300 W. Humboldt Blvd. by 4:00 p.m.?
TRANQUYL:
SELECT ∗FROM ALL TRIPS(user.current location, 300 W. Humboldt Blvd.) AS t
WITH MODES pedestrian WITH CERTAINTY .78 WHERE ENDS(t) ≤4:00 p.m.
MINIMIZE DURATION(t)
Crowd mining
NLQ: What are the most interesting places near Forest Hotel, Buffalo, we should visit
in the fall?
OASSIS-QL:",N/A,N/A
"in the fall?
OASSIS-QL:
SELECT VARIABLES $x WHERE {$x instanceOf Place.
$x near For-
est Hotel, Buffalo, NY} SATISFYING {$x hasLabel “interesting”} ORDER BY
DESC(SUPPORT) LIMIT 5 AND {[] visit $x.
[] in Fall} WITH SUPPORT
THRESHOLD = 0.1
only the simple select query. The queries in WikiSQL and Spider cover a multitude of domains. In recent years,
GeoQuery, MAS, WikiSQL and Spider have been employed with considerable frequency.",N/A,N/A
"The details of popular benchmarks are shown in Table 9. Early data sets consist of only one domain and one
database, such as ATIS, Restaurant and GeoQuery. In contrast, the latest data sets, for example WikiSQL and
Spider, contain multiple domains and several databases with larger and more diverse NLQs and SQLs.
(i) ATIS (Airline Travel Information System) [108] is a classical data set with a relatively old age, having",N/A,N/A
"been introduced by Texas Instruments in 1990. ATIS is built on the relational database Official Airline Guide,
comprising 25 tables and 5871 queries written in English. The queries pertain to details regarding flights, ticket
prices, destinations, and services available at airports. The queries in ATIS are for the air travel field, including
join queries and nested queries, but no grouping and sorting queries. The average length of NLQs and SQLs",N/A,N/A
"in ATIS is approximately 11 and 67 words, respectively. Each query operates on an average of six tables. An
example query is as follows.
Q1: What aircraft is used on delta flight 1984 from Kansas city to Salt Lake city?
(ii) Restaurant [127] comprises a vast collection of dining establishments located in Northern California,
storing restaurant names, locations, features, and travel guide ratings. The benchmark contains 250 questions",N/A,N/A
"about restaurants, food types and locations. An example query is as follows.
Q2: Where is a good Chinese restaurant in Palo Alto?
(iii) GeoQuery [128] consists of 8 tables and 880 natural language queries in the US geographic database. The
queries in GeoQuery are designed for the geographic domain, including join queries, nested queries, grouping
20
Table 8: Comparison of benchmarks for NL2SQL
Benchmark
Select query
Group query
Sort query
Join query
Nested query
Fields involved
Usage in papers",N/A,N/A
"Nested query
Fields involved
Usage in papers
ATIS
✓
✓
✓
air travel
[62, 47, 103, 104, 120]
Restaurant
✓
✓
restaurant
[127, 107, 81, 80]
GeoQuery
✓
✓
✓
✓
✓
geography
[127, 128, 107, 163, 81, 52,
113, 62, 47, 80, 104, 115,
120, 42, 141]
MAS
✓
✓
✓
academic
[77, 113, 153, 35, 9, 115, 131,
132]
Scholar
✓
✓
academic
[47]
IMDB
✓
✓
internet movie
[153, 9, 58, 131, 132]
YELP
✓
✓
business review
[153, 9, 131, 132]
WikiSQL
✓
multiple fields (e.g.
state,
college, manufacturer)
[167, 54, 158, 156, 87, 142,",N/A,N/A
"[167, 54, 158, 156, 87, 142,
48, 51, 125]
ParaphraseBench
✓
✓
medical
[133]
Advising
✓
✓
✓
university course
[47]
Spider
✓
✓
✓
✓
✓
138 different fields (e.g.
car, stadium, country)
[160, 53, 156, 115, 19, 50, 92,
131, 42, 43, 48, 51, 125]
Table 9: Details of popular benchmarks
Benchmark
Year
#queries
#tables
Domains covered
ATIS [108]
1990
5871
25
single field
Restaurant [127]
2000
250
3
single field
GeoQuery [128]
2001
880
7
single field
MAS [77]
2014
196
17
single field
Scholar [62]
2017
816",N/A,N/A
"2014
196
17
single field
Scholar [62]
2017
816
10
single field
IMDB [153]
2017
131
16
single field
YELP [153]
2017
128
7
single field
WikiSQL [167]
2017
80654
24241
multiple fields
ParaphraseBench [133]
2018
290
1
single field
Advising [47]
2018
4387
15
single field
Spider [160]
2018
10181
1020
multiple fields
queries and sorting queries. The average length of NLQs and SQLs in GeoQuery is about 8 and 16 words,",N/A,N/A
"respectively. Additionally, each query operates on an average of one table. Although the queries are relatively
brief in length, they are highly composable, with nearly half of the SQL containing at least one nested sub-query.
One of the English queries is as follows.
Q3: What is the largest city in states that border California?
(iv) MAS [77] is generated from the Microsoft Academic Search database, which stores information such as",N/A,N/A
"academic papers, authors, journals, and conferences. The source of NLQs in MAS is the logical queries that are
capable of being articulated in the search interface of the Microsoft Academic Search platform. The fields of MAS
and Scholar are both academic in nature, but exhibit distinct patterns. One English query is as follows.
Q4: Return authors who have more papers than Bob in VLDB after 2000.",N/A,N/A
"(v) Scholar [62] consists of 816 NLQs for academic database search that are annotated with SQL. The average
length of NLQs and SQLs in Scholar is approximately 7 and 29 words, respectively. Each query operates on an
21
Table 10: Query categories and examples for ParaphraseBench
Category
Example queries
Naive
What is the average length of stay of patients where age is 80?
Syntactic
Where age is 80, what is the average length of stay of patients?
Morphological",N/A,N/A
"Morphological
What is the averaged length of stay of patients where age equaled 80?
Lexical
What is the mean length of stay of patients where age is 80 years?
Semantic
What is the average length of stay of patients older than 80?
Missing Information
What is the average stay of patients who are 80?
average of 3 tables. Iyer et al. [62] provide a database for performing these queries, which includes academic",N/A,N/A
"articles, journal details, author information, keywords, citations, and utilized datasets. One of the English queries
is as follows.
Q5: Get all author having data set as DATASET TYPE.
(vi) IMDB and YELP [153] are generated using data from the Internet Movie Database and Business Review
Database, respectively. The NLQs are obtained from coworkers of the authors of the paper [153], who are only
aware of the types of data available in the database and not the underlying database schema.",N/A,N/A
"(vii) WikiSQL [167], introduced in 2017, is a comprehensive and meticulously annotated collection of natural
language to SQL mappings, and currently represents the most extensive data set for NL2SQL. WikiSQL contains
SQL table instances extracted from 24241 HTML tables on Wikipedia, and 80654 natural language queries, each
accompanied by an SQL. WikiSQL comprises genuine data extracted from the web, with queries involving a",N/A,N/A
"multitude of tables, but the queries do not involve complex operations such as GROUP BY and multi-table union
queries. The majority of questions in WikiSQL are between 8 and 15 words in length, most SQLs are between
8 and 11 words, and most table columns are between 5 and 7. In addition, most natural language queries are of
the what type, followed by which, name, how many, who. The execution accuracy of WikiSQL has significantly",N/A,N/A
"improved from the initial 59.4% to 93.0%, and the method has undergone a transformation from a simple seq2seq
approach to a multi-tasking, transfer learning, and pre-training paradigm. A pair of questions and SQLs for the
CFLDraft table can be formulated as follows.
Q6: How many CFL teams are from York College?
SQL Q6: SELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”
(viii) ParaphraseBench [133], a component of the DBPal paper [10], is a benchmark utilized to assess the",N/A,N/A
"robustness of NLIDBs. Unlike existing benchmarks, ParaphraseBench covers diverse language variants of user
input NLQs and maps natural language to the anticipated SQL output. The benchmark is constructed upon a
medical database that contains a single table for storing patient information. The language variants utilized in
NLQs permit the classification of NLQs into six categories, as illustrated in Table 10.",N/A,N/A
"(ix) Advising [47] was proposed in 2018, and the NLQs were built on a database of course information from
the University of Michigan containing fictitious student profiles. A portion of the queries are collected from the
Facebook platform of the EECS department, and the remaining questions are formulated by computer science
students well-versed in database topics that might be raised in academic consulting appointments. The queries in",N/A,N/A
"Advising are for student-advising tasks, including join queries and nested queries. One of the English queries is
as follows.
Q7: For next semester, who is teaching EECS 123?
(x) Spider [160] is a large NL2SQL data set introduced by Yale University in 2018, in order to solve the
requirement for extensive and high-caliber datasets for a novel intricate cross-domain semantic parsing challenge.
22",N/A,N/A
"22
The data set contains 10181 natural language queries and 5693 corresponding complex SQLs, which are dis-
tributed across 200 independent databases, and the content covers 138 different domains. The average length of
questions and SQL statements in Spider is approximately 13 and 21 words, respectively. While the number of
questions and SQLs in Spider is not as extensive as that of WikiSQL, Spider contains all common SQL patterns",N/A,N/A
"and complex SQL usages, including advanced operations like HAVING, GROUP BY, ORDER BY, table joins,
and nested queries, which makes Spider closely aligned with real-world scenarios. The following is an illustra-
tive example of a complex problem and the corresponding SQL, which contains a nested query, a GROUP BY
component, and multiple table joins.
Q8: What are the name and budget of the departments with average instructor salary greater than the overall
average?",N/A,N/A
"average?
SQL Q8: SELECT T2.name, T2.budget FROM instructor as T1 JOIN department as T2 ON T1.department id =
T2.id GROUP BY T1.department id HAVING avg (T1.salary) > (SELECT avg (salary) FROM instructor)
4.2
Generation of new benchmarks
Modifying an existing NL2SQL benchmark to generate a new one is a common practice. The following steps
describe the process in detail.
(i) Researchers are required to conduct a meticulous analysis of the existing benchmarks, including an exam-",N/A,N/A
"ination of the data structures, query types, and complexity. Through the analysis, they can gain insight into the
constraints of the benchmark and identify potential avenues for enhancement.
(ii) Designing a modification strategy is a critical step, which involves determining how to modify and extend
the benchmark on the basis of the analysis results. The step may include adding new queries, changing the
linguistic expression of queries, and introducing complex query types.",N/A,N/A
"(iii) In the process of implementing modifications, researchers are expected to execute the designed modifica-
tion strategy with precision in order to ensure that the new benchmark meets the expected requirements.
(iv) Evaluating the performance is a pivotal aspect of the process. The researchers employ the modified
benchmark to train and test NL2SQL models, subsequently assessing the models’ performance and generalization
capabilities according to the new benchmark.",N/A,N/A
"capabilities according to the new benchmark.
Building on Spider [160], Kaoshik et al. [67] propose a new NL2SQL benchmark, named ACL-SQL, contain-
ing five tables and 3100 pairs of NLQ and SQL. By defining and annotating three types of questions on temporal
aspects in Spider: (i) questions querying for temporal information, (ii) questions querying for temporal infor-
mation with grouping or ordering, and (iii) questions with temporal conditions, Vo et al. [136] propose a new",N/A,N/A
"data set, TempQ4NLIDB, which can assist NLIDB systems based on machine learning approaches to improve
their performance on temporal aspects. To address the dearth of publicly available benchmarks on ambiguous
queries, Bhaskar et al. [11] generate a new benchmark called AmbiQT by modifying Spider with a combination
of synonym generation and ChatGPT-based and standard rules-based perturbation. AmbiQT comprises in excess",N/A,N/A
"of 3000 examples, each of which can be interpreted as two valid SQLs due to lexical ambiguities (namely, unam-
biguous column and table names) or structural ambiguities (namely, the necessity of joins and the pre-computation
of aggregations).
In light of the limitations of existing benchmarks, including (i) the presence of data bias or linguistic ex-
pression limitations, and (ii) the limited coverage of domains and contexts that cannot fully represent real-world",N/A,N/A
"diversity, researchers have proposed generators for Text2SQL benchmarks. Weir et al. [149] present a synthesized
data generator that synthesizes SQL patterns in the template syntax, including aggregations, simple nesting, and
column joins. Each SQL pattern is matched with numerous different natural language (NL) patterns, allowing
for the generation of a vast number of domain-specific NLQs and SQLs. Luo et al. [90] propose an NL2VIS",N/A,N/A
"synthesizer, named NL2SQL-to-NL2VIS, which is capable of generating multiple pairs of natural language and
VIS from a single NL and SQL pair based on semantic joins between SQL and VIS queries. NL2SQL-to-NL2VIS
23
can be utilized to create NL2VIS benchmarks from established NL2SQL benchmarks. Hu et al. [59] suggest
a framework for synthesizing Text2SQL benchmarks. The framework involves first synthesizing SQL and then",N/A,N/A
"generating NLQs. At the stage of synthesizing SQL, a method is suggested for column sampling based on pattern
distance weighting to prevent excessive complexity in concatenation. In the process of generating text from SQL,
an intermediate representation is used to facilitate the transition from SQL to NLQ, thereby enhancing the quality
of the generated NLQ.
4.3
Evaluation metrics
NLIDB is intended to assist users in efficiently querying and retrieving query results, and thus evaluating the",N/A,N/A
"response time and effectiveness of the system is essential. Response time measures how quickly the system can
process a user’s natural language queries and return the relevant results. Effectiveness measures how well the
system translates natural languages into accurate and relevant executable database languages, which consists of
two measures: (i) translatability and (ii) translation precision.",N/A,N/A
"DEFINITION 1 (Translatability). Given the set E of executable languages generated by the system and the set
N of input natural language queries, the translatability T is defined as follows.
T = |E|
|N|
DEFINITION 2 (Translation precision). Given the set ER of executable languages that meet the expected
results, the set N of natural language queries entered into the system, the translation precision TP is defined as
follows.
TP = |ER|
|N|",N/A,N/A
"follows.
TP = |ER|
|N|
Response time denotes the duration necessary for the system to transform the input natural language into the
executable language of the database. This temporal interval represents the difference between the moment when
the system furnishes the translated output and the moment when the natural language is received. Translatability
is a measure of the likelihood of the system accurately translating a natural language into an executable language.",N/A,N/A
"This metric is quantified as the proportion of correctly translated queries out of the total number of queries sub-
mitted to the system. Translation precision refers to the likelihood that the final output of the translated executable
language matches the expected outcome, and is quantified as the ratio of executable languages producing the
desired results to the overall number of queries.
The outcomes of evaluating a system may be different depending on the benchmark used. The size of the",N/A,N/A
"benchmark affects the accuracy of the semantic parsing part of the system. Complex queries in the benchmark can
be used to assess the system’s ability for generalization. In related papers, PRECISE achieves 95.0% translatabil-
ity and translation precision on the Restaurant benchmark and 77.5% on the GeoQuery benchmark. ATHENA has
a translatability and translation precision of 87.2% on the GeoQuery benchmark and 88.3% on the MAS bench-",N/A,N/A
"mark. The translatability and translation precision of NALMO on the benchmark MOQ are 98.1% and 88.1%,
respectively.
5
System interfaces development
We categorize recently developed NLIDBs according to the technical approach and the data stored in the backend.
The methods of developing and using the system interfaces are then divided into two categories for analysis and
summary:(i) used as an independent software and (ii) used as a module of a database management system. Finally,",N/A,N/A
"enhancements to the existing NLIDB system are presented in three aspects.
24
5.1
Recently developed NLIDBs
We are concerned with the NLIDBs, which have emerged since 2000. There are several ways to classify NLIDBs.
Affolter et al. [2] divide recently developed systems into four categories.
(i) Keyword-based systems are represented by SODA [15]. The core of such a system lies in the search",N/A,N/A
"process, where the inverted index containing fundamental data and metadata from the database is utilized as the
retrieval target. This process involves comparison with natural language, and identification of keywords referenced
in the query. Although simple, the approach fails to identify the potential semantics that are not directly present
in natural language. Such systems are unable to respond to aggregation queries and complex questions involving
sub-queries.",N/A,N/A
"sub-queries.
(ii) Pattern-based systems, exemplified by NLQ/A [166] and QuestIO [27], are extensions of keyword-based
systems that are capable of incorporating natural language patterns and mapping to pre-specified query sentence
patterns.
(iii) Parsing-based systems are typified by NaLIR, a general interactive natural language interface designed
for querying relational databases. NaLIR employs the existing natural language parser to acquire the semantic",N/A,N/A
"understanding of the given NLQ which is represented by a parse tree, and then converts the semantic understand-
ing into database understanding and finally into SQL. Such systems incorporate a multitude of natural language
processing methods, including the parsing of natural language sentences employing parse trees. One principal
benefit of this method is the ability to map semantics into predefined SQL templates.",N/A,N/A
"(iv) Grammar-based systems are represented by TR Discover [121] and MEANS [1]. The foundation of such
systems consists of a predetermined set of grammar rules, which are used to constrain the questions that users can
pose to the system in order to form formal NLQs that are straightforward to analyze. The primary advantage of
this approach is that the systems are capable of providing users with guidance as they enter questions, and can",N/A,N/A
"respond to all questions that adhere to the established rules. In comparison to keyword-based, pattern-based and
parsing-based systems, grammar-based systems are considered to be the most robust, despite relying significantly
on predefined manual rules.
In this survey, we categorize NLIDBs into seven distinct groups according to the data stored in the backend.
The representative systems for each category are depicted in Figure 8. Among the various categories, natural",N/A,N/A
"language interfaces for relational data are the most prevalent and functional, and are subjected to ongoing research
on an annual basis. Recently, research on NLIs for XML data has not advanced, remaining at the same stage as
in 2007. The two main reasons are (i) an increasing preference for JSON as a format for data exchange over
XML, and (ii) the suitability of NoSQL databases for handling unstructured or semi-structured data over XML",N/A,N/A
"databases. Since 2013, NLIs for natural language queries over RDF data, ontology data, graph data, spatial data,
and spatio-temporal data have been developed. The executable languages transformed by these NLIs correspond
to the databases used.
NLIDB for relational data transforms natural language queries into SQL. IRNet [53] first identifies the entities
contained in the NLQ, including columns, tables and values. Subsequently, a neural model based on syntax is",N/A,N/A
"used to synthesize an intermediate representation connecting natural language with SQL. Finally, IRNet derives
SQLs on the basis of intermediate representations. Representative NLIDBs for XML databases are NaLIX [85]
and DaNaLIX [81], which transform natural language queries into XQuery. NaLIX restricts natural language to a
predefined subset of the grammar. DaNaLIX builds upon NaLIX and enables users to leverage domain knowledge",N/A,N/A
"for query transformation. TEQUILA [64] is a typical NLIDB for RDF data, which transforms natural language
queries into SPARQL. TEQUILA employs a standard knowledge-based question and answer system to evaluate
sub-questions independently. The results of the sub-questions are then combined for inference to compute the
answer to the full question. QuestIO [27] works for querying structured data represented in ontology format.",N/A,N/A
"Built on the ontology and a knowledge base containing instances of the ontology’s concepts, QuestIO accepts
NLQ as input and produces SeRQL as output. Utilizing the language processing framework GATE, QuestIO
25
CHILL, BIN-CAT, PRECISE, SODA,
NLProv, ATHENA, SQLizer, Seq2SQL, NLProveNAns,
DialSQL, SyntaxSQLNet, TypeSQL, TEMPLAR, MyNLIDB, IRNet,
MISP-SQL, GLAMORISE,                                          ATHENA++, DBPal,",N/A,N/A
"BiBERT-SQL, ezNL2SQL,                                         ValueNet, COMBINE,
DBTagger, MIE, Veezoo, Auto-Query, ApproxEDA, LogicalBeam, 
GAR, GENSQL, IKnow-SQL, CatSQL, STAMP,
   SV2-SQL, xDBTagger, NaLIR
Relational data
gAnswer
MEANS
NL2CM
TEQUILA
EXAQT
RDF data
SpatialNLI
SP-CNN
NALSpatial
NALSD
NeuroSPE
Spatial data
NL2TRANQUYL
NLMO
NALMO
Spatio-temporal data
NaLIX
DaNaLIX
XML data
Querix
QuestIO
CNL-RDF-Query
Ontology data
Graph data
TR Discover
FINESSE",N/A,N/A
"Ontology data
Graph data
TR Discover
FINESSE
Figure 8: Classification of NLIDBs based on data stored in the backend
combines fundamental concepts with keywords, blocks and phrases to deduce potential relationships among the
concepts in the ontology. In the spatio-temporal domain, NLIDB can handle GIS-related queries, such as historical
meteorological data at a specific location, and geographic position information at different moments. NeuroSPE",N/A,N/A
"[109] is a spatial extraction model designed to identify spatial relations within Chinese natural language text. The
model extends a bidirectional gated recurrent neural network with a series of pre-trained models and is able to
address specific challenges in a variety of natural language text, including the absence of direct context and the
occurrence of abbreviations, special languages, and symbols. NALMO [144, 143] is a natural language interface",N/A,N/A
"designed for moving objects that allows users to submit queries of five types, including (i) time interval queries,
(ii) range queries, (iii) nearest neighbor queries, (iv) trajectory similarity queries, and (v) join queries.
Several systems have been created that can be used across various back-end data stores, with the objective of
enhancing the generality of NLIDB. TR Discover [121] is one such system which transforms NLQ into SPARQL",N/A,N/A
"or SQL. TR Discover generates FOL representations by analyzing natural language using a feature-based context-
independent grammar consisting of entries in the vocabulary for leaf nodes and rules governing the phrase structure
for non-terminal nodes. The FOL representation is then parsed into a parse tree through the utilization of a first-
order logic parser. The parse tree is traversed sequentially and transformed into SPARQL or SQL. FINESSE",N/A,N/A
"[63], an extension to ATHENA, is a system that seamlessly connects to multiple structured data stores. FINESSE
can access various structured backends (e.g., RDF stores and Graph stores) by automatically transforming the
intermediate query language OQL into the corresponding structured query language specific to the backends (e.g.,
SPARQL and Gremlin).
5.2
Development and usage of system interfaces",N/A,N/A
"5.2
Development and usage of system interfaces
The combination of the aforementioned three components, including (i) natural language preprocessing, (ii) nat-
ural language understanding and (iii) natural language translation, constitutes a comprehensive system architec-
ture. Then the theoretical knowledge is implemented in the form of a system. There are two primary methods of
development and usage:",N/A,N/A
"development and usage:
(i) A stand-alone software. In this scenario, the system generally comprises a separate visual interface and a
database, and the architecture is shown in Figure 9(a). A visual interface allows users to write natural language
26
Natural Language
Interface
DBMS
User
(a) A stand-alone software
User
Natural Language
Interface
Query Processor
DBMS
(b) A plug-in for DBMS
Figure 9: The architecture of the database system with NLI",N/A,N/A
"problems that are interactively translated into executable language. By submitting the executable language in
the corresponding database management system, the query results can be obtained. The paper [78] presents
the JavaScript-driven interface of NaLIR, which interacts with a master server implemented in Java. NL2CM
is implemented in Java 7, whose web user interface is constructed in PHP 5.3 and jQuery 1.x. The paper [62]",N/A,N/A
"develops a web interface designed to receive NLQs from users directed towards academic databases and display
translated SQLs. The interface also shows several example utterances to assist users in comprehending the domain.
The tool that comes with the NLMO system is a web application written in Java.
(ii) A plug-in for the database management system. In this instance, the system exists in a format analogous",N/A,N/A
"to a Python custom module and interacts with the user through the visual interface of the database management
system. The system architecture is illustrated in Figure 9(b). The user inputs NLQ by invoking the interface
provided by the system. Thereafter, the database management system automatically calls the NLI module to
process the NLQ, and displays the translated executable language on the visual interface. One of the most typical",N/A,N/A
"systems is NALMO, which is developed on a laptop running Ubuntu 14.04. The final interface form in SECONDO
is represented as an algebraic module with an operator. The users can use the operator on the moving objects
databases in SECONDO to perform the corresponding NLQ translation of moving objects.
5.3
Enhancement of NLIDB systems
Although existing NLIDBs have been able to achieve the transformation from natural language to executable",N/A,N/A
"database language, the research on NLIDB is a long process and the systems need to be optimized step by step
because natural language has rich expressions, ambiguous semantic knowledge and intricate correlations [61].
Enhancements to the existing NLIDB systems are mainly in the following three areas: (i) interpreting answers
and non-answers to queries, (ii) improving the effectiveness of the system, and (iii) securing the system against
potential vulnerabilities.
5.3.1",N/A,N/A
"potential vulnerabilities.
5.3.1
Interpreting answers and non-answers to queries
Researchers have enhanced the functionalities of existing systems with regards to providing explanations for both
query answers and non-answers. Users of NLIDB do not usually have the relevant expertise and may have diffi-
culty in understanding the results or verifying their correctness. In this work, papers [31, 32, 33, 34] complement",N/A,N/A
"these efforts by providing NL explanations for query answers. The authors propose a system named NLProv,
which employs the original NLQ structure to transform the provenance information into natural language. The
obtained provenance information is then presented to the user in the form of natural language answers, through a
four-step process:
27
• The user inputs a query using natural language that is transmitted to the improved NaLIR. The system",N/A,N/A
"processes the NLQ, constructs a formal query, and stores the translated portions of the NLQ in relation to
the formal query.
• NLProv employs the SelP system [36] to evaluate formal queries and records the provenance of each query,
indicating the correlation between dependency tree nodes and specific provenance sections.
• The source information is decomposed and then compiled into an NL answer with explanation.",N/A,N/A
"• The system presents the factorized answer to the user. In cases where the answer is excessively detailed and
difficult to comprehend, users have the option to access summaries at various levels of nesting.
The paper [34] proposes a general solution for NLProv that is not specific to NaLIR. The core of the solution
is an alternative architecture that does not depend on the query builder for producing the partial mappings between",N/A,N/A
"the nodes of the dependency tree and the components of the query. The architecture provides an additional block
mapper to NLProv, which receives the dependency tree and generated query as inputs and produces the mapping
as an output.
Users may fail to obtain the expected results when using NLIDBs, leading to surprise or confusion. NL-
ProveNAns [35] enriches NaLIR by supporting interpretations of non-answer. NLProveNAns can provide two",N/A,N/A
"explanations, corresponding to two different why-not source models: (i) a concise explanation rooted in the picky
boundary model and (ii) a comprehensive explanation derived from the polynomial model. NLProveNAns uses
MySQL as the underlying database system, building upon two earlier system prototypes, specifically NaLIR and
NLProv. NLProveNAns initially provides the user with a natural language interpretation of the query results and",N/A,N/A
"the tuples in the result set generated by NLProv. The user then formulates a “why-not” query. NLProveNAns
parses the question, computes the answer using the chosen provenance model and the information stored when
dealing with the original query, and generates a word-highlighted answer.
5.3.2
Improving the effectiveness of the system
Numerous researchers have provided user interaction components for NLIDB systems to improve effectiveness.",N/A,N/A
"When a user submits a question, the system assists the user in formulating an appropriate query by providing a
list of available queries and indicating the types of queries. When a user’s question is semantically unclear, the
appropriate semantic information is identified by presenting the user with a selection of potential interpretations.
When the data inputted by the user is not found in the database, similar information in the database can be",N/A,N/A
"provided to the user in the form of an associative prompt. Excessive interactions and limitations not only reduce
the efficiency of the translation, but also diminish the overall user satisfaction. Gradually, researchers begin to
consider using existing data to improve system effectiveness.
A key challenge to improving system effectiveness lies in closing the semantic gap between natural language",N/A,N/A
"and the fundamental data in the database. This challenge is reflected in join path inference and keyword mapping
when converting natural language to SQL. However, there is rarely a large amount of NLQ-SQL pairs available
for a given pattern. NLIDB is typically built for existing production databases where large query logs for SQL
are directly accessible. By analyzing the information in the query logs, NLIDB can identify potential join paths",N/A,N/A
"and keyword mappings. TEMPLAR [9] augments existing pipeline-based NLIDBs using query log information,
and the architecture is shown in Figure 10. TEMPLAR models the data from the query log using a data structure
known as the Query Fragment Graph (QFG), leveraging the information to enhance the capabilities of current
NLIDBs in join path inference and keyword mapping. The QFG stores information about the occurrence of query",N/A,N/A
"fragments in the log, and the symbiotic relationship between every pair of query fragments. Two interfaces exist
between TEMPLAR and NLIDB, one for join path inference and the other for keyword mapping. The experimen-
tal evaluation in the paper [9] proves the effectiveness of TEMPLAR, which greatly improves the translatability
of NaLIR and Pipeline by using query logs for SQL.
Taking the NLQ “Find papers from 2000 until 2010.” from the Microsoft Academic Search database as an
28
NLIDB
NLQ
SQL",N/A,N/A
"28
NLIDB
NLQ
SQL
Keyword Mapper
Join Path Generator
QFG
Query Logs
TEMPLAR
Database
Figure 10: The architecture of the NLIDB enhanced by TEMPLAR
example, the translation process of NaLIR enhanced with TEMPLAR is as follows.
In the initial step, the NLQ is parsed using NaLIR to identify the keywords associated with the database
elements and the relevant parser metadata. In this instance, the keywords identified by NaLIR are papers and from",N/A,N/A
"2000 until 2010. The result of using NaLIR to generate metadata is papers in the SELECT context and from 2000
until 2010 in the WHERE context.
In the second step, the keywords are transmitted to the Keyword Mapper that utilizes the keyword metadata
and pertinent information from the database to associate each keyword with potential query segments and assign
a score to these segments. In this example, the candidate mappings for papers include (journal.name, SELECT)",N/A,N/A
"and (publication.title, SELECT), and from 2000 until 2010 is mapped to (publication.year ≥2000 AND publica-
tion.year ≤2010, WHERE). The Keyword Mapper transmits the two most likely candidate configurations back to
NaLIR as follows.
• [(journal.name, SELECT);
(publication.year >= 2000 AND publication.year <= 2010, WHERE)]
• [(publication.title, SELECT);
(publication.year >= 2000 AND publication.year <= 2010, WHERE)]",N/A,N/A
"In the third step, NaLIR sends the known relationship of every candidate configuration to the Join Path Gen-
erator to generate the most probable join path. In this example, the Join Path Generator generates the join paths
journal-publication and publication for the two configurations, respectively.
In the final step, NaLIR utilizes the join paths returned by the Join Path Generator to construct and return the",N/A,N/A
"SQL for each candidate configuration. In this example, the final translated SQLs are as follows.
• SELECT j.name FROM journal j, publication p
WHERE p.year >= 2000 AND p.year <= 2010 AND j.jid = p.jid
• SELECT title FROM publication WHERE year >= 2000 AND year <= 2010
5.3.3
Securing the system against potential vulnerabilities
Research on the security vulnerabilities arising from malicious user interactions is relatively limited. Zhang et al.",N/A,N/A
"[164] propose a backdoor-based SQL injection framework for Text2SQL systems named TrojanSQL, using two
injection attacks: (i) boolean-based and (ii) union-based. Boolean-based injection is used for conditional queries
29
with WHERE clauses and invalidates the original query condition by performing boolean operations on existing
conditional judgments to bypass the original query condition. Union-based injection aims to steal private informa-",N/A,N/A
"tion, including database meta-information and user data privacy by performing a union query on the original user
query. Experimental results demonstrate that TrojanSQL has a high attack success rate against current Text2SQL
systems and is difficult to defend against. Zhang et al. [164] provide security practice recommendations for
NLIDB developers to reduce the risk of SQL injection attacks:",N/A,N/A
"• The utilization of only officially recognized or peer-reviewed data sets for model training is recommended.
• The selection of a verified and reputable source for initializing model weights is advised.
• The implementation of additional layers of security or filtering should be considered when using model
linking techniques.
• Rigorous testing should be performed prior to the integration of NLIDB APIs provided by third parties into
an application.
6",N/A,N/A
"an application.
6
Discussions about Text2SQL with LLM, SQL2Text and Speech2SQL
We discuss deep language understanding and database interaction techniques related to NLIDB, including the use
of LLM for Text2SQL tasks, the creation of natural language interpretations from SQL, and the transformation of
speech queries into SQL.
6.1
Text2SQL with LLM
The advent of the Transformer architecture [134] has resulted in considerable success of LLMs in natural language",N/A,N/A
"processing tasks. The models effectively capture the deep structure and semantic information of language through
pre-training and fine-tuning [94]. Decoder-only, encoder-only and encoder-decoder are the principal structures of
LLMs.
(i) The decoder-only model, represented by GPT [18, 98], exclusively comprises a decoder and generates
output sequences progressively through an autoregressive approach. The model is suitable for generative tasks",N/A,N/A
"such as text generation and dialogue systems [110]. However, the model exhibits limited effectiveness when
processing long texts due to the autoregressive nature. Additionally, the model does not directly handle input
information, posing a challenge of unidirectional information transmission.
(ii) The encoder-only model, represented by BERT [37], contains only an encoder and extracts context through",N/A,N/A
"bidirectional training. This architecture is applicable to tasks involving context comprehension and supervised
learning. Lacking a direct output generation mechanism, the model is unsuitable for generative tasks. In addition,
the model cannot handle variable-length outputs in seq2seq tasks.
(iii) The encoder-decoder model, represented by T5 [111], consists of an encoder and a decoder. The encoder",N/A,N/A
"maps the input sequence to a high-dimensional contextual representation, which is then utilized by the decoder
to produce the output sequence. The architecture excels in tasks requiring global information transfer, such as
machine translation and summary generation [76]. However, the computational resource demands of the model
are high, and the complexity of information transfer may lead to performance degradation in certain tasks.",N/A,N/A
"LLMs contribute to the development of NLIDB. Notably, the growing popularity of GPT [18, 98] opens new
possibilities for NLP in NLIDB systems. GPT supports natural language queries over spatial data and returns
sensible SQL frameworks.
EXAMPLE 1. Taking the NLQ “Can you tell me what POIs are available in Jiangning District?” as an example,
the SQL generated by GPT is as follows.
SELECT POI.name
FROM POI JOIN district ON ST Within(POI.geom, district.geom)
30",N/A,N/A
"30
WHERE district.name = ‘Jiangning District’;
The query employs the ST Within function to ascertain whether the location of each POI is within Jiangning
District. GPT extracts the entities (POI and district) and the query type (range query).
However, GPT is primarily designed for traditional relational data and has limited ability to represent spatial
data. While adept at processing simple objects(e.g., points), GPT’s representation capabilities are less effective",N/A,N/A
"when dealing with more intricate objects(e.g., lines and regions).
EXAMPLE 2. Taking the NLQ “What cinemas are there on Sterndamm street?” as an example, the SQL gener-
ated by GPT is as follows.
SELECT name
FROM cinemas
WHERE ST Intersects (location, ST GeomFromText (‘ LINESTRING (13.531836 52.437831, 13.536510
52.434202 )’, 4326));
GPT is capable of capturing the pivotal semantic details contained within the query, including cinemas, Stern-",N/A,N/A
"damm street and the spatial correlation between them. However, the representation of Sterndamm street in the
executable language is not accurate and Sterndamm street comprises multiple segments. Upon receiving the
prompt “Sterndamm street is stored in the spatial relation streets”, GPT generates a reasonable SQL:
SELECT name
FROM cinemas
WHERE ST Intersects (location, (SELECT ST Buffer (geom, 0.0001) FROM streets WHERE name =
‘Sterndamm’));",N/A,N/A
"‘Sterndamm’));
The query utilizes the ST Buffer function to create a buffer with a size of 0.0001 degrees (approximately 11 meters)
around Sterndamm street and subsequently employs the ST Intersects function to examine whether the location of
each cinema intersects with the buffer.
The advent of intricate deep learning architectures has prompted a focus on accurately interpreting natural
language and generating structured language by optimizing LLMs. This direction emphasizes optimizing the",N/A,N/A
"LLM through larger data pre-training, superior language representation learning techniques, and more efficient
fine-tuning methods. Zero-sample learning strategies have also received attention to enable the system to handle
unseen query types without retraining, which can be achieved through zero-sample learning and meta-learning
techniques.
6.2
SQL2Text
The purpose of SQL2Text is to transform complex SQL into natural language description. This transformation",N/A,N/A
"helps non-technical users to comprehend the logic and structure of SQL, thus making database interactions trans-
parent and understandable. Koutrika et al. [73] utilize a graph-based approach for transforming SQL into natural
language. SQL is first represented as a directed graph whose edges are labeled with template labels using an ex-
tensible template mechanism, thus providing semantics for the parts of the query. These graphs are then explored",N/A,N/A
"and textual query description is composed using a variety of graph traversal strategies, including the binary search
tree algorithm, the multi-reference point algorithm, and the template combination algorithm. Eleftherakis et al.
[40] address SQL2Text by extending the graph-based model of Logos to translate a wider range of queries (e.g.
SELECT TOP, LIMIT, IN, and LIKE). The SQL is first analyzed to generate a parse tree storing the essential",N/A,N/A
"information utilized to construct the query graph, and then the textual description of the SQL is created through
31
the application of the multi-reference point traversal strategy. Camara et al. [20] employ LLM to generate ex-
planations of SQL. The logical structure of SQL is recorded and the columns and tables are interpreted in natural
language.
Although progress has been made in this direction, there remains ample opportunity for enhancement. Future",N/A,N/A
"research will focus on improving the quality and richness of the generated natural language explanations, ensuring
that they are both accurate and rich. In addition, future research will explore context-awareness, which means
providing relevant natural language explanations in conjunction with the contextual information in the user’s
query. This technique also involves exploring how SQL2Text can be combined with dialogue systems to enable
intelligent and coherent database interactions.
6.3",N/A,N/A
"6.3
Speech2SQL
Speech2SQL technology is designed to transform speech input into SQL, making the process of database query-
ing as simple and intuitive as speaking, thus significantly reducing the barrier to database interaction. SpeakQL
[21, 119, 117, 118] converts speech SQL into queries that are displayed on the screen, where users can perform
interactive query corrections using a screen-based touch interface or a single click. SpeakQL utilizes automatic",N/A,N/A
"speech recognition (ASR) tools to record speech SQL which will be output as text. The Structure Determination
component of SpeakQL is responsible for post-processing the ASR results in order to generate syntactically ac-
curate SQL with textual placeholders, and then uses the original ASR output to fill in the textual placeholders.
SpeakNav [165, 12] is a system that combines natural language understanding with route search related to naviga-",N/A,N/A
"tion. Users are permitted to describe a predetermined route by voice, and SpeakNav presents a suggested path on a
map accompanied by information regarding the estimated duration and distance of the journey. MUVE [147, 148]
converts NLQs formulated in speech to SQL using a greedy heuristic approach that does not ensure an optimal
solution, but produces a solution that is close to optimal. MUVE answers speech queries by utilizing a multi-plot",N/A,N/A
"approach, including multiple bar graphs that display the outcomes of various query options. SpeechSQLNet [122]
is an end-to-end neural architecture designed to convert speech into SQL directly, obviating the necessity for an ex-
ternal ASR. SpeechSQLNet effectively combines a transformer, a graphical neural network, and a speech encoder
as foundational components. The speech encoder is first used to transform speech into a concealed representation,",N/A,N/A
"and the GNN-based encoder is employed to convert patterns that have a considerable influence on the desired SQL
into hidden features to safeguard the structural information. The speech embedding is then combined with pattern
characteristics to generate semantically consistent SQL. Wav2SQL [86] is also an end-to-end Speech2SQL parser
that utilizes self-supervised learning to address the challenge of limited data availability and generate diverse rep-",N/A,N/A
"resentations. Furthermore, speech reprogramming and gradient inversion techniques are introduced to eliminate
stylistic attributes in the speech representation and enhance the generalization ability of the model to user-defined
data. VoiceQuerySystem [123] is a speech-based database query system that generates SQL from NLQ speech
using two methods:
• Cascade approach involves converting speech-based natural language queries to text using a proprietary",N/A,N/A
"ASR module, followed by the generation of SQL through IRNet.
• End-to-end approach directly converts speech to SQL without the need for text as an intermediate medium,
by using SpeechSQLNet.
Despite the considerable efforts invested in speech recognition and interaction technologies, there remain
significant challenges that require further attention. Subsequent research is expected to concentrate on enhancing",N/A,N/A
"the accuracy of speech recognition, possibly by utilizing end-to-end speech recognition models and integrating
multiple modalities with other input sources. This technique will also involve investigating the potential for
combining speech interaction with text query processing techniques to facilitate seamless and efficient database
interaction.
32
7
Future research and conclusions
We investigate unresolved issues and potential directions for future research in the area of NLIDB and provide the",N/A,N/A
"conclusions of this paper.
7.1
Open problems
Despite the considerable advancements made by NLIDB, numerous challenges and issues remain to be addressed.
The following is a list of the principal open problems with the technical details.
Natural language disambiguation. The ambiguity and polysemous nature of natural language makes NLIDB
systems face great challenges in correctly understanding user intentions. Future research should focus on the
following aspects.",N/A,N/A
"following aspects.
(i) Contextual understanding. Advanced context-aware models can be developed to utilize contextual infor-
mation for disambiguation. Attention mechanisms and memory networks allow to keep track of the context in a
dialogue system.
(ii) Multi-round dialogue. Introducing multiple rounds of dialogue enables the system to gradually clarify
users’ intent through a series of interactions, which requires the design of an effective dialogue management",N/A,N/A
"strategy and a mechanism for confirming users’ intent.
(iii) Semantic parsing. Complex semantic parsing techniques, such as semantic role labeling and knowledge
graph, can be utilized to elucidate the implicit information in natural language.
Query optimization. Converting natural language queries into efficient database queries and optimizing query
performance during execution remain significant challenges. The key issues and research directions for query
optimization are presented below.",N/A,N/A
"optimization are presented below.
(i) Index Selection. Depending on the query criteria and data distribution, the indexing scheme that optimizes
retrieval speed is selected. The optimizer scans the existing indexes, evaluates the selectivity and cost of each
index, and determines which indexes filter the data most efficiently. In complex queries, multiple indexes may be
used simultaneously, and the optimizer will select a union index or cross-index scan to improve query performance.",N/A,N/A
"(ii) Query rewriting is a method of simplifying the execution plan and improving query efficiency. Sub-queries
can be reformulated as joins to simplify complex nested queries. Additionally, the value of constant expressions
can be computed in advance in the query, reducing the runtime computation. Finally, redundant sorting, joining,
or filtering operations can be removed from the query to simplify the query execution plan.",N/A,N/A
"(iii) Execution plan selection. The cost of each execution plan is evaluated using statistical information (e.g.,
table size and index distribution) and a cost model (rule-based or cost-based). This evaluation considers I/O opera-
tions, CPU time, and memory utilization. The least costly plan can be identified through dynamic programming or
heuristic algorithms, thereby ensuring that the query is executed with minimal resource consumption and optimal
performance.",N/A,N/A
"performance.
(iv) Join optimization. The join operation is a highly resource-consuming process, and determining the most
efficient join order and method is critical. The selection of suitable join algorithms (e.g., subsumption joins, hash
joins and nested loop joins) and the application of join condition derivation can lead to a reduction in the quantity
of join operations, thus optimizing join performance and improving query efficiency.",N/A,N/A
"Corpus construction. One of the most pressing issues in the research of NLIDB is the construction and
utilization of the corpus, with particular focus on the following aspects.
(i) In order to guarantee the generality and adaptability of the natural language interface system, one needs to
collect data from diverse sources. Multi-source data integration techniques can be employed to gather information",N/A,N/A
"from user query logs, social media conversations, and customer service records to ensure that the corpus is diverse
and representative.
33
(ii) A high-quality corpus relies on accurate annotation, which requires the integration of manual and auto-
mated tools. The development of collaborative annotation platforms and automated annotation tools can enhance
the efficiency and uniformity of annotation, concurrently establishing a quality assessment system to detect and",N/A,N/A
"rectify annotation errors, thus ensuring the accuracy and reliability of data annotation.
(iii) Protecting user privacy and data security is of paramount importance when constructing and utilizing the
corpus. The application of differential privacy and data encryption techniques, in conjunction with the formulation
of guidelines for the ethical use of data, can guarantee legality and compliance in the process of data collection",N/A,N/A
"and utilization. Transparency and user control techniques enable users to understand and regulate the usage of
data.
(iv) The construction and evaluation of the corpus necessitate a unified and standardized framework to facil-
itate the comparison of research results and the sharing of data. The establishment of open data platforms and
the promotion of cross-institutional cooperation can address legal and technical challenges in data sharing and",N/A,N/A
"promote the sharing and reuse of resources and results.
7.2
Conclusions
This paper offers a comprehensive review of recently proposed NLIDBs. We summarize the translation process
from natural language to database executable language in three stages: (i) natural language preprocessing, (ii)
natural language understanding, and (iii) natural language translation. At the natural language preprocessing",N/A,N/A
"stage, we observe that almost every system employs named entity recognition and part-of-speech tagging. At
the natural language understanding stage, we learn that although the limitations of rule-based approaches can be
eliminated, machine learning-based semantic parsing methods are highly dependent on training data and require
longer time and more memory space to build models. At the natural language translation stage, we provide a",N/A,N/A
"general process for building executable languages over relational and spatio-temporal databases. Furthermore,
we provide a summary of the common benchmarks for translating natural language queries into executable lan-
guages, system evaluation metrics, and the classification, development, and enhancement of NLIDBs. Despite the
potential to enhance database accessibility, NLIDB still faces numerous challenges, including natural language",N/A,N/A
"disambiguation, query optimization, and corpus construction. Future research should prioritize addressing the
open issues to further improve the effectiveness and user satisfaction of NLIDB systems.
References
[1] Asma Ben Abacha and Pierre Zweigenbaum. MEANS: A medical question-answering system combining
NLP techniques and semantic web technologies. Inf. Process. Manag., 51(5):570–594, 2015.",N/A,N/A
"[2] Katrin Affolter, Kurt Stockinger, and Abraham Bernstein. A comparative survey of recent natural language
interfaces for databases. VLDB J., 28(5):793–819, 2019.
[3] Karam Ahkouk and Mustapha Machkour. Towards an interface for translating natural language questions to
SQL: a conceptual framework from a systematic review. Int. J. Reason. based Intell. Syst., 12(4):264–275,
2020.
[4] Muhammed Jassem Al-Muhammed and Deryle W. Lonsdale. Ontology-aware dynamically adaptable free-",N/A,N/A
"form natural language agent interface for querying databases. Knowl. Based Syst., 239:108012, 2022.
[5] Yael Amsterdamer, Anna Kukliansky, and Tova Milo. A natural language interface for querying general
and individual knowledge. Proc. VLDB Endow., 8(12):1430–1441, 2015.
[6] Yael Amsterdamer, Anna Kukliansky, and Tova Milo.
Nl2cm: A natural language interface to crowd
mining. In SIGMOD, pages 1433–1438, 2015.",N/A,N/A
"mining. In SIGMOD, pages 1433–1438, 2015.
[7] Ion Androutsopoulos, Graeme D. Ritchie, and Peter Thanisch. Natural language interfaces to databases -
an introduction. Nat. Lang. Eng., 1(1):29–81, 1995.
34
[8] Yoav Artzi and Luke S. Zettlemoyer. Bootstrapping semantic parsers from conversations. In EMNLP, pages
421–432, 2011.
[9] Christopher Baik, H. V. Jagadish, and Yunyao Li. Bridging the semantic gap with SQL query logs in natural",N/A,N/A
"language interfaces to databases. In IEEE ICDE, pages 374–385, 2019.
[10] Fuat Basik, Benjamin H¨attasch, Amir Ilkhechi, Arif Usta, Shekar Ramaswamy, Prasetya Utama, Nathaniel
Weir, Carsten Binnig, and Ugur C¸ etintemel. Dbpal: A learned nl-interface for databases. In SIGMOD,
pages 1765–1768, 2018.
[11] Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, and Sunita Sarawagi. Benchmarking and improving
text-to-sql generation under ambiguity. In EMNLP, pages 7053–7074, 2023.",N/A,N/A
"[12] Lei Bi, Juan Cao, Guohui Li, Nguyen Quoc Viet Hung, Christian S. Jensen, and Bolong Zheng. Speaknav:
A voice-based navigation system via route description language understanding. In ICDE, pages 2669–2672,
2021.
[13] Steven Bird. NLTK: the natural language toolkit. In ACL, 2006.
[14] Adrian N. Bishop, Jeremie Houssineau, Daniel Angley, and Branko Ristic. Spatio-temporal tracking from
natural language statements using outer probability theory. Inf. Sci., 463-464:56–74, 2018.",N/A,N/A
"[15] Lukas Blunschi, Claudio Jossen, Donald Kossmann, Magdalini Mori, and Kurt Stockinger. SODA: gener-
ating SQL for business users. Proc. VLDB Endow., 5(10):932–943, 2012.
[16] Joel Booth, Barbara Di Eugenio, Isabel F. Cruz, and Ouri Wolfson. Robust natural language processing for
urban trip planning. Appl. Artif. Intell., 29(9):859–903, 2015.
[17] Joel Booth, A. Prasad Sistla, Ouri Wolfson, and Isabel F. Cruz. A data model for trip planning in multimodal",N/A,N/A
"transportation systems. In EDBT, volume 360 of ACM International Conference Proceeding Series, pages
994–1005, 2009.
[18] Tom B. Brown, Benjamin Mann, Nick Ryder, and et al. Language models are few-shot learners. Advances
in neural information processing systems, 33:1877–1901, 2020.
[19] Ursin Brunner and Kurt Stockinger. Valuenet: A natural language-to-sql system that learns from database
information. In ICDE, pages 2177–2182, 2021.",N/A,N/A
"information. In ICDE, pages 2177–2182, 2021.
[20] Vanessa Cˆamara, Rayol Mendonca-Neto, Andr´e Silva, and Luiz Cordovil Jr.
A large language model
approach to sql-to-text generation. In ICCE, pages 1–4, 2024.
[21] Dharmil Chandarana, Vraj Shah, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven
multi-modal querying. In HILDA@SIGMOD, pages 11:1–11:6, 2017.
[22] Chih-Yung Chang, Yuan-Lin Liang, Shih-Jung Wu, and Diptendu Sinha Roy. Sv2-sql: a text-to-sql trans-",N/A,N/A
"formation mechanism based on BERT models for slot filling, value extraction, and verification. Multim.
Syst., 30(1):16, 2024.
[23] Peng Chen, Hui Li, Sourav S. Bhowmick, Shafiq R. Joty, and Weiguo Wang.
LANTERN: boredom-
conscious natural language description generation of query execution plans for database education. In
SIGMOD, pages 2413–2416, 2022.
[24] Yi-Hui Chen, Eric Jui-Lin Lu, and Ting-An Ou. Intelligent SPARQL query generation for natural language",N/A,N/A
"processing systems. IEEE Access, 9:158638–158650, 2021.
[25] Jianpeng Cheng, Siva Reddy, Vijay A. Saraswat, and Mirella Lapata. Learning structured natural language
representations for semantic parsing. In ACL, pages 44–55, 2017.
[26] Danica Damljanovic, Milan Agatonovic, and Hamish Cunningham. Freya: An interactive way of querying
linked data using natural language. In ESWC, volume 7117 of Lecture Notes in Computer Science, pages
125–138, 2011.",N/A,N/A
"125–138, 2011.
[27] Danica Damljanovic, Valentin Tablan, and Kalina Bontcheva. A text-based query interface to OWL ontolo-
gies. In LREC, 2008.
35
[28] Alaka Das and Rakesh Chandra Balabantaray. Mynlidb: A natural language interface to database. In ICIT,
pages 234–238, 2019.
[29] C. J. Date. A critique of the SQL database language. SIGMOD Rec., 14(3):8–54, 1984.
[30] Ephrem Tadesse Degu and Rosa Tsegaye Aga. Natural language interface for covid-19 amharic database",N/A,N/A
"using LSTM encoder decoder architecture with attention. In ICT4DA, pages 95–100, 2021.
[31] Daniel Deutch, Nave Frost, and Amir Gilad. Nlprov: Natural language provenance. Proc. VLDB Endow.,
9(13):1537–1540, 2016.
[32] Daniel Deutch, Nave Frost, and Amir Gilad. Provenance for natural language queries. Proc. VLDB Endow.,
10(5):577–588, 2017.
[33] Daniel Deutch, Nave Frost, and Amir Gilad. Natural language explanations for query results. SIGMOD
Rec., 47(1):42–49, 2018.",N/A,N/A
"Rec., 47(1):42–49, 2018.
[34] Daniel Deutch, Nave Frost, and Amir Gilad.
Explaining natural language query results.
VLDB J.,
29(1):485–508, 2020.
[35] Daniel Deutch, Nave Frost, Amir Gilad, and Tomer Haimovich. Nlprovenans: Natural language provenance
for non-answers. Proc. VLDB Endow., 11(12):1986–1989, 2018.
[36] Daniel Deutch, Amir Gilad, and Yuval Moskovitch. Selective provenance for datalog programs using top-k
queries. Proc. VLDB Endow., 8(12):1394–1405, 2015.",N/A,N/A
"[37] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirec-
tional transformers for language understanding. In NAACL-HLT, pages 4171–4186, 2019.
[38] Li Dong and Mirella Lapata. Language to logical form with neural attention. In ACL, 2016.
[39] Li Dong and Mirella Lapata. Coarse-to-fine decoding for neural semantic parsing. In ACL, pages 731–742,
2018.",N/A,N/A
"2018.
[40] Stavroula Eleftherakis, Orest Gkini, and Georgia Koutrika. Let the database talk back: Natural language
explanations for SQL. In SEA-Data, volume 2929 of CEUR Workshop Proceedings, pages 14–19, 2021.
[41] Tatiana N. Erekhinskaya, Dmitriy Strebkov, Sujal Patel, Mithun Balakrishna, Marta Tatu, and Dan I.
Moldovan. Ten ways of leveraging ontologies for natural language processing and its enterprise appli-
cations. In SBD@SIGMOD, pages 8:1–8:6, 2020.",N/A,N/A
"cations. In SBD@SIGMOD, pages 8:1–8:6, 2020.
[42] Yuankai Fan, Zhenying He, Tonghui Ren, Dianjun Guo, Lin Chen, Ruisi Zhu, Guanduo Chen, Yinan Jing,
Kai Zhang, and X. Sean Wang. Gar: A generate-and-rank approach for natural language to SQL translation.
In ICDE, pages 110–122, 2023.
[43] Yuankai Fan, Tonghui Ren, Dianjun Guo, Zhigang Zhao, Zhenying He, X. Sean Wang, Yu Wang, and Tao
Sui. An integrated interactive framework for natural language to SQL translation. In WISE, volume 14306",N/A,N/A
"of Lecture Notes in Computer Science, pages 643–658, 2023.
[44] Yuankai Fan, Tonghui Ren, Zhenying He, X. Sean Wang, Ye Zhang, and Xingang Li. Gensql: A generative
natural language interface to database systems. In ICDE, pages 3603–3606, 2023.
[45] Alessandro Fantechi, Stefania Gnesi, Samuele Livi, and Laura Semini. A spacy-based tool for extracting
variability from NL requirements. In SPLC, pages 32–35, 2021.",N/A,N/A
"[46] S´ebastien Ferr´e. Sparklis: An expressive query builder for SPARQL endpoints with guidance in natural
language. Semantic Web, 8(3):405–418, 2017.
[47] Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui
Zhang, and Dragomir R. Radev. Improving text-to-sql evaluation methodology. In ACL, pages 351–360,
2018.
[48] Han Fu, Chang Liu, Bin Wu, Feifei Li, Jian Tan, and Jianling Sun. Catsql: Towards real world natural",N/A,N/A
"language to SQL applications. Proc. VLDB Endow., 16(6):1534–1547, 2023.
36
[49] Kaitlyn Fulford and Aspen Olmsted. Mobile natural language database interface for accessing relational
data. In i-Society, pages 86–87, 2017.
[50] Yujian Gan, Xinyun Chen, Jinxia Xie, Matthew Purver, John R. Woodward, John H. Drake, and Qiaofu
Zhang. Natural SQL: making SQL easier to infer from natural language specifications. In EMNLP, pages
2030–2042, 2021.",N/A,N/A
"2030–2042, 2021.
[51] Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nalla-
pati, and Xiaofei Ma. Multitask pretraining with structured knowledge for text-to-sql generation. In ACL,
pages 11067–11083, 2023.
[52] Alessandra Giordani and Alessandro Moschitti.
Translating questions to SQL queries with generative
parsers discriminatively reranked. In COLING, pages 401–410, 2012.",N/A,N/A
"[53] Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu, and Dongmei Zhang. Towards
complex text-to-sql in cross-domain database with intermediate representation. In ACL, pages 4524–4535,
2019.
[54] Izzeddin Gur, Semih Yavuz, Yu Su, and Xifeng Yan. Dialsql: Dialogue based structured query generation.
In ACL, pages 1339–1349, 2018.
[55] Ralf Hartmut G¨uting. An introduction to spatial database systems. VLDB J., 3(4):357–399, 1994.",N/A,N/A
"[56] Ralf Hartmut G¨uting, Thomas Behr, and Christian D¨untgen. SECONDO: A platform for moving objects
database research and for publishing and integrating research implementations. IEEE Data Eng. Bull.,
33(2):56–63, 2010.
[57] Ditiman Hazarika, Gopal Konwar, Shuvam Deb, and Dibya Jyoti Bora. Sentiment analysis on twitter by
using textblob for natural language processing. In ICRMAT, volume 24 of Annals of Computer Science and
Information Systems, pages 63–67, 2020.",N/A,N/A
"Information Systems, pages 63–67, 2020.
[58] Jos´e Henarejos-Blasco, Jos´e Antonio Garc´ıa-D´ıaz, ´Oscar Apolinario-Arzube, and Rafael Valencia-Garc´ıa.
Cnl-rdf-query: a controlled natural language interface for querying ontologies and relational databases. In
EATIS, pages 35:1–35:5, 2020.
[59] Yiqun Hu, Yiyun Zhao, Jiarong Jiang, Wuwei Lan, Henghui Zhu, Anuj Chauhan, Alexander Hanbo Li,
Lin Pan, Jun Wang, Chung-Wei Hang, Sheng Zhang, Jiang Guo, Mingwen Dong, Joseph Lilien, Patrick",N/A,N/A
"Ng, Zhiguo Wang, Vittorio Castelli, and Bing Xiang. Importance of synthesizing high-quality data for
text-to-sql parsing. In ACL, pages 1327–1343, 2023.
[60] Ruizhe Huang and Lei Zou. Natural language question answering over RDF data. In SIGMOD, pages
1289–1290, 2013.
[61] Zachary G. Ives. Technical perspective: : Natural language explanations for query results. SIGMOD Rec.,
47(1):41, 2018.",N/A,N/A
"47(1):41, 2018.
[62] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, and Luke Zettlemoyer. Learning a
neural semantic parser from user feedback. In ACL, pages 963–973, 2017.
[63] Manasa Jammi, Jaydeep Sen, Ashish R. Mittal, Sagar Verma, Vardaan Pahuja, Rema Ananthanarayanan,
Pranay Lohia, Hima Karanam, Diptikalyan Saha, and Karthik Sankaranarayanan. Tooling framework for
instantiating natural language querying system. Proc. VLDB Endow., 11(12):2014–2017, 2018.",N/A,N/A
"[64] Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Str¨otgen, and Gerhard Weikum. TEQUILA:
temporal question answering over knowledge bases. In CIKM, pages 1807–1810, 2018.
[65] Jiffy Joseph, Janu R Panicker, and Meera M. An efficient natural language interface to xml database. In
ICIS, pages 207–212, 2016.
[66] Aishwarya Kamath and Rajarshi Das. A survey on semantic parsing. In AKBC, 2019.",N/A,N/A
"[67] Ronak Kaoshik, Rohit Patil, Prakash R, Shaurya Agarawal, Naman Jain, and Mayank Singh. ACL-SQL:
generating SQL queries from natural language. In CODS-COMAD, page 423, 2021.
37
[68] George Katsogiannis-Meimarakis and Georgia Koutrika. A survey on deep learning approaches for text-to-
sql. VLDB J., 32(4):905–936, 2023.
[69] Esther Kaufmann, Abraham Bernstein, and Renato Zumstein. Querix: A natural language interface to query
ontologies based on clarification dialogs. In ISWC, 2006.",N/A,N/A
"[70] Hyeonji Kim, Byeong-Hoon So, Wook-Shin Han, and Hongrae Lee. Natural language to SQL: where are
we today? Proc. VLDB Endow., 13(10):1737–1750, 2020.
[71] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.
[72] Georgia Koutrika. Natural language data interfaces: A data access odyssey (invited talk). In ICDT, volume
290 of LIPIcs, pages 1:1–1:22, 2024.",N/A,N/A
"290 of LIPIcs, pages 1:1–1:22, 2024.
[73] Georgia Koutrika, Alkis Simitsis, and Yannis E. Ioannidis. Explaining structured queries in natural lan-
guage. In ICDE, pages 333–344, 2010.
[74] Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. Neural semantic parsing with type constraints
for semi-structured tables. In EMNLP, pages 1516–1526, 2017.
[75] Claude Lehmann, Dennis Gehrig, Stefan Holdener, Carlo Saladin, Jo˜ao Pedro Monteiro, and Kurt",N/A,N/A
"Stockinger. Building natural language interfaces for databases in practice. In SSDBM, pages 20:1–20:4,
2022.
[76] Mike Lewis, Yinhan Liu, Naman Goyal, and et al. BART: denoising sequence-to-sequence pre-training for
natural language generation, translation, and comprehension. In ACL, pages 7871–7880, 2020.
[77] Fei Li and H. V. Jagadish. Constructing an interactive natural language interface for relational databases.
Proc. VLDB Endow., 8(1):73–84, 2014.",N/A,N/A
"Proc. VLDB Endow., 8(1):73–84, 2014.
[78] Fei Li and H. V. Jagadish. Nalir: an interactive natural language interface for querying relational databases.
In SIGMOD, pages 709–712, 2014.
[79] Fei Li and H. V. Jagadish. Understanding natural language queries over relational databases. SIGMOD
Rec., 45(1):6–13, 2016.
[80] Jingjing Li, Wenlu Wang, Wei-Shinn Ku, Yingtao Tian, and Haixun Wang. Spatialnli: A spatial domain",N/A,N/A
"natural language interface to databases using spatial comprehension. In ACM SIGSPATIAL, pages 339–348,
2019.
[81] Yunyao Li, Ishan Chaudhuri, Huahai Yang, Satinder Singh, and H. V. Jagadish. Danalix: a domain-adaptive
natural language interface for querying XML. In SIGMOD, pages 1165–1168, 2007.
[82] Yunyao Li and Davood Rafiei. Natural language data management and interfaces: Recent development and
open challenges. In ACM SIGMOD, pages 1765–1770, 2017.",N/A,N/A
"[83] Yunyao Li and Davood Rafiei. Natural Language Data Management and Interfaces. Synthesis Lectures on
Data Management. 2018.
[84] Yunyao Li, Huahai Yang, and H. V. Jagadish. Nalix: an interactive natural language interface for querying
XML. In SIGMOD, pages 900–902, 2005.
[85] Yunyao Li, Huahai Yang, and H. V. Jagadish. Nalix: A generic natural language search environment for
XML data. ACM Trans. Database Syst., 32(4):30, 2007.",N/A,N/A
"[86] Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize Cheng, and Zhou Zhao. Wav2sql:
Direct generalizable speech-to-sql parsing. CoRR, abs/2305.12552, 2023.
[87] Jian Liu, Qian Cui, Hongwei Cao, Tianyuan Shi, and Min Zhou. Auto-conversion from natural language to
structured query language using neural networks embedded with pre-training and fine-tuning mechanism.
In CAC, pages 6651–6654, 2020.",N/A,N/A
"In CAC, pages 6651–6654, 2020.
[88] Mengyi Liu, Xieyang Wang, and Jianqiu Xu. NALSD: A natural language interface for spatial databases.
In SSTD, pages 175–179, 2023.
38
[89] Mengyi Liu, Xieyang Wang, Jianqiu Xu, and Hua Lu. Nalspatial: An effective natural language transfor-
mation framework for queries over spatial data. In SIGSPATIAL/GIS, pages 57:1–57:4, 2023.
[90] Yuyu Luo, Nan Tang, Guoliang Li, Chengliang Chai, Wenbo Li, and Xuedi Qin. Synthesizing natural",N/A,N/A
"language to visualization (NL2VIS) benchmarks from NL2SQL benchmarks. In SIGMOD, pages 1235–
1247, 2021.
[91] Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven Bethard, and David
McClosky. The stanford corenlp natural language processing toolkit. In ACL, pages 55–60, 2014.
[92] Youssef Mellah, Abdelkader Rhouati, El Hassane Ettifouri, Toumi Bouchentouf, and Mohammed Ghaouth",N/A,N/A
"Belkasmi. COMBINE: A pipeline for SQL generation from natural language. In ICACDS, volume 1441 of
Communications in Computer and Information Science, pages 97–106, 2021.
[93] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Distributed representa-
tions of words and phrases and their compositionality. In NIPS, pages 3111–3119, 2013.
[94] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko",N/A,N/A
"Agirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained
language models: A survey. ACM Comput. Surv., 56(2):30:1–30:40, 2024.
[95] Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong, Andreas Z¨ufle, and et al. Mobility data science
(dagstuhl seminar 22021). Dagstuhl Reports, 12(1):1–34, 2022.
[96] Kevin Mote. Natural language processing - A survey. CoRR, abs/1209.6238, 2012.",N/A,N/A
"[97] Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen Zhang, Arman Cohan, and
Dragomir Radev. Enhancing text-to-sql capabilities of large language models: A study on prompt design
strategies. In EMNLP, pages 14935–14956, 2023.
[98] Long Ouyang, Jeffrey Wu, Xu Jiang, and et al. Training language models to follow instructions with human
feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.",N/A,N/A
"[99] Fatma Ozcan, Abdul Quamar, Jaydeep Sen, Chuan Lei, and Vasilis Efthymiou. State of the art and open
challenges in natural language interfaces to data. In SIGMOD, pages 2629–2636, 2020.
[100] Parth Parikh, Oishik Chatterjee, Muskan Jain, Aman Harsh, Gaurav Shahani, Rathin Biswas, and Kavi
Arya. Auto-query - A simple natural language to SQL query generator for an e-learning platform. In
EDUCON, pages 936–940, 2022.",N/A,N/A
"EDUCON, pages 936–940, 2022.
[101] Bijan Parsia. Querying the web with SPARQL. In Reasoning Web, volume 4126 of Lecture Notes in
Computer Science, pages 53–67, 2006.
[102] Panupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured tables. In ACL,
pages 1470–1480, 2015.
[103] Rodolfo A. Pazos, Jos´e A. Mart´ınez F., Juan Javier Gonz´alez Barbosa, and Andr´es A. Ver´astegui O. Al-",N/A,N/A
"gorithm for processing queries that involve boolean columns for a natural language interface to databases.
Computaci´on y Sistemas, 24(1), 2020.
[104] Rodolfo A. Pazos, Jos´e A. Mart´ınez F., and Alan G. Aguirre L. Processing natural language queries via a
natural language interface to databases with design anomalies. Polibits, 62:43–50, 2020.
[105] Hoifung Poon and Pedro M. Domingos. Unsupervised semantic parsing. In EMNLP, pages 1–10, 2009.",N/A,N/A
"[106] Ana-Maria Popescu, Alex Armanasu, Oren Etzioni, David Ko, and Alexander Yates. Modern natural lan-
guage interfaces to databases: Composing statistical parsing with semantic tractability. In COLING, 2004.
[107] Ana-Maria Popescu, Oren Etzioni, and Henry A. Kautz. Towards a theory of natural language interfaces to
databases. In IUI, pages 149–157, 2003.
[108] Patti J. Price. Evaluation of spoken language systems: the ATIS domain. In Speech and Natural Language,
pages 91–95, 1990.
39",N/A,N/A
"pages 91–95, 1990.
39
[109] Qinjun Qiu, Zhong Xie, Kai Ma, Liufeng Tao, and Shiyu Zheng. Neurospe: A neuro-net spatial relation
extractor for natural language text fusing gazetteers and pretrained models. Trans. GIS, 27(5):1526–1549,
2023.
[110] Xipeng Qiu, Tianxiang Sun, Yige Xu, and et al. Pre-trained models for natural language processing: A
survey. Sci. China Technol. Sci., 63(10):1872–1897, 2020.",N/A,N/A
"[111] Colin Raffel, Noam Shazeer, Adam Roberts, and et al. Exploring the limits of transfer learning with a
unified text-to-text transformer. J. Mach. Learn. Res., 21:140:1–140:67, 2020.
[112] Ohad Rubin and Jonathan Berant. Smbop: Semi-autoregressive bottom-up semantic parsing. In NAACL-
HLT, pages 311–324, 2021.
[113] Diptikalyan Saha, Avrilia Floratou, Karthik Sankaranarayanan, Umar Farooq Minhas, Ashish R. Mittal,",N/A,N/A
"and Fatma ¨Ozcan. ATHENA: an ontology-driven system for natural language querying over relational data
stores. Proc. VLDB Endow., 9(12):1209–1220, 2016.
[114] Xavier Schmitt, Sylvain Kubler, J´er´emy Robert, Mike Papadakis, and Yves Le Traon. A replicable com-
parison study of NER software: Stanfordnlp, nltk, opennlp, spacy, gate. In SNAMS, pages 338–343, 2019.
[115] Jaydeep Sen, Chuan Lei, Abdul Quamar, Fatma ¨Ozcan, Vasilis Efthymiou, Ayushi Dalmia, Greg Stager,",N/A,N/A
"Ashish R. Mittal, Diptikalyan Saha, and Karthik Sankaranarayanan. ATHENA++: natural language query-
ing for complex nested SQL queries. Proc. VLDB Endow., 13(11):2747–2759, 2020.
[116] Jaydeep Sen, Fatma Ozcan, Abdul Quamar, Greg Stager, Ashish R. Mittal, Manasa Jammi, Chuan Lei, Dip-
tikalyan Saha, and Karthik Sankaranarayanan. Natural language querying of complex business intelligence
queries. In SIGMOD, pages 1997–2000, 2019.",N/A,N/A
"queries. In SIGMOD, pages 1997–2000, 2019.
[117] Vraj Shah. Speakql: Towards speech-driven multimodal querying. In SIGMOD, pages 1847–1849, 2019.
[118] Vraj Shah, Side Li, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven multimodal
querying of structured data. In SIGMOD, pages 2363–2374, 2020.
[119] Vraj Shah, Side Li, Kevin Yang, Arun Kumar, and Lawrence K. Saul. Demonstration of speakql: Speech-
driven multimodal querying of structured data. In SIGMOD, pages 2001–2004, 2019.",N/A,N/A
"[120] Grigori Sidorov, Rodolfo A. Pazos Rangel, Jos´e A. Mart´ınez F., Juan Mart´ın Carpio, and Alan G. Aguirre
L. Configuration module for treating design anomalies in databases for a natural language interface to
databases. In Intuitionistic and Type-2 Fuzzy Logic Enhancements in Neural and Optimization Algorithms,
volume 862 of Studies in Computational Intelligence, pages 703–714. 2020.
[121] Dezhao Song, Frank Schilder, Charese Smiley, Chris Brew, Tom Zielund, Hiroko Bretz, Robert Martin,",N/A,N/A
"Chris Dale, John Duprey, Tim Miller, and Johanna Harrison. TR discover: A natural language interface for
querying and analyzing interlinked datasets. In ISWC, pages 21–37, 2015.
[122] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. Speech-to-sql: Towards speech-
driven SQL query generation from natural language question. CoRR, abs/2201.01209, 2022.
[123] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. Voicequerysystem: A voice-",N/A,N/A
"driven database querying system using natural language questions. In SIGMOD, pages 2385–2388, 2022.
[124] Niculae Stratica, Leila Kosseim, and Bipin C. Desai. Using semantic templates for a natural language
interface to the CINDI virtual library. Data Knowl. Eng., 55(1):4–19, 2005.
[125] Shuo Sun, Yuze Gao, Yuchen Zhang, Jian Su, Bin Chen, Yingzhan Lin, and Shuqi Sun. An exploratory
study on model compression for text-to-sql. In ACL, pages 11647–11654, 2023.",N/A,N/A
"[126] Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin Chen, and Jian Su. Battle of the
large language models: Dolly vs llama vs vicuna vs guanaco vs bard vs chatgpt - A text-to-sql parsing
comparison. In EMNLP, pages 11225–11238, 2023.
[127] Lappoon R. Tang and Raymond J. Mooney. Automated construction of database interfaces: Intergrating
statistical and relational learning for semantic parsing. In EMNLP, pages 133–141, 2000.
40",N/A,N/A
"40
[128] Lappoon R. Tang and Raymond J. Mooney. Using multiple clause constructors in inductive logic program-
ming for semantic parsing. In EMCL, volume 2167 of Lecture Notes in Computer Science, pages 466–477,
2001.
[129] Peihao Tong, Qifan Zhang, and Junjie Yao. Leveraging domain context for question answering over knowl-
edge graph. Data Sci. Eng., 4(4):323–335, 2019.
[130] Immanuel Trummer. Database tuning using natural language processing. SIGMOD Rec., 50(3):27–28,
2021.",N/A,N/A
"2021.
[131] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. Dbtagger: Multi-task learning for keyword mapping in
nlidbs using bi-directional recurrent neural networks. Proc. VLDB Endow., 14(5):813–821, 2021.
[132] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. xdbtagger: explainable natural language interface to
databases using keyword mappings and schema graph. VLDB J., 33(2):301–321, 2024.",N/A,N/A
"[133] Prasetya Utama, Nathaniel Weir, Fuat Basik, Carsten Binnig, Ugur C¸ etintemel, Benjamin H¨attasch, Amir
Ilkhechi, Shekar Ramaswamy, and Arif Usta. An end-to-end neural natural language interface for databases.
CoRR, abs/1804.00401, 2018.
[134] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, pages 5998–6008, 2017.",N/A,N/A
"[135] Moses Visperas, Aunhel John Adoptante, Christalline Joie Borjal, Ma. Teresita Abia, Jasper Kyle Catapang,
and Elmer C. Peramo. On modern text-to-sql semantic parsing methodologies for natural language interface
to databases: A comparative study. In ICAIIC, pages 390–396, 2023.
[136] Ngoc Phuoc An Vo, Octavian Popescu, Irene Manotas, and Vadim Sheinin. Tackling temporal questions in
natural language interface to databases. In EMNLP, pages 179–187, 2022.",N/A,N/A
"[137] Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson.
RAT-SQL:
relation-aware schema encoding and linking for text-to-sql parsers. In ACL, pages 7567–7578, 2020.
[138] Runze Wang, Zhen-Hua Ling, Jing-Bo Zhou, and Yu Hu. A multiple-integration encoder for multi-turn
text-to-sql semantic parsing. IEEE ACM Trans. Audio Speech Lang. Process., 29:1503–1513, 2021.
[139] Weiguo Wang, Sourav S. Bhowmick, Hui Li, Shafiq R. Joty, Siyuan Liu, and Peng Chen. Towards en-",N/A,N/A
"hancing database education: Natural language generation meets query execution plans. In SIGMOD, pages
1933–1945, 2021.
[140] Wenlu Wang. A cross-domain natural language interface to databases using adversarial text method. In
VLDB, volume 2399 of CEUR Workshop Proceedings. CEUR-WS.org, 2019.
[141] Wenlu Wang, Jingjing Li, Wei-Shinn Ku, and Haixun Wang. Multilingual spatial domain natural language
interface to databases. GeoInformatica, 28(1):29–52, 2024.",N/A,N/A
"[142] Wenlu Wang, Yingtao Tian, Haixun Wang, and Wei-Shinn Ku. A natural language interface for database:
Achieving transfer-learnability using adversarial method for question understanding. In ICDE, pages 97–
108, 2020.
[143] Xieyang Wang, Mengyi Liu, Jianqiu Xu, and Hua Lu. NALMO: transforming queries in natural language
for moving objects databases. GeoInformatica, 27(3):427–460, 2023.
[144] Xieyang Wang, Jianqiu Xu, and Hua Lu.
NALMO: A natural language interface for moving objects",N/A,N/A
"databases. In SSTD, pages 1–11, 2021.
[145] Xieyang Wang, Jianqiu Xu, and Yaxin Wang. NLMO: towards a natural language tool for querying moving
objects. In MDM, pages 228–229, 2020.
[146] Yushi Wang, Jonathan Berant, and Percy Liang. Building a semantic parser overnight. In ACL, pages
1332–1342, 2015.
[147] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Demonstrating robust voice querying with MUVE:",N/A,N/A
"optimally visualizing results of phonetically similar queries. In SIGMOD, pages 2798–2802, 2021.
41
[148] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Robust voice querying with MUVE: optimally
visualizing results of phonetically similar queries. Proc. VLDB Endow., 14(11):2397–2409, 2021.
[149] Nathaniel Weir and Prasetya Utama. Bootstrapping an end-to-end natural language interface for databases.
In SIGMOD, pages 1862–1864, 2019.",N/A,N/A
"In SIGMOD, pages 1862–1864, 2019.
[150] Yuk Wah Wong and Raymond J. Mooney. Learning for semantic parsing with statistical machine trans-
lation. In Human Language Technology Conference of the North American Chapter of the Association of
Computational Linguistics, 2006.
[151] Chunyang Xiao, Marc Dymetman, and Claire Gardent. Sequence-based structured prediction for semantic
parsing. In ACL, 2016.",N/A,N/A
"parsing. In ACL, 2016.
[152] Xiaojun Xu, Chang Liu, and Dawn Song. Sqlnet: Generating structured queries from natural language
without reinforcement learning. CoRR, abs/1711.04436, 2017.
[153] Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, and Thomas Dillig. Sqlizer: query synthesis from natural
language. Proc. ACM Program. Lang., 1(OOPSLA):63:1–63:26, 2017.
[154] Yuquan Yang, Qifan Zhang, and Junjie Yao. Task-driven neural natural language interface to database. In",N/A,N/A
"WISE, volume 14306 of Lecture Notes in Computer Science, pages 659–673, 2023.
[155] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. Xlnet:
Generalized autoregressive pretraining for language understanding. In NeurIPS, pages 5754–5764, 2019.
[156] Ziyu Yao, Yu Su, Huan Sun, and Wen-tau Yih.
Model-based interactive semantic parsing: A unified
framework and A text-to-sql case study. In EMNLP-IJCNLP, pages 5446–5457, 2019.",N/A,N/A
"[157] Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation. In
ACL, pages 440–450, 2017.
[158] Tao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and Dragomir R. Radev. Typesql: Knowledge-based type-aware
neural text-to-sql generation. In NAACL-HLT, pages 588–594, 2018.
[159] Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, and Dragomir R. Radev.",N/A,N/A
"Syntaxsqlnet: Syntax tree networks for complex and cross-domain text-to-sql task. In EMNLP, pages
1653–1663, 2018.
[160] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning
Yao, Shanelle Roman, Zilin Zhang, and Dragomir R. Radev. Spider: A large-scale human-labeled dataset
for complex and cross-domain semantic parsing and text-to-sql task. In EMNLP, pages 3911–3921, 2018.",N/A,N/A
"[161] John M. Zelle and Raymond J. Mooney. Learning to parse database queries using inductive logic program-
ming. In AAAI IAAI, pages 1050–1055, 1996.
[162] Gideon Zenz, Xuan Zhou, Enrico Minack, Wolf Siberski, and Wolfgang Nejdl. From keywords to semantic
queries - incremental query construction on the semantic web. J. Web Semant., 7(3):166–176, 2009.
[163] Luke S. Zettlemoyer and Michael Collins. Learning to map sentences to logical form: Structured classifi-",N/A,N/A
"cation with probabilistic categorial grammars. In UAI, pages 658–666, 2005.
[164] Jinchuan Zhang, Yan Zhou, Binyuan Hui, Yaxin Liu, Ziming Li, and Songlin Hu. Trojansql: SQL injection
against natural language interface to database. In EMNLP, pages 4344–4359, 2023.
[165] Bolong Zheng, Lei Bi, Juan Cao, Hua Chai, Jun Fang, Lu Chen, Yunjun Gao, Xiaofang Zhou, and Chris-
tian S. Jensen. Speaknav: Voice-based route description language understanding for template driven path",N/A,N/A
"search. Proc. VLDB Endow., 14(12):3056–3068, 2021.
[166] Weiguo Zheng, Hong Cheng, Lei Zou, Jeffrey Xu Yu, and Kangfei Zhao.
Natural language ques-
tion/answering: Let users talk with the knowledge graph. In ACM CIKM, pages 217–226, 2017.
[167] Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating structured queries from natural
language using reinforcement learning. CoRR, abs/1709.00103, 2017.",N/A,N/A
"[168] Lei Zou, Ruizhe Huang, Haixun Wang, Jeffrey Xu Yu, Wenqiang He, and Dongyan Zhao. Natural language
question answering over RDF: a graph data driven approach. In SIGMOD, pages 313–324, 2014.
42",N/A,N/A
"Integrating AI Planning with Natural Language Processing:
A Combination of Explicit and Tacit Knowledge
KEBING JIN and HANKZ HANKUI ZHUO∗, School of Computer Science and Engineering, Sun
Yat-sen University, China
Natural language processing (NLP) aims at investigating the interactions between agents and humans, pro-
cessing and analyzing large amounts of natural language data. Large-scale language models play an important",N/A,N/A
"role in current natural language processing. However, the challenges of explainability and complexity come
along with the developments of language models. One way is to introduce logical relations and rules into
natural language processing models, such as making use of Automated Planning. Automated planning (AI
planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals",N/A,N/A
"based on domain models. Recently, there have been plenty of works related to these two fields, which have
the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from
tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing
effectively improves the communication between human and intelligent agents. This paper outlines the",N/A,N/A
"commons and relations between AI planning and natural language processing, argues that each of them can
effectively impact on the other one by five areas: (1) planning-based text understanding, (2) planning-based
natural language processing, (3) planning-based explainability, (4) text-based human-robot interaction, and
(5) applications. We also explore some potential future issues between AI planning and natural language",N/A,N/A
"processing. To the best of our knowledge, this survey is the first work that addresses the deep connections
between AI planning and Natural language processing.
CCS Concepts: • Computing methodologies →Natural language processing; Planning and schedul-
ing; Information extraction; Natural language generation.
Additional Key Words and Phrases: AI planning, Natural language processing, Natural language understanding,
Human-robot interaction, Explainability
ACM Reference Format:",N/A,N/A
"ACM Reference Format:
Kebing Jin and Hankz Hankui Zhuo. 2022. Integrating AI Planning with Natural Language Processing: A
Combination of Explicit and Tacit Knowledge. ACM Trans. Intell. Syst. Technol. 1, 1 (April 2022), 24 pages.
https://doi.org/XXXXXXX.XXXXXXX
1
INTRODUCTION
Natural language processing (NLP) aims at investigating the interactions between agents and
humans, processing and analyzing large amounts of natural language data. In recent years, for",N/A,N/A
"attaining better performance and handling large corpora, building large-scale language models
is an inevitable trend in real applications [62, 78, 126]. Despite the success of language models in
various domains, the explainability and complexity of language models have drawn intense research
interests recently. In order to make models explainable and lightweight, integrating models with
∗Corresponding author",N/A,N/A
"∗Corresponding author
Authors’ address: Kebing Jin, jinkb@mail2.sysu.edu.cn; Hankz Hankui Zhuo, zhuohank@mail.sysu.edu.cn, School of
Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China, 510006.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and",N/A,N/A
"the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2022 Association for Computing Machinery.
2157-6904/2022/4-ART $15.00
https://doi.org/XXXXXXX.XXXXXXX",N/A,N/A
"https://doi.org/XXXXXXX.XXXXXXX
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
arXiv:2202.07138v2  [cs.AI]  13 Apr 2023
2
Jin et al.
symbolic planning has been demonstrated effective in various NLP tasks. Symbolic planning (AI
planning) is a branch of artificial intelligence that focuses on building symbolic domain models and
synthesizing plans to transit initial states to goals based on domain models. The plans are typically",N/A,N/A
"for execution by intelligent agents, autonomous robots, and unmanned vehicles. Different from
classical control and classification problems, the solutions are complex and must be discovered and
optimized in multidimensional space. Generally, those approaches are mostly based on structured
data, which has a well-defined structure and logically explainable to humans.
Compared with structured data used in AI planning, natural language descriptions are often",N/A,N/A
"complicated by omissions, inverted order, etc., resulting in difficulties in reasoning about language
descriptions. It is thus often hard to directly train neural models to generate available and correct
solutions, although deep learning has been widely used to handle unstructured data. Deep learning
methods do well in acquiring knowledge from data, capturing implied rules, and expressing them
by mathematical and neural models, which are tacit and unable to be directly shared with other",N/A,N/A
"humans and agents. Different from deep learning methods that aim to learn tacit knowledge,
planning-based methods are better at capturing changes, formalizing them by rules, and generating
valid plans when handling structured data. Rules are already codified, namely explicit knowledge,
which can be clearly expressed and easily shared with others. Therefore, AI planning is one of the
considerable steps to understand implied rules and build domain models from large amount of texts",N/A,N/A
"in natural language processing [32, 72].
On the other hand, unstructured data in real world is not disorderly but often a sequence based
on rules. As for a natural language description, there is a theme running through it, along with a
series of relevant events and a coherent text unfolds. Each sentence relates to the preceding texts
and influences following sentences, just like preconditions and effects of actions in AI planning. For",N/A,N/A
"example, in a recipe about making a meatloaf shown in Figure 1(a), humans can easily understand it
and capture the main information including verbs, e.g., “Heat”, and objects, e.g., “butter” and “skillet”.
However, as for agents, when given a mass of data in the form of sentences, it is hard to directly build
models to reason about the implied rules and predict next moves. If we extract these information and",N/A,N/A
"formalize them structurally, as shown in Figure 1(b), it is easier to construct models based on planning
methods for guiding future unseen tasks.
Besides using AI planning to help reason about implied rules in texts, the power of AI planning
about capturing implied relations and computing valid solutions is another effective way to improve
natural language processing, such as text summarization and machine translation. For example,",N/A,N/A
"there have been planning-based text generation methods [57, 119] extending a clear storyline
ordered in advance. Those methods first compute sequences composed of keywords, key phrases,
or contents as storylines, then use natural language processing techniques to extend storylines
to coherent texts. In the above-mentioned example, generating an available recipe in a correct order
shown in Figure 1(a) is hard. However, given some rules, such as domain models about the operations",N/A,N/A
"of cooking, agents can compute plans toward achieving specified goals like a theme about making a
meatloaf, as shown in Figure 1(b). Agents can easily extend the plan and gain a valid recipe.
The integration of AI planning and natural language processing combines the best of tacit
knowledge learning from sentences and explicit knowledge in the form of rules. As discussed
in [52], it would be more effective to combine explicit and tacit knowledge rather than giving",N/A,N/A
"up explicit knowledge and learning everything from tacit knowledge, which is the current trend.
Integrating AI planning and natural language processing allows human to communicate with
agents in a more comfortable way, and enables intelligent agents to explain themselves to human
in a human-understandable way. Natural language, as the most comfortable way to communicate
with humans, establishes a relationship between humans and intelligent agents. In recent years,",N/A,N/A
"researchers have made efforts to connect with natural language and robots, such as by dialogue
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
3
Heat butter in a large skillet.  Add the onions, garlic, celery and carrot. 
Cook the mixture over medium heat for 5 minutes, stirring frequently. Add",N/A,N/A
"the ketchup sauce  and the salt and pepper. Cook the mixture for another 
minute. Combine the meat, bread crumbs, eggs  and parsley in a mixing 
bowl. Add the cooked vegetables from the skillet. Mix everything well 
together. Push the mixture into the baking loaf pan. Then put the loaf into 
the oven and bake for about an hour. When the meatloaf is done, allow it 
to cool slightly, then slowly remove the loaf from the baking pan by cutting",N/A,N/A
"along the sides with a butter knife. Gently lift the meatloaf from the pan 
and place on serving plate. Cut into slices of approximately 3/4 inch thick. 
Heat(butter, skillet) → Add (onions, garlic, celery, carrot, skillet) → 
Cook(mixture, medium heat, 5 minutes) → stirring() → Add(ketchup sauce, 
salt, pepper, skillet) → Cook(mixture, medium heat, one minute) → 
Combine(meat, bread crumbs, eggs, parsley ,bowl) → Add(cooked",N/A,N/A
"vegetables, bowl) → Mix() → Push(mixture, loaf pan) → Put(loaf, oven) → 
Bake(an hour) →  Cool() → Remove(loaf) → Cut(sides, knife) → 
Lift(meatloaf, pan) → Place(meatloaf, plate) → Cut(meatloaf, 3/4 inch thick)
(a) A recipe for making a meatloaf.
  
 
 
 
(b)
 
A
 
trace
 
extracted
 
from
 
(a).
Fig. 1. An example textual recipe about making a meatloaf.
systems [82, 105] and natural language commands understanding [59, 108]. On the other hand,",N/A,N/A
"planning-based natural language models are based on structured data or implied rules, such as
predicted storylines, which allows human to partly understand the principles of models.
In this paper, we first introduce some background knowledge in AI planning and natural language
processing as well as their relations. Then we give a comprehensive overview of integrating AI
planning and natural language processing by four aspects and their challenges: planning-based text",N/A,N/A
"understanding, planning-based natural language processing, planning-based explainability, and
text-based human-robot interaction. Their relations are shown in Figure 2. Firstly, planning-based
natural language understanding includes extracting actions from texts and learning domain models
from texts. Secondly, we introduce planning-based natural language processing by three tasks
integrated with AI planning, i.e., text generation, text summarization, and machine translation. Then",N/A,N/A
"we discuss planning-based explainability. Next, we introduce text-based human-robot interaction by
extracting actions from natural language instructions, natural language command understanding,
and dialogue generation. Finally, we present current applications, several future directions and
conclude this paper. To the best of our knowledge, this survey is the first work that addresses the
deep connections between AI planning and NLP.
2
PLANNING DOMAIN DESCRIPTION LANGUAGE AND NLP",N/A,N/A
"2
PLANNING DOMAIN DESCRIPTION LANGUAGE AND NLP
In this section, we introduce modeling knowledge in AI planning, backgrounds in natural language
processing (NLP), and relations between AI planning and NLP, including similarities, differences,
and language model-based planning.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
4
Jin et al.
Natural Language
Text
Make use of extracted rules 
to improve coherence and 
reasonability.
Human
Robot",N/A,N/A
"reasonability.
Human
Robot
Actions Extraction
Natural Language 
Command Understanding
Dialogue Systems
Human-robot 
Interaction
As a 
Medium 
Explainability
Text Generation
Text Summarization
Machine Translation
Planning-based
Natural Language Processing
Action traces Extraction
Domain Models Learning
Planning-based Natural 
Language Understanding
Extract information, capture rules, 
and build domain models.
Learn implied rules, 
organize skeletons, 
and predict key 
information.",N/A,N/A
"and predict key 
information.
Give instructions
Execute 
instructions
Fig. 2. Relations between AI planning and Natural language processing
2.1
Planning domain description language
A planning problem is composed of a planning domain D and an instance 𝑝, defined by planning
domain description language. With the development of AI planning, more and more extended
planning domain description languages [34, 39, 92] have been proposed. Taking PDDL (Planning",N/A,N/A
"Domain Definition Language) [71] as an example, a planning domain D is made up by several
action models. An action model is defined by a tuple of 𝐴= ⟨𝑎, pre(𝑎), eff(𝑎)⟩, where 𝑎is an action
name with zero or more types of parameters. An action is a grounding of an action model, each
of whose parameters is an object. pre(𝑎) is a set of preconditions requiring to be satisfied when
executing 𝑎, each of which is a proposition or a numeric constraint. Similarly, eff(𝑎) is a set of effects,",N/A,N/A
"an effect can be a topical proposition, added into or deleted from the state after executing 𝑎, or a
numeric updating, increasing or decreasing the value of variables according to specified functions.
An instance is defined by 𝑝= ⟨𝑠0,𝑔, 𝜉⟩, where 𝑠0 is a set of initial assignments by propositions
and variables, and 𝑔is a set of goals requiring to be achieved. 𝜉is an objective function guiding
planner to compute for a minimum cost or maximum reward. A planning problem is to compute",N/A,N/A
"an available action sequence, which can transfer 𝑠0 to a state containing desired goals 𝑔.
For example, parts of action models in the Rover domain are shown in Figure 3(a), where “(equipped_for
_imaging ?r)” is a proposition asking that a rover “?r” should equip with a camera for taking image
when executing action “Calibrate”. “(>= (energy ?r) 1)” is a numeric precondition requiring the energy",N/A,N/A
"of rover “?r” should be larger than 1. Figure 3(b) and (c) show an initial state and goals, respectively.
An example valid plan, updating the initial state to a state achieving the goals, is shown in Figure 3(d),
where each action is a grounding action model with parameters.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
5
(:action Calibrate",N/A,N/A
"5
(:action Calibrate
 :parameters (?r - rover ?i - camera ?t - objective ?w - waypoint)
 :precondition (and (equipped_for_imaging ?r) (>= (energy ?r) 2) (calibration_target ?i ?t) (at ?r ?w) 
        (visible_from ?t ?w) (on_board ?i ?r))
 :effect (and (decrease (energy ?r) 2)(calibrated ?i ?r) ))
(:action Take_image
 :parameters (?r - rover ?p - waypoint ?o - objective ?i - camera ?m - mode)
 :precondition (and (calibrated ?i ?r) (on_board ?i ?r) (equipped_for_imaging ?r) (supports ?i ?m)",N/A,N/A
"(visible_from ?o ?p) (at ?r ?p) (>= (energy ?r) 1))
 :effect (and (have_image ?r ?o ?m)(not (calibrated ?i ?r))(decrease (energy ?r) 1)))
...
Calibrate (rover0 camera0 objective1 waypoint3) → Take_image (rover0 waypoint3 objective1 camera0 high_res) → Communicate_image_data (rover0 camera objective1 high_res waypoint3",N/A,N/A
"waypoint0) → Sample_rock (rover0 rover0store waypoint3) → Drop (rover0 rover0store) → Communicate_rock_data (rover0 camera waypoint3 waypoint3 waypoint0) → Navigate (rover0 
waypoint3 waypoint1) → Navigate (rover0 waypoint1 waypoint2) → Sample_soil (rover0 rover0store waypoint2) → Communicate_soil_data (rover0 camera waypoint2 waypoint2 waypoint0)
(:init
(equipped_for_imaging rover0) (calibration_target camera0 objective1) 
(at rover0 waypoint3) (on_board camera0 rover0) (available rover0)",N/A,N/A
"(calibration_target camera0 objective1) (supports camera0 colour)
(supports camera0 high_res) (in_sun waypoint0) (= (energy rover0) 50)
.... )
(:goal (and
(communicated_soil_data waypoint2)
(communicated_rock_data waypoint3)
(communicated_image_data objective1 high_res)))
(a) Action models.
(b) Initial state.
(c) Goals.
(d) An example plan for the planning problem.
Fig. 3. An example in the Rover domain, including action models, initial state, goals, and an available plan.
2.2",N/A,N/A
"2.2
Natural language processing
Recently, natural language processing (NLP) [17, 54, 114] has attracted lots of attention, and it
builds a bridge between human and agents. Natural language processing is grand, including various
fields, such as natural language understanding (NLU)[81, 107], natural language generation (NLG),
[30, 37] machine translation[80], and spelling correction[43]. NLP has undergone several stages",N/A,N/A
"of rule-based models, statistic-based models, and neural network models. Rule-based NLP [97] is
led by hand-crafted rule sets, whose main task is to understand natural language. It is, however,
difficult and time-consuming to build all hand-crafted rules, lacking of scalability. Statistic-based
NLP [65] makes use of probability distributions to generate proper words and sentences, promoting
the application of statistical machine learning methods based on large-scale corpora in natural",N/A,N/A
"language processing. Nevertheless, statistic-based models is barely to capture long-term relations
and use information included in contexts. Recently, deep learning has been widely used in NLP
tasks[106], it is able to capture tacit knowledge implied in texts. However, deep learning is to fit
neural networks and predict based on statistics, it can not “understand” the real meaning in natural
language. In this paper, we focus on those NLP tasks related to AI planning. Compared with NLP",N/A,N/A
"approaches totally based on deep learning, planning-based NLP methods are more curious about
implied logic and reasons of the solutions.
2.3
Relations between AI planning and natural language processing
In this section, we will sketch the relations between AI planning and natural language processing,
which is mentioned by [38, 116, 122]. We will first introduce the similarities between AI planning
and natural language processing, and then talk about their differences and deep relations.",N/A,N/A
"We discuss the similarities between AI planning and natural language processing by two aspects.
First of all, AI planning and natural language processing both revolve around observations and
knowledge [38]. Planning tasks aim at either solving problems based on a current observation and
goals along with priori knowledge like action models, or constructing knowledge such as transition
functions based on sequential observations. Similarly, in natural language processing tasks, a text",N/A,N/A
"can be regarded as a sequence of observations, each observation is a sentence describing a partially
observed state, where observations changes following implied rules. Secondly, they share two
major common problems in planning tasks and natural language processing tasks: consistency and
diversity. Both of plan traces and texts are cohesive descriptions and stringed by some rules and
goals. As for planning, the rules are action models and transition functions, which update current",N/A,N/A
"states to next ones. The goals are sets of goal states or objective functions, guiding planners to attain
optimal solutions. As for natural language processing, the rules are implied in the organization of
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
6
Jin et al.
texts, such as transition connections or consequences. Their goals can be titles, themes, or topics.",N/A,N/A
"On the other hand, in natural language processing, given goals, we can generate lots of coherent
texts composed of different events, similar to different plan traces computed for the same goal
states. Moreover, a sequence of events can be written as various stylized texts. As shown in Table
1, we enumerate some concepts in AI planning and natural language processing, which can have
some similarities. For example, objects, such as “rover0” and “objective1” in Figure 3, in planning",N/A,N/A
"problems are similar to entities in texts, e.g., “skillet” and “onions” in Figure 1.
Table 1. Similar concepts between AI planning and natural language processing
AI planning
Natural language texts
Objects
Entities
States
Sentences, sentiments, and intentions
Actions
Events
Domain models
Implied rules, transitions, and relations
Goals
Topics, and themes
Plan traces
Storylines, skeletons, and frameworks
Although AI planning and natural language processing have those commons, the difference",N/A,N/A
"between them is that AI planning is good at generating explicit knowledge, such as domain models
[128–131], while natural language processing often learns tacit knowledge, such as training models
from natural language data. [52] argues that AI systems should be able to know when to take advice
and when to learn, to find a balance between explicit and tacit knowledge. Taking planning-based
text generation as an example, although texts are required to be coherent and with correct logic,",N/A,N/A
"natural language processing is weak in computing available and valid events, which AI planning
is good at. And the integration of both allows agents to generate coherent texts by first using AI
planning to generate storylines and then learning text generator by natural language processing
techniques.
In a word, there are close ties between AI planning and natural language processing, due to
their different advantages of explicit and tacit knowledge. The combination allows each of them to",N/A,N/A
"effectively impact on the other one.
2.4
Language Model-based Planning
Although AI planning can effectively capture rules from action sequences, it is hard for humans
without expert knowledge to construct structured plans. A natural and intuitive way is to use human
natural language to describe plans, asking language model-based planners to be able to handle
text sequences and predict the next moves [94, 132]. Prior works mostly make use of pre-trained",N/A,N/A
"language models (LMs) to understand abstract, high-level textual actions and learn actionable
knowledge for guiding planning [47, 50, 61]. Specifically, Huang et al. [46] use large language
models (LLMs) to generate natural language actions, they investigated actionable knowledge already
contained pre-trained LLMs. On the other hand, some works map natural language instructions
and high-level goals to actions and goals, and learn policy to make decisions [98]. For example, LID",N/A,N/A
"[61] uses policies initialized with pre-trained LMs and fine-tunes policies for predicting actions,
validating that LMs are able to contain rich actionable knowledge. Language model-based planners
are mostly based on templated textual actions datasets, rather than complex natural language
instructions with various styles of descriptions. In the following sections, we introduce deep
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.",N/A,N/A
"Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
7
connections between AI planning and natural language processing, to rise to the dual challenges
from rules and natural language.
3
PLANNING-BASED NATURAL LANGUAGE UNDERSTANDING
In this section, we introduce a comprehension overview of natural language understanding based on
AI planning. Natural language understanding aims at comprehending human language, including",N/A,N/A
"sentiments, relations in contexts, topics, etc. Compared with learning relations from structured state
traces, learning relations between extracted events from texts are even more challenging. It asks
agents to reason about contexts, capture themes of sentences by selecting words to represent them,
compute causal relationships between the selected words. There are two major areas introduced in
the following section, which are both based on AI planning, to understand the texts and learn causal",N/A,N/A
"relationships from texts. The first one is to extract action sequences from texts, which requires
agents to understand complex contexts from action descriptions. Moreover, it requires agents to be
capable of reasoning about connotations in texts, such as exclusion relations and optional relations
between actions. The other one is to first select words to represent the main ideas of sentences,
and then learn the rules implied in sentences and formalize them by readable domain models for",N/A,N/A
"guiding agents to solve future unseen tasks and helping agents and people understand logical
relations between events.
3.1
Extracting actions from texts
There have been works on extracting action sequences from action descriptions [127]. The inputs
of the task mostly include some texts describing some actions and procedures, the outputs are
action sequences from the texts, each action is composed of a verb as action name and some objects.",N/A,N/A
"Figure 4 shows an example in [32], where an input text is in left part of Figure 4, extracting action
traces are shown in the right part of Figure 4, the relations between actions are shown in the middle
of Figure 4. This task does not only need extract a word standing for an action of the sentence,
but also reason about contexts for completing omissions caused by pronouns. Early approaches
[55, 70] mostly make use of specialized resources, such as semantic parsers and learned lexicons,",N/A,N/A
"to reason about natural language route instructions. For example, MARCO [68] was proposed to
Cook the rice the day before, or use leftover 
rice in the refrigerator.  The important thing 
to remember is not to heat up the rice, but 
keep it cold.  In a bowl, add 1 tablespoon of 
oil to rice.  Use a spoon or your hands to 
work the oil into the rice, evenly coating the 
rice.  Transfer the rice to a colander and 
drain.  Combine eggs and salt in a small bowl",N/A,N/A
"drain.  Combine eggs and salt in a small bowl 
and gently whisk until blended.  Heat 1 
tablespoon oil in a wok.  Add whisked eggs 
and cumin seeds to wok.  Stir frequently, 
working the eggs to a scramble.  Heat the 
remaining oil in the wok.  If desired, you can 
recycle some of the oil that drained from the 
rice.  Add the garlic and onion to the wok.  
Stir-fry together over high heat for about 5 
minutes or until the onion looks transparent,",N/A,N/A
"minutes or until the onion looks transparent, 
but is not soft.  Add the rice, eggs, soy sauce, 
chili sauce, vinegar, and celery.  Mix 
together, continuing to stir-fry over high 
heat for 1-2 minutes while stirring 
frequently.  Spoon onto a plate and serve. 
Input Training Text
Mission 
Start
Cook
Use
Keep
Heat
Add
Recycle
Work
Serve
EX 
EX
ES
ES
ES
ES
ES
OP
Extracting Action Names and Action Arguments
Some Possible Outputs
ES: essential 
OP: optional 
EX: exclusive
Make Egg Fried Rice",N/A,N/A
"OP: optional 
EX: exclusive
Make Egg Fried Rice
Mission 
End
Cook
rice
Use
leftover 
rice
Keep
rice, 
cold
Add
oil
spoon
Use
hands
Action 
Names
Action 
Arguments
ES
ES
ES
ES
EX
EX
x Cook (rice) Æ Keep (rice, cold) Æ Add 
(oil) Æ Use (spoon) Æ Work (oil, rice) 
Æ …  Æ Work (eggs) Æ Heat (oil) Æ … 
Æ Serve ()
x Use (leftover rice) Æ Keep (rice, cold) 
Æ Add (oil) Æ Use (spoon) Æ Work 
(oil, rice) Æ …  Æ Work (eggs) Æ Heat 
(oil) Æ … Æ Serve ()
x Use (leftover rice) Æ Keep (rice, cold)",N/A,N/A
"x Use (leftover rice) Æ Keep (rice, cold) 
Æ Add (oil) Æ Use (hands) Æ Work 
(oil, rice) Æ …  Æ Work (eggs) Æ Heat 
(oil) Æ … Æ Serve ()
x Use (leftover rice) Æ Keep (rice, cold) 
Æ Add (oil) Æ Use (hands) Æ Work 
(oil, rice) Æ …  Æ Work (eggs) Æ 
Recycle (oil) Æ Heat (oil) Æ … Æ 
Serve ()
x ...
Fig. 4. An illustration of action sequence extraction problem in [32]
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
8
Jin et al.",N/A,N/A
"8
Jin et al.
map free-form natural language route instructions to action sequences, arising great interest in
natural language processing community. MARCO is able to model a sentence by an instruction,
e.g., “Turn to face the green hallway” can be modeled by “Turn(until=(object=Path, appear=Green,
side=Front, dist=0:))”. [22] presented a system along with a plan refinement algorithm to transform
natural language navigation instructions into executable formal plans. Generally, methods with",N/A,N/A
"semantics parsers require high simplicity of the texts. Therefore, mostly approaches are based on
instructional texts or similar texts following some templates.
In recent years, learning methods, such as reinforcement learning and LSTM, have been widely
used in natural language processing, as well as extracting action sequences from natural language
texts, with the rapid development of artificial intelligence. For example, [13] proposed a reinforce-",N/A,N/A
"ment learning approach for mapping natural language instructions in two domains, Windows
troubleshooting guides and game tutorials, to sequences of executable actions. It uses a reward
function to define the quality of the executed actions, and a policy gradient algorithm to estimate
the parameters of a log-linear model for action selection. The learner repeatedly constructs action
sequences for a set of documents, executes those actions, and observes the resulting reward. To",N/A,N/A
"handle free natural language without restricted templates, EASDRL [32] was presented to extract
action sequences from texts, making use of deep reinforcement learning. It builds Q-networks
to learn policies of extracting actions and extract plans from the labeled texts. EASDRL regards
texts associated with actions as “states”, and associating words in texts with labels as “actions”.
During capturing relations, EASDRL considers previously extracted actions as parts of states for",N/A,N/A
"deciding the choice of next operations. Therefore, EASDRL is able to reason about connotations in
texts, such as exclusion relations and optional relations between actions. Except for reinforcement
learning, there are more techniques used in extracting actions from texts. With the help of with long
short-term memory (LSTM) recurrent neural networks, Mei at al. [72] proposed a neural sequence-
to-sequence model to translate single-sentence natural language instructions to action sequences",N/A,N/A
"based upon a representation of the observable world state. LSTMs are applicable to a number of
sequence learning problems, due to their ability to learn long-term dependencies, and they have
been shown to be effective in tasks existing sequences. The LSTM framework allows agents to
bidirectionally encode the navigational instruction sequence and decode the representation to an
action sequence, based on a representation of the current state.
3.2
Learning domain models from texts",N/A,N/A
"3.2
Learning domain models from texts
Besides extracting action sequences from texts, another way to understand text is to learn the
implied relations from sentences. The input of the learning task is a set of texts, and the output
is a planning domain model composed of action models describing the relations by propositional
preconditions and effects following the syntax of planning domain description language, such as",N/A,N/A
"PDDL [71]. Preconditions and effects make use of propositions to describe conditions that must be
satisfied when executing actions and results after executing them, respectively.
Learning domain models from instructional texts is a little different from narrative stories. In-
structional texts are simpler than narrative stories, and the words are domain-dependent. Narrative
stories are mostly third person synopses and they are always along with omission, which results in",N/A,N/A
"complexity when parsing sentences. A general way to construct a domain model is first to extract
words and objects by parsing sentences for annotations (e.g., OpenNLP1 and Stanford CoreNLP2 ),
and then learn causal relationships between them and formalize the relations by action models.
1https://opennlp.apache.org/
2http://stanfordnlp.github.io/CoreNLP/
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.",N/A,N/A
"Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
9
To learn domain models from instructional texts, Sil and Yates [103] used text mining via a
search method to identify documents that contain words that represent target verbs or events.
Then they used inductive learning techniques to identify appropriate action preconditions and
effects. The method relies on handcrafted Pointwise Mutual Information to learn a SVM-based",N/A,N/A
"classifier that scores preconditions for a given action. Branavan et al. [14] presented a reinforcement
learning framework to extract precondition and effects relations implied by the text, and used
these relations to compute action sequences for completing given tasks in the environment. Single
argument predicates are extracted from the text as states, and regarded as sub-goals to construct
hierarchical planning problems. Yordanova and Kirste [121] extracted verbs and objects from text",N/A,N/A
"instructions based on part of speech (POS) tagging module, and discovered causal relations on the
basis of the order of appearance to build PDDL models. However, due to lacking of connections
between texts and world states and analyses between variable texts with the same meaning, it is
hard to directly construct domain models as learning action models from structured data. In this
paper, domain models are constructed according to some templates after parsing sentences. For",N/A,N/A
"example, “If the apple is ripe, put the apple on the table. ” indicates that “ripe”, a state of an apple, is
a precondition of action “put”. Therefore, a precondition of action “put” is “(state-ripe)”. Although
the model is readable for human, it is kind of redundant and not easy to understand for agents
because of synonyms and polysemous words. Similarly, Lindsay et al. [64] assumed texts are in
restricted templates when describing actions. They generated sequences of actions by constructing",N/A,N/A
"representations of sentences and cluster operators by computing similarity, and built PDDL domain
models with the help of a domain model acquisition tool.
Considering the power of AI planning about offering correct causality and flexible narrative
generation possibilities, constructing domain models has been used in narrative systems recently.
Hayton et al. [42] proposed an approach taking natural language sentences which summarise",N/A,N/A
"the main elements of stories as inputs and generating action representations following PDDL,
a narrative planning domain model. To overcome difficulties in parsing narrative stories, they
presented two sets of rules to handle pronouns in stories. Then they used a template similar to [121]
to construct planning domains. Another specific difficulty for planning-based narrative systems
is that hand-crafted domain models require more narrative actions and types of narrative objects",N/A,N/A
"compared to generated planning domains. The plentiful actions and objects let generated plan
traces and storyline be more interesting and they can be extended to enjoyable stories. To achieve
it, Porteous et al. [87] tried to anticipate the consequences of plan failure and the remedial actions
or objects needed, or described several potential alternatives. They extended narrative planning
domains by two types of principled mechanisms to operationalize narrative action and object",N/A,N/A
"substitution during narrative plan authoring. An original domain model can be extended with the
addition generated by two mechanisms alternately.
3.3
Challenges and future prospects
In AI planning, rules implied in states and actions are enforcedly constrained by preconditions
and effects. Compared with AI planning, rules between events, such as concurrence, causality, and
progression, in natural language processing are more flexible, which often intricately correlate",N/A,N/A
"with others. Moreover, the preconditions and effects are implied in natural language, which are
abstract and hard to be modeled by propositions. In the other hand, in natural language text, a event
can be written in different words, and a word owns various meanings. It therefore is difficult to
directly distinguish them by only parsers. Those challenges make it hard to extract detailed logical
relations implied in natural language, let along model implied relations by constructing structural",N/A,N/A
"domain models. It might be interesting to dig out clear logical relations implied in natural language
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
10
Jin et al.
text, which can lay a foundation for natural language processing tasks, such as explainability and
controllable text generation.
4
PLANNING-BASED NATURAL LANGUAGE PROCESSING
In this section, we introduce three natural language tasks integrated with AI planning, including",N/A,N/A
"text generation, text summarization, and machine translation. Planning-based natural language
processing tasks concern about reasonability and coherence, making use of the power of AI planning
about reasoning about rules and relations.
4.1
Planning-based text generation
One important field combined with AI planning is text generation, in which there have been
significant advances, recently. Text generation asks models to generate coherent and interesting",N/A,N/A
"text based on preceding parts of the text, topics, titles, or themes, requiring agents to be capable
of generating valid and clear logical frameworks. AI planning is one of crucial steps to guide
models to generate well-organized long texts, owing to its power in learning domain models
and computing solutions for goal-driven tasks. In this section, we introduce planning-based text
generation methods with respect to the following two features:",N/A,N/A
"• Symbolic planning text generation combines text generation with a classical planning
framework, taking prior knowledge, e.g., domain models formalized by planning domain
description language, as extra inputs.
• Neural planning text generation are neural generators combined learning with a skeleton
planning, to make up for the difficulties in building hand-crafted domain models.
4.1.1
Symbolic planning text generation. In order to generate coherent text with correct logic, it is",N/A,N/A
"natural to give agents some prior knowledge about basic rules between events. On the other hand,
early rule-based researches [9, 21, 83] about natural language processing explore constructing
representations of texts and combine with hand-crafted rules. It, however, is hard and tedious to
enumerate all rules. Therefore, making use of AI planning to capture implied rules in the form of
domain models with symbolic representations and compute proper skeletons is a natural way, which",N/A,N/A
"can overcome the difficulties of manually constructing rules [36, 56, 66]. For example, Porteous
et al. [86] proposed an approach injecting narrative control into plan generation through the use
of PDDL [71] state trajectory constraints, to express narrative control information within the
planning representation. They constructed constraint trees according to input domain models, and
injected control into automatically generated narratives system. With the help of constraints, the",N/A,N/A
"approach decomposes problems into sets of smaller subproblems using the temporal orderings
described by the constraints, and solves subproblems incrementally by a planner. Intentional Partial
Order Causal Link (IPOCL) planning framework [90] is an extension of classical planning, it aims
at finding a sound and believable sequence of character actions that transforms an initial state
into a state arriving goals. IPOCL does not only create causally sound plot progression, but also",N/A,N/A
"reasons about character intentionality by identifying possible character goals that explain their
actions and creating plans that explain why those characters commit to their goals. Compared to
IPOCL, CPOCL [115] preserves the conflicting subplans without damaging the causal soundness of
the overall story to generate interesting stories. CPOCL is an extension of IPOCL that explicitly
captures how characters can thwart one another in pursuit of their goals, which is the essence of",N/A,N/A
"narrative conflicts. Making use of hand-crafted, well-defined domain models, symbolic planning
text generation methods have the ability to produce impressive results in limited domains.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
11
4.1.2
Neural planning text generation. However, it is often tedious or difficult to build domain mod-",N/A,N/A
"els by hand due to the high requirements of manual efforts and domain knowledge. Automatically
learning domains and constructing storylines have significantly attracted researchers’ attention
recently [88, 104].
To automatically learn domain models for helping generate coherent and valid stories, Li et
al. [60] used a crowd-sourced corpus of stories to learn plot graphs that can then be used as
constrained search spaces for sequences of story events, instead of relying on priori domain",N/A,N/A
"models. Specifically, the approach crowdsources a corpus of narrative examples of a new domain,
automatically constructs domain models capturing different possible, non-contradictory story
trajectories, and samples from the space of stories allowed by the domain model according to
some story quality criteria. During the plot graph learning, learning mutual exclusion relations
and optional events lets the generated story be coherent. C2PO [2] learns a branching story graph",N/A,N/A
"structure that can be searched, and introduces soft causal relations as causal relations inferred
from commonsense reasoning. It creates a branching space of possible story continuations that
bridge between plot points that are automatically extracted from existing natural language plot
summaries.
Another way for constructing valid line of text is to construct storylines in advance, which can be
skeletons, or sequences of keywords, key phrases, or contents. Xu et al. [118] generated skeletons",N/A,N/A
"composed of phrases learned by a reinforcement learning method, and then expanded skeletons
to complete and fluent sentences. Fan et al. [31] proposed a novel approach which first generates
plans in the form of predicate-argument structures, then generates stories with placeholder tokens
to indicate entities, and finally replaces tokens by entities based on the global story contexts. The
inputs of the task are short descriptions of scenes or events, and the approach outputs relevant",N/A,N/A
"narrative stories following the inputs.
Instead of generating skeletons with detailed prompts, some approaches first plan out storylines,
which enable them to generate controllable stories with goals. [119] proposed a hierarchical
generation framework that first planned a controllable storyline composed of keywords towards a
goal (i.e., a title), and then generated a story based on the storyline. The RAKE algorithm [91] takes",N/A,N/A
"each sentence as an input and combines several word frequency based and graph-based metrics to
weight the importance of the words. The approach regards the most important word as the keyword.
The storyline is planned out based on the title, previously generated sentences, and the previous
keywords in the storyline. In the experiments, they explore two strategies, dynamic schema and
static schema. Results show the static schema performs better than the other one because it plans",N/A,N/A
"the storyline holistically, thus tends to generate more coherent and relevant stories. Similarly,
[57] made use of a related framework, which first plans out storyline composed of a sequence
of keywords and then generates the whole story, to handle stylized story generation. Stylized
story generation is to generate stories with specified style given a leading context. Keywords are
selected following some emotion-driven style, such as “fear”, “anger”, and “surprsie”. According",N/A,N/A
"to the stylized keywords, the approach can generate generates the whole stylized story with the
guidance of the keywords. Yu et al. [123] followed Yao et al. [119] and used the RAKE algorithm to
extract keywords to train a generation model for conducting keyword planning given story titles
as inputs. Then the approach combines the story titles and the corresponding keywords of each
story as the inputs of the graph module to automatically generate a graph for each story. According",N/A,N/A
"to the keywords, titles, story graphs, the approach encodes them into latent variables and further
decodes them to generate the corresponding stories.
Except for generating stories according to prompts or goals, DYPLOC [44], a dynamic planning
generation framework, takes a set of content items as inputs, each content item consists of a title, a
set of entities, and a set of core concepts. To organize unordered content items, DYPLOC introduces",N/A,N/A
"ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
12
Jin et al.
a plan scoring network, which learns to dynamically select and order contents based on what has
been produced previously while generating the outputs.
4.1.3
Challenges and future prospects. Recently, text generation [49, 51, 124] has gained lots
of attraction, aiming at letting intelligent agents express like humans. Numbers of methods to",N/A,N/A
"generate coherent texts have been proposed in recent years. Generating logical and controllable
texts, however, is still a challenging task. AI planning is one of critical ways to enable agents to
generate logical and controllable texts. Compared with symbolic planning text generation methods
and neural planning text generation methods, the former is more capable of generating logical
storylines with goals, and the texts generated by the latter are more diverse and coherent. Specially,",N/A,N/A
"symbolic planning methods can generate more explainable storylines, which is still challenging
for deep learning methods. In general, it would be interesting to combine both for generating
logical, controllable, and coherent text with diversity. Although there have been some approaches
[31, 96, 109] proposed, based on the syntax of plans or representation of structure in AI planning,
they use neural networks to predict unseen events instead of speculating based on logical relations",N/A,N/A
"implied. We hold the opinion that, compared with only learning blackbox neural models with
implicit rules, appropriately combined with explicit logical relations would be a new attempt, which
maybe contribute to natural language processing tasks.
4.2
Planning-based Text Summarization
Text summarization is to extract important information from texts and generate new texts based
on those information in the form of summarizes. It requires agents to understand texts, filter",N/A,N/A
"information from abundant descriptions and organize them to form summarizes, which is one of
the most researched areas among the NLP community. Text summarization can be categorized into
extractive and abstractive techniques. Extractive summarization aims at selecting subsets of words
or sentences from input articles to summarize them. Abstractive summarization takes articles as
inputs, tries to understand the texts and generate summarizes. In recent years, some researchers try",N/A,N/A
"to integrate text summarization models with AI planning. The combination of AI planning and text
summarization is mostly based on deep learning abstractive summarization, making use of content
planning which describes or predicts skeletons of articles. Planning-based text summarization
methods first plan out skeletons of summarizies or compute probability distributions, and then
generate the whole sentences based on the skeletons or predictions. For example, Narayan et al.",N/A,N/A
"[77] first computed plans in the form of entity chains, which are ordered sequences of entities, and
then generated summaries conditioned on the plans. Marfurt et al. [69] proposed an abstractive
summarization model implemented with a planning step, done by a hierarchical decoder, which first
plans out an outline for the next sentence in the form of sentence representations and generates
words according to the representations. Amplayo et al. [3] incorporated content planning in",N/A,N/A
"unsupervised summarization and datasets creation. They predicted aspect and sentiment probability
distributions as content plans and generated sentences according to the predictions. During creating
datasets, they made use of the distributions parametrized by the content planner to control the
structures of created datasets.
In current planning-based text summarization approaches, content planning is based on deep",N/A,N/A
"learning which learns models and probability distributions to predict. However, only fitting deep
learning models based on representations of sentences and words is hard to capture the relations
implied. We believe that it would be interesting and challenging to let content planning modules
understand relations implied in texts, which will allow content plans to be more coherent and
controllable. On the other hand, although some mainstream text summarization methods are not",N/A,N/A
"based on AI planning, there are some commonalities between them. For example, tree-based and
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
13
graph-based text summarization approaches[4, 8, 58] first find the most important information from
the text and then use trees and graphs to create summaries. Those structures aim at representing the",N/A,N/A
"relations between sentences, which is similar to the relations between actions in AI planning but at
a more abstract level. Secondly, some text summarization methods try to obtain important words
from sentences, such as verbs, objects, and subjects, to represent sentences semantically [1]. These
forms have similarities with the structured representations in AI planning such as propositions
and first-order predicates. Thirdly, ontology-based text summarization methods [74, 117] collect",N/A,N/A
"entities and their relationships, which reminds us of domain models in AI planning. We believe
that there is a vast scope for researchers to combine AI planning and text summarization.
4.3
Planning-based Machine Translation
Machine translation aims at automatically translating content from source language to another
target language, having a long history. One way to understand source texts and generate target",N/A,N/A
"texts is to combine neural language models with planning phases, i.e., first generating skeletons,
and extending them by target languages. For example, Gülçehre et al. [41] integrated an auto-
encoder with a planning mechanism, the auto-encoder first encodes texts by sequences of vector
representations and decodes representations by generating target translation character-by-character.
Specifically, they first created plans ahead in the form of action matrices, which are sequences of",N/A,N/A
"probability distributions, and made use of commitment plan vectors to govern whether to recompute
plans or use them. Then they computed soft alignments based on the plan and generated texts in
target language at each time-step. Shu and Nakayama [102] combined neural machine translation
with a planning phase, which first generates planner codes to disambiguate uncertain information
about the sentence structure and control the structure of output sentences. Bahdanau et al. [7]",N/A,N/A
"used actor-critic methods from reinforcement learning (RL) to generate sequences. They showed
that sequences can be used in machine translation tasks, gaining better translation performance.
Those approaches first produce big pictures of output texts by planning, then generate complete
sentences conditioned on plans. They take advantages of capturing implied rules to generate more
accurate and coherent target texts.",N/A,N/A
"accurate and coherent target texts.
In natural language texts, the transitions between sentences imply relations and rules. Machine
translation tasks do not only need to understand word-level structures of sentences, but also need
to capture sentence-level relationships. Only relying on word-by-word text generation is hard and
challenging to generate coherent and logical texts, especially when generating accurate transitions",N/A,N/A
"between sentences. Current approaches to capture implied rules and generate plans are mostly based
on neural black-box models, lacking the explainability of making decisions. Previous researches
about rule-based translation are explainable, they are based on hand-crafted rules. Although those
rules are explicit and accurate, it is hard to manually write rules and the rules are not scalable.
Producing rules are time-consuming and tedious. However, it would be interesting if we regard it as",N/A,N/A
"action models learning in planning community, which structurally formalize rules by preconditions
and effects. We believe that combining rule-based machine translation with planning and neural
machine translation may spark new ideas.
5
PLANNING-BASED EXPLAINABILITY
Nowadays, although deep learning approaches have been widely used in AI fields, human cannot
understand practical meaning inside black-box neural models. Differently, AI planning is able to",N/A,N/A
"offer explicit knowledge, in the form of first-order logic, domain models, etc, implied in natural
language. Therefore, the combination of natural language and AI planning may enable AI systems
to be able to explain their reasoning to humans, which meets the needs for AI systems to work
synergistically with humans. Those systems require agents to be aware of the intentions, capabilities
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
14
Jin et al.
Lack",N/A,N/A
"14
Jin et al.
Lack 
explainability
Offer rules, 
storylines,
action sequences,
domain models
Neural 
AI systems
Human
Planning-based
AI systems
Human-
understandable 
symbolic interface
Give feedbacks, 
such as rewards 
and punishments
Annotate, 
answer, or 
explain
Give human-
understandable 
queries
Query
Combine with
AI planning
Fig. 5. Two types of making neural AI systems be explainable: (1) integrating AI systems with planning
techniques; (2) making use of human-understandable interface.",N/A,N/A
"and mental model of the human in the loop during its decision process. As shown in Figure 5,
besides extracting action sequences [32, 68] and building domain models [14, 64] mentioned
above, another way for making AI system explainable is to construct human-understandable
symbolic interfaces (cf. [53]). A human-understandable symbolic interface is not only developed
for its own computational efficiency, but also beneficial to humans. EXPAND system [40] and",N/A,N/A
"SERLfD framework [125], respectively. EXPAND system accelerates Human-in-the-Loop deep
reinforcement learning by using human evaluative feedback and visual explanation. SERLfD uses
self-explanation to recognize valuable high-level relational features as an interpretation of why a
successful trajectory is successful, allowing SERLfD to guide itself and improve the efficiency.
6
TEXT-BASED HUMAN-ROBOT INTERACTION",N/A,N/A
"6
TEXT-BASED HUMAN-ROBOT INTERACTION
The rapid developments of artificial intelligence let robots move out from industrial environments,
and enter the daily life of humans, such as homes and hospitals. It requires robots to be able to
respond quickly and effectively to rapidly-changing conditions and expectations. Language–based
communication is the most natural method for humans to communicate with others, so natural",N/A,N/A
"language is a good candidate to be robot instruction for human-robot interaction. In this section,
we will introduce text-based human-robot interaction from three aspects: extracting actions from
natural language commands, natural language command understanding, and dialogue generation,
as shown in the Figure 6.
6.1
Extracting actions from natural language command
One of important tasks in text-based human-robot interaction is to extract actions from natural",N/A,N/A
"language commands [48, 79, 85, 111]. Extracting actions from natural language commands is
similar to action extraction in Section 3.1. Differently, extracting actions from natural language
commands is not only to capture important words to indicate sentences, but also to understand
implied rules and generate action sequences to guide robots to achieve tasks. Some approaches
make use of with language descriptions, then build models that map language commands to",N/A,N/A
"action sequences. Tellex et al. [110] introduced a system, Generalized Grounding Graphs (G3),
taking a natural language command as input and outputting a plan for the robot. G3 instantiates a
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
15
Human
Robot
Natural language 
commands
Natural language 
commands
Natural language 
commands
Action 
sequences",N/A,N/A
"Natural language 
commands
Action 
sequences
Action models 
(understand 
implied 
intentions)
Planning-based 
dialogue systems
Extract actions 
Execute
Capture 
implied rules and 
intentions
Communicate
Generate 
utterances
Give feedbacks
Understand new 
commands
Fig. 6. Relations of researches in human-robot interaction.
probabilistic graphical model for a particular natural language command according to hierarchical",N/A,N/A
"and compositional semantic structure of the command. Cantrell et al. [20] presented a robotic
architecture equipping with a planner that uses newly discovered information to produce new and
updated plans, specifically information originating in spoken input produced by human operators.
The robot can learn action sequences with defined preconditions and effects from natural language
descriptions, and immediately apply this knowledge to improve planning. On the other hand, some",N/A,N/A
"approaches [16, 120] focus on temporal logic between natural language commands, aiming at
handling semantic disambiguation of natural language.
6.2
Natural Language Command Understanding
Another important task is to enable agents to understand natural language commands given by
humans, which requires agents to understand natural language commands and capture implied rules
[10, 10, 12, 25, 25, 99], or learn new actions based on natural language commands and dialogues[35,",N/A,N/A
"75, 95, 101]. To understand natural language commands, Thomason et al. [113] introduced a dialog
agent to understand human natural language commands through semantic parsing, actively resolve
ambiguities using a dialog manager, and incrementally learn from human-robot conversations. The
agent employs incremental learning of a semantic parser from conversations on a mobile robot.
It is implemented and tested both on a web interface with hundreds of users and on a mobile",N/A,N/A
"robot over several days, tasked with understanding navigation and delivery requests through
natural language in an office environment. Brawer et al. [15] presented a framework for effectively
grounding situated and natural language to action selection during human-robot interaction. It
integrates verbal commands from a human partner with contextual information in the form of a
task model. The approach is capable of acquiring and deploying new task representations from",N/A,N/A
"limited and natural language data sets, and without any prior domain knowledge of language
or the task itself. Moreover, understanding action models and predicting next actions are widely
researched for robotic tasks and navigation tasks with natural language commands [24, 26, 112].
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
16
Jin et al.
On the other hand, another challenge in natural language command understanding tasks is",N/A,N/A
"to learn new actions when facing unknown natural language commands [6, 100]. Cantrell et al.
[19] introduced an algorithm, to learn meanings of action verbs through dialogue-based natural
language descriptions and integrated it in the robot’s natural language subsystem. The algorithm
allows robots to perform the actions associated with the learned verb meanings right away without
any additional help or learning trials. Moreover, it allows human to interact with a robot to explain",N/A,N/A
"new action words in natural language, and lets the robot be able to perform the new action and
store the procedural knowledge for future usage. Learning by Instruction Agent (LIA) [5] was
proposed to learn new commands by natural language interaction with human. When facing a
new natural language command that LIA does not understand, it prompts users to explain how
to achieve the command through a sequence of natural language steps. LIA interprets commands",N/A,N/A
"using a semantic parser that maps each command to a logical form, which contains one or more of
functions and predicates.
Undoubtedly, letting agents understand natural language commands and infer about next actions
is an important but challenging task. An agent does not only need to capture rules implied in
utterances, but also need to distinguish sentences described in different ways. We believe that the",N/A,N/A
"combination of planning-based natural language processing and human-robot interaction would
create something interesting for natural language commands understanding tasks.
6.3
Dialogue Systems
Dialogue systems [23, 67] have been a bridge between human and robots, which interacts with
human in natural language. AI planning is one of crucial mechanisms used in dialogue systems
to recognize the intentions conveyed in dialogues [18, 76]. Planning-based dialogue systems take",N/A,N/A
"advantage of the power of capturing and expressing rules and use it to manage utterances or guide
the generation. Rules, plans and intentions offer proper logical forms which derive appropriate
communication acts in dialogue systems [28]. Plan-based model [27, 93] were proposed to manage
the intentions and information implied in dialogues. Those models describe the common activities
and relations between utterances, and can be used in the following generation processes. However,",N/A,N/A
"planning-based dialogue systems are still in early stages [28, 84], which facing the challenges
of complex representations in open-domain, difficulties of manually constructing models and
limitations of scalability of dialogue models. Nevertheless, we believe that planning could be a
strong suit for dialogue systems by integrating with automatically domain models learning and
searching strategies, especially for controlled dialogue generation. Moreover, we are interested in",N/A,N/A
"the explainability of planning-based dialogue systems, it would be interesting to know the reason
for intentions generation.
7
APPLICATIONS
In this section, we introduce some reality applications based on combinations of AI planning and
natural language processing. AI planning is widely used in reality management systems, such as
logistics management, workshop schedule, and reservoir operation. Moreover, natural language",N/A,N/A
"processing (NLP) helps human communicate with agents, the combination of AI planning and NLP
enables applications to be found in many fields, such as emergency managements [11, 29, 29, 33]
and urban planning [63, 63, 89]. For example, the Urban Redevelopment Authority (URA) Centre in
Singapore 3 deployed Robotic Process Automation and NLP to help conduct operations for resource
optimization. The combination allows routine tasks to make use of AI planning and NLP, such",N/A,N/A
"as chatbots for public queries, which capture information from large datasets, analyze textual
3https://www.ura.gov.sg/Corporate/Resources/Ideas-and-Trends/AI-in-Urban-Planning
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
17
feedback, make planning decisions, and respond intelligently. On the other hand, the navigation",N/A,N/A
"systems in daily use, such as Baidu Maps 4 and Google Maps 5, combine making decisions and
NLP techniques, which plan out routes with different objectives according to goals, and generate
natural language suggestions to guide human. Moreover, agents learn from human commands and
navigation datasets, helping agents understand human behaviors [45, 73].
8
CONCLUSION
In this paper, we consider that AI planning and natural language processing have strong ties, and we",N/A,N/A
"introduce recent works about four related tasks, i.e., planning-based text understanding, planning-
based natural language processing, planning-based explainability, and text-based human-robot
interaction. We first introduce backgrounds about AI planning and natural language processing
and discuss commons between them, as well as their abilities to generate explicit knowledge,
e.g., domain models, and learning from tacit knowledge, e.g., neural models. We then introduce",N/A,N/A
"methods of planning-based text understanding by extracting action sequences from texts and
learning domain models from texts. Next, we give an overview of planning-based natural language
processing about text generation, text summarization, and machine translation. Then, we introduce
recent works in planning-based explainability and text-based human-robot interaction.
With this paper, we aim to provide a high-level view of AI planning and natural language",N/A,N/A
"processing for further studies, about integrating them for a combination of explicit and tacit
knowledge. Combining learning from tacit knowledge and using explicit knowledge in a fully
principled way is an open problem, although there are non-negligible relations between AI planning
and natural language processing, allowing each of them can effectively impact the other one.
However, there is not enough communication between these two fields. While many advances have",N/A,N/A
"been made in natural language processing by using AI planning algorithms, a significant amount
of research is still required to understand the implied knowledge hidden in texts. Meanwhile,
improving the ability to describe environments by domain models and solve large-scale planning
problems is also beneficial to understanding texts and generating coherent and interesting texts.
We believe that integrating AI planning and natural language processing, a complex combination of",N/A,N/A
"explicit and tacit knowledge, is a promising research area, which can improve the communication
between human and intelligent agents.
REFERENCES
[1] S Alshaina, Ansamma John, and Aneesh G Nath. 2017. Multi-document abstractive summarization based on predicate
argument structure. In 2017 IEEE International Conference on Signal Processing, Informatics, Communication and Energy
Systems (SPICES). IEEE, 1–6.",N/A,N/A
"Systems (SPICES). IEEE, 1–6.
[2] Prithviraj Ammanabrolu, Wesley Cheung, William Broniec, and Mark O. Riedl. 2021. Automated Storytelling
via Causal, Commonsense Plot Ordering. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium
on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021. 5859–5867. https:",N/A,N/A
"//ojs.aaai.org/index.php/AAAI/article/view/16733
[3] Reinald Kim Amplayo, Stefanos Angelidis, and Mirella Lapata. 2021. Unsupervised Opinion Summarization with
Content Planning. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference
on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in",N/A,N/A
"Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021. 12489–12497. https://ojs.aaai.org/index.php/AAAI/
article/view/17481
[4] Mozhgan Nasr Azadani, Nasser Ghadiri, and Ensieh Davoodijam. 2018. Graph-based biomedical text summarization:
An itemset mining and sentence clustering approach. J. Biomed. Informatics 84 (2018), 42–58. https://doi.org/10.1016/
j.jbi.2018.06.005
4https://map.baidu.com/
5https://www.google.de/maps",N/A,N/A
"5https://www.google.de/maps
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
18
Jin et al.
[5] Amos Azaria, Jayant Krishnamurthy, and Tom M. Mitchell. 2016. Instructable Intelligent Personal Agent. In Proceedings
of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, Dale Schuurmans
and Michael P. Wellman (Eds.). 2681–2689. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12383",N/A,N/A
"[6] Amos Azaria, Shashank Srivastava, Jayant Krishnamurthy, Igor Labutov, and Tom M. Mitchell. 2020. An agent for
learning new natural language commands. Auton. Agents Multi Agent Syst. 34, 1 (2020), 6. https://doi.org/10.1007/
s10458-019-09425-x
[7] Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C. Courville,
and Yoshua Bengio. 2017. An Actor-Critic Algorithm for Sequence Prediction. In 5th International Conference",N/A,N/A
"on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.
https:
//openreview.net/forum?id=SJDaqqveg
[8] Siddhartha Banerjee, Prasenjit Mitra, and Kazunari Sugiyama. 2015. Multi-Document Abstractive Summarization
Using ILP Based Multi-Sentence Compression. In Proceedings of the Twenty-Fourth International Joint Conference on
Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, Qiang Yang and Michael J. Wooldridge",N/A,N/A
"(Eds.). 1208–1214. http://ijcai.org/Abstract/15/174
[9] Robert Baud, Christian Lovis, Laurence Alpay, Anne-Marie Rassinoux, JR Scherrer, Anthony Nowlan, and Alan
Rector. 1993. Modelling for natural language understanding.. In Proceedings of the Annual Symposium on Computer
Application in Medical Care. American Medical Informatics Association, 289.
[10] Yonatan Bisk, Kevin J. Shih, Yejin Choi, and Daniel Marcu. 2018. Learning Interpretable Spatial Operations in a Rich",N/A,N/A
"3D Blocks World. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th
innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in
Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, Sheila A. McIlraith and Kilian Q.
Weinberger (Eds.). 5028–5036. https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17410",N/A,N/A
"[11] Simon Blindheim, Sebastien Gros, and Tor Arne Johansen. 2020. Risk-based model predictive control for autonomous
ship emergency management. IFAC-PapersOnLine 53, 2 (2020), 14524–14531.
[12] Valts Blukis, Dipendra Kumar Misra, Ross A. Knepper, and Yoav Artzi. 2018. Mapping Navigation Instructions to
Continuous Control Actions with Position-Visitation Prediction. In 2nd Annual Conference on Robot Learning, CoRL",N/A,N/A
"2018, Zürich, Switzerland, 29-31 October 2018, Proceedings (Proceedings of Machine Learning Research, Vol. 87). 505–518.
http://proceedings.mlr.press/v87/blukis18a.html
[13] S. R. K. Branavan, Harr Chen, Luke S. Zettlemoyer, and Regina Barzilay. 2009. Reinforcement Learning for Mapping
Instructions to Actions. In ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational",N/A,N/A
"Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009,
Singapore, Keh-Yih Su, Jian Su, and Janyce Wiebe (Eds.). 82–90. https://aclanthology.org/P09-1010/
[14] S. R. K. Branavan, Nate Kushman, Tao Lei, and Regina Barzilay. 2012. Learning High-Level Planning from Text. In
The 50th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, July 8-14,",N/A,N/A
"2012, Jeju Island, Korea - Volume 1: Long Papers. 126–135. https://aclanthology.org/P12-1014/
[15] Jake Brawer, Olivier Mangin, Alessandro Roncone, Sarah Widder, and Brian Scassellati. 2018. Situated Human-
Robot Collaboration: predicting intent from grounded natural language. In 2018 IEEE/RSJ International Conference on
Intelligent Robots and Systems, IROS 2018, Madrid, Spain, October 1-5, 2018. 827–833. https://doi.org/10.1109/IROS.
2018.8593942",N/A,N/A
"2018.8593942
[16] Igor Buzhinsky. 2019. Formalization of natural language requirements into temporal logics: a survey. In 17th
IEEE International Conference on Industrial Informatics, INDIN 2019, Helsinki, Finland, July 22-25, 2019. 400–406.
https://doi.org/10.1109/INDIN41052.2019.8972130
[17] Erik Cambria and Bebo White. 2014. Jumping NLP curves: A review of natural language processing research. IEEE
Computational intelligence magazine 9, 2 (2014), 48–57.",N/A,N/A
"[18] Guy Camilleri. 2002. Dialogue systems and planning. In International Conference on Text, Speech and Dialogue. Springer,
429–436.
[19] Rehj Cantrell, Paul W. Schermerhorn, and Matthias Scheutz. 2011. Learning actions from human-robot dialogues. In
20th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2011, Atlanta, Georgia,
USA, July 31 - August 3, 2011, Henrik I. Christensen (Ed.). 125–130. https://doi.org/10.1109/ROMAN.2011.6005199",N/A,N/A
"[20] Rehj Cantrell, Kartik Talamadupula, Paul W. Schermerhorn, J. Benton, Subbarao Kambhampati, and Matthias Scheutz.
2012. Tell me when and why to do it!: run-time planner model updates via natural language instruction. In HRI,
Holly A. Yanco, Aaron Steinfeld, Vanessa Evers, and Odest Chadwicke Jenkins (Eds.). 471–478. https://doi.org/10.
1145/2157689.2157840
[21] Nick Cercone and Gordon McCalla. 1986. Accessing knowledge through natural language. In Advances in Computers.",N/A,N/A
"Vol. 25. Elsevier, 1–99.
[22] David L. Chen and Raymond J. Mooney. 2011. Learning to Interpret Natural Language Navigation Instructions from
Observations. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco,
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
19",N/A,N/A
"19
California, USA, August 7-11, 2011, Wolfram Burgard and Dan Roth (Eds.). http://www.aaai.org/ocs/index.php/AAAI/
AAAI11/paper/view/3701
[23] Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang. 2017. A Survey on Dialogue Systems: Recent Advances
and New Frontiers. SIGKDD Explor. 19, 2 (2017), 25–35. https://doi.org/10.1145/3166054.3166058
[24] Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, and Yoav Artzi. 2019.
TOUCHDOWN: Nat-",N/A,N/A
"TOUCHDOWN: Nat-
ural Language Navigation and Spatial Reasoning in Visual Street Environments. In IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019. 12538–
12547.
http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_TOUCHDOWN_Natural_Language_
Navigation_and_Spatial_Reasoning_in_Visual_Street_CVPR_2019_paper.html
[25] Haonan Chen, Hao Tan, Alan Kuntz, Mohit Bansal, and Ron Alterovitz. 2020. Enabling Robots to Understand",N/A,N/A
"Incomplete Natural Language Instructions Using Commonsense Reasoning. In 2020 IEEE International Conference
on Robotics and Automation, ICRA 2020, Paris, France, May 31 - August 31, 2020. 1963–1969. https://doi.org/10.1109/
ICRA40945.2020.9197315
[26] Ta-Chung Chi, Minmin Shen, Mihail Eric, Seokhwan Kim, and Dilek Hakkani-Tür. 2020. Just Ask: An Interactive
Learning Framework for Vision and Language Navigation. In The Thirty-Fourth AAAI Conference on Artificial",N/A,N/A
"Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The
Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February
7-12, 2020. 2459–2466. https://ojs.aaai.org/index.php/AAAI/article/view/5627
[27] Jennifer Chu-Carroll and Sandra Carberry. 1994. A plan-based model for response generation in collaborative
task-oriented dialogues. arXiv preprint cmp-lg/9405011 (1994).",N/A,N/A
"[28] Philip R Cohen. 2020. Back to the future for dialogue research. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 34. 13514–13519.
[29] Daniel G Costa, João Paulo J Peixoto, Thiago C Jesus, Paulo Portugal, Francisco Vasques, Elivelton Rangel, and Maycon
Peixoto. 2022. A Survey of Emergencies Management Systems in Smart Cities. IEEE Access (2022).
[30] Chenhe Dong, Yinghui Li, Haifan Gong, Miaoxin Chen, Junxin Li, Ying Shen, and Min Yang. 2021. A Survey of",N/A,N/A
"Natural Language Generation. arXiv preprint arXiv:2112.11739 (2021).
[31] Angela Fan, Mike Lewis, and Yann N. Dauphin. 2019. Strategies for Structuring Story Generation. In Proceedings
of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August
2, 2019, Volume 1: Long Papers, Anna Korhonen, David R. Traum, and Lluís Màrquez (Eds.). 2650–2660.
https:
//doi.org/10.18653/v1/p19-1254",N/A,N/A
"https:
//doi.org/10.18653/v1/p19-1254
[32] Wenfeng Feng, Hankz Hankui Zhuo, and Subbarao Kambhampati. 2018. Extracting Action Sequences from Texts
Based on Deep Reinforcement Learning. In IJCAI. 4064–4070.
[33] Daniela Fogli and Giovanni Guida. 2013. Knowledge-centered design of decision support systems for emergency
management. Decision Support Systems 55, 1 (2013), 336–347.
[34] Maria Fox and Derek Long. 2002. PDDL+: Modeling continuous time dependent effects. In Proceedings of the 3rd",N/A,N/A
"International NASA Workshop on Planning and Scheduling for Space, Vol. 4. 34.
[35] Tyler M. Frasca, Bradley Oosterveld, Meia Chita-Tegmark, and Matthias Scheutz. 2021. Enabling Fast Instruction-
Based Modification of Learned Robot Skills. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium",N/A,N/A
"on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021. 6075–6083. https:
//ojs.aaai.org/index.php/AAAI/article/view/16757
[36] Konstantina Garoufi. 2014. Planning-Based Models of Natural Language Generation. Lang. Linguistics Compass 8, 1
(2014), 1–10. https://doi.org/10.1111/lnc3.12053
[37] Albert Gatt and Emiel Krahmer. 2018. Survey of the state of the art in natural language generation: Core tasks,",N/A,N/A
"applications and evaluation. Journal of Artificial Intelligence Research 61 (2018), 65–170.
[38] Christopher W. Geib and Mark Steedman. 2007. On Natural Language Processing and Plan Recognition. In IJCAI
2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12,
2007, Manuela M. Veloso (Ed.). 1612–1617. http://ijcai.org/Proceedings/07/Papers/260.pdf",N/A,N/A
"[39] Alfonso Gerevini and Derek Long. 2005. Plan constraints and preferences in PDDL3. Technical Report. Technical
Report 2005-08-07, Department of Electronics for Automation ....
[40] Lin Guan, Mudit Verma, Sihang Guo, Ruohan Zhang, and Subbarao Kambhampati. 2021. Widening the Pipeline in
Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation. Advances in
Neural Information Processing Systems 34 (2021).",N/A,N/A
"Neural Information Processing Systems 34 (2021).
[41] Çaglar Gülçehre, Francis Dutil, Adam Trischler, and Yoshua Bengio. 2017. Plan, Attend, Generate: Character-Level
Neural Machine Translation with Planning. In Proceedings of the 2nd Workshop on Representation Learning for NLP,
Rep4NLP@ACL 2017, Vancouver, Canada, August 3, 2017, Phil Blunsom, Antoine Bordes, Kyunghyun Cho, Shay B.
Cohen, Chris Dyer, Edward Grefenstette, Karl Moritz Hermann, Laura Rimell, Jason Weston, and Scott Yih (Eds.).",N/A,N/A
"ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
20
Jin et al.
228–234. https://doi.org/10.18653/v1/w17-2627
[42] Thomas Hayton, Julie Porteous, João Fernando Ferreira, and Alan Lindsay. 2020. Narrative Planning Model Acquisition
from Text Summaries and Descriptions. In AAAI. 1709–1716.
[43] Daniel Hládek, Ján Staš, and Matúš Pleva. 2020. Survey of automatic spelling correction. Electronics 9, 10 (2020), 1670.",N/A,N/A
"[44] Xinyu Hua, Ashwin Sreevatsa, and Lu Wang. 2021. DYPLOC: Dynamic Planning of Content Using Mixed Language
Models for Text Generation. In Proceedings of ACL. 6408–6423.
[45] Jizhou Huang, Haifeng Wang, Miao Fan, An Zhuo, Yibo Sun, and Ying Li. 2020. Understanding the Impact of
the COVID-19 Pandemic on Transportation-related Behaviors with Human Mobility Data. (2020), 3443–3450.
https://doi.org/10.1145/3394486.3412856",N/A,N/A
"https://doi.org/10.1145/3394486.3412856
[46] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. 2022. Language Models as Zero-Shot Planners:
Extracting Actionable Knowledge for Embodied Agents. 162 (2022), 9118–9147. https://proceedings.mlr.press/v162/
huang22a.html
[47] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor",N/A,N/A
"Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,
and Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning with Language Models. CoRR
abs/2207.05608 (2022). https://doi.org/10.48550/arXiv.2207.05608 arXiv:2207.05608
[48] Pham Ngoc Hung and Takashi Yoshimi. 2016. Extracting actions from instruction manual and testing their execution
in a robotic simulation. ASEAN Engineering Journal 6, 1 (2016), 47–58.",N/A,N/A
"[49] Touseef Iqbal and Shaima Qureshi. 2020. The survey: Text generation models in deep learning. Journal of King Saud
University-Computer and Information Sciences (2020).
[50] Peter A. Jansen. 2020. Visually-Grounded Planning without Vision: Language Models Infer Detailed Plans from
High-level Instructions. EMNLP 2020 (2020), 4412–4417. https://doi.org/10.18653/v1/2020.findings-emnlp.395",N/A,N/A
"[51] HanQi Jin, Yue Cao, TianMing Wang, XinYu Xing, and XiaoJun Wan. 2020. Recent advances of neural text generation:
Core tasks, datasets, models and challenges. Science China Technological Sciences 63, 10 (2020), 1990–2010.
[52] Subbarao Kambhampati. 2021. Polanyi’s revenge and AI’s new romance with tacit knowledge. Commun. ACM 64, 2
(2021), 31–32. https://doi.org/10.1145/3446369
[53] Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, and Lin Guan. 2021. Symbols as a Lingua",N/A,N/A
"Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems. CoRR abs/2109.09904 (2021).
arXiv:2109.09904 https://arxiv.org/abs/2109.09904
[54] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. 2022. Natural language processing: State of the art,
current trends and challenges. Multimedia Tools and Applications (2022), 1–32.
[55] Joohyun Kim and Raymond J. Mooney. 2012. Unsupervised PCFG Induction for Grounded Language Learning with",N/A,N/A
"Highly Ambiguous Supervision. In EMNLP-CoNLL, Jun’ichi Tsujii, James Henderson, and Marius Pasca (Eds.). 433–444.
https://aclanthology.org/D12-1040/
[56] Alexander Koller and Jörg Hoffmann. 2010. Waking Up a Sleeping Rabbit: On Natural-Language Sentence Generation
with FF. In Proceedings of the 20th International Conference on Automated Planning and Scheduling, ICAPS 2010, Toronto,
Ontario, Canada, May 12-16, 2010, Ronen I. Brafman, Hector Geffner, Jörg Hoffmann, and Henry A. Kautz (Eds.).",N/A,N/A
"AAAI, 238–241. http://www.aaai.org/ocs/index.php/ICAPS/ICAPS10/paper/view/1415
[57] Xiangzhe Kong, Jialiang Huang, Ziquan Tung, Jian Guan, and Minlie Huang. 2021. Stylized Story Generation with
Style-Guided Planning. In ACL-IJCNLP. 2430–2436.
[58] Litton J Kurisinkel, Yue Zhang, and Vasudeva Varma. 2017. Abstractive multi-document summarization by partial
tree extraction, recombination and linearization. In Proceedings of the Eighth International Joint Conference on Natural",N/A,N/A
"Language Processing (Volume 1: Long Papers). 812–821.
[59] Anastassia Küstenmacher and Paul G Plöger. 2021. Improving the Reliability of Service Robots by Symbolic Represen-
tation of Execution Specific Knowledge. In Robust and Reliable Autonomy in the Wild (R2AW).
[60] Boyang Li, Stephen Lee-Urban, George Johnston, and Mark Riedl. 2013. Story Generation with Crowdsourced Plot
Graphs. In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, July 14-18, 2013, Bellevue,",N/A,N/A
"Washington, USA, Marie desJardins and Michael L. Littman (Eds.). http://www.aaai.org/ocs/index.php/AAAI/AAAI13/
paper/view/6399
[61] Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek,
Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba, and Yuke Zhu. 2022. Pre-Trained Language
Models for Interactive Decision-Making. CoRR abs/2202.01771 (2022). arXiv:2202.01771 https://arxiv.org/abs/2202.
01771",N/A,N/A
"01771
[62] Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, and Ion Stoica. 2021. Terapipe:
Token-level pipeline parallelism for training large-scale language models. In International Conference on Machine
Learning. PMLR, 6543–6552.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
21",N/A,N/A
"21
[63] Claudius Lieven, Bianca Lüders, Daniel Kulus, and Rosa Thoneick. 2021. Enabling digital co-creation in urban
planning and development. (2021), 415–430.
[64] Alan Lindsay, Jonathon Read, João F. Ferreira, Thomas Hayton, Julie Porteous, and Peter Gregory. 2017. Framer:
Planning Models from Natural Language Action Descriptions. In ICAPS. 434–442.
[65] Adam Lopez. 2008. Statistical Machine Translation. ACM Comput. Surv. 40, 3, Article 8 (aug 2008), 49 pages.",N/A,N/A
"https://doi.org/10.1145/1380584.1380586
[66] Stephanie M Lukin and Marilyn A Walker. 2019. A narrative sentence planner and structurer for domain independent,
parameterizable storytelling. Dialogue & Discourse 10, 1 (2019), 34–86.
[67] Longxuan Ma, Mingda Li, Wei-Nan Zhang, Jiapeng Li, and Ting Liu. 2022. Unstructured Text Enhanced Open-Domain
Dialogue System: A Systematic Survey. ACM Trans. Inf. Syst. 40, 1 (2022), 9:1–9:44. https://doi.org/10.1145/3464377",N/A,N/A
"[68] Matt MacMahon, Brian Stankiewicz, and Benjamin Kuipers. 2006. Walk the Talk: Connecting Language, Knowledge,
and Action in Route Instructions. In AAAI. 1475–1482. http://www.aaai.org/Library/AAAI/2006/aaai06-232.php
[69] Andreas Marfurt and James Henderson. 2021. Sentence-level Planning for Especially Abstractive Summarization. In
Proceedings of the Third Workshop on New Frontiers in Summarization. 1–14.",N/A,N/A
"[70] Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010. Following directions using statistical machine translation. In
HRI, Pamela J. Hinds, Hiroshi Ishiguro, Takayuki Kanda, and Peter H. Kahn Jr. (Eds.). 251–258. https://doi.org/10.
1145/1734454.1734552
[71] Drew McDermott, Malik Ghallab, Adele E. Howe, Craig A. Knoblock, Ashwin Ram, Manuela M. Veloso, Daniel S.
Weld, and David E. Wilkins. 1998. PDDL-the planning domain definition language.",N/A,N/A
"[72] Hongyuan Mei, Mohit Bansal, and Matthew R. Walter. 2016. Listen, Attend, and Walk: Neural Mapping of Navigational
Instructions to Action Sequences. In Thirtieth AAAI Conference on Artificial Intelligence, Dale Schuurmans and
Michael P. Wellman (Eds.). 2772–2778. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12522
[73] Shah Jahan Miah, Huy Quan Vu, and Damminda Alahakoon. 2022. A social media analytics perspective for human-",N/A,N/A
"oriented smart city planning and management. Journal of the Association for Information Science and Technology 73, 1
(2022), 119–135.
[74] M Jishma Mohan, C Sunitha, Amal Ganesh, and A Jaya. 2016. A study on ontology based abstractive summarization.
Procedia Computer Science 87 (2016), 32–37.
[75] Shiwali Mohan and John E. Laird. 2014. Learning Goal-Oriented Hierarchical Tasks from Situated Interactive",N/A,N/A
"Instruction. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Québec
City, Québec, Canada, Carla E. Brodley and Peter Stone (Eds.). 387–394. http://www.aaai.org/ocs/index.php/AAAI/
AAAI14/paper/view/8630
[76] Christian Muise, Tathagata Chakraborti, Shubham Agarwal, Ondrej Bajgar, Arunima Chaudhary, Luis A Lastras-
Montano, Josef Ondrej, Miroslav Vodolan, and Charlie Wiecha. 2019. Planning for goal-oriented dialogue systems.",N/A,N/A
"arXiv preprint arXiv:1910.08137 (2019).
[77] Shashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo Simões, Vitaly Nikolaev, and Ryan McDonald. 2021. Planning with
learned entity prompts for abstractive summarization. Transactions of the Association for Computational Linguistics 9
(2021), 1475–1492.
[78] Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary, Vijay Korthikanti, Dmitri",N/A,N/A
"Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, et al. 2021. Efficient large-scale language model
training on gpu clusters using megatron-lm. In Proceedings of the International Conference for High Performance
Computing, Networking, Storage and Analysis. 1–15.
[79] Daniel Nyga and Michael Beetz. 2012. Everything robots always wanted to know about housework (but were afraid
to ask). In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 243–250.",N/A,N/A
"[80] MD Okpor. 2014. Machine translation approaches: issues and challenges. International Journal of Computer Science
Issues (IJCSI) 11, 5 (2014), 159.
[81] Daniel W Otter, Julian R Medina, and Jugal K Kalita. 2020. A survey of the usages of deep learning for natural
language processing. IEEE transactions on neural networks and learning systems 32, 2 (2020), 604–624.
[82] Vishal Pallagani and Biplav Srivastava. 2021. A Generic Dialog Agent for Information Retrieval Based on Automated",N/A,N/A
"Planning Within a Reinforcement Learning Platform. Bridging the Gap Between AI Planning and Reinforcement
Learning (PRL) (2021).
[83] C. Raymond Perrault and James F. Allen. 1980. A Plan-Based Analysis of Indirect Speech Acts. Am. J. Comput.
Linguistics 6, 3-4 (1980), 167–182.
[84] Ronald PA Petrick and Mary Ellen Foster. 2016. Using general-purpose planning for action selection in human-robot
interaction. In 2016 AAAI Fall Symposium Series.",N/A,N/A
"interaction. In 2016 AAAI Fall Symposium Series.
[85] Ngoc Hung Pham and Takashi Yoshimi. 2015. Extraction of actions and objects from instruction manual for executable
robot planning. In 2015 15th International Conference on Control, Automation and Systems (ICCAS). IEEE, 881–885.
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
22
Jin et al.",N/A,N/A
"22
Jin et al.
[86] Julie Porteous and Marc Cavazza. 2009. Controlling Narrative Generation with Planning Trajectories: The Role of
Constraints. In ICIDS 2009 (Lecture Notes in Computer Science, Vol. 5915), Ido Iurgel, Nelson Zagalo, and Paolo Petta
(Eds.). 234–245. https://doi.org/10.1007/978-3-642-10643-9_28
[87] Julie Porteous, João F. Ferreira, Alan Lindsay, and Marc Cavazza. 2021. Automated narrative planning model extension.",N/A,N/A
"Auton. Agents Multi Agent Syst. 35, 2 (2021), 19. https://doi.org/10.1007/s10458-021-09501-1
[88] Julie Porteous, João F Ferreira, Alan Lindsay, and Marc Cavazza. 2021. Automated narrative planning model extension.
Autonomous Agents and Multi-Agent Systems 35, 2 (2021), 1–29.
[89] Bernd Resch, Anja Summa, Peter Zeile, and Michael Strube. 2016. Citizen-centric urban planning through extracting",N/A,N/A
"emotion information from twitter in an interdisciplinary space-time-linguistics algorithm. Urban Planning 1, 2 (2016),
114–127.
[90] Mark O. Riedl and Robert Michael Young. 2010. Narrative Planning: Balancing Plot and Character. J. Artif. Intell. Res.
39 (2010), 217–268. https://doi.org/10.1613/jair.2989
[91] Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley. 2010. Automatic keyword extraction from individual
documents. Text mining: applications and theory 1 (2010), 1–20.",N/A,N/A
"[92] Scott Sanner et al. 2010. Relational dynamic influence diagram language (rddl): Language description. Unpublished
ms. Australian National University 32 (2010), 27.
[93] Milene Santos Teixeira and Mauro Dragoni. 2022. A Review of Plan-Based Approaches for Dialogue Management.
Cognitive Computation (2022), 1–20.
[94] Buser Say. 2021. A Unified Framework for Planning with Learned Neural Network Transition Models. (2021),
5016–5024. https://ojs.aaai.org/index.php/AAAI/article/view/16635",N/A,N/A
"[95] Matthias Scheutz, Evan A. Krause, Bradley Oosterveld, Tyler M. Frasca, and Robert Platt Jr. 2017. Spoken Instruction-
Based One-Shot Object and Action Learning in a Cognitive Robotic Architecture. In Proceedings of the 16th Conference
on Autonomous Agents and MultiAgent Systems, AAMAS 2017, São Paulo, Brazil, May 8-12, 2017, Kate Larson, Michael
Winikoff, Sanmay Das, and Edmund H. Durfee (Eds.). 1378–1386. http://dl.acm.org/citation.cfm?id=3091315",N/A,N/A
"[96] Lei Sha, Lili Mou, Tianyu Liu, Pascal Poupart, Sujian Li, Baobao Chang, and Zhifang Sui. 2018. Order-Planning Neural
Text Generation From Structured Data. In AAAI, Sheila A. McIlraith and Kilian Q. Weinberger (Eds.). 5414–5421.
[97] Khaled Shaalan et al. 2010. Rule-based approach in Arabic natural language processing. The International Journal on
Information and Communication Technologies (IJICT) 3, 3 (2010), 11–19.",N/A,N/A
"[98] Pratyusha Sharma, Antonio Torralba, and Jacob Andreas. 2022. Skill Induction and Planning with Latent Language.
(2022), 1713–1726. https://doi.org/10.18653/v1/2022.acl-long.120
[99] Lanbo She and Joyce Yue Chai. 2017. Interactive Learning of Grounded Verb Semantics towards Human-Robot
Communication. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017,",N/A,N/A
"Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, Regina Barzilay and Min-Yen Kan (Eds.). 1634–1644.
https://doi.org/10.18653/v1/P17-1150
[100] Lanbo She, Yu Cheng, Joyce Yue Chai, Yunyi Jia, Shaohua Yang, and Ning Xi. 2014. Teaching Robots New Actions
through Natural Language Instructions. In The 23rd IEEE International Symposium on Robot and Human Interactive
Communication, IEEE RO-MAN 2014, Edinburgh, UK, August 25-29, 2014. 868–873. https://doi.org/10.1109/ROMAN.
2014.6926362",N/A,N/A
"2014.6926362
[101] Lanbo She, Shaohua Yang, Yu Cheng, Yunyi Jia, Joyce Yue Chai, and Ning Xi. 2014. Back to the Blocks World: Learning
New Actions through Situated Human-Robot Dialogue. In Proceedings of the SIGDIAL 2014 Conference, The 15th
Annual Meeting of the Special Interest Group on Discourse and Dialogue, 18-20 June 2014, Philadelphia, PA, USA. 89–97.
https://doi.org/10.3115/v1/w14-4313",N/A,N/A
"https://doi.org/10.3115/v1/w14-4313
[102] Raphael Shu and Hideki Nakayama. 2018. Discrete Structural Planning for Neural Machine Translation. CoRR
abs/1808.04525 (2018). arXiv:1808.04525 http://arxiv.org/abs/1808.04525
[103] Avirup Sil and Alexander Yates. 2011. Extracting STRIPS Representations of Actions and Events. In RANLP. 1–8.
[104] Nisha Simon and Christian Muise. 2022. TattleTale: Storytelling with Planning and Large Language Models. (2022).",N/A,N/A
"[105] Sarath Sreedharan, Tathagata Chakraborti, Christian Muise, Yasaman Khazaeni, and Subbarao Kambhampati. 2020.
–d3wa+–a case study of xaip in a model acquisition task for dialogue planning. In Proceedings of the International
Conference on Automated Planning and Scheduling, Vol. 30. 488–497.
[106] Felix Stahlberg. 2020. Neural Machine Translation: A Review. J. Artif. Intell. Res. 69 (2020), 343–418.
https:
//doi.org/10.1613/jair.1.12007",N/A,N/A
"https:
//doi.org/10.1613/jair.1.12007
[107] Shane Storks, Qiaozi Gao, and Joyce Y Chai. 2019. Commonsense reasoning for natural language understanding: A
survey of benchmarks, resources, and approaches. arXiv preprint arXiv:1904.01172 (2019), 1–60.
[108] Gavin Suddrey, Ben Talbot, and Frederic Maire. 2022. Learning and executing re-usable behaviour trees from natural
language instruction. IEEE Robotics and Automation Letters (2022).",N/A,N/A
"[109] Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J. Martin, Animesh Mehta, Brent Harrison, and Mark O. Riedl.
2019. Controllable Neural Story Plot Generation via Reward Shaping. In Proceedings of the Twenty-Eighth International
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge
23",N/A,N/A
"23
Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, Sarit Kraus (Ed.). 5982–5988.
https://doi.org/10.24963/ijcai.2019/829
[110] Stefanie Tellex, Thomas Kollar, Steven Dickerson, Matthew R. Walter, Ashis Gopal Banerjee, Seth J. Teller, and
Nicholas Roy. 2011. Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.
In AAAI, Wolfram Burgard and Dan Roth (Eds.). http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3623",N/A,N/A
"[111] Moritz Tenorth, Daniel Nyga, and Michael Beetz. 2010. Understanding and executing instructions for everyday
manipulation tasks from the World Wide Web. In IEEE International Conference on Robotics and Automation, ICRA
2010, Anchorage, Alaska, USA, 3-7 May 2010. 1486–1491. https://doi.org/10.1109/ROBOT.2010.5509955
[112] Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer. 2019. Vision-and-Dialog Navigation. In 3rd",N/A,N/A
"Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 - November 1, 2019, Proceedings (Proceedings
of Machine Learning Research, Vol. 100), Leslie Pack Kaelbling, Danica Kragic, and Komei Sugiura (Eds.). 394–406.
http://proceedings.mlr.press/v100/thomason20a.html
[113] Jesse Thomason, Shiqi Zhang, Raymond J. Mooney, and Peter Stone. 2015. Learning to Interpret Natural Language",N/A,N/A
"Commands through Human-Robot Dialog. In IJCAI 2015, Qiang Yang and Michael J. Wooldridge (Eds.). 1923–1929.
http://ijcai.org/Abstract/15/273
[114] Amirsina Torfi, Rouzbeh A Shirvani, Yaser Keneshloo, Nader Tavaf, and Edward A Fox. 2020. Natural language
processing advancements by deep learning: A survey. arXiv preprint arXiv:2003.01200 (2020).
[115] Stephen G. Ware and Robert Michael Young. 2011. CPOCL: A Narrative Planner Supporting Conflict. In AIIDE, Vadim",N/A,N/A
"Bulitko and Mark O. Riedl (Eds.). http://www.aaai.org/ocs/index.php/AIIDE/AIIDE11/paper/view/4058
[116] Robert Wilensky. 1981. Meta-Planning: Representing and Using Knowledge About Planning in Problem Solving and
Natural Language Understanding. Cogn. Sci. 5, 3 (1981), 197–233. https://doi.org/10.1207/s15516709cog0503_2
[117] Chuncheng Xiang, Tingsong Jiang, Baobao Chang, and Zhifang Sui. 2015. ERSOM: A Structural Ontology Matching",N/A,N/A
"Approach Using Automatically Learned Entity Representation. In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, Lluís Màrquez, Chris
Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton (Eds.). 2419–2429. https://doi.org/10.18653/v1/d15-1289
[118] Jingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xiaoyan Cai, and Xu Sun. 2018. A Skeleton-Based Model for Promoting",N/A,N/A
"Coherence Among Sentences in Narrative Story Generation. In EMNLP. 4306–4315. https://aclanthology.org/D18-
1462/
[119] Lili Yao, Nanyun Peng, Ralph M. Weischedel, Kevin Knight, Dongyan Zhao, and Rui Yan. 2019. Plan-and-Write:
Towards Better Automatic Storytelling. In AAAI. 7378–7385.
[120] Rongguang Ye, Qingchuan Xu, Jie Liu, Yang Hong, Chengfeng Sun, Wenzheng Chi, and Lining Sun. 2021. A Natural",N/A,N/A
"Language Instruction Disambiguation Method for Robot Grasping. In IEEE International Conference on Robotics and
Biomimetics, ROBIO 2021, Sanya, China, December 27-31, 2021. 601–606. https://doi.org/10.1109/ROBIO54168.2021.
9739456
[121] Kristina Y. Yordanova and Thomas Kirste. 2016. Learning Models of Human Behaviour from Textual Instructions. In
ICAART. 415–422.
[122] R Michael Young, Stephen G Ware, Brad A Cassell, and Justus Robertson. 2013. Plans and planning in narrative",N/A,N/A
"generation: a review of plan-based approaches to the generation of story, discourse and interactivity in narratives.
Sprache und Datenverarbeitung, Special Issue on Formal and Computational Models of Narrative 37, 1-2 (2013), 41–64.
[123] Meng-Hsuan Yu, Juntao Li, Zhangming Chan, Rui Yan, and Dongyan Zhao. 2021. Content Learning with Structure-
Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling. In AAAI.
6021–6029.",N/A,N/A
"6021–6029.
[124] Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, and Meng Jiang. 2022. A survey of
knowledge-enhanced text generation. ACM Computing Surveys (CSUR) (2022).
[125] Yantian Zha, Lin Guan, and Subbarao Kambhampati. 2021. Learning from Ambiguous Demonstrations with Self-
Explanation Guided Reinforcement Learning. CoRR abs/2110.05286 (2021). arXiv:2110.05286 https://arxiv.org/abs/
2110.05286",N/A,N/A
"2110.05286
[126] Zhengyan Zhang, Yuxian Gu, Xu Han, Shengqi Chen, Chaojun Xiao, Zhenbo Sun, Yuan Yao, Fanchao Qi, Jian Guan,
Pei Ke, et al. 2021. Cpm-2: Large-scale cost-effective pre-trained language models. AI Open 2 (2021), 216–224.
[127] Fengda Zhao, Zhikai Yang, Xianshan Li, Dingding Guo, and Haitao Li. 2021. Extract Executable Action Sequences
from Natural Language Instructions Based on DQN for Medical Service Robots. Int. J. Comput. Commun. Control 16,",N/A,N/A
"2 (2021). https://doi.org/10.15837/ijccc.2021.2.4115
[128] Hankz Hankui Zhuo and Subbarao Kambhampati. 2013. Action-Model Acquisition from Noisy Plan Traces. In IJCAI.
2444–2450.
[129] Hankz Hankui Zhuo and Subbarao Kambhampati. 2017. Model-lite planning: Case-based vs. model-based approaches.
Artif. Intell. 246 (2017), 1–21. https://doi.org/10.1016/j.artint.2017.01.004
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.
24
Jin et al.",N/A,N/A
"24
Jin et al.
[130] Hankz Hankui Zhuo, Héctor Muñoz-Avila, and Qiang Yang. 2014. Learning hierarchical task network domains from
partially observed plan traces. Artif. Intell. 212 (2014), 134–157.
[131] Hankz Hankui Zhuo and Qiang Yang. 2014. Action-model acquisition for planning via transfer learning. Artif. Intell.
212 (2014), 80–103. https://doi.org/10.1016/j.artint.2014.03.004
[132] Hankz Hankui Zhuo, Yantian Zha, Subbarao Kambhampati, and Xin Tian. 2020. Discovering Underlying Plans Based",N/A,N/A
"on Shallow Models. ACM Trans. Intell. Syst. Technol. 11, 2 (2020), 18:1–18:30. https://doi.org/10.1145/3368270
Received xxxx; revised xxxx; accepted xxxx
ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022.",N/A,N/A
"Some Insights into Lifelong Reinforcement Learning Systems
Changjian Li 1
Abstract
A lifelong reinforcement learning system is a
learning system that has the ability to learn
through trail-and-error interaction with the en-
vironment over its lifetime. In this paper, I give
some arguments to show that the traditional rein-
forcement learning paradigm fails to model this
type of learning system. Some insights into life-
long reinforcement learning are provided, along",N/A,N/A
"long reinforcement learning are provided, along
with a simplistic prototype lifelong reinforcement
learning system.
1. Introduction
An agent is an abstraction of a decision-maker. At each time
instance t, it receives an observation ot ∈O, and outputs an
action at ∈A to be carried out in the environment it lives in.
Here, O is the (ﬁnite) set of possible observations the agent
can receive, and A is the (ﬁnite) set of actions the agent can",N/A,N/A
"choose from. An agent’s observation ot depends on the cur-
rent environment state st ∈S through an agent observation
function S →O, where S is the set of possible environment
states. The observation history ho
t = (o1, o2..., ot) is the
sequence of observations the agent has received till time t.
Let Ho
t be the set of possible observation histories of length
t, the policy πt : Ho
t →A at time t is deﬁned as the map-
ping from an observation history of length t to the action the",N/A,N/A
"agent will take. An agent’s behavior can thus be fully speci-
ﬁed by its policy across all timesteps π = (π1, π2, ..., πt, ...).
Throughout the paper, it is assumed that an agent has a ﬁnite
lifespan T.
1.1. Scalar Reward Reinforcement Learning System
We are interested in agents that can achieve some goal. In
reinforcement learning, a goal is expressed by a scalar signal
rt ∈R called the reward. The reward is dependent on the
agent’s observation history, and is assumed to be available",N/A,N/A
"to the agent at each timestep in addition to the observation
1Department of Electrical and Computer Engineering, Uni-
versity of Waterloo, Canada. Correspondence to: Changjian Li
<changjian.li@uwaterloo.ca>.
Preliminary work. Under Review.
ot. Our aim is to ﬁnd policies that maximize the expected
cumulative reward an agent receives over its lifetime:
max
π
E[
T
X
t=1
rt(ho
t)]
(1)
Using the maximization of expected cumulative scalar re-
ward to formulate the general notion of goal is a design",N/A,N/A
"choice in reinforcement learning, based on what is com-
monly known as the reward hypothesis (Sutton & Barto,
2018), In Sutton’s own words:
That all of what we mean by goals and purposes
can be well thought of as the maximization of
the expected value of the cumulative sum of a
received scalar signal (called reward).
This design choice, however, is somewhat arbitrary. Among
other things, the reward needs not be a scalar (e.g. multi-
objective reinforcement learning (White, 1982)), nor does",N/A,N/A
"it have to be a quantity whose cumulative sum is to be
maximized (which we will come to shortly). Leaving aside
the question of whether or not all goals can be formulated
by Eq. 1, I intend to show in this paper that the problem
of lifelong reinforcement learning probably should not be
formulated as such.
Note that in Eq. 1, I deﬁned the reward in terms of the obser-
vation history, instead of the history of environment states
as in most reinforcement learning literature. This reﬂects",N/A,N/A
"the view that reward signals are internal to the agent, as
pointed out by Singh et al. (2004) in their work on intrinsic
motivation. Since the observations are all that the agent has
access to from the external environment, the intrinsic reward
should depend on the environment state only through the
agent’s observation history.
Although the above reinforcement learning formulation rec-
ognizes the reward as a signal intrinsic to an agent, it fo-",N/A,N/A
"cuses on learning across different generations 1 of agents,
as opposed to learning within an agent’s lifespan. From an
agent’s point of view, the cumulative reward is known only
when it reaches its end of life, by which time no learning can
1Usage of the word ‘generation’ here is only to emphasize that
learning cannot be achieved within an agent’s lifespan, and does
not imply that evolution algorithms need to be used.
arXiv:2001.09608v1  [cs.LG]  27 Jan 2020",N/A,N/A
"arXiv:2001.09608v1  [cs.LG]  27 Jan 2020
Some Insights into Lifelong Reinforcement Learning Systems
Figure 1: Architecture of a traditional reinforcement learn-
ing system. At the beginning of an agent’s life, it receives
a policy πi = (πi
1, πi
2, ...πi
T ) from the learning algorithm
that carries out a mix of exploitation and exploration, where
the superscript i indicates that the agent belongs to the ith
generation. The agent receives an observation ot at each",N/A,N/A
"timestep t, and act according to πi
t. At the end of the agent’s
life, the learning algorithm gathers the observation history
ho
T and the cumulative reward PT
t=1 r(ho
t) from the agent,
and outputs the the next policy πi+1 to be executed. The
learning algorithm does not need to optimize the perfor-
mance of any particular πi, as long as it is guaranteed to
be able to eventually ﬁnd the policies that maximize the
expected cumulative reward.",N/A,N/A
"expected cumulative reward.
be done by the ‘dying’ agent itself. The individual reward
received at each timestep does not really matter, since the
optimization objective is the cumulative sum (of reward).
The information gathered by the agent, however, can be used
to improve the policy of the next generation. In other words,
with the conventional reinforcement learning formulation,
learning can only happen at a level higher than the lives of",N/A,N/A
"individual agents (Figure 1), with the goal that an optimal
agent can eventually be found — the lifetime behavior of a
particular agent is not of concern.
1.2. Towards Lifelong Reinforcement Learning
In lifelong reinforcement learning, on the other hand, the
focus is the agent’s ability to learn and adapt to the environ-
ment throughout its lifetime. Intuitively, this implies that
learning component of the learning system should reside
within the agent.",N/A,N/A
"within the agent.
To shed some lights on lifelong reinforcement learning,
consider the Q-learning (Watkins & Dayan, 1992) algorithm
for the standard reinforcement learning problem formulated
by Eq. 1. For the purpose of this example only, it is further
assumed that:
• The reward depends only on the current observation.
I.e., r(ho
t) = r(ot)
• Observations are Markov with respect to past observa-
tions and actions. I.e., P(ot|ot−1, at−1, ..., o1, a1) =
P(ot|ot−1, at−1)",N/A,N/A
"P(ot|ot−1, at−1)
These assumptions are only made so that Q-learning will
ﬁnd the solution to Eq. 1, and are not essential for the gen-
eral discussion. The (non-lifelong) learning system works
as follows:
1. The agent receives its initial Q estimate from the past
generation.
2. At each timestep t, the agent takes an ϵ-greedy action
based on the current Q estimate, then does a Bellman
update on the Q estimate:
Q(ot, at) :=
Q(ot, at) + α(r(ot) + max
a
Q(ot+1, a) −Q(ot, at))
(2)",N/A,N/A
"a
Q(ot+1, a) −Q(ot, at))
(2)
3. When the agent dies, pass the updated Q estimate to
the next generation.
At ﬁrst sight, the fact that the Q estimate is updated every
timestep seems to contradict my argument that learning only
happens across generations. However, for Eq. 2 to be a valid
update, the timestep t needs to be part of the observation
— the observation ot here is in fact the raw observation o−
t
augmented by time t, i.e., ot = (o−
t , t). Since the timestep",N/A,N/A
"t , t). Since the timestep
is part of the observation, no same observation will be expe-
rienced more than once throughout the agent’s lifetime, and
it makes no difference to the agent whether the Q estimate
is updated every timestep, or after its life ends 2.
It’s clear that for an agent to exhibit any sensible behavior,
the initial Q estimate it inherits from the past generation is
vital. If the agent receives a random initial Q estimate, then",N/A,N/A
"it’s lifelong behavior is bound to be random and meaningless.
On the other side of the spectrum, if the agent receives
the true Q function, then it will behave optimally. This
suggests that if we care about the lifetime behaviour (which
includes lifelong learning behavior) of a Q-learning agent,
then Q(ot, ·) is a fundamental signal the agent needs to
receive in addition to the scalar reward. In a sense, if the
signal represented by the scalar reward is a speciﬁcation",N/A,N/A
"of what the goal is, then the signal represented by the Q
estimate is the knowledge past generations have collected
about what the goal means for this type of agent. As an
analogy, the pain associated with falling to the ground could
be the former signal, while the innate fear of height could
be the latter.
2The statement does not strictly hold true if function approxi-
mation is used. An update to Qθ(ot, a) can potentially affect the",N/A,N/A
"Q estimate of all other observations. However, this is more a side
effect than a desired property.
Some Insights into Lifelong Reinforcement Learning Systems
From a computational perspective, the separation of these
two signals may not be necessary. Both signals can be
considered as ‘annotations’ for the observation history that
the agent receives along with its observation, and can be
incorporated into the concept of reward. The reward signals",N/A,N/A
"are no longer restricted scalars, nor are they necessarily
quantities whose cumulative sum is to be maximized — they
are just messages in some reward language that ‘encode’
the knowledge pertaining to an agent’s observation history
— knowledge that enables the agent to learn continuously
throughout its life. Such knowledge may include the goals
of the agent, the subgoals that constitute these goals, the
heuristics for achieving them, and so on. The reward is",N/A,N/A
"then ‘decoded’ by the learning algorithm, which deﬁnes
how the agent responds to the reward given the observation
history. The learning system should be designed such that
by responding to the reward in its intended way, the agent
will learn to achieve the goals implied by the reward before
its end of life (Figure 2).
To be precise, the reward r(ho
t) ∈Σ now belongs to some
reward space Σ. The learning algorithm is a mapping from
reward histories to policies. Denoting the set of possible",N/A,N/A
"reward history of length t as Hr
t , and the set of all possi-
ble policies at time t as Πt, the learning algorithm m can
be represented by m = (m1, m2, ..., mt, ..., mT ), where
mt : Hr
t →Πt. The formulation is general, and a learning
system formulated as such is not automatically a lifelong
learning system. In fact, it subsumes traditional reinforce-
ment learning: the reward space is set to the real numbers
(Σ = R), and the learning algorithm can be set to any algo-",N/A,N/A
"rithm that converges to a policy that maximizes the expected
cumulative reward. Unfortunately, the reward in traditional
reinforcement learning does not contain enough information
for an agent to learn within its lifetime.
Viewing the reward as a general language, and the learning
algorithm as the response to the reward opens up the possi-
bilities for principled ways to embed learning bias such as
guidance and intrinsic motivation into the learning system,",N/A,N/A
"instead of relying solely on manipulating the scalar reward
on an ad-hoc basis. In the rest of the paper, my focus re-
mains on lifelong reinforcement learning, more speciﬁcally,
what lifelong reinforcement learning requires of the reward
language and the corresponding learning algorithm.
1.3. Reward as Formal Language
Although the term ‘language’ used above can be understood
in its colloquial sense, it can also be understood as the formal",N/A,N/A
"term in automata theory. To see this, consider the following
deterministic ﬁnite automaton ⟨Σ, Q, δ, q0, F⟩, where:
• Σ is the alphabet of the automaton, and is set to the
reward space of the learning system. In other words,
Figure 2: Architecture of lifelong reinforcement learning
system. In contrast to traditional reinforcement learning
(Figure 1), the learning algorithm resides inside the agent.
The internal environment of the agent can be thought of as a",N/A,N/A
"built-in mechanism for the agent-designer to communicate
with the agent (through the reward). At each timestep, the
learning algorithm receives some message (encoded in the
form of reward r(ho
t)) from the agent’s internal environment,
and outputs a policy πt as a response.
the alphabet of this automaton consists of all possible
reward the agent can receive at any single timestep.
A string is a sequence of symbols chosen from some
alphabet. For this particular automaton, a string is in",N/A,N/A
"fact a sequence of reward, so the notation for reward
history hr
t is also used to denote a string of length t.
The set of all strings of length k over Σ is denoted as
Σk, and the set of all strings (of any length) is denoted
as Σ∗.
• Q is the set of states of the automaton. Each state of
this automaton is a possible pair of reward history and
policies till some timestep t. For example, members of
Q include:
⟨hr
t=1,
(π1)⟩
⟨hr
t=2,
(π1, π2)⟩
...
⟨hr
t=T ,
(π1, π2, ..., πT )⟩",N/A,N/A
"t=2,
(π1, π2)⟩
...
⟨hr
t=T ,
(π1, π2, ..., πT )⟩
for any π1 ∈Π1, π2 ∈Π2, ..., πT ∈ΠT , and hr
t=1 ∈
Σ1, hr
t=2 ∈Σ2, ..., hr
t=T ∈ΣT . In addition, Q has a
special ‘empty’ member q0, which corresponds to the
initial state before any reward is received.
• δ
:
(Q × Σ)
→
Q
is
the
transition
function.
The transition function corresponds
to the learning algorithm of the learning sys-
tem, so we have δ(⟨hr
t, (π1, ..., πt)⟩,
rt+1)
=
⟨hr
t+1,
(π1, ..., πt, mt+1(hr
t+1))⟩, where hr
t+1
=
(hr
t, rt+1).",N/A,N/A
"t+1))⟩, where hr
t+1
=
(hr
t, rt+1).
Some Insights into Lifelong Reinforcement Learning Systems
• q0 is the initial state of the automaton as explained
above.
• F ⊂Q is the set of accepting states, which are the
desired states of the automaton.
It’s not hard to see that this automaton is a model of the
learning system described in Section 1.2, with its desired
property speciﬁed by the accepting states F. In this pa-
per, the desired property is that the system be a lifelong",N/A,N/A
"learning system, so the accepting states F are the set of
⟨hr
T ,
(π1, π2, ..., πT )⟩pairs that correspond to a lifelong
learner 3.
To specify learning objectives, each possible reward r ∈Σ
is assigned some semantics. These semantics implicitly
deﬁne the set of valid reward sequences L ⊂Σ∗. Since L
is a subset of Σ∗, it is a language over Σ. We want to make
sure that — for all reward sequences in L, lifelong learning
can be achieved by the learning system abstracted by this",N/A,N/A
"automaton, or equivalently, all reward sequences in L lead
to accepting states F.
2. A Prototype Lifelong Reinforcement
Learning System
Designing a lifelong reinforcement learning system involves
designing the reward language and the learning algorithm
holistically. Intuitively, the reward needs to contain enough
information to control the relevant aspects of the learning
algorithm, and the learning algorithm in turn needs to ‘inter-",N/A,N/A
"pret’ the reward signal in its intended way. In this section, I
aim to provide some insights into the design process with a
prototype lifelong reinforcement learning system.
2.1. Reward Language
The main reason lifelong learning is impossible in conven-
tional reinforcement learning is that the learning objective in
conventional reinforcement learning is global, in the sense
that the goal of the agent is deﬁned in terms of the observa-",N/A,N/A
"tion history of its entire life. For a lifelong reinforcement
learning agent, the learning objectives should instead be lo-
cal, meaning that the goals should be deﬁned only for some
smaller tasks that the agent can encounter multiple times
during its lifetime. Once a local goal expires, whether it is
because the goal has been achieved or because the agent has
failed to achieve it within a certain time limit, a new local
goal (can potentially be another instantiation of the same",N/A,N/A
"goal) ensues. This way, the agent has the opportunity to
gather knowledge for each of the goals, and improve upon
3Recall that an agent’s behavior is fully decided by its policy
π = (π1, π2, ..., πT ). Therefore given a reward history hr
T , the
policy is sufﬁcient for us to tell whether the agent is a successful
lifelong learner.
them, all within one life. Local goals like this are ubiquitous
for humans. For example, when a person is hungry, his main",N/A,N/A
"concern is probably not the global goal of being happy for
the rest of his life — his goal is to have food. After the per-
son is full, he might feel like taking a nap, which is another
local goal. In fact, the local goals and the transition of them
seems to embody what we mean by intrinsic motivation.
To be able to specify a series of local goals, the reward in
this prototype learning system has two parts: the reward
state rs
t ∈G, and the reward value rv
t ∈R, where G is the",N/A,N/A
"t ∈R, where G is the
set of local goals the agent may have. This form of reward is
inspired by the reward machine (Icarte et al., 2018), a Mealy
machine for specifying history-dependent reward, but the se-
mantics we assign to the reward will be different. Also note
that this Mealy machine bears no relation to the automaton
we discussed in Section 1.3 — the reward machine models
the reward, while the automaton in Section 1.3 models the
learning system, and takes the reward as input. Each reward",N/A,N/A
"state rs corresponds to a local goal. When a local goal (or
equivalently, a reward state) expires, the agent receives a
numerical reward value rv. For all other timesteps (other
than the expiration of local goals), the reward value can be
considered to take a special NULL value, meaning that no
reward value is received. The reward value is an evalua-
tion of the agent’s performance in an episode of a reward
state, where an episode of a reward state is deﬁned as the",N/A,N/A
"time period between the expiration of the previous reward
state (exclusive) and the expiration of the reward state itself
(inclusive). The reward state can potentially depend on the
entire observation history, while the reward value can only
depend on the observation history of the episode it is assess-
ing. Overall, the reward is speciﬁed by (rs
t , rv
t ) = r(ho
t).
The local goals described here are technically similar to
subgoals in hierarchical reinforcement learning (Dietterich,",N/A,N/A
"2000; Sutton et al., 1999; Parr & Russell, 1997). However,
the term ‘subgoal’ suggests that there is some higher-level
goal that the agent needs to achieve, and that the higher-level
goal is the true objective the agent needs to optimize. That
is not the case here — although it is totally possible that the
local goals are designed in such a way that some global goal
can be achieved, the agent only needs to optimize the local
goals.
The reward language in this prototype system makes two",N/A,N/A
"assumptions on the learning algorithm. As long as the two
assumptions are met, the learning algorithm is considered
to ‘interpret’ the reward correctly. The ﬁrst assumption is
that the learning algorithm only generates policies that are
episode-wise stationary, meaning that πt1 = πt2 for any
timesteps t1 and t2 in the same episode of a reward state,
and that πt1 : O →A. This assumption is not particularly
restrictive, because in cases where a local goal requires a",N/A,N/A
"more complex policy, we can always split the goal into mul-
Some Insights into Lifelong Reinforcement Learning Systems
tiple goals (by modifying the reward function) for which the
policies are episode-wise stationary. With this assumption,
we can use a single policy πrs : O →A to represent the
policies at all timesteps within an episode of reward state
rs. The second assumption is that the learning algorithm
keeps a pool of ‘elite’ policies for each reward state: a pol-",N/A,N/A
"icy that led to high reward value in some episode has the
opportunity to enter the pool, and a policy that consistently
leads to higher reward value eventually dominates the policy
pool. The exact criterion for selection into the pool (e.g., to
use the expected reward value as the criterion, or to use the
probability of the reward value being higher than a certain
threshold, etc.) is not enforced, and is left up to the learning
algorithm.
2.2. Learning Algorithm",N/A,N/A
"algorithm.
2.2. Learning Algorithm
The learning algorithm in this prototype lifelong learning
system is an evolutionary algorithm, adjusted to meet the
assumptions made by the reward. The algorithm maintains
a policy pool Drs of maximum size d for each reward state
rs ∈G. Each item in the pool is a two tuple ⟨π, rv
π⟩where
π is a policy and rv
π is the reward value of the last episode in
which π was executed. Conceptually, the algorithm consists",N/A,N/A
"of three steps: policy generation, policy execution, and
(policy) pool update, which are described below.
POLICY GENERATION
When an episode of reward state rs starts, a policy πrs is
generated from one of the following methods with probabil-
ity p1, p2, p3, respectively:
1. Randomly sample a policy from the policy pool Drs,
and mutate the policy.
2. Randomly sample a policy from Drs and keep it as
is. Remove the sampled policy from Drs. This is to",N/A,N/A
"re-evaluate a policy in the pool. Since the transition of
observations might be stochastic, the same policy does
not necessarily always result in the same reward value.
3. Randomly generate a new policy πrs : O →A from
scratch. This is to keep the diversity of the policy pool.
p1, p2 and p3 should sum up to 1, and are hyper-parameters
of the algorithm.
POLICY EXECUTION
Execute the generated policy πrs until a numerical reward
value rv is received.
POOL UPDATE",N/A,N/A
"value rv is received.
POOL UPDATE
If the policy pool is not full, insert ⟨πrs, rv⟩into the pool.
Otherwise compare rv with the minimum reward value in
Figure 3: A simplistic abstraction of guidance in reinforce-
ment learning.
the pool. If rv is greater than or equal to the minimum
reward value, replace the policy and reward value pair (that
has the minimum reward value) with ⟨πrs, rv⟩.
2.3. Embedding Learning Bias
Learning bias in reinforcement learning systems refers to",N/A,N/A
"the explicit or implicit assumptions made by the learning
algorithm about the policy. Our assumption that the policy
is episode-wise stationary is an example of learning bias.
Arguably, a good learning bias is as important as a good
learning algorithm, therefore it is important that mechanisms
are provided to embed learning bias into the learning system.
A straight-forward way to embed learning bias into the
above lifelong learning system is through the policy gen-",N/A,N/A
"eration process. This includes how existing policies are
mutated, and what distribution new policies are sampled
from. The learning bias provided this way does not depend
on the agent’s observation and reward history, and is some-
times implicit (e.g., the learning bias introduced by using a
neural network of particular architecture).
Another type of learning bias common in reinforcement
learning is guidance, the essence of which can be illustrated",N/A,N/A
"by Figure 3. Suppose in some reward state, the agent starts
from observation o and the goal is to reach 4 observation
o′. Prior knowledge indicates that to reach o′, visiting o′′
is a good heuristic, but reaching o′′ itself has little or no
merit. In other words, we would like to encourage the
agent to visit and explore around o′′ more frequently (than
other parts of the observation space) until a reliable policy
to reach o′ is found.
To provide guidance to the agent",N/A,N/A
"To provide guidance to the agent
in the prototype lifelong learning system, we can utilize
the property of the learning algorithm that policies leading
to high reward values will enter the policy pool. Once a
policy enters the pool, it has the opportunity to be sampled
(possibly with mutation) and executed. Therefore, we just
need to assign a higher reward value for reaching o′′ (before
the expiration of the reward state) than reaching neither o′",N/A,N/A
"nor o′′. Also important is the ability to control the extent
to which region around o′′ is explored. To achieve this,
recall that the learning algorithm occasionally re-evaluates
policies in the policy pool. If we assign a lower reward value
for reaching o′′ with some probability, we can prevent the
4For sake of terminological convenience, we pretend that the
observations here are environment states.
Some Insights into Lifelong Reinforcement Learning Systems",N/A,N/A
"policy pool from being overwhelmed only by policies that
lead to o′′. In other words, the reward value for reaching o′′
should have multiple candidates. Let rv({O −{o′, o′′}})
denote the reward value for an episode where the agent
reaches neither o′ nor o′′, rv(o′) denote the reward value for
reaching o′, we can set the reward value rv(o′′) for reaching
o′′ as:
rv(o′′) :=
(
a,
with probability p
b,
with probability 1 −p
where b < rv({O −{o′, o′′}}) < a < rv(o′). The proba-",N/A,N/A
"bility p controls the frequency region around o′′ is to be ex-
plored compared the other parts of the observation space 5.
3. Experiment
Now we evaluate the behaviour of the prototype lifelong
reinforcement learning system. The source code of the
experiments can be found at https://gitlab.com/
lifelong-rl/lifelongRL_gridworld
3.1. Environment
Consider a gridworld agent whose life revolves around get-
ting food and taking the food back home for consumption.",N/A,N/A
"The agent lives in a 11 by 11 gridworld shown in Figure
4. The shaded areas are barriers that the agent cannot go
through. Some potential positions of interest are marked
with letters: F is the food source and is assumed to have
inﬁnite supply of food; H is the agent’s home. To get to the
food source from home, and to carry the food home, the
agent must pass through one of the two tunnels — the tunnel
on the left is marked with L and the tunnel on the right is",N/A,N/A
"marked with R. At each timestep, the agent observes its posi-
tion in the gridworld as well as a signal indicating whether it
is in one of the four positions of interest (if yes, which), and
chooses from one of the four actions: UP, RIGHT, DOWN
and LEFT. Each action deterministically takes the agent
to the adjacent grid in the corresponding direction, unless
the destination is a barrier, in which case the agent remains
in its original position. The agent starts from home at the",N/A,N/A
"beginning of its life, and needs to go to the food source to
get food. Once it reaches the food source, it needs to carry
the food back home. This process repeats until the agent
dies. The lifespan of the agent is assumed to be 100 million
timesteps. The agent is supposed to learn to reliably achieve
these two local goals within its lifetime.
5Note that the word ‘probability’ here should be interpreted as
the ‘long-run proportion’, and therefore the reward value needs",N/A,N/A
"not be truly stochastic. E.g., we can imagine that the reward has a
third component which is the state of a pseudo-random generator.
Figure 4: Gridworld environment.
3.2. Learning System Setup
The reward state in this experiment is represented by the
conjunction of Boolean variables. For example, if three
Boolean variables A, B and C are deﬁned, then the re-
ward state would be in the form of rs = A ∧B ∧C or
rs = A ∧¬B ∧C, etc. At the bare minimum, one Boolean",N/A,N/A
"variable GET FOOD needs to be deﬁned for this agent, where
GET FOOD being true corresponds to the local goal of going
to the food source, and ¬GET FOOD corresponds to the local
goal of carrying the food home. The agent receives a reward
value of +1 if GET FOOD is true and the agent reaches F,
in which case the Boolean variable GET FOOD transitions
to false. Similarly, the agent receives a reward value of
+1 if ¬GET FOOD is true and the agent reaches H, in which",N/A,N/A
"case GET FOOD transitions to true. On top of GET FOOD, we
deﬁne another Boolean variable TIMED OUT, which indi-
cates whether the agent has exceeded a certain time limit
for trying to get to the food source, or for trying to carry the
food home. If the reward state is ¬TIMED OUT ∧GET FOOD,
and the agent fails to reach F within the time limit, itre-
ceives a reward value of −1, and the reward state transition
to TIMED OUT ∧GET FOOD. From TIMED OUT ∧GET FOOD,",N/A,N/A
"to TIMED OUT ∧GET FOOD. From TIMED OUT ∧GET FOOD,
if the agent still fails to get to F within the time limit, it
receives a reward value of 0. The agent will remain in
TIMED OUT ∧GET FOOD, until it reaches F, when the reward
state transitions to ¬TIMED OUT ∧¬GET FOOD (and receive
a +1 reward value as already mentioned). For the case
when GET FOOD is false, the reward transition is deﬁned
similarly. Throughout the experiments, the time limit is set",N/A,N/A
"to 24, which is enough for the agent to accomplish any of
the local goals. We refer to this reward design as the base
case.
Unfortunately, even for a toy problem like this, learning can
be difﬁcult if no proper learning bias is provided. Since
there are 4 actions and 74 possible positions, the number
of possible episode-wise stationary policies is 474 for each
reward state. Among those policies, very few can achieve
the local goals. If the policy generation and mutation is",N/A,N/A
"purely random, it will take a long time for the agent to ﬁnd
Some Insights into Lifelong Reinforcement Learning Systems
a good policy.
BIASED POLICY
The ﬁrst learning bias we consider is biased policy, which is
in contrast to the unbiased policy case where the policy gen-
eration and mutation is purely random. More speciﬁcally,
we make the policy generation process biased towards poli-
cies that take the same action for similar observations. This",N/A,N/A
"would encourage policies that head consistently in one di-
rection, and discourage those that indeﬁnitely roam around
between adjacent positions.
PROGRESS-BASED GUIDANCE
The second learning bias we consider is guidance based on
the agent’s progress. Different from the base case where
the agent always receives a 0 (if TIMED OUT is true) or
−1 (if TIMED OUT is false) reward value when it fails to
achieve the local goal within the time limit, the agent now",N/A,N/A
"has some probability p = 0.8 of receiving a reward value
proportional to the Manhattan distance d it has traveled
since the beginning of the episode. To be precise:
rv :=
(
0.01d
with probability p
same as the base case
with probability 1 −p
This way, policies leading to more progress (albeit not nec-
essary towards the local goal) will be encouraged.
SUB-OPTIMAL GUIDANCE
Finally, we consider a case of sub-optimal guidance that
encourages the agent to explore a sub-optimal trajectory.",N/A,N/A
"As we have mentioned, both reaching the food source from
home and carrying the food home require the agent to go
through one of the two tunnels. However, if the agent
goes through the left tunnel, it has to travel more dis-
tance. Suppose that we prefer the agent to take the shorter
route, but we only know the route that goes through the
left tunnel; and as a result, we sub-optimally encourage
the agent to explore the left tunnel. To guide the agent",N/A,N/A
"to take the left tunnel, Boolean variable VISITED LEFT is
introduced as an indicator of whether L has been visited
since the last visitation of F or H. Now we have 23 = 9
elements in the reward space, corresponding to 9 possible
local goals. The reward transition is different from the base
case in that if the agent has already visited L when the lo-
cal goal GET FOOD ∧¬TIMED OUT ∧¬VISITED LEFT or
¬GET FOOD ∧¬TIMED OUT ∧¬VISITED LEFT times out,",N/A,N/A
"¬GET FOOD ∧¬TIMED OUT ∧¬VISITED LEFT times out,
VISITED LEFT becomes true, and the agent will receive a
reward value of +0.6 with 0.8 probability, and −0.2 with
0.2 probability. To express our preference for the shorter
route, the agent receives a reward value of +0.8 (instead of
+1) when it reaches F (when GET FOOD is true) or H (when
GET FOOD is false) through the left tunnel.
3.3. Results
(a) unbiased policy, progressed-based guidance
(b) biased policy, progressed-based guidance",N/A,N/A
"(b) biased policy, progressed-based guidance
Figure 5: Learning curve for unbiased/biased policy with
progress-based guidance, averaged over 20 runs.
Figure 5 shows the learning curves for reward state
GET FOOD ∧¬TIMED OUT with progress-based guidance.
The x-axis is the timesteps (in million), and the y-axis is the
percentage of times the agent transitions into a particular
next reward state starting from GET FOOD∧¬TIMED OUT. A
next reward state of ¬GET FOOD ∧¬TIMED OUT means that",N/A,N/A
"the agent successfully reached F within the time limit, and a
next reward state of GET FOOD ∧TIMED OUT means that the
agent failed to do so. As we can see, with unbiased policy, it
took the agent around 25 million timesteps to achieve 100%
success rate; while with biased policy, this only took around
8 million timesteps.
Figure 6 shows the learning curves for reward state
GET FOOD ∧¬TIMED OUT ∧¬VISITED LEFT with the sub-
optimal guidance described in Section 3.2. Similar to Fig-",N/A,N/A
"ure 5, the x-axis is the timesteps (in million), and the y-
axis is the percentage of times the agent transitioned into
a particular next reward state starting from GET FOOD ∧
Some Insights into Lifelong Reinforcement Learning Systems
(a) unbiased policy, sub-optimal guidance
(b) biased policy, sub-optimal guidance
Figure 6: Learning curve for unbiased/biased policy with
sub-optimal guidance, averaged over 20 runs.
¬TIMED OUT ∧¬VISITED LEFT. A next reward state of",N/A,N/A
"¬TIMED OUT ∧¬VISITED LEFT. A next reward state of
¬GET FOOD ∧¬TIMED OUT ∧¬VISITED LEFT means that
the agent successfully reached F within the time limit; a next
reward state of GET FOOD ∧TIMED OUT ∧VISITED LEFT
means that the agent failed to reach the food source, but was
able to ﬁnd a way to the left tunnel; and a next reward state
of GET FOOD ∧TIMED OUT ∧¬VISITED LEFT means that
the agent was neither able to reach the left tunnel nor the",N/A,N/A
"food source within the time limit. As we can see, for both
unbiased and biased policy, learning is much slower than
progress-based guidance. This is likely due to the much
sparser guidance signal — the agent receives guidance only
when it reaches the left tunnel. For the unbiased policy case,
100% success rate was not achieved within 100 million
timesteps, but we can clearly see that exploration around
the left tunnel was encouraged as intended. For the biased",N/A,N/A
"policy case, the agent was able to reach 100% success rate
after 50 million timesteps. But was the agent able to ﬁgure
out the optimal route, or did it only learn to take the sub-
optimal route as guided? Recall that the agent receives a
reward value of +1 if it takes the optimal route, and a reward
value of +0.8 if it takes the sub-optimal route. As shown
in Figure 7, although the agent was taking the sub-optimal
route by 50 million timesteps when it just learned to reach",N/A,N/A
"the food source reliably, it was eventually able to ﬁgure out
the optimal route by 90 million timesteps.
Figure 7: Reward value for GET FOOD ∧¬TIMED OUT ∧
¬VISITED LEFT (biased policy with sub-optimal guidance,
averaged over 20 runs).
4. Conclusions
Lifelong reinforcement learning is sometimes viewed as
a multi-task reinforcement learning problem (Abel et al.,
2018), where the agent must learn to solve tasks sampled
from some distribution D. The agent is expected to (explic-",N/A,N/A
"itly or implicitly) discover the relation between tasks, and
generalize its policy to unseen tasks from D. The focus is
therefore on the transfer learning (Taylor & Stone, 2009)
and continual learning (Ring, 1998) aspects of lifelong rein-
forcement learning.
In this paper, I provided a systems view on lifelong rein-
forcement learning. In particular, I showed that the reward
in a lifelong reinforcement learning system can be a general
language, and that the language needs to be designed holis-",N/A,N/A
"tically with the learning algorithm. A prototype lifelong
reinforcement learning system was given, with an empha-
size on how learning bias can be embedded into the learning
system through the synergy of the reward language and the
learning algorithm.
Acknowledgements
The author would like to thank Gaurav Sharma (Borealis
AI) for his comments on a draft of the paper.
References
Abel, D., Arumugam, D., Lehnert, L., and Littman, M. L.
State abstractions for lifelong reinforcement learning. In",N/A,N/A
"Proceedings of the 35th International Conference on Ma-
Some Insights into Lifelong Reinforcement Learning Systems
chine Learning, ICML 2018, Stockholmsm¨assan, Stock-
holm, Sweden, July 10-15, 2018, pp. 10–19, 2018.
Dietterich, T. G. Hierarchical reinforcement learning with
the MAXQ value function decomposition. J. Artif. Intell.
Res., 13:227–303, 2000.
Icarte, R. T., Klassen, T. Q., Valenzano, R. A., and McIl-
raith, S. A. Using reward machines for high-level task",N/A,N/A
"speciﬁcation and decomposition in reinforcement learn-
ing. In Proceedings of the 35th International Conference
on Machine Learning, ICML 2018, Stockholmsm¨assan,
Stockholm, Sweden, July 10-15, 2018, pp. 2112–2121,
2018.
Parr, R. and Russell, S. J. Reinforcement learning with
hierarchies of machines. In Advances in Neural Informa-
tion Processing Systems 10, [NIPS Conference, Denver,
Colorado, USA, 1997], pp. 1043–1049, 1997.
Ring, M. B. Child: A ﬁrst step towards continual learning.",N/A,N/A
"In Learning to Learn, pp. 261–292. 1998. doi: 10.1007/
978-1-4615-5529-2\ 11. URL https://doi.org/
10.1007/978-1-4615-5529-2_11.
Singh, S. P., Barto, A. G., and Chentanez, N. Intrinsically
motivated reinforcement learning. In Advances in Neural
Information Processing Systems 17 [Neural Information
Processing Systems, NIPS 2004, December 13-18, 2004,
Vancouver, British Columbia, Canada], pp. 1281–1288,
2004.
Sutton, R. S. and Barto, A. G. Reinforcement Learning: An",N/A,N/A
"Introduction. The MIT Press, second edition, 2018.
Sutton, R. S., Precup, D., and Singh, S. P. Between mdps
and semi-mdps: A framework for temporal abstraction in
reinforcement learning. Artif. Intell., 112(1-2):181–211,
1999.
Taylor, M. E. and Stone, P. Transfer learning for reinforce-
ment learning domains: A survey. J. Mach. Learn. Res.,
10:1633–1685, 2009.
Watkins, C. J. C. H. and Dayan, P. Technical note q-learning.
Machine Learning, 8:279–292, 1992.
White, D.",N/A,N/A
"Machine Learning, 8:279–292, 1992.
White, D.
Multi-objective inﬁnite-horizon discounted
markov decision processes. Journal of Mathematical
Analysis and Applications, 89(2):639 – 647, 1982. ISSN
0022-247X.",N/A,N/A
"arXiv:2405.15430v1  [cs.LG]  24 May 2024
Counterexample-Guided Repair of Reinforcement
Learning Systems Using Safety Critics
David Boetius[0000−0002−9071−1695] and Stefan Leue[0000−0002−4259−624X]
University of Konstanz, 78457 Konstanz, Germany
{david.boetius,stefan.leue}@uni-konstanz.de
Abstract. Naïvely trained Deep Reinforcement Learning agents may
fail to satisfy vital safety constraints. To avoid costly retraining, we may",N/A,N/A
"desire to repair a previously trained reinforcement learning agent to ob-
viate unsafe behaviour. We devise a counterexample-guided repair al-
gorithm for repairing reinforcement learning systems leveraging safety
critics. The algorithm jointly repairs a reinforcement learning agent and
a safety critic using gradient-based constrained optimisation.
Keywords: Reinforcement Learning · Safety · Repair.
1
Introduction
Deep Reinforcement Learning is at the core of several recent breakthroughs in",N/A,N/A
"AI [13,23,26]. With the increasing abilities of reinforcement learning agents, it
becomes vital to eﬀectively constrain such agents to avoid harm, particularly
in safety-critical applications. A particularly eﬀective class of constraints are
formal guarantees on the non-occurrence of undesired behaviour (safety). Such
guarantees are obtainable through formal veriﬁcation [22].
Counterexample-guided repair is a successful iterative reﬁnement algorithm",N/A,N/A
"for obtaining formally veriﬁed deep neural networks in supervised learning [6].
The repair algorithm alternates searching counterexamples and modifying the
model under repair to remove counterexamples. A central component of the
algorithm is a function that quantiﬁes the safety of a neural network output. In
reinforcement learning, the safety of an output depends on the interaction with
the environment. Therefore, quantifying the safety of an output is expensive,",N/A,N/A
"making it challenging to apply counterexample-guided repair to reinforcement
learning. To overcome this challenge, we propose to learn a safety critic [5,18,31]
to quantify safety. Since safety critics are themselves imperfect machine learning
models, we propose to repair the safety critic alongside the actual reinforcement
learning agent.
In the spirit of actor-critic reinforcement learning algorithms [33], a safety",N/A,N/A
"critic learns to predict the safety of a state from gathered experience [5]. The
idea of safety critics is analogous to the widely used [24,29] concept of value
critics that learn to predict the value of a state from experience. We can use
recorded unsafe trajectories, coupled with safe trajectories, as a starting point
2
D. Boetius, S. Leue
for learning a safety critic. Since our aim is to repair a reinforcement learning",N/A,N/A
"agent, we can assume that the agent was already found to behave unsafely and,
therefore, unsafe trajectories are available.
When using a safety critic in counterexample-guided repair, it is vital that
the safety critic correctly recognises new counterexamples as unsafe. Otherwise,
counterexample-guided repair can not proceed to repair the reinforcement learn-
ing agent. To achieve this, we propose to iteratively repair the safety critic along-",N/A,N/A
"side the reinforcement learning agent, such that the safety critic correctly recog-
nises newly found counterexamples.
Our approach allows for great generality regarding the environments in which
an agent operates. Similarly, our approach does not restrict the class of safety
speciﬁcations that can be repaired. It solely requires the ability to falsify or verify
the speciﬁcation given an agent and an environment. Even in the absence of a",N/A,N/A
"falsiﬁer or veriﬁer, our approach can be used to repair a reinforcement learning
agent whenever unsafe behaviour is detected.
The following section reviews the literature relevant to this paper. Follow-
ing this, we formally introduce safe reinforcement learning, safety critics, and
counterexample-guided repair. The subsequent section describes our approach
of counterexample-guided repair using safety critics in more detail and rigour.",N/A,N/A
"We conclude with an outlook on future work. This includes an experimental
evaluation.
2
Related Work
Reinforcement learning is the process by which an agent learns to solve a task by
repeatedly interacting with an environment. The agent leans by maximising the
return it receives during the interaction. State-of-the-art algorithms for reinforce-
ment learning include Advantage Actor-Critic (A2C) [24], Asynchronous Ad-
vantage Actor-Critic (A3C) [24], and Proximal Policy Optimisation (PPO) [29].",N/A,N/A
"These algorithms are based on deep neural networks as reinforcement learn-
ing agents. Due to the prevalence of deep neural networks in state-of-the-art
reinforcement learning methods, this paper is primarily concerned with deep
reinforcement learning. However, our approach is not limited to this class of
models.
In safe reinforcement learning, the agent must also respect additional safety
constraints. An overview of safe reinforcement learning is presented in [15].",N/A,N/A
"More recent developments include shielding [1], safe reinforcement learning us-
ing abstract interpretation [20,32], and safe reinforcement learning via safety
critics [5,18,31,39]. In contrast to safe reinforcement learning, the repair of re-
inforcement learning agents is concerned with making an existing reinforcement
agent safe. In this paper, we apply safety critics to repairing reinforcement learn-
ing agents.
Veriﬁcation of reinforcement learning systems is concerned with proving that",N/A,N/A
"a reinforcement learning agent behaves safely. Recent approaches for reinforce-
Counterexample-Guided Repair using Safety Critics
3
ment learning veriﬁcation build upon reachability analysis [3,19,37] and model
checking [2,3,12]. A survey of the ﬁeld is provided by [22].
In the domain of supervised learning, machine learning models are veriﬁed
using Satisﬁability Modulo Theories (SMT) solving [11,17,21], Mixed Integer
Linear Programming (MILP) [36], and Branch and Bound (BaB) [7,14,38,40].",N/A,N/A
"Many repair algorithms for supervised machine learning models are based on
counterexample-guided repair [6]. The approaches for removing counterexam-
ples range from augmenting the training set [28,34] and constrained optimisa-
tion [4,16] to specialised neural network architectures [8,16]. Non-iterative repair
approaches for neural networks include [30,35].
3
Preliminaries
This section introduces Safe Reinforcement Learning, Safety Critics, Veriﬁca-",N/A,N/A
"tion, Falsiﬁcation, and Repair. While our algorithm’s envisioned target is deep
reinforcement learning agents (neural networks), our approach is not speciﬁc to
a particular model class.
3.1
Safe Reinforcement Learning
Following [5], we adopt a perspective on safe reinforcement learning where un-
safe behaviour may occur during training but not when an agent is deployed.
Our assumption is that we can train the agent to behave safely in a simulation",N/A,N/A
"where unsafe behaviour is inconsequential. A safe reinforcement learning task
is formalised as a Constrained Markov Decision Process (CMDP). We consider
CMDPs with deterministic transitions.
Deﬁnition 1 (CMDP). A Constrained Markov Decision Process (CMDP)
with deterministic transitions is a tuple (S, A, P, R, S0, C), where S is the state
space, A is the set of actions, P : S × A →S is the transition function, R :
S × A →R is the reward, C ⊂S is a set of safe states, and S0 ⊂C is a set of",N/A,N/A
"initial states.
For a ﬁnite time-horizon T ∈N, τ = s0, a0, s1, a1, . . . , sT is a trajectory of
a CMDP if s0 ∈S0 and st = P(st−1, at−1), ∀t ∈{1, . . . , T }.
Deﬁnition 2 (Return). Given a discount factor γ ∈[0, 1], the return G of a
trajectory τ = s0, a0, s1, a1, . . . , sT is
G(τ) =
T −1
X
t=0
γtR(st, at).
Deﬁnition 3 (Safe Trajectories). For a set of safe states C, a trajectory τ =
s0, a0, s1, a1, . . . , sT is safe if s0, s1, . . . , sT ∈C. We write τ ⊨C if τ is safe.
4
D. Boetius, S. Leue",N/A,N/A
"4
D. Boetius, S. Leue
Assuming a uniform distribution U(S0) over the initial states, our goal is to learn
a (deterministic) parametric policy πθ : S →A that maximises the expected
return while maintaining safety
maximise
θ
Es0∼U(S0)[G(τ(s0, πθ))]
subject to
τ(s0, πθ) ⊨C
∀s0 ∈S0,
(1)
where τ(s0, πθ) = s0, a0, s1, a1, . . . , sT is a trajectory with at = πθ(st), ∀t ∈
{0, . . . , T −1}.
A parametric policy may be given, for example, by a neural network netθ :",N/A,N/A
"Rn →A reading a numeric representation of a state xs ∈Rn, n ∈N, s ∈S
and returning an action a ∈A. In this paper, we use the terms policy and agent
interchangeably.
3.2
Safety Critics
Safety critics learn the safety value function V πθ
C
: S →R
V πθ
C (s) =
min
t∈{0,...,T } c(st),
(2)
where s0 = s, st = P(st−1, πθ(st−1)), ∀t ∈{1, . . .T }, and c : S →R is a
satisfaction function [4] or robustness measure [9] for the safe set C.",N/A,N/A
"Deﬁnition 4 (Satisfaction Function). A function c : S →R is a satisfaction
function of a set C ⊆S if ∀s ∈S : c(s) ≥0 ⇔s ∈C.
The concept of a safety critic is analogous to (value) critics in actor-critic rein-
forcement learning [33]. Classical (value) critics learn the value of a state V πθ.
The value is the expected return when starting in a state. Safety critics can be
learned using the methods from [5,31,39].
3.3
Veriﬁcation, Falsiﬁcation, and Repair",N/A,N/A
"3.3
Veriﬁcation, Falsiﬁcation, and Repair
Given a CMDP M = (S, A, P, R, S0, C) and a policy πθ, we are interested in the
question whether the policy guarantees safety for all initial states. A counterex-
ample is an initial state for which following the policy leads to unsafe states.
Deﬁnition 5 (Counterexample). Given a policy πθ, a counterexample is an
initial state s0 ∈S0, such that the trajectory τ = s0, a0, s1, a1, . . . , sT , T ∈N",N/A,N/A
"with at = πθ(st−1), ∀t ∈{1, . . . , T −1} contains an unsafe state st /∈C for
some t ∈{1, . . ., T }.
Since counterexamples lead to unsafe states, the safety value function V πθ
C
of a
counterexample is negative.
When considering algorithms for searching counterexamples, we diﬀerentiate
between falsiﬁers and veriﬁers. While falsiﬁers are sound counterexample-search
algorithms, veriﬁers are sound and complete.
Counterexample-Guided Repair using Safety Critics
5",N/A,N/A
"5
Deﬁnition 6 (Soundness and Completeness). A counterexample-search al-
gorithm is sound if it only produces genuine counterexamples. Additionally, an
algorithm is complete if it terminates and produces a counterexample for every
unsafe policy.
Proposition 1. A policy πθ is safe whenever a veriﬁer does not produce a coun-
terexample for πθ.
Proof. Proposition 1 follows from contraposition on the completeness of veriﬁers.",N/A,N/A
"Given an unsafe policy πθ, the task of repair is to modify the policy to be
safe while maintaining high returns. A successful repair algorithm for supervised
learning is counterexample-guided repair [4,6,34]. The following section intro-
duces a counterexample-guided repair algorithm for reinforcement learning.
4
Counterexample-Guided Repair using Safety Critics
Existing counterexample-guided repair algorithms repair supervised learning",N/A,N/A
"models by alternating counterexample search and counterexample removal. Al-
gorithm 1 describes the algorithmic skeleton of counterexample-guided repair.
This skeleton is akin to all counterexample-guided repair algorithms.
Algorithm 1: Counterexample-Guided Repair
Input: CMDP M = (S, A, P, R, S0, C), Policy πθ
1 Sc ←ﬁnd counterexamples(M, πθ)
2 do
3
θ ←remove counterexamples(Sc, πθ, M)
4
Sc ←Sc ∪ﬁnd counterexamples(M, πθ)
5 while ∃s0 ∈Sc : s0 is counterexample",N/A,N/A
"5 while ∃s0 ∈Sc : s0 is counterexample
When using a veriﬁer to ﬁnd counterexamples, Algorithm 1 is guaranteed
to produce a safe policy if it terminates [6]. However, Algorithm 1 is not gen-
erally guaranteed to terminate [6]. Despite this, counterexample-guided repair
has proven successful in repairing deep neural networks [4] and other machine
learning models [34].
Algorithm 1 has two sub-procedures we need to instantiate for obtaining an",N/A,N/A
"executable algorithm: ﬁnding counterexamples and removing counterexamples.
For ﬁnding counterexamples, we can use tools for verifying reinforcement learn-
ing systems [2,3,12,19,37] (see [22] for a survey). In the remainder of this paper,
we address removing counterexamples using safety critics.
6
D. Boetius, S. Leue
4.1
Removing Counterexamples
Similarly to the supervised setting [6], removing counterexamples corresponds
to solving a constrained optimisation problem
maximise
θ",N/A,N/A
"maximise
θ
Es0∼U(S0)[G(τ(s0, πθ))]
subject to
τ(s0, πθ) ⊨C
∀s0 ∈Sc,
(3)
where τ(s0, πθ) is as in Equation (1) and Sc is a ﬁnite set of counterexamples.
In the supervised setting, we can remove counterexamples by directly solving
the analogue of Equation (3) using gradient-based optimisation algorithms [4].
However, for repairing reinforcement learning policies, checking whether a set of
parameters θ is feasible for Equation (3) is expensive, as it requires simulating",N/A,N/A
"the CMDP. Additionally, the term τ(s0, πθ) ⊨C suﬀers from exploding gradi-
ents [27] due to the repeated application of πθ for obtaining the trajectory. These
properties of Equation (3) hinder the application of gradient-based optimisation
algorithms for removing counterexamples by solving Equation (3) directly.
To obtain an algorithm for removing counterexamples, we ﬁrst note that
Equation (3) can equivalently be reformulated using the safety value function V πθ
C",N/A,N/A
"C
from Equation (2). Concretely, we can replace the constraint τ(s0, πθ) ⊨C
by V πθ
C (s0) > 0. Now, when approximating V πθ
C
using a safety critic eV πθ
C , we
obtain
maximise
θ
Es0∼U(S0)[G(τ(s0, πθ))]
subject to
eV πθ
C (s0) ≥0
∀s0 ∈Sc,
(4)
While Equation (4) is not equivalent to Equation (3) due to using an approxi-
mation of V πθ
C , Equation (4) can be solved using techniques such as stochastic
gradient descent/ascent [10] or the ℓ1 penalty function method [4,25]. To ensure",N/A,N/A
"that solving Equation (4) actually removes counterexamples, we repair the safety
critic eV πθ
C
alongside the policy.
4.2
Repairing Safety Critics
To allow us to remove counterexamples by solving Equation (4), the safety
critic eV πθ
C
needs to correctly recognise the counterexamples in Sc as coun-
terexamples. By recognising a counterexample s0 as a counterexample, we mean
that eV πθ
C (s0) < 0. We can ensure that the safety critic recognises all counterex-
amples in Sc by solving
minimise
θ",N/A,N/A
"amples in Sc by solving
minimise
θ
J(eV πθ
C )
subject to
eV πθ
C (s0) < 0
∀s0 ∈Sc with V πθ
C (s0) < 0,
(5)
where J(eV πθ
C ) is a loss function for training the safety critic [5,31,39]. Solving
Equation (5) can itself be understood as removing counterexamples of the safety
critic. As Equation (4), we can solve Equation (5) using stochastic gradient
descent/ascent [10] or the ℓ1 penalty function method [4,25].
Counterexample-Guided Repair using Safety Critics
7",N/A,N/A
"7
Algorithm 2: Counterexample Removal
Input: CMDP M = (S, A, P, R, S0, C), Unsafe policy πθ, Safety Critic eV πθ
C ,
Counterexamples Sc
1 while ∃s0 ∈Sc : s0 is counterexample do
2
update eV πθ
C
by solving Equation (5)
3
update πθ by solving Equation (4) using eV πθ
C
4.3
Counterexample Removal Algorithm
We propose jointly modifying the safety critic and the unsafe reinforcement
learning agent πθ. Algorithm 2 summarises our approach. We ﬁrst update the",N/A,N/A
"safety critic to recognise the available counterexamples. This corresponds to
solving Equation (5). Using the updated safety critic, we update πθ to remove
the counterexamples by solving Equation (4).
Since the safety critic may fail to recognise a counterexample as a coun-
terexample for the updated policy, we iterate the previous two steps until all
counterexamples are removed.
In principle, this procedure may fail to terminate if the safety-critic “forgets”",N/A,N/A
"to recognise the counterexamples of the initial policy when being updated in the
second iteration of Algorithm 2. Since the policy is updated in the ﬁrst iteration
of Algorithm 2, updating eV πθ
C
in the second iteration does not consider coun-
terexamples for the initial policy. Therefore, the policy may revert to its initial
parameters in the second iteration to evade the updated safety critic. This leads
to an inﬁnite loop. However, this issue can be circumvented by including pre-",N/A,N/A
"vious unsafe trajectories in Equation (5), similarly to how counterexamples are
retained in Algorithm 1 for later iterations to counter reintroducing counterex-
amples.
5
Conclusion
We introduce a counterexample-guided repair algorithm for reinforcement learn-
ing systems. We leverage safety critics to circumvent costly simulations during
counterexample removal. Our approach applies to a wide range of speciﬁcations
and can work with any veriﬁer and falsiﬁer. The central idea of our approach is",N/A,N/A
"to repair the policy and the safety critic jointly.
Future work includes evaluating our algorithm experimentally and comparing
it with abstract-interpretation-based safe reinforcement learning [20,32]. Since
counterexample-guided repair avoids the abstraction error of abstract interpreta-
tion, we expect that counterexample-guided repair can produce less conservative,
safe reinforcement learning agents. Additionally, our ideas are not inherently lim-",N/A,N/A
"ited to reinforcement learning but can be applied whenever satisfaction functions
are unavailable or costly to compute. Exploring such applications is another di-
rection for future research.
8
D. Boetius, S. Leue
Disclosure of Interests. The authors have no competing interests to declare that
are relevant to the content of this article.
References
1. Alshiekh,
M.,
Bloem,
R.,
Ehlers,
R.,
Könighofer,
B.,
Niekum,
S.,
Topcu, U.: Safe
reinforcement
learning via shielding.
In: McIlraith,
S.A.,",N/A,N/A
"learning via shielding.
In: McIlraith,
S.A.,
Weinberger,
K.Q.
(eds.)
AAAI.
pp.
2669–2678.
AAAI
Press
(2018).
https://doi.org/10.1609/AAAI.V32I1.11797
2. Amir,
G.,
Schapira,
M.,
Katz,
G.:
Towards
scalable
veriﬁcation
of
deep
reinforcement
learning.
In:
FMCAD.
pp.
193–203.
IEEE
(2021).
https://doi.org/10.34727/2021/ISBN.978-3-85448-046-4_28
3. Bacci,
E.,
Giacobbe,
M.,
Parker, D.: Verifying reinforcement
learning
up
to
inﬁnity.
In:
Zhou,
Z.
(ed.)
IJCAI.
pp.
2154–2160.
ijcai.org
(2021).",N/A,N/A
"Z.
(ed.)
IJCAI.
pp.
2154–2160.
ijcai.org
(2021).
https://doi.org/10.24963/IJCAI.2021/297
4. Bauer-Marquart, F., Boetius, D., Leue, S., Schilling, C.: SpecRepair: Counter-
Example Guided Safety Repair of Deep Neural Networks. In: Legunsen, O., Rosu,
G. (eds.) SPIN. Lecture Notes in Computer Science, vol. 13255, pp. 79–96. Springer
(2022). https://doi.org/10.1007/978-3-031-15077-7_5
5. Bharadhwaj, H., Kumar, A., Rhinehart, N., Levine, S., Shkurti, F., Garg, A.:",N/A,N/A
"Conservative safety critics for exploration. In: ICLR. OpenReview.net (2021),
https://openreview.net/forum?id=iaO86DUuKi
6. Boetius,
D.,
Leue,
S.,
Sutter,
T.:
A
robust
optimisation
perspective
on
counterexample-guided repair of neural networks. In: Krause, A., Brunskill,
E., Cho, K., Engelhardt, B., Sabato, S., Scarlett, J. (eds.) ICML. Proceed-
ings of Machine Learning Research, vol. 202, pp. 2712–2737. PMLR (2023),
https://proceedings.mlr.press/v202/boetius23a.html",N/A,N/A
"7. Bunel, R., Lu, J., Turkaslan, I., Torr, P.H.S., Kohli, P., Kumar, M.P.: Branch and
Bound for Piecewise Linear Neural Network Veriﬁcation. J. Mach. Learn. Res. 21,
42:1–42:39 (2020), http://jmlr.org/papers/v21/19-468.html
8. Dong,
G.,
Sun,
J.,
Wang,
J.,
Wang,
X.,
Dai,
T.:
Towards
Repair-
ing
Neural
Networks
Correctly.
In:
QRS.
pp.
714–725.
IEEE
(2021).
https://doi.org/10.1109/QRS54544.2021.00081
9. Donzé,
A.,
Maler,
O.:
Robust
satisfaction
of
temporal
logic
over
real-",N/A,N/A
"Robust
satisfaction
of
temporal
logic
over
real-
valued signals. In: Chatterjee, K., Henzinger, T.A. (eds.) FORMATS. Lec-
ture Notes in Computer Science, vol. 6246, pp. 92–106. Springer (2010).
https://doi.org/10.1007/978-3-642-15297-9_9
10. Eban, E., Schain, M., Mackey, A., Gordon, A., Rifkin, R., Elidan, G.: Scalable
Learning of Non-Decomposable Objectives. In: Singh, A., Zhu, X.J. (eds.) AIS-
TATS. Proceedings of Machine Learning Research, vol. 54, pp. 832–840. PMLR",N/A,N/A
"(2017), http://proceedings.mlr.press/v54/eban17a.html
11. Ehlers,
R.:
Formal
Veriﬁcation
of
Piece-Wise
Linear
Feed-Forward
Neu-
ral
Networks.
In:
D’Souza,
D.,
Kumar,
K.N.
(eds.)
ATVA.
Lecture
Notes
in
Computer
Science,
vol.
10482,
pp.
269–286.
Springer
(2017).
https://doi.org/10.1007/978-3-319-68167-2_19
12. Eliyahu, T., Kazak, Y., Katz, G., Schapira, M.: Verifying learning-augmented sys-
tems. In: Kuipers, F.A., Caesar, M.C. (eds.) SIGCOMM. pp. 305–318. ACM (2021).",N/A,N/A
"https://doi.org/10.1145/3452296.3472936
Counterexample-Guided Repair using Safety Critics
9
13. Fawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain,
M.,
Novikov,
A.,
R.
Ruiz,
F.J.,
Schrittwieser,
J.,
Swirszcz,
G.,
Sil-
ver,
D.,
Hassabis,
D.,
Kohli,
P.:
Discovering
faster
matrix
multiplica-
tion algorithms with reinforcement learning. Nat. 610(7930), 47–53 (2022).
https://doi.org/10.1038/s41586-022-05172-4",N/A,N/A
"https://doi.org/10.1038/s41586-022-05172-4
14. Ferrari, C., Mueller, M.N., Jovanović, N., Vechev, M.: Complete Veriﬁcation via
Multi-Neuron Relaxation Guided Branch-and-Bound. In: ICLR. OpenReview.net
(2022), https://openreview.net/forum?id=l_amHf1oaK
15. García,
J.,
Fernández,
F.:
A
comprehensive
survey
on
safe
rein-
forcement
learning.
J.
Mach.
Learn.
Res.
16,
1437–1480
(2015).
https://doi.org/10.5555/2789272.2886795",N/A,N/A
"(2015).
https://doi.org/10.5555/2789272.2886795
16. Guidotti, D., Leofante, F., Pulina, L., Tacchella, A.: Veriﬁcation and Repair
of Neural Networks: A Progress Report on Convolutional Models. In: AI*IA.
Lecture Notes in Computer Science, vol. 11946, pp. 405–417. Springer (2019).
https://doi.org/10.1007/978-3-030-35166-3_29
17. Guidotti, D., Leofante, F., Tacchella, A., Castellini, C.: Improving reliability of
myocontrol using formal veriﬁcation. IEEE Trans. Neural Syst. Rehabilitation Eng.",N/A,N/A
"27(4), 564–571 (2019). https://doi.org/10.1109/TNSRE.2019.2893152
18. Hans,
A.,
Schneegaß,
D.,
Schäfer,
A.M.,
Udluft,
S.:
Safe
explo-
ration
for
reinforcement
learning.
In:
ESANN.
pp.
143–148
(2008),
https://www.esann.org/sites/default/ﬁles/proceedings/legacy/es2008-36.pdf
19. Ivanov, R.,
Weimer,
J.,
Alur,
R.,
Pappas,
G.J.,
Lee,
I.:
Verisig:
verify-
ing
safety
properties
of
hybrid
systems
with
neural
network
controllers.
In:
Ozay,
N.,
Prabhakar,
P.
(eds.)
HSCC.
pp.
169–178.
ACM
(2019).",N/A,N/A
"P.
(eds.)
HSCC.
pp.
169–178.
ACM
(2019).
https://doi.org/10.1145/3302504.3311806
20. Jin, P., Tian, J., Zhi, D., Wen, X., Zhang, M.: Trainify: A CEGAR-Driven Training
and Veriﬁcation Framework for Safe Deep Reinforcement Learning. In: Shoham,
S., Vizel, Y. (eds.) CAV(1). Lecture Notes in Computer Science, vol. 13371, pp.
193–218. Springer (2022). https://doi.org/10.1007/978-3-031-13185-1_10
21. Katz, G., Barrett, C.W., Dill, D.L., Julian, K.D., Kochenderfer, M.J.: Reluplex:",N/A,N/A
"An Eﬃcient SMT Solver for Verifying Deep Neural Networks. In: Majumdar, R.,
Kuncak, V. (eds.) CAV (1). Lecture Notes in Computer Science, vol. 10426, pp.
97–117. Springer (2017). https://doi.org/10.1007/978-3-319-63387-9_5
22. Landers, M., Doryab, A.: Deep reinforcement learning veriﬁcation: A survey. ACM
Comput. Surv. 55(14s), 330:1–330:31 (2023). https://doi.org/10.1145/3596444
23. Mankowitz, D.J., Michi, A., Zhernov, A., Gelmi, M., Selvi, M., Paduraru, C.,",N/A,N/A
"Leurent, E., Iqbal, S., Lespiau, J.B., Ahern, A., Köppe, T., Millikin, K., Gaﬀney,
S., Elster, S., Broshear, J., Gamble, C., Milan, K., Tung, R., Hwang, M., Cemgil,
T., Barekatain, M., Li, Y., Mandhane, A., Hubert, T., Schrittwieser, J., Hassabis,
D., Kohli, P., Riedmiller, M., Vinyals, O., Silver, D.: Faster sorting algorithms
discovered using deep reinforcement learning. Nat. 618(7964), 257–263 (2023).
https://doi.org/10.1038/s41586-023-06004-9",N/A,N/A
"https://doi.org/10.1038/s41586-023-06004-9
24. Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T.P., Harley, T.,
Silver, D., Kavukcuoglu, K.: Asynchronous methods for deep reinforcement
learning.
In:
Balcan,
M.,
Weinberger,
K.Q.
(eds.)
ICML.
JMLR
Work-
shop and Conference Proceedings, vol. 48, pp. 1928–1937. JMLR.org (2016),
http://proceedings.mlr.press/v48/mniha16.html
25. Nocedal, J., Wright, S.J.: Numerical Optimization. Springer, 2 edn. (2006).
https://doi.org/10.1007/b98874",N/A,N/A
"https://doi.org/10.1007/b98874
26. OpenAI: Introducing ChatGPT (2022), https://openai.com/blog/chatgpt, ac-
cessed 14th March 2024
10
D. Boetius, S. Leue
27. Philipp, G., Song, D., Carbonell, J.G.: The exploding gradient problem demys-
tiﬁed - deﬁnition, prevalence, impact, origin, tradeoﬀs, and solutions. CoRR
abs/1712.05577 (2017), http://arxiv.org/abs/1712.05577
28. Pulina, L., Tacchella, A.: An Abstraction-Reﬁnement Approach to Veriﬁcation of",N/A,N/A
"Artiﬁcial Neural Networks. In: CAV. Lecture Notes in Computer Science, vol. 6174,
pp. 243–257. Springer (2010). https://doi.org/10.1007/978-3-642-14295-6_24
29. Schulman,
J.,
Wolski,
F.,
Dhariwal,
P.,
Radford,
A.,
Klimov,
O.:
Prox-
imal
policy
optimization
algorithms.
CoRR
abs/1707.06347
(2017),
http://arxiv.org/abs/1707.06347
30. Sotoudeh, M., Thakur, A.V.: Provable repair of deep neural networks. In: PLDI.
pp. 588–603. ACM (2021). https://doi.org/10.1145/3453483.3454064
31. Srinivasan,
K.,",N/A,N/A
"31. Srinivasan,
K.,
Eysenbach,
B.,
Ha,
S.,
Tan,
J.,
Finn,
C.:
Learning
to
be
safe:
Deep
RL
with
a
safety
critic.
CoRR
abs/2010.14603
(2020),
https://arxiv.org/abs/2010.14603
32. Sun,
X.,
Shoukry,
Y.:
Provably
correct
training
of
neural
network
con-
trollers
using
reachability
analysis.
CoRR
abs/2102.10806
(2021),
https://arxiv.org/abs/2102.10806
33. Sutton, R.S., Barto, A.G.: Reinforcement Learning: An Introduction. Adap-
tive
computation
and
machine
learning,
MIT
Press,
Second
edn. (2018),",N/A,N/A
"machine
learning,
MIT
Press,
Second
edn. (2018),
https://mitpress.mit.edu/9780262039246/reinforcement-learning/
34. Tan, C., Zhu, Y., Guo, C.: Building veriﬁed neural networks with speciﬁcations
for systems. In: Gunawi, H.S., Ma, X. (eds.) APSys. pp. 42–47. ACM (2021).
https://doi.org/10.1145/3476886.3477508
35. Tao,
Z.,
Nawas,
S.,
Mitchell,
J.,
Thakur,
A.V.:
Architecture-preserving
provable
repair
of
deep
neural
networks.
CoRR
abs/2304.03496
(2023).
https://doi.org/10.48550/arXiv.2304.03496",N/A,N/A
"(2023).
https://doi.org/10.48550/arXiv.2304.03496
36. Tjeng, V., Xiao, K.Y., Tedrake, R.: Evaluating Robustness of Neural Networks
with Mixed Integer Programming. In: ICLR (Poster). OpenReview.net (2019),
https://openreview.net/forum?id=HyGIdiRqtm
37. Tran, H., Yang, X., Lopez, D.M., Musau, P., Nguyen, L.V., Xiang, W., Bak,
S., Johnson, T.T.: NNV: The Neural Network Veriﬁcation Tool for Deep
Neural Networks and Learning-Enabled Cyber-Physical Systems. In: CAV (1).",N/A,N/A
"Lecture Notes in Computer Science, vol. 12224, pp. 3–17. Springer (2020).
https://doi.org/10.1007/978-3-030-53288-8_1
38. Wang, S., Zhang, H., Xu, K., Lin, X., Jana, S., Hsieh, C., Kolter, J.Z.: Beta-
CROWN: Eﬃcient Bound Propagation with Per-neuron Split Constraints for
Neural Network Robustness Veriﬁcation. In: Ranzato, M., Beygelzimer, A.,
Dauphin, Y.N., Liang, P., Vaughan, J.W. (eds.) NeurIPS. pp. 29909–29921 (2021),",N/A,N/A
"https://proceedings.neurips.cc/paper/2021/hash/fac7fead96dafceaf80c1daﬀeae82a4-Abstract.html
39. Yang, Q., Simão, T.D., Tindemans, S.H., Spaan, M.T.J.: Safety-constrained rein-
forcement learning with a distributional safety critic. Mach. Learn. 112(3), 859–887
(2023). https://doi.org/10.1007/S10994-022-06187-8
40. Zhang, H., Wang, S., Xu, K., Li, L., Li, B., Jana, S., Hsieh, C., Kolter, J.Z.:
General Cutting Planes for Bound-Propagation-Based Neural Network Veriﬁca-",N/A,N/A
"tion. In: Oh, A.H., Agarwal, A., Belgrave, D., Cho, K. (eds.) NeurIPS (2022),
https://openreview.net/forum?id=5haAJAcofjc",N/A,N/A
"Deep Reinforcement Learning in Computer Vision:
A Comprehensive Survey
Ngan Le∗∗
Vidhiwar Singh Rathour∗
Kashu Yamazaki∗
Khoa Luu
Marios Savvides
August 27, 2021
Abstract
Deep reinforcement learning augments the reinforcement learning framework and
utilizes the powerful representation of deep neural networks. Recent works have demon-
strated the remarkable successes of deep reinforcement learning in various domains in-",N/A,N/A
"cluding ﬁnance, medicine, healthcare, video games, robotics, and computer vision. In
this work, we provide a detailed review of recent and state-of-the-art research advances
of deep reinforcement learning in computer vision. We start with comprehending the
theories of deep learning, reinforcement learning, and deep reinforcement learning. We
then propose a categorization of deep reinforcement learning methodologies and discuss",N/A,N/A
"their advantages and limitations. In particular, we divide deep reinforcement learning
into seven main categories according to their applications in computer vision, i.e. (i)
landmark localization (ii) object detection; (iii) object tracking; (iv) registration on
both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos
analysis; and (vii) other applications. Each of these categories is further analyzed with",N/A,N/A
"reinforcement learning techniques, network design, and performance. Moreover, we
provide a comprehensive analysis of the existing publicly available datasets and exam-
ine source code availability. Finally, we present some open issues and discuss future
research directions on deep reinforcement learning in computer vision.
1
Introduction
Reinforcement learning (RL) is a machine learning technique for learning a sequence of ac-",N/A,N/A
"tions in an interactive environment by trial and error that maximizes the expected reward
[351]. Deep Reinforcement Learning (DRL) is the combination of Reinforcement Learning
and Deep Learning (DL) and it has become one of the most intriguing areas of artiﬁcial intel-
ligence today. DRL can solve a wide range of complex real-world decision-making problems
with human-like intelligence that were previously intractable. DRL was selected by [316],",N/A,N/A
"[106] as one of ten breakthrough techniques in 2013 and 2017, respectively.
The past years have witnessed the rapid development of DRL thanks to its amazing
achievement in solving challenging decision-making problems in the real world. DRL has
1
arXiv:2108.11510v1  [cs.CV]  25 Aug 2021
been successfully applied into many domains including games, robotics, autonomous driving,
healthcare, natural language processing, and computer vision.
In contrast to supervised",N/A,N/A
"In contrast to supervised
learning which requires large labeled training data, DRL samples training data from an
environment. This opens up many machine learning applications where big labeled training
data does not exist.
Far from supervised learning, DRL-based approaches focus on solving sequential decision-
making problems. They aim at deciding, based on a set of experiences collected by interacting
with the environment, the sequence of actions in an uncertain environment to achieve some",N/A,N/A
"targets. Diﬀerent from supervised learning where the feedback is available after each system
action, it is simply a scalar value that may be delayed in time in the DRL framework. For
example, the success or failure of the entire system is reﬂected after a sequence of actions.
Furthermore, the supervised learning model is updated based on the loss/error of the output
and there is no mechanism to get the correct value when it is wrong. This is addressed by",N/A,N/A
"policy gradients in DRL by assigning gradients without a diﬀerentiable loss function. This
aims at teaching a model to try things out randomly and learn to do correct things more.
Many survey papers in the ﬁeld of DRL including [13] [97] [414] have been introduced
recently.
While [13] covers central algorithms in DRL, [97] provides an introduction to
DRL models, algorithms, and techniques, where particular focus is the aspects related to",N/A,N/A
"generalization and how DRL can be used for practical applications. Recently, [414] introduces
a survey, which discusses the broad applications of RL techniques in healthcare domains
ranging from dynamic treatment regimes in chronic diseases and critical care, an automated
medical diagnosis from both unstructured and structured clinical data, to many other control
or scheduling domains that have inﬁltrated many aspects of a healthcare system. Diﬀerent",N/A,N/A
"from the previous work, our survey focuses on how to implement DRL in various computer
vision applications such as landmark detection, object detection, object tracking, image
registration, image segmentation, and video analysis.
Our goal is to provide our readers good knowledge about the principle of RL/DRL and
thorough coverage of the latest examples of how DRL is used for solving computer vision
tasks. We structure the rest of the paper as follows: we ﬁrst introduce fundamentals of",N/A,N/A
"Deep Learning (DL) in section 2 including Multi-Layer Perceptron (MLP), Autoencoder,
Deep Belief Network, Convolutional Neural Networks (CNNs), Recurrent Neural Networks
(RNNs). Then, we present the theories of RL in section 3, which starts with the Markov
Decision Process (MDP) and continues with value function and Q-function. In the end of
section 3, we introduce various techniques in RL under two categories of model-based and",N/A,N/A
"model-free RL. Next, we introduce DRL in section 4 with main techniques in both value-
based methods, policy gradient methods, and actor-critic methods under model-based and
model-free categories. The application of DRL in computer vision will then be introduced
in sections 5, 6, 7, 8, 9, 10, 11 corresponding respectively to DRL in landmark detection,
DRL in object detection, DRL in object tracking, DRL in image registration, DRL in im-",N/A,N/A
"age segmentation, DRL in video analysis and other applications of DRL. Each application
category ﬁrst starts with a problem introduction and then state-of-the-art approaches in the
ﬁeld are discussed and compared through a summary table. We are going to discuss some
2
future perspectives in section 12 including challenges of DRL in computer vision and the
recent advanced techniques.
2
Introduction to Deep Learning
2.1
Multi-Layer Perceptron (MLP)",N/A,N/A
"2.1
Multi-Layer Perceptron (MLP)
Deep learning models, in simple words, are large and deep artiﬁcial neural networks. Let us
consider the simplest possible neural network which is called ”neuron” as illustrated in Fig.
1. A computational model of a single neuron is called a perceptron which consists of one or
more inputs, a processor, and a single output.
o
x0
x1
x2
+1
Figure 1: An example of one neuron which takes input x = [x1, x2, x3], the intercept term
+1 as bias, and the output o.
o
x2
x1",N/A,N/A
"+1 as bias, and the output o.
o
x2
x1
+1
x0
+1
Layer l0
Layer l1
Layer l2
Figure 2: An example of multi-layer perceptron network (MLP)
In this example, the neuron is a computational unit that takes x = [x0, x1, x2] as input,
the intercept term +1 as bias b, and the output o. The goal of this simple network is to
learn a function f : RN →RM where N is the number of dimensions for input x and M is
the number of dimensions for output which is computed as o = f(x, θ), where θ is a set of
3",N/A,N/A
"3
Latent Space
Latent Space
Latent Distribution
Input Layer
Hidden Layer
Hidden Layer
Output Layer
Input Layer
Hidden Layer
Output Layer
(a)
(b)
(c)
(d)
RBM 1
RBM 2
RBM 3
Output
Figure 3: An illustration of various DL architectures. (a): Autoencoder (AE); (b): Deep
Belief Network; (c): Convolutional Neural Network (CNN); (d): Recurrent Neural Network
(RNN).
weights and are known as weights θ = {wi}. Mathematically, the output o of a one neuron
is deﬁned as:
o = f(x, θ) = σ
 N
X
i=1
wixi + b
!",N/A,N/A
"is deﬁned as:
o = f(x, θ) = σ
 N
X
i=1
wixi + b
!
= σ(WTx + b)
(1)
In this equation, σ is the point-wise non-linear activation function. The common non-
linear activation functions for hidden units are hyperbolic tangent (Tanh), sigmoid, softmax,
ReLU, and LeakyReLU. A typical multi-layer perception (MLP) neural network is composed
of one input layer, one output layer, and many hidden layers. Each layer may contain many",N/A,N/A
"units. In this network, x is the input layer, o is the output layer. The middle layer is called
the hidden layer. In Fig. 2(b), MLP contains 3 units of the input layer, 3 units of the hidden
layer, and 1 unit of the output layer.
In general, we consider a MLP neural network with L hidden layers of units, one layer
of input units and one layer of output units. The number of input units is N, output units",N/A,N/A
"is M, and units in hidden layer lth is N l. The weight of the jth unit in layer lth and the ith
unit in layer (l + 1)th is denoted by wl
ij. The activation of the ith unit in layer lth is hl
i.
2.2
Autoencoder
Autoencoder is an unsupervised algorithm used for representation learning, such as feature
selection or dimension reduction. A gentle introduction to Variational Autoencoder (VAE)
is given in [11] and VAE framework is illustrated in Fig.3(a). In general, VAE aims to learn",N/A,N/A
"a parametric latent variable model by maximizing the marginal log-likelihood of the training
data.
2.3
Deep Belief Network
Deep Belief Network (DBN) and Deep Autoencoder are two common unsupervised ap-
proaches that have been used to initialize the network instead of random initialization.
4
Figure 4: Architecture of a typical convolutional network for image classiﬁcation containing
three basic layers: convolution layer, pooling layer and fully connected layer",N/A,N/A
"While Deep Autoencoder is based on Autoencoder, Deep Belief Networks is based on Re-
stricted Boltzmann Machine (RBM), which contains a layer of input data and a layer of
hidden units that learn to represent features that capture high-order correlations in the data
as illustrated in Fig.3(b).
2.4
Convolutional Neural Networks (CNN)
Convolutional Neural Network (CNN) [204] [203] is a special case of fully connected MLP that",N/A,N/A
"implements weight sharing for processing data. CNN uses the spatial correlation of the signal
to utilize the architecture in a more sensible way. Their architecture, somewhat inspired by
the biological visual system, possesses two key properties that make them extremely useful
for image applications: spatially shared weights and spatial pooling. These kinds of networks
learn features that are shift-invariant, i.e., ﬁlters that are useful across the entire image (due",N/A,N/A
"to the fact that image statistics are stationary).
The pooling layers are responsible for
reducing the sensitivity of the output to slight input shifts and distortions, and increasing
the reception ﬁeld for next layers.
Since 2012, one of the most notable results in Deep
Learning is the use of CNN to obtain a remarkable improvement in object recognition in
ImageNet classiﬁcation challenge [72] [187].
A typical CNN is composed of multiple stages, as shown in Fig. 3(c). The output of each",N/A,N/A
"stage is made of a set of 2D arrays called feature maps. Each feature map is the outcome of
one convolutional (and an optional pooling) ﬁlter applied over the full image. A point-wise
non-linear activation function is applied after each convolution. In its more general form, a
CNN can be written as
h0 =x
hl =pooll(σl(wlhl−1 + bl)), ∀l ∈1, 2, ...L
o =hL
(2)
5
where wl, bl are trainable parameters as in MLPs at layer lth. x ∈Rc×h×w is vectorized from",N/A,N/A
"an input image with c being the color channels, h the image height and w the image width.
o ∈Rn×h′×w′ is vectorized from an array of dimension h′ × w′ of output vector (of dimension
n). pooll is a (optional) pooling function at layer lth.
Compared to traditional machine learning methods, CNN has achieved state-of-the-
art performance in many domains including image understanding, video analysis and au-
dio/speech recognition. In image understanding [404], [426], CNN outperforms human ca-",N/A,N/A
"pacities [39]. Video analysis [422], [217] is another application that turns the CNN model
from a detector [374] into a tracker [94]. As a special case of image segmentation [194], [193],
saliency detection is another computer vision application that uses CNN [381], [213]. In addi-
tion to the previous applications, pose estimation [290], [362] is another interesting research
that uses CNN to estimate human-body pose. Action recognition in both still images and",N/A,N/A
"videos is a special case of recognition and is a challenging problem. [110] utilizes CNN-based
representation of contextual information in which the most representative secondary region
within a large number of object proposal regions, together with the contextual features,
is used to describe the primary region. CNN-based action recognition in video sequences
is reviewed in [420]. Text detection and recognition using CNN is the next step of optical",N/A,N/A
"character recognition (OCR) [406] and word spotting [160]. Not only in computer vision,
CNN has been successfully applied into other domains such as speech recognition and speech
synthesis [274], [283], biometrics [242], [85], [281], [350],[304], [261], biomedical [191], [342],
[192], [411].
2.5
Recurrent Neural Networks (RNN)
RNN is an extremely powerful sequence model and was introduced in the early 1990s [172].",N/A,N/A
"A typical RNN contains three parts, namely, sequential input data (xt), hidden state (ht)
and sequential output data (yt) as shown in Fig. 3(d).
RNN makes use of sequential information and performs the same task for every element
of a sequence where the output is dependent on the previous computations. The activation
of the hidden states at time-step t is computed as a function f of the current input symbol",N/A,N/A
"xt and the previous hidden states ht−1. The output at time t is calculated as a function g
of the current hidden state ht as follows
ht = f(Uxt + Wht−1)
yt = g(Vht)
(3)
where U is the input-to-hidden weight matrix, W is the state-to-state recurrent weight
matrix, V is the hidden-to-output weight matrix. f is usually a logistic sigmoid function or
a hyperbolic tangent function and g is deﬁned as a softmax function.
Most works on RNN have made use of the method of backpropagation through time",N/A,N/A
"(BPTT) [318] to train the parameter set (U, V, W) and propagate error backward through
time. In classic backpropagation, the error or loss function is deﬁned as
E(y’, y) =
X
t
||y’t −yt||2
(4)
6
where yt is the prediction and y’t is the labeled groundtruth.
For a speciﬁc weight W, the update rule for gradient descent is deﬁned as Wnew =
W −γ ∂E
∂W, where γ is the learning rate. In RNN model, the gradients of the error with",N/A,N/A
"respect to our parameters U, V and W are learned using Stochastic Gradient Descent
(SGD) and chain rule of diﬀerentiation.
The diﬃculty of training RNN to capture long-term dependencies has been studied in
[26]. To address the issue of learning long-term dependencies, Hochreiter and Schmidhuber
[139] proposed Long Short-Term Memory (LSTM), which can maintain a separate memory
cell inside it that updates and exposes its content only when deemed necessary. Recently, a",N/A,N/A
"Gated Recurrent Unit (GRU) was proposed by [51] to make each recurrent unit adaptively
capture dependencies of diﬀerent time scales. Like the LSTM unit, the GRU has gating units
that modulate the ﬂow of information inside the unit but without having separate memory
cells.
Several variants of RNN have been later introduced and successfully applied to wide
variety of tasks, such as natural language processing [257], [214], speech recognition [115],",N/A,N/A
"[54], machine translation [175], [241], question answering [138], image captioning [247], [78],
and many more.
3
Basics of Reinforcement Learning
This section serves as a brief introduction to the theoretical models and techniques in RL. In
order to provide a quick overview of what constitutes the main components of RL methods,
some fundamental concepts and major theoretical problems are also clariﬁed. RL is a kind",N/A,N/A
"of machine learning method where agents learn the optimal policy by trial and error. Unlike
supervised learning, the feedback is available after each system action, it is simply a scalar
value that may be delayed in time in RL framework, for example, the success or failure of the
entire system is reﬂected after a sequence of actions. Furthermore, the supervised learning
model is updated based on the loss/error of the output and there is no mechanism to get",N/A,N/A
"the correct value when it is wrong. This is addressed by policy gradients in RL by assigning
gradients without a diﬀerentiable loss function which aims at teaching a model to try things
out randomly and learn to do correct things more.
Inspired by behavioral psychology, RL was proposed to address the sequential decision-
making problems which exist in many applications such as games, robotics, healthcare, smart",N/A,N/A
"grids, stock, autonomous driving, etc. Unlike supervised learning where the data is given,
an artiﬁcial agent collects experiences (data) by interacting with its environment in RL
framework. Such experience is then gathered to optimize the cumulative rewards/utilities.
In this section, we focus on how the RL problem can be formalized as an agent that
can make decisions in an environment to optimize some objectives presented under reward",N/A,N/A
"functions. Some key aspects of RL are: (i) Address the sequential decision making; (ii) There
is no supervisor, only a reward presented as scalar number; and (iii) The feedback is highly
delayed. Markov Decision Process (MDP) is a framework that has commonly been used to
solve most RL problems with discrete actions, thus we will ﬁrst discuss MDP in this section.
7
We then introduce value function and how to categorize RL into model-based or model-free",N/A,N/A
"methods. At the end of this section, we discuss some challenges in RL.
Environment
Action
Reward
Observations
Figure 5: An illustration of agent-environment interaction in RL
3.1
Markov Decision Process
The standard theory of RL is deﬁned by a Markov Decision Process (MDP), which is an
extension of the Markov process (also known as the Markov chain). Mathematically, the
Markov process is a discrete-time stochastic process whose conditional probability distribu-",N/A,N/A
"tion of the future states only depends upon the present state and it provides a framework to
model decision-making situations. An MDP is typically deﬁned by ﬁve elements as follows:
• S: a set of state or observation space of an environment. s0 is starting state.
• A: set of actions the agent can choose.
• T: a transition probability function T(st+1|st, at), specifying the probability that the
environment will transition to state st+1 ∈S if the agent takes action at ∈A in state
st ∈S.",N/A,N/A
"st ∈S.
• R: a reward function where rt+1 = R(st, st+1) is a reward received for taking action at
at state st and transfer to the next state st+1.
• γ: a discount factor.
Considering MDP(S, A, γ, T, R), the agent chooses an action at according to the pol-
icy π(at|st) at state st.
Notably, agent’s algorithm for choosing action a given current
state s, which in general can be viewed as distribution π(a|s), is called a policy (strat-",N/A,N/A
"egy). The environment receives the action, produces a reward rt+1 and transfers to the next
state st+1 according to the transition probability T(st+1|st, at). The process continues until
the agent reaches a terminal state or a maximum time step. In RL framework, the tuple
(st, at, rt+1, st+1) is called transition. Several sequential transitions are usually referred to as
8
roll-out. Full sequence (s0, a0, r1, s1, a1, r2, ...) is called a trajectory. Theoretically, trajectory",N/A,N/A
"is inﬁnitely long, but the episodic property holds in most practical cases. One trajectory of
some ﬁnite length τ is called an episode. For given MDP and policy π, the probability of
observing (s0, a0, r1, s1, a1, r2, ...) is called trajectory distribution and is denoted as:
Tπ =
Y
t
π(at|st)T(st+1|st, at)
(5)
The objective of RL is to ﬁnd the optimal policy π∗for the agent that maximizes the cumu-
lative reward, which is called return. For every episode, the return is deﬁned as the weighted",N/A,N/A
"sum of immediate rewards:
R =
τ−1
X
t=0
γtrt+1
(6)
Because the policy induces a trajectory distribution, the expected reward maximization can
be written as:
ETπ
τ−1
X
t=0
rt+1 →max
π
(7)
Thus, given MDP and policy π, the discounted expected reward is deﬁned:
G(π) = ETπ
τ−1
X
t=0
γtrt+1
(8)
The goal of RL is to ﬁnd an optimal policy π∗, which maximizes the discounted expected
reward, i.e. G(π) →maxπ.
3.2
Value and Q- functions",N/A,N/A
"3.2
Value and Q- functions
The value function is applied to evaluate how good it is for an agent to utilize policy π
to visit state s. The concept of ”good” is deﬁned in terms of expected return, i.e. future
rewards that can be expected to receive in the future and it depends on what actions it will
take. Mathematically, the value is the expectation of return, and value approximation is
obtained by Bellman expectation equation as follows:
V π(st) = E[rt+1 + γV π(st+1)]
(9)",N/A,N/A
"V π(st) = E[rt+1 + γV π(st+1)]
(9)
V π(st) is also known as state-value function, and the expectation term can be expanded as
a product of policy, transition probability, and return as follows:
V π(st) =
X
at∈A
π(at|st)
X
st+1∈S
T(st+1|st, at)[R(st, st+1) + γV π(st+1)]
(10)
This equation is called the Bellman equation. When the agent always selects the action
according to the optimal policy π∗that maximizes the value, the Bellman equation can be
9
expressed as follows:
V ∗(st) = max
at
X
st+1∈S",N/A,N/A
"9
expressed as follows:
V ∗(st) = max
at
X
st+1∈S
T(st+1|st, at)[R(st, st+1) + γV ∗(st+1)]
∆= max
at Q∗(st, at)
(11)
However, obtaining optimal value function V ∗does not provide enough information to re-
construct some optimal policy π∗because the real-world environment is complicated. Thus,
a quality function (Q-function) is also called the action-value function under policy π. The
Q-function is used to estimate how good it is for an agent to perform a particular action (at)",N/A,N/A
"in a state (st) with a policy π and it is introduced as:
Qπ(st, at) =
X
st+1
T(st+1|st, at)[R(st, st+1) + γV π(st+1)]
(12)
Unlike value function which speciﬁes the goodness of a state, a Q-function speciﬁes the
goodness of action in a state.
3.3
Category
In general, RL can be divided into either model-free or model-based methods. Here, ”model”
is deﬁned by the two quantity: transition probability function T(st+1|st, at) and the reward
function R(st, st+1).
3.3.1
Model-based RL",N/A,N/A
"function R(st, st+1).
3.3.1
Model-based RL
Model-based RL is an approach that uses a learnt model, i.e.
T(st+1|st, at) and reward
function R(st, st+1) to predict the future action. There are four main model-based techniques
as follows:
• Value Function: The objective of value function methods is to obtain the best policy
by maximizing the value functions in each state. A value function of a RL problem
can be deﬁned as in Eq.10 and the optimal state-value function is given in Eq.11",N/A,N/A
"which are known as Bellman equations. Some common approaches in this group are
Diﬀerential Dynamic Programming [208], [266], Temporal Diﬀerence Learning [249],
Policy Iteration [334] and Monte Carlo [137].
• Transition Models: Transition models decide how to map from a state s, taking
action a to the next state (s’) and it strongly aﬀects the performance of model-based
RL algorithms. Based on whether predicting the future state s’ is based on the proba-",N/A,N/A
"bility distribution of a random variable or not, there are two main approaches in this
group: stochastic and deterministic. Some common methods for deterministic models
are decision trees [280] and linear regression [265]. Some common methods for stochas-
tic models are Gaussian processes [71], [1], [12], Expectation-Maximization [59] and
dynamic Bayesian networks [280].
10
• Policy Search: Policy search approach directly searches for the optimal policy by",N/A,N/A
"modifying its parameters, whereas the value function methods indirectly ﬁnd the ac-
tions that maximize the value function at each state. Some of the popular approaches
in this group are: gradient-based [87], [267], information theory [1], [189] and sampling
based [21].
• Return Functions: Return functions decide how to aggregate rewards or punishments
over an episode. They aﬀect both the convergence and the feasibility of the model.",N/A,N/A
"There are two main approaches in this group: discounted returns functions [21], [75],
[393] and averaged returns functions [34], [3]. Between the two approaches, the former
is the most popular which represents the uncertainty about future rewards. While
small discount factors provide faster convergence, its solution may not be optimal.
In practice, transition and reward functions are rarely known and hard to model.
The",N/A,N/A
"The
comparative performance among all model-based techniques is reported in [385] with over 18
benchmarking environments including noisy environments. The Fig.6 summarizes diﬀerent
model-based RL approaches.
3.3.2
Model-free methods
Learning through the experience gained from interactions with the environment, i.e. model-
free method tries to estimate the t. discrete problems transition probability function and the",N/A,N/A
"reward function from the experience to exploit them in acquisition of policy. Policy gradient
and value-based algorithms are popularly used in model-free methods.
• The policy gradient methods: In this approach, RL task is considered as optimiza-
tion with stochastic ﬁrst-order optimization. Policy gradient methods directly optimize
the discounted expected reward, i.e. G(π) →maxπ to obtains the optimal policy π∗
without any additional information about MDP. To do so, approximate estimations of",N/A,N/A
"the gradient with respect to policy parameters are used. Take [392] as an example,
policy gradient parameterizes the policy and updates parameters θ,
Gθ(π) = ETφ
X
t=0
log(πθ(at|st))γtR
(13)
where R is the total accumulated return and deﬁned in Eq. 6. Common used policies
are Gibbs policies [20], [352] and Gaussian policies [294]. Gibbs policies are used in
discrete problems whereas Gaussian policies are used in continuous problems.",N/A,N/A
"• Value-based methods: In this approach, the optimal policy π∗is implicitly con-
ducted by gaining an approximation of optimal Q-function Q∗(s, a). In value-based
methods, agents update the value function to learn suitable policy while policy-based
RL agents learn the policy directly. To do that, Q-learning is a typical value-based
method. The update rule of Q-learning with learning rate λ is deﬁned as:
Q(st, at) = Q(st, at) + λδt
(14)
11",N/A,N/A
"Q(st, at) = Q(st, at) + λδt
(14)
11
Table 1: Comparison between model-based RL and model-free RL
Factors
Model-based RL
Model-free RL
Number of iterations between
agent and environment
Small
Big
Convergence
Fast
Slow
Prior knowledge of transitions
Yes
No
Flexibility
Strongly depend on
a learnt model
Adjust based
on trials and errors
where δt = R(st, st+1)+γarg maxa Q(st+1, a) −Q(st, a) is the temporal diﬀerence (TD)
error.",N/A,N/A
"error.
Target at self-play Chess, [394] investigates inasmuch it is possible to leverage the
qualitative feedback for learning an evaluation function for the game. [319] provides
the comparison of learning of linear evaluation functions between using preference
learning and using least-squares temporal diﬀerence learning, from samples of game
trajectories. The value-based methods depend on a speciﬁc, optimal policy, thus it is
hard for transfer learning.",N/A,N/A
"hard for transfer learning.
• Actor-critic is an improvement of policy gradient with an value-based critic Γ, thus,
Eq.13 is rewritten as:
Gθ(π) = ETφ
X
t=0
log(πθ(at|st))γtΓt
(15)
The critic function Γ can be deﬁned as Qπ(st, at) or Qπ(st, at) −V π
t
or R[st−1, st] +
V π
t+1 −V π
t
Actor-critic methods are combinations of actor-only methods and critic-only methods. Thus,
actor-critic methods have been commonly used RL. Depend on reward setting, there are two",N/A,N/A
"groups of actor-critic methods, namely discounted return [282], [30] and average return [289],
[31]. The comparison between model-based and model-free methods is given in Table 1.
4
Introduction to Deep Reinforcement Learning
DRL, which was proposed as a combination of RL and DL, has achieved rapid developments,
thanks to the rich context representation of DL. Under DRL, the aforementioned value and
policy can be expressed by neural networks which allow dealing with a continuous state or",N/A,N/A
"action that was hard for a table representation. Similar to RL, DRL can be categorized into
model-based algorithms and model-free algorithms which will be introduced in this section.
4.1
Model-Free Algorithms
There are two approaches, namely, Value-based DRL methods and Policy gradient DRL
methods to implement model-free algorithms.
12
Model-based RL
Value Functions
Diﬀerential Dynamic Programming [208], [266]
Temporal Diﬀerence Learning [249]
Policy Iteration [334]
Monte Carlo [137]",N/A,N/A
"Policy Iteration [334]
Monte Carlo [137]
Transition Models
Deterministic models
Decision trees [280]
Linear regression [265]
Stochastic models
Gaussian processes [71], [1], [12]
Expectation-Maximization [59]
Dynamic Bayesian networks [280]
Policy Search
Gradient-based [87], [267]
Information theory [1], [189]
Sampling based [21]
Return Functions
Discounted returns functions [21], [75], [393]
Averaged returns functions [34], [3]
Figure 6: Summarization of model-based RL approaches
13
4.1.1",N/A,N/A
"13
4.1.1
Value-based DRL methods
Deep Q-Learning Network (DQN): Deep Q-learning [264] (DQN) is the most famous
DRL model which learns policies directly from high-dimensional inputs by CNNs. In DQN,
input is raw pixels and output is a quality function to estimate future rewards as given in
Fig.7. Take regression problem as an instance. Let y denote the target of our regression
task, the regression with input (s, a), target y(s, a) and the MSE loss function is as:",N/A,N/A
"LDQN = L(y(st, at), Q∗(st, at, θt))
= ||y(st, at) −Q∗(st, at, θt)||2
y(st, at) = R(st, st+1) + γ max
at+1 Q∗(st1, at+1, θt)
(16)
Where θ is vector of parameters, θ ∈R|S||R| and st+1 is a sample from T(st+1|st, at) with
input of (st, at).
Minimizing the loss function yields a gradient descent step formula to update θ as follows:
θt+1 = θt −αt
∂LDQN
∂θ
(17)
Figure 7: Network structure of Deep Q-Network (DQN), where Q-values Q(s,a) are generated
for all actions for a given state.",N/A,N/A
"for all actions for a given state.
Double DQN: In DQN, the values of Q∗in many domains were leading to overestimation
because of max. In Eq.16, y(s, a) = R(s, s′) + γ maxa′ Q∗(s′, a′, θ) shifts Q-value estima-
tion towards either to the actions with high reward or to the actions with overestimating
approximation error. Double DQN [370] is an improvement of DQN that combines double
Q-learning [130] with DQN and it aims at reducing observed overestimation with better
14",N/A,N/A
"14
performance. The idea of Double DQN is based on separating action selection and action
evaluation using its own approximation of Q∗as follows:
max
at+1 Q∗(st+1, at+1; θ) = Q∗(st+1, arg max
at+1
Q∗(st+1, at+1; θ1); θ2)
(18)
Thus
y = R(st, st+1) + γQ∗(st+1, arg max
at+1
Q∗(st+1, at+1; θ1); θ2)
(19)
The easiest and most expensive implementation of double DQN is to run two independent
DQNs as follows:
y1 = R(st, st+1)+
γQ∗
1(st+1, arg max
at+1
Q∗
2(st+1, at+1; θ2); θ1)
y2 = R(st, st+1)+
γQ∗",N/A,N/A
"Q∗
2(st+1, at+1; θ2); θ1)
y2 = R(st, st+1)+
γQ∗
2(st+1, arg max
at+1
Q∗
1(st+1, at+1; θ1); θ2)
(20)
Dueling DQN: In DQN, when the agent visits an unfavorable state, instead of lowering its
value V ∗, it remembers only low pay-oﬀby updating Q∗. In order to address this limitation,
Dueling DQN [390] incorporates approximation of V ∗explicitly in a computational graph
by introducing an advantage function as follows:
Aπ(st, at) = Qπ(st, at) −V π(st)
(21)",N/A,N/A
"Aπ(st, at) = Qπ(st, at) −V π(st)
(21)
Therefore, we can reformulate Q-value: Q∗(s, a) = A∗(s, a) + V ∗(s). This implies that after
DL the feature map is decomposed into two parts corresponding to V ∗(v) and A∗(s, a) as
illustrated in Fig.8.
This can be implemented by splitting the fully connected layers in
the DQN architecture to compute the advantage and state value functions separately, then
combining them back into a single Q-function. An interesting result has shown that Dueling",N/A,N/A
"DQN obtains better performance if it is formulated as:
Q∗(st, at) = V ∗(st) + A∗(st, at) −max
at+1 A∗(st, at+1)
(22)
In practical implementation, averaging instead of maximum is used, i.e.
Q∗(st, at) = V ∗(st) + A∗(st, at) −meanat+1A∗(st, at+1)
Furthermore, to address the limitation of memory and imperfect information at each decision
point, Deep Recurrent Q-Network (DRQN) [131] employed RNNs into DQN by replacing",N/A,N/A
"the ﬁrst fully-connected layer with an RNN. Multi-step DQN [68] is one of the most popular
improvements of DQN by substituting one-step approximation with N-steps.
15
Figure 8: Network structure of Dueling DQN, where value function V (s) and advantage
function A(s, a) are combined to predict Q-values Q(s, a) for all actions for a given state.
4.1.2
Policy gradient DRL methods
Policy Gradient Theorem: Diﬀerent from value-based DRL methods, policy gradient",N/A,N/A
"DRL optimizes the policy directly by optimizing the following objective function which is
deﬁned as a function of θ.
G(θ) = ET ∼πθ
X
t=1
γt−1R(st−1, st) →max
θ
(23)
For any MDP and diﬀerentiable policy πθ, the gradient of objective Eq.23 is deﬁned by policy
gradient theorem [353] as follows:
▽θ G(θ) = ET ∼πθ
X
t=0
γtQπ(st, at) ▽θ logπθ(at|st)
(24)
REINFORCE: REINFORCE was introduced by [392] to approximately calculate the gra-",N/A,N/A
"dient in Eq.24 by using Monte-Carlo estimation. In REINFORCE approximate estimator,
Eq.24 is reformulated as:
▽θ G(θ) ≈
N
X
T
X
t=0
γt ▽θ logπθ(at|st)(
X
t′=t
γt′−tR(st′, st′+1))
(25)
where T is trajectory distribution and deﬁned in Eq.5. Theoretically, REINFORCE can be
straightforwardly applied into any parametric πtheta(a|s). However, it is impractical to use
because of its time-consuming nature for convergence and local optimums problem. Based",N/A,N/A
"on the observation that the convergence rate of stochastic gradient descent directly depends
16
on the variance of gradient estimation, the variance reduction technique was proposed to
address naive REINFORCE’s limitations by adding a term that reduces the variance without
aﬀecting the expectation.
4.1.3
Actor-Critic DRL algorithm
Both value-based and policy gradient algorithms have their own pros and cons, i.e. policy",N/A,N/A
"gradient methods are better for continuous and stochastic environments, and have a faster
convergence whereas, value-based methods are more sample eﬃcient and steady. Lately,
actor-critic [182] [262] was born to take advantage from both value-based and policy gradient
while limiting their drawbacks. Actor-critic architecture computes the policy gradient using
a value-based critic function to estimate expected future reward. The principal idea of actor-",N/A,N/A
"critic is to divide the model into two parts: (i) computing an action based on a state and (ii)
producing the Q values of the action. As given in Fig.9, the actor takes as input the state
st and outputs the best action at. It essentially controls how the agent behaves by learning
the optimal policy (policy-based). The critic, on the other hand, evaluates the action by
computing the value function (value-based). The most basic actor-critic method (beyond the",N/A,N/A
"tabular case) is naive policy gradients (REINFORCE). The relationship between actor-critic
is similar to kid-mom. The kid (actor) explores the environment around him/her with new
actions i.e. tough ﬁre, hit a wall, climb a tree, etc while the mom (critic) watches the kid
and criticizes/compliments him/her. The kid then adjusts his/her behavior based on what
his/her mom told. When the kids get older, he/she can realize which action is bad/good.",N/A,N/A
"Figure 9: Flowchart showing the structure of actor critic algorithm.
Advantage Actor-Critic (A2C) Advantage Actor-Critic (A2C) [263] consist of two neural
networks i.e.
actor network πθ(at|st) representing for policy and critic network V π
ω with
parameters ω approximately estimating actor’s performance.
In order to determine how
much better, it is to take a speciﬁc action compared to the average, an advantage value is
17",N/A,N/A
"17
Figure 10: An illustration of Actor-Critic algorithm in two cases: sharing parameters (a)
and not sharing parameters (b).
deﬁned as:
Aπ(st, at) = Qπ(st, at) −V π(st)
(26)
Instead of constructing two neural networks for both the Q value and the V value, using the
Bellman optimization equation, we can rewrite the advantage function as:
Aπ(st, at) = R(st, st+1) + γV π
ω (st+1) −V π
ω (st)
(27)
For given policy π, its value function can be obtained using point iteration for solving:",N/A,N/A
"V π(st) = Eat∼π(at|st)Est+1∼T(st+1|at,st)(R(st, st+1) + γV π(st+1))
(28)
Similar to DQN, on each update a target is computed using current approximation:
y = R(st, st+1) + γV π
ω (st+1)
(29)
At time step t, the A2C algorithm can be implemented as following steps:
• Step 1: Compute advantage function using Eq.27.
• Step 2: Compute target using Eq.29.
• Step 3: Compute critic loss with MSE loss: L =
1
B
P
T ||y −V π(st))||2, where B is
batch size and V π(st) is deﬁned in Eq.28.
18",N/A,N/A
"batch size and V π(st) is deﬁned in Eq.28.
18
• Step 4: Compute critic gradient: ▽critic = ∂L
∂ω.
• Step 5: Compute actor gradient: ▽actor = 1
B
P
T ▽θlogπ(at|st)Aπ(st, at)
Asynchronous Advantage Actor Critic (A3C) Besides A2C, there is another strategy
to implement an Actor-Critic agent.
Asynchronous Advantage Actor-Critic (A3C) [263]
approach does not use experience replay because this requires a lot of memory. Instead, A3C",N/A,N/A
"asynchronously executes diﬀerent agents in parallel on multiple instances of the environment.
Each worker (copy of the network) will update the global network asynchronously. Because
of the asynchronous nature of A3C, some workers (copy of the agents) will work with older
values of the parameters. Thus the aggregating update will not be optimal. On the other
hand, A2C synchronously updates the global network. A2C waits until all workers ﬁnished",N/A,N/A
"their training and calculated their gradients to average them, to update the global network.
In order to update the entire network, A2C waits for each actor to ﬁnish their segment of
experience before updating the global parameters. As a consequence, the training will be
more cohesive and faster. Diﬀerent from A3C, each worker in A2C has the same set of
weights since and A2C updates all their workers at the same time. In short, A2C is an",N/A,N/A
"alternative to the synchronous version of the A3C. In A2C, it waits for each actor to ﬁnish
its segment of experience before updating, averaging over all of the actors. In a practical
experiment, this implementation is more eﬀectively uses GPUs due to larger batch sizes. The
structure of an actor-critic algorithm can be divided into two types depending on parameter
sharing as illustrated in Fig.10.
In order to overcome the limitation of speed, GA3C [16] was proposed and it achieved",N/A,N/A
"a signiﬁcant speedup compared to the original CPU implementation. To more eﬀectively
train A3C, [141] proposed FFE which forces random exploration at the right time during a
training episode, that can lead to improved training performance.
4.2
Model-Based Algorithms
We have discussed so far model-free methods including the value-based approach and pol-
icy gradient approach. In this section, we focus on the model-based approach, that deals",N/A,N/A
"with the dynamics of the environment by learning a transition model that allows for sim-
ulation of the environment without interacting with the environment directly. In contrast
to model-free approaches, model-based approaches are learned from experience by a func-
tion approximation. Theoretically, no speciﬁc prior knowledge is required in model-based
RL/DRL but incorporating prior knowledge can help faster convergence and better-trained",N/A,N/A
"model, speed up training time as well as the number of training samples. While using raw
data with pixel, it is diﬃcult for model-based RL to work on high dimensional and dynamic
environments. This is addressed in DRL by embedding the high-dimensional observations
into a lower-dimensional space using autoencoders [95]. Many DRL approaches have been
based on scaling up prior work in RL to high-dimensional problems. A good overview of",N/A,N/A
"model-based RL for high-dimensional problems can be found in [297] which partition model-
based DRL into three categories: explicit planning on given transitions, explicit planning on
19
learned transitions, and end-to-end learning of both planning and transitions. In general,
DRL targets training DNNs to approximate the optimal policy π∗together with optimal
value functions V ∗and Q∗. In the following, we will cover the most common model-based",N/A,N/A
"DRL approaches including value function and policy search methods.
4.2.1
Value function
We start this category with DQN [264] which has been successfully applied to classic Atari
and illustrated in Fig.7. DQN uses CNNs to deal with high dimensional state space like
pixels, to approximate the Q-value function.
Monte Carlo tree search (MCTS) MCTS [62] is one of the most popular methods to
look-ahead search and it is combined with a DNN-based transition model to build a model-",N/A,N/A
"based DRL in [9]. In this work, the learned transition model predicts the next frame and
the rewards one step ahead using the input of the last four frames of the agent’s ﬁrst-person-
view image and the current action. This model is then used by the Monte Carlo tree search
algorithm to plan the best sequence of actions for the agent to perform.
Value-Targeted Regression (UCRL-VTR) Alex, et al. proposed model-based DRL for",N/A,N/A
"regret minimization [167]. In their work, a set of models, that are ‘consistent’ with the data
collected, is constructed at each episode. The consistency is deﬁned as the total squared
error, whereas the value function is determined by solving the optimistic planning problem
with the constructed set of models
4.2.2
Policy search
Policy search methods aim to directly ﬁnd policies by means of gradient-free or gradient-
based methods.",N/A,N/A
"based methods.
Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) ME-TRPO [190]
is mainly based on Trust Region Policy Optimization (TRPO) [327] which imposes a trust
region constraint on the policy to further stabilize learning.
Model-Based Meta-Policy-Optimization (MB-MPO) MB-MPO [58] addresses the
performance limitation of model-based DRL compared against model-free DRL when learn-
ing dynamics models. MB-MPO learns an ensemble of dynamics models, a policy that can",N/A,N/A
"quickly adapt to any model in the ensemble with one policy gradient step. As a result, the
learned policy exhibits less model bias without the need to behave conservatively.
A summary of both model-based and model-free DRL algorithms is given in Table 2.
In this Table, we also categorized DRL techniques into either on-policy or oﬀ-policy. In
on-policy RL, it allows the use of older samples (collected using the older policies) in the",N/A,N/A
"calculation. The policy πk is updated with data collected by πk itself. In oﬀ-policy RL, the
data is assumed to be composed of diﬀerent policies π0, π0, ..., πk. Each policy has its own
data collection, then the data collected from π0, π1, ..., πk is used to train πk+1.
20
Table 2: Summary of model-based and model-free DRL algorithms consisting of value-based
and policy gradient methods.
DRL Algorithms
Description
Category
DQN [264]
Deep Q Network
Value-based
Oﬀ-policy
Double DQN [370]",N/A,N/A
"Value-based
Oﬀ-policy
Double DQN [370]
Double Deep Q Network
Value-based
Oﬀ-policy
Dueling DQN [390]
Dueling Deep Q Network
Value-based
Oﬀ-policy
MCTS [9]
Monte Carlo tree search
Value-based
On-policy
UCRL-VTR[167]
optimistic planning problem
Value-based
Oﬀ-policy
DDPG [223]
DQN with Deterministic Policy Gradient
Policy gradient
Oﬀ-policy
TRPO [327]
Trust Region Policy Optimization
Policy gradient
On-policy
PPO [328]
Proximal Policy Optimization
Policy gradient
On-policy
ME-TRPO [190]",N/A,N/A
"Policy gradient
On-policy
ME-TRPO [190]
Model-Ensemble Trust-Region Policy Optimization
Policy gradient
On-policy
MB-MPO [58]
Model-Based Meta- Policy-Optimization
Policy gradient
On-policy
A3C [263]
Asynchronous Advantage Actor Critic
Actor Critic
On-Policy
A2C [263]
Advantage Actor Critic
Actor Critic
On-Policy
21
4.3
Good practices
Inspired by Deep Q-learning [264], we discuss some useful techniques that are used during
training an agent in DRL framework in practices.",N/A,N/A
"training an agent in DRL framework in practices.
Experience replay Experience replay [417] is a useful part of oﬀ-policy learning and is
often used while training an agent in RL framework. By getting rid of as much information
as possible from past experiences, it removes the correlations in training data and reduces
the oscillation of the learning procedure. As a result, it enables agents to remember and
re-use past experiences sometimes in many weights updates which increases data eﬃciency.",N/A,N/A
"Minibatch learning Minibatch learning is a common technique that is used together with
experience replay. Minibatch allows learning more than one training sample at each step,
thus, it makes the learning process robust to outliers and noise.
Target Q-network freezing As described in [264], two networks are used for the training
process.
In target Q-network freezing: one network interacts with the environment and",N/A,N/A
"another network plays the role of a target network. The ﬁrst network is used to generate
target Q-values that are used to calculate losses. The weights of the second network i.e.
target network are ﬁxed and slowly updated to the ﬁrst network [224].
Reward clipping A reward is the scalar number provided by the environment and it aims
at optimizing the network. To keep the rewards in a reasonable scale and to ensure proper",N/A,N/A
"learning, they are clipped to a speciﬁc range (-1 ,1). Here 1 refers to as positive reinforcement
or reward and -1 is referred to as negative reinforcement or punishment.
Model-based v.s.
model-free approach Whether the model-free or model-based ap-
proaches is chosen mainly depends on the model architecture i.e. policy and value function.
5
DRL in Landmark Detection
Autonomous landmark detection has gained more and more attention in the past few years.",N/A,N/A
"One of the main reasons for this increased inclination is the rise of automation for evaluating
data. The motivation behind using an algorithm for landmarking instead of a person is that
manual annotation is a time-consuming tedious task and is prone to errors. Many eﬀorts
have been made for the automation of this task. Most of the works that were published for
this task using a machine learning algorithm to solve the problem. [64] proposed a regression",N/A,N/A
"forest-based method for detecting landmark in a full-body CT scan. Although the method
was fast it was less accurate when dealing with large organs. [101] extended the work of [64]
by adding statistical shape priors that were derived from segmentation masks with cascade
regression.
In order to address the limitations of previous works on anatomy detection, [105] re-
formulated the detection problem as a behavior learning task for an artiﬁcial agent using",N/A,N/A
"MDP. By using the capabilities of DRL and scale-space theory [226], the optimal search
strategies for ﬁnding anatomical structures are learned based on the image information at
multiple scales. In their approach, the search starts at the coarsest scale level for capturing
global context and continues to ﬁner scales for capturing more local information. In their
22
RL conﬁguration, the state of the agent at time t, st = I(⃗pt) is deﬁned as an axis-aligned",N/A,N/A
"box of image intensities extracted from the image I and centered at the voxel-position ⃗pt
in image space. An action at allows the agent to move from any voxel position ⃗pt to an
adjacent voxel position ⃗pt+1. The reward function represents distance-based feedback, which
is positive if the agent gets closer to the target structure and negative otherwise. In this
work, a CNN is used to extract deep semantic features. The search starts with the coarsest",N/A,N/A
"scale level M −1, the algorithm tries to maximize the reward which is the change in distance
between ground truth and predicted landmark location before and after the action of moving
the scale window across the image. Upon convergence, the scale level is changed to M −2
and the search continued from the convergence point at scale level M −1. The process is
repeated on the following scales until convergence on the ﬁnest scale. The authors performed",N/A,N/A
"experiments on 3D CT scans and obtained an average accuracy increase of 20-30% and lower
distance error than the other techniques such as SADNN [104] and 3D-DL [427]
Focus on anatomical landmark localization in 3D fetal US images, [10] proposed and
demonstrated use cases of several diﬀerent Deep Q-Network RL models to train agents that
can precisely localize target landmarks in medical scans. In their work, they formulate the",N/A,N/A
"landmark detection problem as an MDP of a goal-oriented agent, where an artiﬁcial agent
is learned to make a sequence of decisions towards the target point of interest. At each time
step, the agent should decide which direction it has to move to ﬁnd the target landmark.
These sequential actions form a learned policy forming a path between the starting point
and the target landmark. This sequential decision-making process is approximated under",N/A,N/A
"RL. In this RL conﬁguration, the environment is deﬁned as a 3D input image, action A is a
set of six actions ax+, ax−, ay+, ay−, az+, az−corresponding to three directions, the state
s is deﬁned as a 3D region of interest (ROI) centered around the target landmark and the
reward is chosen as the diﬀerence between the two Euclidean distances: the previous step
and current step. This reward signiﬁes whether the agent is moving closer to or further away",N/A,N/A
"from the desired target location. In this work, they also proposed a novel ﬁxed- and multi-
scale optimal path search strategy with hierarchical action steps for agent-based landmark
localization frameworks.
Whereas pure policy or value-based methods have been widely used to solve RL-based
localization problems, [7] adopts an actor-critic [262] based direct policy search method
framed in a temporal diﬀerence learning approach. In their work, the state is deﬁned as",N/A,N/A
"a function of the agent-position which allows the agent at any position to observe an m ×
m × 3 block of surrounding voxels.
Similar to other previous work, the action space is
ax+, ax−, ay+, ay−, az+, az−.
The reward is chosen as a simple binary reward function,
where a positive reward is given if an action leads the agent closer to the target landmark,
and a negative reward is given otherwise. Far apart from the previous work, their approach",N/A,N/A
"proposes a non-linear policy function approximator represented by an MLP whereas the value
function approximator is presented by another MLP stacked on top of the same CNN from
the policy net. Both policy (actor) and value (critic) networks are updated by actor-critic
learning. To improve the learning, they introduce a partial policy-based RL to enable solving
the large problem of localization by learning the optimal policy on smaller partial domains.
23",N/A,N/A
"23
The objective of the partial policy is to obtain multiple simple policies on the projections
of the actual action space, where the projected policies can reconstruct the policy on the
original action space.
Based on the hypothesis that the position of all anatomical landmarks is interdependent
and non-random within the human anatomy and this is necessary as the localization of dif-
ferent landmarks requires learning partly heterogeneous policies, [377] concluded that one",N/A,N/A
"landmark can help to deduce the location of others. For collective gain, the agents share
their accumulated knowledge during training. In their approach, the state is deﬁned as RoI
centered around the location of the agent. The reward function is deﬁned as the relative
improvement in Euclidean distance between their location at time t and the target land-
mark location. Each agent is considered as Partially Observable Markov Decision Process",N/A,N/A
"(POMDP) [107] and calculates its individual reward as their policies are disjoint. In or-
der to reduce the computational load in locating multiple landmarks and increase accuracy
through anatomical interdependence, they propose a collaborative multi-agent landmark de-
tection framework (Collab-DQN) where DQN is built upon a CNN. The backbone CNN is
shared across all agents while the policy-making fully connected layers are separate for each
agent.",N/A,N/A
"agent.
Table 3: Comparing various DRL-based landmark detection meth-
ods. The ﬁrst group on Single Landmark Detection (SLD) and the
second group for Multiple Landmark Detection (MLD)
Approaches Year
Training
Tech-
nique
Actions
Remarks
Performance
Datasets
and
source code
SLD [105]
2017
DQN
6 action:
2 per axis
State:
an
axis-
aligned
box
cen-
tered at the voxel-
position.
Action:
move
from
⃗pt
to
⃗pt+1.
Reward:
distance-based
feedback
Average accuracy in-
crease 20-30%. Lower
distance
error",N/A,N/A
"crease 20-30%. Lower
distance
error
than
other techniques such
as SADNN [104] and
3D-DL [427]
3D CT Scan
SLD [10]
2019
DQN,
DDQN,
Duel
DQN
and
Duel
DDQN
6 action:
2 per axis
Environment:
3D
input image. State:
3D
RoI
centered
around
the
target
landmark.
Re-
ward:
Euclidean
distance
between
predicted points and
groundtruth points.
Duel DQN performs
the
best
on
Right
Cerebellum
(FS),
Left Cerebellum (FS,
MS) Duel DDQN is
the
best
on
Right
Cerebellum
(MS)
DQN
performs
the
best on Cavum Sep-
tum",N/A,N/A
"(MS)
DQN
performs
the
best on Cavum Sep-
tum
Pellucidum(FS,
MS)
Fetal head, ul-
trasound
scans
[219].
Available code
24
SLD [7]
2019
Actor-
Critic
-based
Partial
-Policy
RL
6 action:
2 per axis
State: a function of
the
agent-position.
Reward:
binary
reward
function.
policy
function:
MLP.
value
func-
tion: MLP
Faster
and
better
convergence,
out-
performs than other
conventional
actor-
critic and Q-learning
CT
volumes:
Aortic
valve.
CT
volumes:
LAA
seed-
point.
MR
images:
Ver-
tebra
centers
[42].",N/A,N/A
"seed-
point.
MR
images:
Ver-
tebra
centers
[42].
MLD
[377]
2019
Collab
DQN
6 action:
2 per axis
State:
RoI centred
around
the
agent.
Reward:
relative
improvement
in
Euclidean distance.
Each
Agent
is
a
POMDP
has
its
own reward. Collab-
DQN:
reduce
the
computational load
Colab DQN got bet-
ter results than su-
pervised
CNN
and
DQN
Brain
MRI
landmark [158],
Cardiac
MRI
landmark
[70],
Fetal
brain
landmark [10].
Available code
MLD
[161]
2020
DQN
6 action 2
per axis
State:
3D
image
patch. Reward: Eu-",N/A,N/A
"per axis
State:
3D
image
patch. Reward: Eu-
clidean distance and
∈[−1, 1]. Backbone
CNN is share among
agents
Each
agent
has it own Fully con-
nected layer
Detection
error
in-
creased as the degree
of
missing
informa-
tion increased Perfor-
mance is aﬀected by
the choice of land-
marks
3D
Head
MR
images
Diﬀerent from the previous works on RL-based landmark detection, which detect a single
landmark,[161] proposed a multiple landmark detection approach to better time-eﬃcient and",N/A,N/A
"more robust to missing data. In their approach, each landmark is guided by one agent. The
MDP is models as follows: The state is deﬁned as a 3D image patch. The reward, clipped in
[-1, +1], is deﬁned as the diﬀerence in the Euclidean distance between the landmark predicted
in the previous time step and the target, and in the landmark predicted in the current time
step and the target. The action space is deﬁned as in other previous works i.e. there are 6",N/A,N/A
"actions ax+, ax−, ay+, ay−, az+, az−in the action space. To enable the agents to share the
information learned by detecting one landmark for use in detecting other landmarks, hard
parameter sharing from multi-task learning is used. In this work, the backbone network is
shared among agents and each agent has its own fully connected layer.
Table 3 summarizes and compares all approaches for DRL in landmark detection, and",N/A,N/A
"a basic implementation of landmark detection using DRL has been shown in Fig. 11. The
ﬁgure illustrates a general implementation of landmark detection with the help of DRL, where
the state is the Region of interest (ROI) around the current landmark location cropped from
the image, The actions performed by the DRL agent are responsible for shifting the ROI
across the image forming a new state and the reward corresponds to the improvement in
25",N/A,N/A
"25
euclidean distance between ground truth and predicted landmark location with iterations as
used by [105],[7],[10],[377],[161].
Figure 11: DRL implementation for landmark detection, The red point corresponds to the
current landmark location and Red box is the Region of Interest (ROI) centered around the
landmark, the actions of DRL agent shift the ROI across the image to maximize the re-
ward corresponding to the improvement in distance between the ground truth and predicted",N/A,N/A
"landmark location.
6
DRL in Object Detection
Object detection is a task that requires the algorithm to ﬁnd bounding boxes for all objects
in a given image. Many attempts have been made towards object detection. A method for
bounding box prediction for object detection was proposed by [109], in which the task was
performed by extracting region proposals from an image and then feeding each of them to
a CNN to classify each region. An improvement to this technique was proposed by [108],",N/A,N/A
"where they used the feature from the CNN to propose region proposals instead of the image
itself, this resulted in fast detection. Further improvement was proposed by [309], where the
authors proposed using a region proposal network (RPN) to identify the region of interest,
resulting in much faster detection. Other attempts including focal loss [225] and Fast YOLO
[332] have been proposed to address the imbalanced data problem in object detection with",N/A,N/A
"focal loss [225], and perform object detection in video on embedded devices in a real-time
manner [332].
Considering MDP as the framework for solving the problem, [43] used DRL for active
object localization. The authors considered 8 diﬀerent actions (up, down, left, right, bigger,
smaller, fatter, taller) to improve the ﬁt of the bounding box around the object and additional
action to trigger the goal state. They used a tuple of feature vector and history of actions",N/A,N/A
"for state and change in IOU across actions as a reward.
26
An improvement to [43] was proposed by [25], where the authors used a hierarchical
approach for object detection by treating the problem of object detection as an MDP. In
their method, the agent was responsible to ﬁnd a region of interest in the image and then
reducing the region of interest to ﬁnd smaller regions from the previously selected region and",N/A,N/A
"hence forming a hierarchy. For the reward function, they used the change in Intersection over
union (IOU) across the actions and used DQN as the agent. As described in their paper, two
networks namely, Image-zooms and Pool45-crops with VGG-16 [340] backbone were used to
extract the feature information that formed the state for DQN along with a memory vector
of the last four actions.
Using a sequential search strategy, [251] proposed a method for object detection using",N/A,N/A
"DRL. The authors trained the model with a set of image regions where at each time step
the agent returned ﬁxate actions that speciﬁed a location in image for actor to explore next
and the terminal state was speciﬁed by done action. The state consisted of a tuple three
elements: the observed region history Ht, selected evidence region history Et and ﬁxate
history Ft. The fixate action was also a tuple of three elements: fixate action, index of",N/A,N/A
"evidence region et and image coordinate of next ﬁxate zt. The done action consisted of: done
action, index of region representing the detected output bt and the detection conﬁdence ct.
The authors deﬁned the reward function that was sensitive to the detection location, the
conﬁdence at the ﬁnal state and incurs a penalty for each region evaluation.
To map the inter-dependencies among the diﬀerent objects, [170] proposed a tree-structured",N/A,N/A
"RL agent (Tree-RL) for object localization by considering the problem as an MDP. The au-
thors in their implementation considered actions of two types: translation and scaling, where
the scaling consisted of ﬁve actions whereas translation consisted of eight actions. In the
speciﬁed work, the authors used the state as a concatenation of the feature vector of the
current window, feature vector of the whole image, and history of taken actions. The feature",N/A,N/A
"vector were extracted from an ImageNet [72] [320] trained VGG-16 [340] model and for re-
ward the change in IOU across an action was used. Tree-RL utilized a top-down tress search
starting from the whole image where each window recursively takes the best action from
each action group which further gives two new windows. This process is repeated recursively
to ﬁnd the object.
The task of breast lesion detection is a challenging yet very important task in the medical",N/A,N/A
"imaging ﬁeld. A DRL method for active lesion detection in the breast was proposed by [246],
where the authors formulated the problem as an MDP. In their formulation, a total of nine
actions consisting of 6 translation actions, 2 scaling actions, and 1 trigger action were used.
In the speciﬁed work, the change in dice coeﬃcient across an action was used as the reward for
scaling and translation actions, and for trigger action, the reward was +η for dice coeﬃcient",N/A,N/A
"greater than rw and −η otherwise, where η and rw were the hyperparameters chosen by the
authors. For network structure, ResNet [133] was used as the backbone and DQN as the
agent.
Diﬀerent from the previous methods, [386] proposed a method for multitask learning using
DRL for object localization. The authors considered the problem as an MDP where the agent
was responsible to perform a series of transformations on the bounding box using a series
27",N/A,N/A
"27
of actions. Utilizing an RL framework the states consisted of feature vector and historical
actions concatenated together, and a total of 8 actions for Bounding box transformation
(left, right, up, down, bigger, smaller, fatter, and taller) were used. For reward the authors
used the change in IOU between actions, the reward being 0 for an increase in IOU and -1
otherwise. For terminal action, however, the reward was 8 for IOU greater than 0.5 and -8",N/A,N/A
"otherwise. The authors in the paper used DQN with multitask learning for localization and
divided terminal action and 8 transformation actions into two networks and trained them
together.
An improvement for the Region proposal networks that greedily select the ROIs was
proposed by [295], where they used RL for the task.
The authors in this paper used a
two-stage detector similar to Fast and Faster R-CNN But used RL for the decision-making",N/A,N/A
"Process. For the reward, they used the normalized change in Intersection over Union (IOU).
Instead of learning a policy from a large set of data, [15] proposed a method for bounding
box reﬁnement (BAR) using RL. In the paper, once the authors have an inaccurate bounding
box that is predicted by some algorithm they use the BAR algorithm to predict a series of
actions for reﬁnement of a bounding box. They considered a total of 8 actions (up, down,",N/A,N/A
"left, right, wider, taller, fatter, thinner) for bounding box transformation and considered
the problem as a sequential decision-making problem (SDMP). They proposed an oﬄine
method called BAR-DRL and an online method called BAR-CB where training is done on
every image. In BAR-DRL the authors trained a DQN over the states which consisted of
features extracted from ResNet50 [133] [354] pretrained on ImageNet [72] [320] and a history",N/A,N/A
"vector of 10 actions. The Reward for BAR-DRL was 1 if the IOU increase after action and -3
otherwise. For BAR-CB they adapted the LinUCB [216] algorithm for an episodic scenario
and considered The Histogram of Oriented Gradients (HOG) for the state to capture the
outline and edges of the object of interest. The actions in the online method (BAR-CB) were
the same as the oﬄine method and the reward was 1 for increasing IOU and 0 otherwise.",N/A,N/A
"For both the implementations, the authors considered β as terminal IOU.
An improvement to sequential search strategy by [251] was proposed by [367], where
they used a framework consisting of two modules, Coarse and ﬁne level search. According to
the authors, this method is eﬃcient for object detection in large images (dimensions larger
than 3000 pixels). The authors ﬁrst performed a course level search on a large image to",N/A,N/A
"ﬁnd a set of patches that are used by ﬁne level search to ﬁnd sub-patches. Both ﬁne and
coarse levels were conducted using a two-step episodic MDP, where The policy network
was responsible for returning the probability distribution of all actions. In the paper, the
authors considered the actions to be the binary action array (0,1) where 1 means that the
agent would consider acquiring sub-patches for that particular patch. The authors in their",N/A,N/A
"implementation considered a number of patches and sub-patches as 16 and 4 respectively
and used the linear combination of Racc (detection recall) and Rcost which combines image
acquisition cost and run-time performance reward.
Table 4: Comparing various DRL-based object detection methods
28
Approaches
Year Training
Tech-
nique
Actions
Remarks
Backbone Performance
Datasets and
source code
Active
Object
Local-
ization
[43]
2015 DQN
8
ac-
tions: up,
down,
left,
right,
bigger,
smaller,
fatter,",N/A,N/A
"down,
left,
right,
bigger,
smaller,
fatter,
taller
States:
feature
vector
of
ob-
served
region
and
action
his-
tory.
Reward:
Change in IOU.
5 layer
pre-
trained
CNN
Higher
mAP
as compared to
methods that did
not
use
region
proposals
like
MultiBox
[89],
RegionLets [433],
DetNet
[356],
and second best
mAP
as
com-
pared to R-CNN
[109]
Pascal VOC-
2007
[90],
2012 [91] Im-
age Dataset.
Hierarchical
Object
Detection
[25]
2016 DQN
5 actions:
1
action
per image
quarter
and
1
at
the
center
States:",N/A,N/A
"per image
quarter
and
1
at
the
center
States:
current
region and mem-
ory vector using
Image-zooms
and
Pool45-
crops.
Reward:
change in IOU.
VGG-
16
[340]
Objects detected
with
very
few
region proposals
per image
Pascal VOC-
2007
Image
Dataset [90].
Available Code
Visual Ob-
ject Detec-
tion [251]
2016 Policy
sam-
pling
and
state
tran-
sition
algo-
rithm
2 actions:
ﬁxate
and done,
where
each is a
tuple
of
three.
States: Observed
region
history,
evidence
region
history
and
ﬁxate
history.
Reward:",N/A,N/A
"region
history
and
ﬁxate
history.
Reward:
sensi-
tive to detection
location
Deep
NN
[187]
Comparable
mAP and lower
run time as com-
pared
to
other
methods
such
as to exhaustive
sliding
window
search(SW),
ex-
haustive
search
over the CPMC
and region pro-
posal
set(RP)
[112] [366]
Pascal
VOC
2012
Object
detection
challenge [91].
Tree-
Structured
Sequential
Object Lo-
calization
(Tree-RL)
[170]
2016 DQN
13
ac-
tions:
8
transla-
tion,
5
scaling.
States:
Feature
vector
of
cur-
rent region, and
whole",N/A,N/A
"Feature
vector
of
cur-
rent region, and
whole
image.
Reward:
change
in IOU.
CNN
trained
on Im-
ageNet
[72]
[320]
Tree-RL
with
faster
R-CNN
outperformed
RPN
with
fast
R-CNN
[108]
in terms of AP
and
comparable
results to Faster
R-CNN [309]
Pascal
VOC
2007 [90] and
2012 [91].
29
Active
Breast
Lesion
Detection
[246]
2017 DQN
9 actions:
6
trans-
lation,
2
scaling, 1
trigger
States:
feature
vector of current
region,
Reward:
improvement
in
localization.
ResNet
[133]
Comparable true
positive
and
false",N/A,N/A
"ResNet
[133]
Comparable true
positive
and
false
positive
proportions
as
compared
to
SL
[253]
and
Ms-C [116], but
with lesser mean
inference time.
DCE-MRI
and
T1-
weighted
anatomical
dataset [253]
Multitask
object
lo-
calization
[386]
2018 DQN
8 actions:
left,
right, up,
down,
bigger,
smaller,
fatter
and taller
States:
feature
vector, historical
actions. Reward:
change in IOU.
diﬀerent network
for
transforma-
tion actions and
terminal actions.
Pretrained
VGG-
16
[340]
with
Ima-
geNet
[72]
[320]",N/A,N/A
"VGG-
16
[340]
with
Ima-
geNet
[72]
[320]
Better mAP as
compared
to
MultiBox
[89],
Caicedo
et
al.
[43] and second
best to R-CNN
[109].
Pascal VOC-
2007
Image
Dataset [90].
Bounding-
Box
Au-
tomated
Reﬁne-
ment
[15]
2020 DQN
8
ac-
tions: up,
down,
left,
right,
bigger,
smaller,
fatter,
taller
Oﬄine
and
online implemen-
tation
States:
feature
vector
for oﬄine (BAR-
DRL), HOG for
online
(BAR-
CB).
Reward:
change in IOU
ResNet50
[133]
Better ﬁnal IOU
for boxes gener-
ated
by
meth-
ods such as Reti-",N/A,N/A
"for boxes gener-
ated
by
meth-
ods such as Reti-
naNet [225].
Pascal VOC-
2007
[90],
2012 [91] Im-
age Dataset.
Eﬃcient
Object
Detection
in
Large
Images
[367]
2020 DQN
binary
action
array:
where
1
means
that
the
agent
would
consider
acquiring
sub-
patches
for
that
par-
ticular
patch
Course
CPNet
and ﬁne FPNet
level
search.
States:
selected
region.
Reward:
detection
recall
image
acquisi-
tion cost. Policy:
REINFORCE
[351]
ResNet32
[133]
for
policy
net-
work.
and
YOLOv3
[306]
with
DarkNet-
53
for",N/A,N/A
"net-
work.
and
YOLOv3
[306]
with
DarkNet-
53
for
Object
detec-
tor
Higher mAP and
lower
run
time
as compared to
other
methods
such as [99].
Caltech
Pedestrian
dataset
(CPD) [77]
Available Code
30
Organ Lo-
calization
in
CT
[275]
2020 DQN
11
ac-
tions:
6
transla-
tion,
2
scaling, 3
deforma-
tion
States: region in-
side the Bound-
ing box. Reward:
change in IOU.
Architecture
similar
to [10]
Lower
distance
error
for
organ
localization
and
run time as com-
pared
to
other
methods such as
3D-RCNN",N/A,N/A
"pared
to
other
methods such as
3D-RCNN
[409]
and CNNs [152]
CT
scans
from
the
VISCERAL
dataset [171]
Monocular
3D Object
Detection
[231]
2020 DQN
[264]
15
ac-
tions,
each
modiﬁes
the
3D
bounding
box in a
speciﬁc
parame-
ter
State:
3D
bounding
box
parameters,
2D
image
of
ob-
ject
cropped
by
2D
its
de-
tected bounding
box.
Reward:
accuracy
im-
provement
after
applying
an
action.
ResNet-
101
[133]
Higher
average
precision
(AP)
compared
to
[268], [302], [210]
and [35]
KITTI [102]",N/A,N/A
"to
[268], [302], [210]
and [35]
KITTI [102]
Localization of organs in CT scans is an important pre-processing requirement for taking
the images of an organ, planning radiotherapy, etc. A DRL method for organ localization was
proposed by [275], where the problem was formulated as an MDP. In the implementation,
the agent was responsible for predicting a 3D bounding box around the organ. The authors
used the last 4 states as input to the agent to stabilize the search and the action space",N/A,N/A
"consists of Eleven actions, 6 for the position of the bounding box, 2 for zoom in and zoom
out the action, and last 3 for height, width, and depth. For Reward, they used the change
the in Intersection over union (IOU) across an action.
Monocular 3D object detection is a problem where 3D bounding boxes of objects are
required to be detected from a single 2D image. Even the sampling-based method is the
SOTA approach, it has a huge ﬂaw, in which most of the samples it generates do not",N/A,N/A
"overlap with the groundtruth. To leverage that method, [231] introduced Reinforced Axial
Reﬁnement Network (RARN) for monocular 3D object detection by utilizing an RL model to
iteratively reﬁning the sampled bounding box to be more overlapped with the groundtruth
bounding box. Given a state having the coordinates of the 3D bounding box and image
patch of the image, the model predicts an action out of a set of 15 actions to reﬁne one of",N/A,N/A
"the bounding box coordinates in a direction at every timestep, the model is trained by DQN
method with the immediate reward is the improvement in detection accuracy between every
pair of timesteps. The whole pipeline, namely RAR-Net, was evaluated on the real-world
KITTI dataset [102] and achieved state-of-the-art performance.
All these methods have been summarised and compared in Table 4, and a basic imple-",N/A,N/A
"mentation of object detection using DRL has been shown in Fig. 12. The ﬁgure illustrates
a general implementation of object detection using DRL, where the state is an image seg-
ment cropped using a bounding box produced by some other algorithm or previous iteration
of DRL, actions predicted by the DRL agent predict a series of bounding box transforma-
31
tion to ﬁt the object better, hence forming a new state and Reward is the improvement in",N/A,N/A
"Intersection over union (IOU) with iterations as used by [43],[25],[15],[386],[170],[275].
Figure 12: DRL implementation for object detection.
The red box corresponds to the
initial bounding box which for t=0 is predicted by some other algorithm or the transformed
bounding box by previous iterations of DRL using the actions to maximize the improvement
in IOU.
7
DRL in Object Tracking
Real-time object tracking has a large number of applications in the ﬁeld of autonomous",N/A,N/A
"driving, robotics, security, and even in sports where the umpire needs accurate estimation of
ball movement to make decisions. Object tracking can be divided into two main categories:
Single object tracking (SOT) and Multiple object tracking (MOT).
Many attempts have been made for both SOT and MOT. SOT can be divided into two
types, active and passive. In passive tracking it is assumed that the object that is being",N/A,N/A
"tracked is always in the camera frame, hence camera movement is not required. In active
tracking, however, the decision to move the camera frame is required so that the object is
always in the frame. Passive tracking has been performed by [397], [146], where [146] per-
formed tracking for both single and multiple objects. The authors of these papers proposed
various solutions to overcome common problems such as a change in lighting and occlusion.",N/A,N/A
"Active tracking is a little bit harder as compared to a passive one because additional deci-
sions are required for camera movement. Some eﬀorts towards active tracking include [74]
[270] [178]. These solutions treat object detection and object tracking as two separate tasks
and tend to fail when there is background noise.
An end-to-end active object tracker using DRL was proposed by [240], where the authors
used CNNs along with an LSTM [139] in their implementation. They used the actor-critic",N/A,N/A
"algorithm [262] to calculate the probability distribution of diﬀerent actions and the value
32
of state and used the object orientation and distance from the camera to calculate rewards.
For experiments, the authors used VizDoom and Unreal Engine as the environment.
Another end-to-end method for SOT using sequential search strategy and DRL was
proposed by [418].
The method included using an RNN along with REINFORCE [392]",N/A,N/A
"algorithm to train the network. The authors used a function f(W0) that takes in St and
frame as input, where St is the object location for the ﬁrst frame and is zero elsewhere. The
output is fed to an LSTM module [139] with past hidden state ht. The authors calculated the
reward function by using insertion over union (IoU) and the diﬀerence between the average
and max.
A deformable face tracking method that could predict bounding box along with facial",N/A,N/A
"landmarks in real-time was proposed by [118].
The dual-agent DRL method (DADRL)
mentioned in the paper consisted of two agents: a tracking and an alignment agent. The
problem of object tracking was formulated as an MDP where state consisted of image regions
extracted by the bounding box and a total of 8 actions (left, right, up, down, scale-up, scale
down, stop and continue) were used, where ﬁrst six consists of movement actions used by
tracking agent and last two for alignment agent.",N/A,N/A
"tracking agent and last two for alignment agent.
The tracking agent is responsible for
changing the current observable region and the alignment agent determines whether the
iteration should be terminated.
For the tracking agent, the reward corresponded to the
misalignment descent and for the alignment agent the reward was +η for misalignment
less than the threshold and −η otherwise. The DADRL implementation also consisted of",N/A,N/A
"communicated message channels beside the tracking agent and the alignment agent. The
tracking agent consisted of a VGG-M [340] backbone followed by a one-layer Q-Network
and the alignment agent was designed as a combination of a stacked hourglass network
with a conﬁdence network. The two communicated message channels were encoded by a
deconvolution layer and an LSTM unit [139] respectively.
Visual object tracking when dealing with deformations and abrupt changes can be a",N/A,N/A
"challenging task. A DRL method for object tracking with iterative shift was proposed by
[308]. The approach (DRL-IS) consisted of three networks: The actor network, the prediction
network, and the critic network, where all three networks shared the same CNN and a fully
connected layer. Given the initial frame and bounding box, the cropped frame is fed to the
CNNs to extract the features to be used as a state by the networks. The actions included",N/A,N/A
"continue, stop and update, stop and ignore, and restart. For continue, the bounding boxes
are adjusted according to the output of the prediction network, for stop and update the
iteration is stopped and the appearance feature of the target is updated according to the
prediction network, for stop and ignore the updating of target appearance feature is ignored
and restart means that the target is lost and the algorithm needs to start from the initial",N/A,N/A
"bounding box. The authors of the paper used reward as 1 for change in IoU greater than
the threshold, 0 for change in IOU between + and - threshold, and -1 otherwise.
Considering the performance of actor-critic framework for various applications, [45] pro-
posed an actor-critic [262] framework for real-time object tracking. The authors of the paper
used a pre-processing function to obtain an image patch using the bounding box that is fed",N/A,N/A
"into the network to ﬁnd the bounding box location in subsequent frames. For actions the
33
authors used △x for relative horizontal translation, △y for relative vertical translation, and
△s for relative scale change, and for a reward they used 1 for IoU greater than a threshold
and -1 otherwise. They proposed oﬄine training and online tracking, where for oﬄine train-
ing a pre-trained VGG-M [340] was used as a backbone, and the actor-critic network was
trained using the DDPG approach [224].",N/A,N/A
"trained using the DDPG approach [224].
An improvement to [45] for SOT was proposed by [84], where a visual tracker was for-
mulated using DRL and an expert demonstrator. The authors treated the problem as an
MDP, where the state consists of two consecutive frames that have been cropped using the
bounding box corresponding to the former frame and used a scaling factor to control the
oﬀset while cropping. The actions consisted of four elements: △x for relative horizontal",N/A,N/A
"translation, △y for relative vertical translation, △w for width scaling, and △h for height
scaling, and the reward was calculated by considering whether the IoU is greater than a
threshold or not. For the agent architecture the authors used a ResNet-18 [133] as backbone
followed by an LSTM unit [391][139] to encode past information, and performed training
based on the on-policy A3C framework [262].
In MOT the algorithm is responsible to track trajectories of multiple objects in the given",N/A,N/A
"video. Many attempts have been made with MOT including [53], [55] and [143]. However,
MOT is a challenging task because of environmental constraints such as crowding or object
overlapping. MOT can be divided into two main techniques: Oﬄine [53] and Online [55]
[143]. In oﬄine batch, tracking is done using a small batch to obtain tracklets and later
all these are connected to obtain a complete trajectory. The online method includes using",N/A,N/A
"present and past frames to calculate the trajectory. Some common methods include Kalman
ﬁltering [177], Particle Filtering [284] or Markov decision [401]. These techniques however
are prone to errors due to environmental constraints.
To overcome the constraints of MOT by previous methods, [401] proposed a method for
MOT where the problem was approached as an MDP. The authors tracked each object in
the frame through the Markov decision process, where each object has four states consisting:",N/A,N/A
"Active, Tracked, Lost, and Inactive.
Object detection is the active state and when the
object is in the lost state for a suﬃcient amount of time it is considered Inactive, which is
the terminal state. The reward function in the implementation was learned through data by
inverse RL problem [279].
Previous approaches for MOT follow a tracking by detection technique that is prone
to errors.
An improvement was proposed by [307], where detection and tracking of the",N/A,N/A
"objects were carried out simultaneously. The authors used a collaborative Q-Network to
track trajectories of multiple objects, given the initial position of an object the algorithm
tracked the trajectory of that object in all subsequent frames. For actions the authors used
△x for relative horizontal translation, △y for relative vertical translation, △w for width
scaling, and △h for height scaling, and the reward consisted of values 1,0,-1 based on the
IoU.",N/A,N/A
"IoU.
Another method for MOT was proposed by [168], where the authors used LSTM [139]
and DRL to approach the problem of multi-object tracking. The method described in the
paper used three basic components: a YOLO V2 [260] object detector, many single object
34
trackers, and a data association module. Firstly the YOLO V2 object detector is used to
ﬁnd objects in a frame, then each detected object goes through the agent which consists of",N/A,N/A
"CNN followed by an LSTM to encode past information for the object. The state consisted
of the image patch and history of past 10 actions, where six actions (right, left, up, down,
scale-up, scale down) were used for bounding box movement across the frame with a stop
action for the terminal state. To provide reinforcement to the agent the reward was 1 if the
IOU is greater than a threshold and 0 otherwise. In their experiments, the authors used",N/A,N/A
"VGG-16 [340] for CNN backbone and performed experiments on MOT benchmark [201] for
people tracking.
Table 5: Comparing various DRL-based object tracking methods.
The First group for Single object tracking (SOT) and the second
group for multi-object tracking (MOT)
Approaches
Year
Training
Tech-
nique
Actions
Remarks
Backbone
Performance
Datasets and
Source code
End
to
end
ac-
tive
object
tracking
[240]
2017
Actor-
Critic
(a3c)
[262]
6 actions:
turn
left, turn
right,
turn
left
and move
forward,",N/A,N/A
"left, turn
right,
turn
left
and move
forward,
turn right
and move
forward,
move
forward,
no-op
Environment:
virtual environ-
ment.
Reward:
calculated
using
object
orientation
and
position.
Tracking Using
LSTM [139]
ConvNet-
LSTM
Higher
ac-
cumulated
reward
and
episode
length
as
compared
to
methods
like
MIL
[17],
Meanshift
[60],
KCF [134].
ViZDoom
[176],
Unreal
Engine
DRL for ob-
ject
track-
ing [418]
2017
DRLT
None
State:
feature
vector, Reward:
change in IOU
use
of
LSTM
[139] and REIN-",N/A,N/A
"change in IOU
use
of
LSTM
[139] and REIN-
FORCE [392]
YOLO
network
[305]
Higher
area
under
curve
(success rate Vs
overlap
thresh-
old),
precision
and speed (fps)
as compared to
STUCK
[126]
and DLT [384].
Object track-
ing
bench-
mark [397].
Available Code
35
Dual-agent
deformable
face tracker
[118]
2018
DQN
8 actions:
left,
right, up,
down,
scale
up, scale
down,
stop and
continue.
States:
image
region
using
Bounding
box.
Reward:
dis-
tance
error.
Facial landmark
detection
and
tracking
using",N/A,N/A
"Facial landmark
detection
and
tracking
using
LSTM [139]
VGG-M
[340]
Lower
normal-
ized
point
to
point error for
landmarks
and
higher
success
rate
for
facial
tracking
as
compared
to
ICCR
[187],
MDM
[336],
Xiao et al [32],
etc.
Large-scale
face
tracking
dataset,
the
300-VW
test
set [336]
Tracking
with
iter-
ative
shift
[308]
2018
Actor-
critic
[262]
4 actions:
continue,
stop and
update,
stop
and
ig-
nore and
restart
States:
im-
age
region
using bounding
box.
Reward:
change in IOU.
Three networks:",N/A,N/A
"box.
Reward:
change in IOU.
Three networks:
actor,
critic
and
prediction
network
3
Layer
CNN and
FC layer
Higher
area
under
curve
for success rate
Vs
overlap
threshold
and
precision
Vs
location
error
threshold
as
compared
to
CREST
[345],
ADNet
[416],
MDNet
[273],
HCFT
[243],
SINT
[358],
DeepSRDCF
[67], and HDT
[301]
OTB-2015
[398], Temple-
Color
[220],
and
VOT-
2016 Dataset
[186]
Tracking
with actor-
critic [45]
2018
Actor-
critic
[262]
3 actions:
△x,
△y
and △s
States:
image
region
using",N/A,N/A
"△x,
△y
and △s
States:
image
region
using
bounding
box.
Reward:
IOU
greater
then
threshold.
Of-
ﬂine
training,
online tracking
VGG-M
[340]
Higher
average
precision
score
then PTAV [93],
CFNet
[368],
ACFN
[52],
SiameFC
[29],
ECO-HC
[67],
etc.
OTB-2013
[397],
OTB-
2015
[398]
and
VOT-
2016
dataset
[186]
Available Code
36
Visual
tracking
and expert
demon-
strator
[84]
2019
Actor-
critic
(a3c)
[262]
4 actions:
△x,
△y,△w
and △h
States:
image
region
using
bounding
box.
Reward: change
in
IOU.
SOT
using",N/A,N/A
"bounding
box.
Reward: change
in
IOU.
SOT
using
LSTM
[391][139]
ResNet-
18 [133]
Comparable
success
and
precision scores
as compared to
LADCF
[408],
SiamRPN [209]
and ECO [66]
GOT-10k
[148], LaSOT
[92], UAV123
[269],
OTB-
100
[397],
VOT-2018
[185]
and
VOT-2019.
Object
tracking
by decision
making
[401]
2015
TLD
Tracker
[174]
7 actions:
corre-
sponding
to
mov-
ing
the
object
between
states
such
as
Active,
tracked,
lost
and
Inactive
States: 4 states:
Active, tracked,
lost
and
Inac-
tive.
Reward:",N/A,N/A
"Active, tracked,
lost
and
Inac-
tive.
Reward:
inverse
RL
problem [279]
None
Comparable
multiple object
tracking
accu-
racy
(MOTA)
and
multiple
object
track-
ing
precision
(MOTP)
[28]
as compared to
DPNMS
[296],
TCODAL
[18],
SegTrack [259],
MotiCon
[200],
etc
M0T15
dataset [201]
Available Code
Collaborative
multi
ob-
ject tracker
[307]
2018
DQN
4 actions:
△x, △y,
△w
and
△h
States:
image
region
using
bounding
box.
Reward:
IOU
greater
then
threshold.
2
networks:
pre-
diction
and
decision
net-
work",N/A,N/A
"2
networks:
pre-
diction
and
decision
net-
work
3
Layer
CNN and
FC Layer
Comparable
multiple object
tracking
accu-
racy
(MOTA)
and
multiple
object
track-
ing
precision
(MOTP)
[28]
as
compared
to SCEA [143],
MDP
[401],
CDADDALpb
[19],
AMIR15
[321]
MOT15 [201]
and
MOT16
[258] datasets
37
Multi
object
tracking in
video [168]
2018
DQN
6 actions:
right,
left,
up,
down,
scale
up, scale
down
States:
image
region
using
bounding
box.
Reward:
IOU
greater
then
threshold.
De-
tection
using
YOLO-V2 [260]",N/A,N/A
"then
threshold.
De-
tection
using
YOLO-V2 [260]
for detector and
LSTM [139] .
VGG-16
[340]
Comparable
if
not
better
multiple object
tracking
accu-
racy
(MOTA)
and
multiple
object
track-
ing
precision
(MOTP)
[28]
as
compared
to RNN-LSTM
[201], LP-SSVM
[401], MDPSub-
CNN [199], and
SiameseCNN
[123]
MOT15
Dataset [201]
Multi agent
multi
ob-
ject tracker
[169]
2019
DQN
9 actions:
move
right,
move left,
move
up, move
down,
scale
up, scale
down,
fatter,
taller and
stop
States:
image
region
using",N/A,N/A
"taller and
stop
States:
image
region
using
bounding
box.
Reward:
IOU
greater
then
threshold.
YOLO-V3 [306]
for
detection
and
LSTM
[139].
VGG-16
[340]
Higher
run-
ning time, and
comparable
if
not
better
multiple object
tracking
accu-
racy
(MOTA)
and
multiple
object
track-
ing
precision
(MOTP)
[28]
as
compared
to RNN-LSTM
[201], LP-SSVM
[401], MDPSub-
CNN [199], and
SiameseCNN
[123]
MOT15 chal-
lenge
bench-
mark [201].",N/A,N/A
"[123]
MOT15 chal-
lenge
bench-
mark [201].
To address the problems in existing tracking methods such as varying numbers of tar-
gets, non-real-time tracking, etc, [169] proposed a multi-object tracking algorithm based on
a multi-agent DRL tracker (MADRL). In their object tracking pipeline the authors used
YOLO-V3 [306] as object detector, where multiple detections produced by YOLO-V3 were
ﬁltered using the IOU and the selected results were used as multiple agents in multiple agent",N/A,N/A
"detector. The input agents were fed into a pre-trained VGG-16 [340] followed by an LSTM
unit [139] that could share information across agents and return the actions encoded in a
38
9-dimensional vector( move right, move left, move up, move down, scale-up, scale down, as-
pect ratio change fatter, aspect ratio change taller and stop), also a reward function similar
to [168] was used.
Various works in the ﬁeld of object tracking have been summarized in Table 5, and a",N/A,N/A
"basic implementation of object tracking using DRL has been shown in Fig. 13. The ﬁgure
illustrates a general implementation of object tracking in videos using DRL, where the state
consists of two consecutive frames (Ft, Ft+1) with a bounding box for the ﬁrst frame produced
by another algorithm for the ﬁrst iteration or by the previous iterations of DRL agent. The
actions corresponds to the moving the bounding on the image to ﬁt the object in frame Ft+1,",N/A,N/A
"hence forming a new state with frame Ft+1 and frame Ft+2 along with the bounding box
for frame Ft+1 predicted by previous iteration and reward corresponds to whether IOU is
greater then a given threshold as used by [118],[308],[45], [84],[307],[168],[169].
Figure 13: DRL implementation for object tracking. Here the state consists of two consecu-
tive frames with bounding box locations for the ﬁrst frame that is predicted by some object",N/A,N/A
"detection algorithm or by the previous iteration of DRL, the actions move the bounding box
present in the ﬁrst frame to ﬁt the object in the second frame to maximize the reward which
is the whether the IOU is greater than a given threshold or not.
8
DRL in Image Registration
Image registration is a very useful step that is performed on 3D medical images for the
alignment of two or more images. The goal of 3D medical image registration is to ﬁnd a",N/A,N/A
"correlation between two images from either diﬀerent patients or the same patients at diﬀerent
times, where the images can be Computed Tomography (CT), Magnetic Resonance Imaging
(MRI), or Positron Emission Tomography (PET). In the process, the images are brought to
the same coordinate system and aligned with each other. The reason for image registration
being a challenging task is the fact that the two images used may have a diﬀerent coordinate
system, scale, or resolution.",N/A,N/A
"system, scale, or resolution.
Many attempts have been made toward automated image registration. A multi-resolution
strategy with local optimizers to perform 2D or 3D image registration was performed by
39
[359]. However, multi-resolution tends to fail with diﬀerent ﬁeld of views. Heuristic semi-
global optimization schemes were proposed to solve this problem and used by [252] through
simulated annealing and through genetic algorithm [317], However, their cost of computation",N/A,N/A
"was very high. A CNN-based approach to this problem was suggested by [256], and [79]
proposed an optical ﬂow method between 2D RGB images. A descriptor learned through a
CNN was proposed by [395], where the authors encoded the posture and identity of a 3D
object using the 2D image. Although all of these formulations produce satisfactory results
yet, the methods could not be applied directly to 3D medical images.
To overcome the problems faced by previous methods, [238] proposed a method for im-",N/A,N/A
"proving probabilistic image registration via RL and uncertainty evaluation. The method in-
volved predicting a regression function that predicts registration error from a set of features
by using regression random forests (RRF) [37] method for training. The authors performed
experiments on 3D MRI images and obtained an accuracy improvement of up to 25%.
Previous image registration methods are often customized to a speciﬁc problem and are",N/A,N/A
"sensitive to image quality and artifacts. To overcome these problems, [221] proposed a robust
method using DRL. The authors considered the problem as an MDP where the goal is to ﬁnd
a set of transformations to be performed on the ﬂoating image to register it on the reference
image. They used the gamma value for future reward decay and used the change in L2
Norm between the predicted transformation and ground truth transformation to calculate",N/A,N/A
"the reward. The authors also used a hierarchical approach to solve the problem with varying
FOVs and resolutions.
Table 6: Comparing various DRL-based image registration meth-
ods.
Approaches
Year
Training
Tech-
nique
Actions
Remarks
Backbone
Performance
Datasets
Image
reg-
istration
using
un-
certainity
evaluation
[238]
2013
DQN
Not spec-
iﬁed
Probabilistic
model
using
regression
ran-
dom
forests
(RRF) [37]
Not spec-
iﬁed
Higher
ﬁnal
Dice
score
(DSC) as com-
pared to other
methods
like
random",N/A,N/A
"(DSC) as com-
pared to other
methods
like
random
seed
selection
and
grid-based seed
selection
3D
MRI
images
from
LONI
Prob-
abilistic
Brain
Atlas
(LPBA40)
Dataset
40
Robust
Image
reg-
istration
[221]
2017
DQN
12
ac-
tions:
corre-
sponding
to
dif-
ferent
transfor-
mations
States:
current
transforma-
tion.
Reward:
distance error.
5
Conv3D
layers
and 3 FC
layers
Better
success
rate then ITK
[153],
Quasi-
global
[255]
and
Semantic
registration[277]
Abdominal
spine
CT
and
CBCT
dataset, Car-",N/A,N/A
"Abdominal
spine
CT
and
CBCT
dataset, Car-
diac CT and
CBCT
Multimodal
image
reg-
istration
[244]
2017
Duel-
DQN
Double-
DQN
Actions
update
the trans-
forma-
tions
on
ﬂoating
image
States: cropped
3D
image.
Duel-DQN
for
value
es-
timation
and
Double
DQN
for
updating
weights.
Batch
normal-
ization
followed
by
5
Conv3D
and
3
Maxpool
layers
Lower
Eu-
clidean
dis-
tance
error
as
compared
to
methods
like
Hausdorﬀ, ICP,
DQN
[264],
Dueling
[390],
etc.
Thorax
and
Abdomen
(ABD)
dataset
Robust
non-rigid",N/A,N/A
"Thorax
and
Abdomen
(ABD)
dataset
Robust
non-rigid
agent-based
registration
[184]
2017
DQN
2n
ac-
tions
for
n dimen-
sional
θ
vector
States:
ﬁxed
and
moving
image. Reward:
change in trans-
formation error.
With
Statisti-
cal deformation
model and fuzzy
action control.
Multi
layer
CNN,
pooling
and
FC
layers.
Higher
Mean
Dice score and
lower Hausdorﬀ
distance
as
compared
to
methods
like
LCC-Demons
[237]
and
Elastix [180].
MICCAI
challenge
PROMISE12
[227]
Robust
Multimodal
registration
[349]
2018",N/A,N/A
"[227]
Robust
Multimodal
registration
[349]
2018
Actor-
Critic
(a3c)
[262]
8 actions:
for
dif-
ferent
transfor-
mations
States:
ﬁxed
and
moving
image. Reward:
Distance
error.
Monte-carlo
method
with
LSTM [139].
Multi
layer
CNN and
FC layer
Comparable
if
not
lower
target
registra-
tion
error
[96]
as
compared
to
methods
like
SIFT
[239],
Elastix
[180],
Pure
SL, RL-matrix,
RL-LME, etc.
CT and MR
images
A multi-modal method for image registration was proposed by [244], where the authors",N/A,N/A
"used DRL for alignment of depth data with medical images. In the speciﬁed work Duel
DQN was used as the agent for estimating the state value and the advantage function, and
the cropped 3D image tensor of both data modalities was considered as the state.
The
41
algorithm’s goal was to estimate a transformation function that could align moving images
to a ﬁxed image by maximizing a similarity function between the ﬁxed and moving image.",N/A,N/A
"A large number of convolution and pooling layer were used to extract high-level contextual
information, batch normalization and concatenation of feature vector from last convolution
layer with action history vector was used to solve the problem of oscillation and closed loops,
and Double DQN architecture for updating the network weights was used.
Previous methods for image registration fail to cope with large deformations and variabil-",N/A,N/A
"ity in appearance. To overcome these issues [184] proposed a robust non-rigid agent-based
method for image registration. The method involves ﬁnding a spatial transformation Tθ that
can map the ﬁxed image with the ﬂoating image using actions at each time step, that is
responsible for optimizing θ. If the θ is a d dimensional vector then there will be 2d possi-
ble actions. In this work, a DQN was used as an agent for value estimation, along with a",N/A,N/A
"reward that corresponded to the change in θ distance between ground truth and predicted
transformations across an action.
An improvement to the previous methods was proposed by [349], where the authors used
a recurrent network with RL to solve the problem. Similar to [221], they considered the
two images as a reference/ﬁxed and ﬂoating/moving, and the algorithm was responsible
for predicting transformation on the moving image to register it on a ﬁxed image. In the",N/A,N/A
"speciﬁed work an LSTM [139] was used to encode past hidden states, Actor-critic [262] for
policy estimation, and a reward function corresponding to distance between ground truth
and transformed predicted landmarks were used.
Various methods in the ﬁeld of Image registration have been summarized and compared
in Table 6, and a basic implementation of image registration using DRL has been shown in
Fig. 14. The ﬁgure illustrates a general implementation of image registration using DRL",N/A,N/A
"where the state consists of a ﬁxed and ﬂoating image. The DRL agent predicts actions in
form of a set of transformations on a ﬂoating image to register it onto the ﬁxed image hence
forming a new state and accepts reward in form of improvement in distance error between
ground truth and predicted transformations with iterations as described by [349],[184],[221].
9
DRL in Image Segmentation
Image segmentation is one of the most extensively performed tasks in computer vision,",N/A,N/A
"where the algorithm is responsible for labeling each pixel position as foreground or back-
ground corresponding to the object being segmented in the image. Image segmentation has
a wide variety of applications in medical, robotics, weather, etc. One of the earlier attempts
with image segmentation includes [125]. With the improvement in detection techniques and
introduction of CNN, new methods are introduced every year for image segmentation. Mask",N/A,N/A
"R-CNN [132] extended the work by Faster R-CNN [309] by adding a segmentation layer
after the Bounding box has been predicted. Some earlier works include [109], [127], [128]
etc. Most of these works give promising results in image segmentation. However, due to
the supervised nature of CNN and R-CNN, these algorithms need a large amount of data.
In ﬁelds like medical, the data is sometimes not readily available hence we needed a way to
42
Figure 14: DRL implementation for image registration.",N/A,N/A
"The state consists of ﬁxed and
ﬂoating image and the actions in form of transformations are performed on the ﬂoating
image so as to maximize reward by minimizing distance between the ground truth and
predicted transformations.
train algorithms to perform a given task when there are data constraints. Luckily RL tends
to shine when the data is not available in a large quantity.
One of the ﬁrst methods for Image segmentation through RL was proposed by [324],",N/A,N/A
"where the authors proposed an RL framework for medical image segmentation. In their
work, they used a Q-Matrix, where the actions were responsible for adjusting the threshold
values to predict the mask and the reward was the normalized change in quality measure
between action steps. [325] also used a similar technique of Tabular method.
To overcome the constraints of the previous method for segmentation, [310] proposed a",N/A,N/A
"method for indoor semantic segmentation through RL. In their paper, the authors proposed
a sequential strategy using RL to combine binary object masks of diﬀerent objects into a
single multi-object segmentation mask. They formulated the binary mask in a Conditional
Random Field Framework (CRF), and used a logistic regression version of AdaBoost [140] for
classiﬁcation. The authors considered the problem of adding multiple binary segmentation",N/A,N/A
"into one as an MDP, where the state consisted of a list of probability distributions of diﬀer-
ent objects in an image, and the actions correspond to the selection of object/background
segmentation for a particular object in the sequential semantic segmentation. In the RL
framework, the reward was considered in terms of pixel-wise frequency weighted Jaccard
Index computed over the set of actions taken at any stage of an episode.",N/A,N/A
"Interactive segmentation is the task of producing an interactive mask for objects in an
image. Most of the previous works in this ﬁeld greatly depend on the distribution of inputs
which is user-dependent and hence produce inadequate results. An improvement was pro-
posed by [343], where the authors proposed SeedNet, an automatic seed generation method
43
for robust interactive segmentation through RL. With the image and initial seed points, the",N/A,N/A
"algorithm is capable of generating additional seed points and image segmentation results.
The implementation included Random Walk (RW) [114] as the segmentation algorithm and
DQN for value estimation by considering the problem as an MDP. They used the current
binary segmentation mask and image features as the state, the actions corresponded to se-
lecting seed points in a sparse matrix of size 20×20(800 diﬀerent actions were possible), and",N/A,N/A
"the reward consisted of the change in IOU across an action. In addition, the authors used
an exponential IOU model to capture changes in IOU values more accurately.
Most of the previous work for image segmentation fail to produce satisfactory results
when it comes to 3D medical data. An attempt on 3D medical image segmentation was done
by [222], where the authors proposed an iteratively-reﬁned interactive multi-agent method",N/A,N/A
"for 3D medical image segmentation. They proposed a method to reﬁne an initial course
segmentation produced by some segmentation methods using RL, where the state consisted of
the image, previous segmentation probability, and user hint map. The actions corresponded
to adjusting the segmentation probability for reﬁnement of segmentation, and a relative
cross-entropy gain-based reward to update the model in a constrained direction was used.",N/A,N/A
"In simple words, it is the relative improvement of previous segmentation to the current one.
The authors utilized an asynchronous advantage actor-critic algorithm for determining the
policy and value of the state.
Table 7: Comparing various DRL-based image segmentation meth-
ods
Approaches Year
Training
Technique
Actions
Remarks
Backbone Performance
Datasets
Semantic
Segmen-
tation for
indoor
scenes[310]
2016
DQN
2
ac-
tions per
object:
object,
back-
ground
States:
current
probability",N/A,N/A
"object,
back-
ground
States:
current
probability
distribution.
Reward:
pixel-
wise
frequency
weighted
Jac-
card
index.
Conditional
Random
Field
Framework
(CRF) and lo-
gistic regression
version of Ad-
aBoost [140] for
classiﬁcation.
Not
Speci-
ﬁed
Pixel-wise
percentage
jaccard
index
comparable
to
Gupta-L
[121]
and
Gupta-P
[120].
NYUD
V2
dataset [338]
44
SeedNet
[343]
2018
DQN,
Double-
DQN,
Duel-DQN
800
ac-
tions:
2
per pixel
States:
image
features
and
segmentation
mask.
Reward:
change in IOU.",N/A,N/A
"and
segmentation
mask.
Reward:
change in IOU.
Random
Walk
(RW) [114] for
segmentation
algorithm.
Multi
layer
CNN
Better
IOU
then
methods
like FCN [236]
and iFCN [407].
MSRA10K
saliency
dataset [49]
Iteratively
reﬁned
multi
agent
segmen-
tation
[222]
2020
Actor-critic
(a3c) [262]
1
action
per voxel
for
ad-
justing
segmen-
tation
probabil-
ity
States:
3D
image
segmen-
tation
proba-
bility and hint
map.
Reward:
cross
entropy
gain
based
framework.
R-net
[378]
Better
perfor-
mance
then
methods
like",N/A,N/A
"[378]
Better
perfor-
mance
then
methods
like
MinCut
[183],
DeepIGeoS
(R-Net)
[378]
and
InterCNN
[36].
BraTS
2015[254],
MM-WHS
[432]
and
NCI-ISBI
2013
Chal-
lenge [33]
Multi-
step
medical
image
segmen-
tation
[360]
2020
Actor-critic
(a3c) [262]
Actions
control
the posi-
tion
and
shape
of
brush
stroke to
modify
segmen-
tation
States:
image,
segmentation
mask and time
step.
Reward:
change
in
dis-
tance
error.
Policy:
DPG
[339].
ResNet18
[133]
Higher
Mean
Dice score and
lower Hausdorﬀ
distance
then",N/A,N/A
"Mean
Dice score and
lower Hausdorﬀ
distance
then
methods
like
Grab-Cut [315],
PSPNet
[425],
FCN
[236],
U-Net
[313],
etc.
Prostate MR
image dataset
(PROMISE12,
ISBI2013)
and
retinal
fundus
im-
age
dataset
(REFUGE
challenge
dataset [285])
Anomaly
Detection
in Images
[56]
2020
REINFORCE
[392]
9 actions,
8 for di-
rections
to
shift
center
of
the
extracted
patch to,
the
last
action
is
to switch
to a ran-
dom new
image
Environment:
input
image
to
the
model.
State:
ob-
served
patch
from the image",N/A,N/A
"the
model.
State:
ob-
served
patch
from the image
centered
by
predicted center
of interest.
None
Superior perfor-
mance
in
[27]
and
[337]
on
all metrics e.g.
precision, recall
and
F1
when
compared
with
U-Net
[313]
and
baseline
unsupervised
method in [27]
but
only
wins
on recall in [44]
MVTec
AD
[27],
Nan-
oTWICE
[44],
Crack-
Forest [337]
45
Further improvement in the results of medical image segmentation was proposed by",N/A,N/A
"[360]. The authors proposed a method for multi-step medical image segmentation using RL,
where they used a deep deterministic policy gradient method (DDPG) based on actor-critic
framework [262] and similar to Deterministic policy gradient (DPG) [339]. The authors used
ResNet18 [133] as backbone for actor and critic network along with batch normalisation
[157] and weight normalization with Translated ReLU [400]. In their MDP formulation,",N/A,N/A
"the state consisted of the image along with the current segmentation mask and step-index,
and the reward corresponded to the change in mean squared error between the predicted
segmentation and ground truth across an action. According to the paper the action was
deﬁned to control the position and shape of brush stroke used to modify the segmentation.
An example in image segmentation outside the medical ﬁeld is [56] proposing to tackle the",N/A,N/A
"problem of anomalies detection and segmentation in images (i.e. damaged pins of an IC chip,
small tears in woven fabric). [56] utilizes an additional module to attend only on a speciﬁc
patch of the image centered by a predicted center instead of the whole image, this module
helps a lot in reducing the imbalance between normal regions and abnormal locations. Given
an image, this module, namely Neural Batch Sampling (NBS), starts from a random initiated",N/A,N/A
"center and recurrently moves that center by eight directions to the abnormal location in the
image if it exists, and it has an additional action to stop moving the center when it has already
converged to the anomaly location or there is not any anomaly can be observed. The NBS
module is trained by REINFORCE algorithm [392] and the whole model is evaluated on
multiple datasets e.g. MVTec AD [27], NanoTWICE [44], CrackForest [337].",N/A,N/A
"Various works in the ﬁelds of Image segmentation have been summarised and compared
in Table 7, and a basic implementation of image segmentation using DRL has been shown
in Fig. 15. The ﬁgure shows a general implementation of image segmentation using DRL.
The states consist of the image along with user hint (landmarks or segmentation mask by
the other algorithm) for the ﬁrst iteration or segmentation mask by the previous iteration.",N/A,N/A
"The actions are responsible for labeling each pixel as foreground and background and reward
corresponds to an improvement in IOU with iterations as used by [343],[222].
10
DRL in Video Analysis
Object segmentation in videos is a very useful yet challenging task in computer vision ﬁeld.
Video object segmentation task focuses on labelling each pixel for each frame as foreground
or background. Previous works in the ﬁeld of video object segmentation can be divided
into three main methods.",N/A,N/A
"into three main methods.
unsupervised [288][402], weakly supervised [48][163] [419] and
semi-supervised [41] [164][292].
A DRL-based framework for video object segmentation was proposed by [323], where
the authors divided the image into a group of sub-images and then used the algorithm on
each of the sub-image. They proposed a group of actions that can perform to change the
local values inside each sub-image and the agent received reward based on the change in the",N/A,N/A
"quality of segmented object inside each sub-image across an action. In the proposed method
deep belief network (DBN) [47] was used for approximating the Q-values.
46
Figure 15: DRL implementation for Image segmentation. The state consists of the image to
be segmented along with a user hint for t=0 or the segmentation mask by the previous itera-
tions. The DRL agent performs actions by labeling each pixel as foreground and background
to maximize the improvement in IOU over the iterations.",N/A,N/A
"Surgical gesture recognition is a very important yet challenging task in the computer
vision ﬁeld. It is useful in assessing surgical skills and for eﬃcient training of surgeons. A
DRL method for surgical gesture classiﬁcation and segmentation was proposed by [228]. The
proposed method could work on features extracted by video frames or kinematic data frames
collected by some means along with the ground truth labels. The problem of classiﬁcation",N/A,N/A
"and segmentation was considered as an MDP, where the state was a concatenation of TCN
[195][199] features of the current frame, 2 future frames a speciﬁed number of frames later,
transition probability of each gesture computed from a statistical language model [311] and
a one-hot encoded vector for gesture classes. The actions could be divided into two sub-
actions, One to decide optimal step size and one for choosing gesture class, and the reward",N/A,N/A
"was adopted in a way that encouraging the agent to adopt a larger step and also penalizes the
agent for errors caused by the action. The authors used Trust Region Policy Optimization
(TRPO) [326] for training the policy and a spacial CNN [196] to extract features.
Earlier approaches for video object segmentation required a large number of actions to
complete the task.
An Improvement was proposed by [124], where authors used an RL",N/A,N/A
"method for object segmentation in videos. They proposed a reinforcement cutting-agent
learning framework, where the cutting-agent consists of a cutting-policy network (CPN)
and a cutting-execution network (CEN). The CPN learns to predict the object-context box
pair, while CEN learns to predict the mask based on the inferred object-context box pair.
The authors used MDP to solve the problem in a semi-supervised fashion. For the state of",N/A,N/A
"CPN the authors used the input frame information, the action history, and the segmentation
mask provided in the ﬁrst frame. The output boxes by CPN were input for the CEN. The
actions for CPN network included 4 translation actions (Up, Down, Left, Right), 4 scaling
47
action (Horizontal shrink, Vertical shrink, Horizontal zoom, Vertical zoom), and 1 terminal
action (Stop), and the reward corresponded to the change in IOU across an action. For the",N/A,N/A
"network architecture, a Fully-Convolutional DenseNet56 [166] was used as a backbone along
with DQN as the agent for CPN and down-sampling followed by up-sampling architecture
for CEN.
Unsupervised video object segmentation is an intuitive task in the computer vision ﬁeld.
A DRL method for this task was proposed by [111], where the authors proposed a motion-
oriented unsupervised method for image segmentation in videos (MOREL). They proposed",N/A,N/A
"a two-step process to achieve the task in which ﬁrst a representation of input is learned to
understand all moving objects through unsupervised video object segmentation, Then the
weights are transferred to the RL framework to jointly train segmentation network along
with policy and value function. The ﬁrst part of the method takes two consecutive frames
as input and predicts a number of segmentation masks, corresponding object translations,",N/A,N/A
"and camera translations. They used a modiﬁed version of actor-critic [262][329][371] for the
network of ﬁrst step. Following the unsupervised fashion, the authors used the approach
similar to [375] and trained the network to interpolate between consecutive frames and used
the masks and translations to estimate the optical ﬂow using the method that was proposed
in Spatial Transformer Networks [159]. They also used structural dissimilarity (DSSIM)",N/A,N/A
"[388] to calculate reconstruction loss and actor-critic [262] algorithm to learn policy in the
second step.
A DRL method for dynamic semantic face video segmentation was proposed by [387],
where Deep Feature Flow [431] was utilized as the feature propagation framework and RL
was used for an eﬃcient and eﬀective scheduling policy.
The method involved dividing
frames into key (Ik) and non-key (Ii), and using the last key frame features for performing",N/A,N/A
"segmentation of non-key frame. The actions made by the policy network corresponded to
categorizing a frame as Ik or Ii and the state consisted of deviation information and expert
information, where the deviation information described the diﬀerence between current Ii and
last Ik and expert information encapsulated the key decision history. The authors utilized
FlowNet2-s model [156] as an optical ﬂow estimation function, and divided the network into",N/A,N/A
"feature extraction module and task-speciﬁc module. After policy network which consisted
of one convolution layer, 4 fully connected layers and 2 concatenated channels consisting of
KAR (Key all ratio: Ratio between key frame and every other frame in decision history) and
LKD (Last key distance: Distance between current and last key frame) predicted the action,
If the current frame is categorized as key frame the feature extraction module produced",N/A,N/A
"the frame features and task-speciﬁc module predicted the segmentation, However if the
frame is categorized as a non-key frame the features from the last key frame along with
the optical ﬂow was used by the task-speciﬁc module to predict the segmentation.
The
authors proposed two types of reward functions, The ﬁrst reward function was calculated by
considering the diﬀerence between the IOU for key and non-key actions. The second reward",N/A,N/A
"function was proposed for a situation when ground truth was not available and was calculated
by considering the accuracy score between segmentation for key and non-key actions.
48
Table 8: Comparing various methods associated with video. First
group for video object segmentation, second group for action recog-
nition and third group for video summarisation
Approaches Year
Training
Technique
Actions
Remarks
Backbone
Performance
Datasets and
Source code
Object
segmen-
tation in
videos[323]
2016",N/A,N/A
"Object
segmen-
tation in
videos[323]
2016
Deep
Belief
Network
[47]
Actions
changed
local
values
in
sub-
images
States:
sub-
images.
Re-
ward: quality of
segmentation.
Not spec-
iﬁed
Not speciﬁed
Not speciﬁed
Surgical
gesture
segmen-
tation
and clas-
siﬁcation
[228]
2018
Trust
Region
Policy Op-
timization
(TRPO)
[326]
2
types:
optimal
step
size
and
gesture
class
States:
TCN
[[195], [199]] and
future
frames.
Reward:
en-
courage
larger
steps and min-
imize
action
errors.
Statis-
tical
language",N/A,N/A
"imize
action
errors.
Statis-
tical
language
model
[311]
for
gesture
probability.
Spacial
CNN
[196]
Comparable
accuracy,
and
higher edit and
F1
scores
as
compared
to
methods
like
SD-SDL
[331],
Bidir
LSTM
[76],
LC-SC-
CRF
[197],
Seg-ST-CNN
[196],
TCN
[198], etc
JIGSAWS
[[6],
[100]]
benchmark
dataset
Available Code
49
Cutting
agent
for video
object
segmen-
tation
[124]
2018
DQN
8 actions:
4
trans-
lation
actions
(Up,
Down,
Left,
Right),
4 scaling
action
(Hori-
zontal
shrink,
Vertical
shrink,",N/A,N/A
"action
(Hori-
zontal
shrink,
Vertical
shrink,
Horizon-
tal zoom,
Vertical
zoom)
and
1
terminal
action
(Stop)
States:
input
frame,
action
history
and
segmentation
mask.
Reward:
change in IOU.
cutting-policy
network for box-
context
pair
and
cutting-
execution
net-
work for mask
generation
DenseNet
[166]
Higher
mean
region
simi-
larity,
counter
accuracy
and
temporal
sta-
bility
[293]
as
compared
to
methods
like
MSK
[292],
ARP
[173],
CTN
[165],
VPN [164], etc.
DAVIS
dataset
[293] and the",N/A,N/A
"VPN [164], etc.
DAVIS
dataset
[293] and the
YouTube Ob-
jects
dataset
[162], [300]
Unsupervised
video ob-
ject
segmen-
tation
(MOREL)
[111]
2018
Actor-
critic
(a2c) [262]
Not spec-
iﬁed
States:
consec-
utive
frames.
Two
step
process
with
optical
ﬂow
using
Spatial
Transformer
Networks
[159]
and
recon-
struction
loss
using structural
dissimilarity
[388].
Multi-
layer
CNN
Higher
total
episodic reward
as compared to
methods
that
used
actor-
critic
without
MOREL
59
Atari
games.
Available Code
50",N/A,N/A
"without
MOREL
59
Atari
games.
Available Code
50
Face
video
segmen-
tation
[387]
2020
Not speci-
ﬁed
2 actions:
categoris-
ing
a
frame
as
a key or
a non-key
States:
devia-
tion information
which described
the
diﬀerence
between
cur-
rent
non-key
and
last
key
decision,
and
expert
infor-
mation
which
encapsulated
the key decision
history.
Re-
ward:
improve-
ment
in
mean
IOU/accuracy
score
between
segmentation of
key and non-key
frames
Multi-
layer
CNN
Higher
mean
IOU then other
methods
like
DVSNet",N/A,N/A
"Higher
mean
IOU then other
methods
like
DVSNet
[410],
DFF [431].
300VW
dataset
[336]
and Cityscape
dataset [61]
Multi-
agent
Video
Object
Segmen-
tation
[373]
2020
DQN
Actions
of
2
types:
move-
ment
actions
(up,
down,
left
and
right)
and
set
action
(action
to
place
location
prior
at
a random
location
on
the
patch)
States:
input
frame,
optical
ﬂow [156] from
previous
frame
and action his-
tory.
Reward:
clicks generated
by
gamiﬁca-
tion.
Down-
sampling
and
up-sampling
similar
to
U-Net [313]",N/A,N/A
"sampling
and
up-sampling
similar
to
U-Net [313]
DenseNet
[147]
Higher
mean
region
similar-
ity and contour
accuracy
[293]
as compared to
semi-supervised
methods such as
SeamSeg
[14],
BSVS
[248],
VSOF
[363],
OSVOS
[41]
and
weakly-
supervised
methods
such
as GVOS [346],
Spftn [419]
DAVIS-17
dataset [293]
51
Skeleton-
based
Action
Recog-
nition
[357]
2018
DQN
3 actions:
shifting
to
left,
staying
the same
and shift-
ing
to
right
States:
Global
video
infor-
mation
and
selected frames.
Reward: change",N/A,N/A
"infor-
mation
and
selected frames.
Reward: change
in
categorical
probability.
2
step
network
(FDNet)
to
ﬁlter
frames
and GCNN for
action labels
Multi-
layer
CNN
Higher
cross
subject
and
cross
view
metrics
for
NTU+RGBD
dataset
[333],
and
higher
accuracy
for
SYSU-3D [145]
and UT-Kinect
Dataset
[399]
when
com-
pared
with
other
methods
like
Dynamic
Skeletons [145],
HBRNN-L [81],
Part-aware
LSTM
[333],
LieNet-3Blocks
[151],
Two-
Stream
CNN
[211], etc.
NTU+RGBD
[333],
SYSU-
3D [145] and
UT-Kinect",N/A,N/A
"NTU+RGBD
[333],
SYSU-
3D [145] and
UT-Kinect
Dataset [399]
Video
summari-
sation
[429]
2018
DQN
2 actions:
selecting
and
re-
jecting
the frame
tates:
bidirec-
tional
LSTM
[150]
produced
states by input
frame
fea-
tures.
Reward:
Diversity-
Representativeness
Reward
Func-
tion.
GoogLeNet
[355]
Higher
F-
score
[421]
as
compared
to
methods
like
Uniform
sampling,
K-medoids,
Dictionary
se-
lection
[88],
Video-MMR
[218],
Vsumm
[69], etc.
TVSum [344]
and
SumMe
[122].
Available Code
52
Video
summa-",N/A,N/A
"and
SumMe
[122].
Available Code
52
Video
summa-
rization
[430]
2018
Duel DQN
Double
DQN
2 actions:
selecting
and
re-
jecting
the frame
States:
se-
quence
of
frames Reward:
Diversity-
Representativeness
Reward
Func-
tion
2
stage
implementa-
tion:
classi-
ﬁcation
and
summarisation
network
using
bidirectional
GRU
network
and LSTM [150]
GoogLeNet
[355]
Higher
F-
score
[421]
as
compared
to
methods
like
Dictionary
se-
lection
[88],
GAN
[245],
DR-DSN
[429],
Backprop-Grad
[287],
etc
in
most cases.",N/A,N/A
"[429],
Backprop-Grad
[287],
etc
in
most cases.
TVSum [344]
and
CoSum
[57] datasets.
Available Code
Video
summa-
rization
in
Ul-
trasound
[233]
2020
Not speci-
ﬁed
2 actions:
selecting
and
re-
jecting
the frame
States:
frame
latent
scores
Reward:
Rdet,
Rrep
and Rdiv
bidirectional
LSTM [150] and
Kernel temporal
segmentation
[298]
Not spec-
iﬁed
Higher
F1-
scores
in
su-
pervised
and
unsupervised
fashion
as
compared
to
methods
like
FCSN [312] and
DR-DSN [429].
Fetal
Ul-
trasound
[179]",N/A,N/A
"DR-DSN [429].
Fetal
Ul-
trasound
[179]
Video object segmentation using human-provided location priors have been capable of
producing promising results. An RL method for this task was proposed by [373], in which
the authors proposed MASK-RL, a multiagent RL framework for object segmentation in
videos. They proposed a weakly supervised method where the location priors were provided
by the user in form of clicks using gamiﬁcation (Web game to collect location priors by",N/A,N/A
"diﬀerent users) to support the segmentation and used a Gaussian ﬁlter to emphasize the
areas. The segmentation network is fed a 12 channel input tensor that contained a sequence
of video frames and their corresponding location priors (3 × 3 color channels + three gray-
scale images). The authors used a fully convoluted DenseNet [147] with down-sampling and
up-sampling similar to U-Net [313] and an LSTM [139] for the segmentation network. For",N/A,N/A
"the RL method, the actor takes a series of steps over a frame divided into a grid of equal
size patches and makes the decision whether there is an object in the patch or not. In their
MDP formulation the states consisted of the input frame, optical ﬂow (computed by [156])
from the previous frame, patch from the previous iteration, and the episode location history,
the actions consisted of movement actions (up, down, left and right) and set action (action",N/A,N/A
"to place location prior at a random location on the patch), and two types of rewards one for
set actions and one for movement actions were used. The reward was calculated using the
53
clicks generated by the game player.
Action recognition is an important task in the computer vision ﬁeld which focuses on
categorizing the action that is being performed in the video frame. To address the problem
a deep progressive RL (DPRL) method for action recognition in skeleton-based videos was",N/A,N/A
"proposed by [357]. The authors proposed a method that distills the most informative frames
and discards ambiguous frames by considering the quality of the frame and the relationship
of the frame with the complete video along with a graph-based structure to map the human
body in form of joints and vertices. DPRL was utilized to ﬁlter out informative frames in a
video and graph-based CNNs were used to learn the spatial dependency between the joints.",N/A,N/A
"The approach consisted of two sub-networks, a frame distillation network (FDNet) to ﬁlter a
ﬁxed number of frames from input sequence using DPRL and GCNN to recognize the action
labels using output in form of a graphical structure by the FDNet. The authors modeled the
problem as an MDP where the state consisted of the concatenation of two tensors F and M,
where F consisted of global information about the video and M consisted of the frames that",N/A,N/A
"were ﬁltered, The actions which correspond to the output of FDNet were divided into three
types: shifting to left, staying the same and shifting to the right, and the reward function
corresponded to the change in probability of categorizing the video equal to the ground truth
clipped it between [-1 and 1] and is provided by GCNN to FDNet.
Video summarization is a useful yet diﬃcult task in the computer vision ﬁeld that involves",N/A,N/A
"predicting the object or the task that is being performed in a video. A DRL method for
unsupervised video summarisation was proposed by [429], in which the authors proposed a
Diversity-Representativeness reward system and a deep summarisation network (DSN) which
was capable of predicting a probability for each video frame that speciﬁed the likeliness of
selecting the frame and then take actions to form video summaries. They used an encode-",N/A,N/A
"decoder framework for the DSN where GoogLeNet [355] pre-trained on ImageNet [320] [72]
was used as an encoder and a bidirectional RNNs (BiRNNs) topped with a fully connected
(FC) layer was used as a decoder. The authors modeled the problem as an MDP where
the action corresponded to the task of selecting or rejecting a frame.
They proposed a
novel Diversity-Representativeness Reward Function in their implementation, where diversity",N/A,N/A
"reward corresponded to the degree of dissimilarity among the selected frames in feature space,
and representativeness reward measured how well the generated summary can represent the
original video.
For the RNN unit they used an LSTM [139] to capture long-term video
dependencies and used REINFORCE algorithm for training the policy function.
An improvement to [429] was proposed by [430], where the summarisation network was",N/A,N/A
"implemented using Deep Q-learning (DQSN), and a trained classiﬁcation network was used
to provide a reward for training the DQSN. The approach included using (Bi-GRU) bidirec-
tional recurrent networks with a gated recurrent unit (GRU) [50] for both classiﬁcation and
summarisation network. The authors ﬁrst trained the classiﬁcation network using a super-
vised classiﬁcation loss and then used the classiﬁcation network with ﬁxed weights for the",N/A,N/A
"classiﬁcation of summaries generated by the summarisation network. The summarisation
network included an MDP-based framework in which states consisted of a sequence of video
frames and actions reﬂected the task of either keeping the frame or discarding it. They used
54
Figure 16: DRL implementation for video summarization. For state a sequence of consecutive
frames are used and the DRL agent decided whether to include the frame in the summary
set that is used to predict video summary.",N/A,N/A
"set that is used to predict video summary.
a structure similar to Duel-DQN where value function and advantage function are trained
together. In their implementation, the authors considered 3 diﬀerent rewards: Global Recog-
nisability reward using the classiﬁcation network with +1 as reward and -5 as punishment,
Local Relative Importance Reward for rewarding the action of accepting or rejecting a frame
by summarisation network, and an Unsupervised Reward that is computed globally using",N/A,N/A
"the unsupervised diversity-representativeness (DR) reward proposed in [429]. The authors
trained both the networks using the features generated by GoogLeNet [355] pre-trained on
ImageNet [72].
A method for video summarization in Ultrasound using DRL was proposed by [233], in
which the authors proposed a deep summarisation network in an encoder-decoder fashion
and used a bidirectional LSTM (Bi-LSTM) [150] for sequential modeling. In their implemen-",N/A,N/A
"tation, the encoder-decoder convolution network extracted features from video frames and
fed them into the Bi-LSTM. The RL network accepted states in form of latent scores from
Bi-LSTM and produced actions, where the actions consist of the task of including or discard-
ing the video frame inside the summary set that is used to produce video summaries. The
authors used three diﬀerent rewards Rdet, Rrep and Rdiv where Rdet evaluated the likelihood",N/A,N/A
"of a frame being a standard diagnostic plane, Rrep deﬁned the representativeness reward and
Rdiv was the diversity reward that evaluated the quality of the selected summary. They used
Kernel temporal segmentation (KTS) [298] for video summary generalization.
Various works associated with video analysis have been summarised and compared in
Table 8 and a basic implementation of video summarization using DRL has been shown in",N/A,N/A
"Fig. 16, where the states consist of a sequence of video frames. The DRL agent performs
55
actions to include or discard a frame from the summary set that is later used by the summa-
rization network to predict video summary. Each research paper propose their own reward
function for this application, for example [429] and [430] used diversity representativeness
reward function and [233] used a combination of various reward functions.
11
Others Applications",N/A,N/A
"11
Others Applications
Object manipulation refers to the task of handling and manipulating an object using a robot.
A method for deformable object manipulation using RL was proposed by [250], where the
authors used a modiﬁed version of Deep Deterministic Policy Gradients (DDPG) [224]. They
used the simulator Pybullet [63] for the environment where the observation consisted of a
84 × 84 × 3 image, the state consists of joint angles and gripper positions and action of four",N/A,N/A
"dimensions: ﬁrst three for velocity and lasts for gripper velocity was used. The authors used
sparse reward for the task that returns the reward at the completion of the task. They used
the algorithm to perform tasks such as folding and hanging cloth and got a success rate of
up to 90%.
Visual perception-based control refers to the task of controlling robotic systems using a
visual input. A virtual to real method for control using semantic segmentation was proposed",N/A,N/A
"by [142], in which the authors combined various modules such as, Perception module, con-
trol policy module, and a visual guidance module to perform the task. For the perception
module, the authors directly used models such as DeepLab [46] and ICNet [424], pre-trained
on ADE20K [428] and Cityscape [61], and used the output of these model as the state for the
control policy module. They implemented the control policy module using the actor-critic",N/A,N/A
"[262] framework, where the action consisted of forward, turn right, and turn left. In their im-
plementation, a reward of 0.001 is given at each time step. They used the Unity3D engine for
the environment and got higher success and lower collision rate than other implementations
such as ResNet-A3C and Depth-A3C.
Automatic tracing of structures such as axons and blood vessels is an important yet chal-
lenging task in the ﬁeld of biomedical imaging. A DRL method for sub-pixel neural tracking",N/A,N/A
"was proposed by [65], where the authors used 2D grey-scale images as the environment. They
considered a full resolution 11px × 11px window and a 21px × 21px window down-scaled to
11px × 11px as state and the actions were responsible for moving the position of agent in 2D
space using continuous control for sub-pixel tracking because axons can be smaller then a
pixel. The authors used a reward that was calculated using the average integral of intensity",N/A,N/A
"between the agent’s current and next location, and the agent was penalized if it does not
move or changes directions more than once. They used an Actor-critic [262] framework to
estimate value and policy functions.
An RL method for automatic diagnosis of acute appendicitis in abdominal CT images
was proposed by [8], in which the authors used RL to ﬁnd the location of the appendix and
then used a CNN classiﬁer to ﬁnd the likelihood of Acute Appendicitis, ﬁnally they deﬁned",N/A,N/A
"a region of low-entropy (RLE) using the spatial representation of output scores to obtain
optimal diagnosis scores. The authors considered the problem of appendix localization as
56
an MDP, where the state consisted of a 50 × 50 × 50 volume around the predicted appendix
location, 6 actions (2 per axis) were used and the reward consisted of the change in distance
between the predicted appendix location and actual appendix location across an action.",N/A,N/A
"They utilized an Actor-critic [262] framework to estimate policy and value functions.
Table 9: Comparing various other methods besides landmark de-
tection, object detection, object tracking, image registration, image
segmentation, video analysis, that is associated with DRL
Approaches
Year
Training
Technique
Actions
Remarks
Backbone
Performance
Datasets
Source code
Object
manip-
ulation
[250]
2018
Rainbow
DDPG
4
actions:
3
for
ve-
locity 1 for
gripper ve-
locity
State: joint an-",N/A,N/A
"locity 1 for
gripper ve-
locity
State: joint an-
gle and gripper
position.
Re-
ward:
at
the
end of task.
Multi
layer CNN
Success rate up
to 90%
Pybullet
[63].
Code
Visual
based
control
[142]
2018
Actor-
critic
(a3c) [262]
3
actions:
forward,
turn right
and
turn
left
State:
output
by
backbones.
Reward:
0.001
at
each
time-
step.
DeepLab
[46]
and
ICNet
[424]
Higher
success
and lower col-
lision rate then
ResNet-A3C
and Depth-A3C
Unity3D
engine
Automatic
tracing
[65]
2019
Actor-
critic
[262]",N/A,N/A
"Automatic
tracing
[65]
2019
Actor-
critic
[262]
4 actions
State:
11px ×
11px
window.
Reward:
av-
erage
integral
of
intensity
between
the
agent’s
cur-
rent
and
next
location.
Multi
layer CNN
Comparable
convergence
%
and
average
error
as
com-
pared to other
methods
like
Vaa3D software
[291] and APP2
neuron
tracer
[403]
Synthetic
and
mi-
croscopy
dataset
[24]
Automatic
diagnosis
(RLE) [8]
2019
Actor-
critic
[262]
6
actions:
2 per axis
State: 50 × 50 ×
50 volume. Re-
ward: change in
distance error.",N/A,N/A
"50 volume. Re-
ward: change in
distance error.
Fully con-
nected
CNN
Higher
sen-
sitivity
and
speciﬁcity
as
compared
to
only CNN clas-
siﬁer and CNN
classiﬁer
with
RL
without
RLE.
Abdominal
CT Scans
57
Learning
to
paint
[149]
2019
Actor-
critic with
DDPG
Actions
control the
stoke
pa-
rameter:
location,
shape,
color
and
trans-
parency
State:
Refer-
ence
image,
Drawing
can-
vas
and
time
step.
Reward:
change
in
dis-
criminator score
(calculated
by
WGAN-GP
[117] across an
action.
GANs",N/A,N/A
"by
WGAN-GP
[117] across an
action.
GANs
[113] to improve
image quality
ResNet18
[133]
Able
to
repli-
cate the original
images
to
a
large
extent,
and
better
resemblance
to
the
origi-
nal
image
as
compared
to
SPIRAL
[98]
with same num-
ber
of
brush
strokes.
MNIST
[202],
SVHN
[276],
CelebA
[235]
and
ImageNet
[320].
Code
Guiding
medical
robots
[129]
2020
Double-
DQN,
Duel-DQN
5
actions:
up, down,
left,
right
and stop
State:
probe
position.
Re-
ward:
Move
closer:
0.05,
Move
away:
-0.1,
Correct
stop:",N/A,N/A
"Move
closer:
0.05,
Move
away:
-0.1,
Correct
stop:
1.0,
In-
correct
stop:
-0.25.
ResNet18
[133]
Higher % of pol-
icy
correctness
and reachability
as compared to
CNN Classiﬁer,
where MS-DQN
showed the best
results
Ultrasound
Images
Dataset.
Code
Crowd
counting
[230]
2020
DQN
9
actions:
-10,
-5,
-2, -1, +1,
+2,
+5,
+10
and
end
State:
weight
vector Wt and
image
feature
vector
FVI.
Reward:
Inter-
mediate reward
and
ending
reward
VGG16
[340]
Lower/comparable
mean
squared
error
(MSE)
and
mean
ab-",N/A,N/A
"mean
squared
error
(MSE)
and
mean
ab-
solute
error
(MAE) as com-
pared to other
methods
like
DRSAN
[232],
PGCNet
[412],
MBTTBF [341],
S-DCNet [405],
CAN [234], etc.
The
Shang-
haiTech
(SHT)
Dataset
[423], The
UCFCC50
Dataset
[154]
and
The UCF-
QNRF
Dataset
[155].
Code
58
Automated
Exposure
bracketing
[389]
2020
Not Speci-
ﬁed
selecting
optimal
bracket-
ing
from
candidates
State: quality of
generated HDR
image. Reward:
improvement in
peak signal to
noise ratio
AlexNet
[188]
Higher
peak",N/A,N/A
"noise ratio
AlexNet
[188]
Higher
peak
signal to noise
ratio
as
com-
pared to other
methods
like
Barakat
[22],
Pourreza-
Shahri
[299],
Beek [369], etc.
Proposed
bench-
mark
dataset.
Code/data
Urban Au-
tonomous
driving
[361]
2020
Rainbow-
IQN
36 or 108
actions:
(9 × 4) or
(27 × 4),
9/27 steer-
ing and 4
throttle
State:
environ-
ment
variables
like traﬃc light,
pedestrians,
position
with
respect
to
center
lane.
Reward: gener-
ated by CARLA
waypoint API
Resnet18
[133]
Won
the
2019
camera
only",N/A,N/A
"Resnet18
[133]
Won
the
2019
camera
only
CARLA
chal-
lenge [314].
CARLA
urban
driving
simulator
[314]
Code
Mitigating
bias
in
Facial
Recog-
nition
[382]
2020
DQN
3
ac-
tions:(Margin
adjust-
ment)
staying
the
same,
shifting to
a
larger
value
and
shifting to
a
smaller
value
State:
the race
group,
current
adaptive
mar-
gin
and
bias
between
the
race group and
Caucasians.
Reward: change
in the sum of
inter-class
and
intra-class bias
Multi-
layer CNN
Proposed
al-
gorithm
had
higher
veriﬁca-
tion",N/A,N/A
"Proposed
al-
gorithm
had
higher
veriﬁca-
tion
accuracy
as compared to
other
methods
such
as
Cos-
Face [379] and
ArcFace [73].
RFW
[383]
and
proposed
novel
datasets:
BUPT-
Globalface
and
BUPT-
Balancedface
Data
Attention
mecha-
nism
to
improve
CNN per-
formance
[212]
2020
DQN [264]
Actions
are
weights
for
every
location or
channel in
the feature
map.
State:
Feature
map
at
each
intermediate
layer of model.
Reward:
pre-
dicted
by
a
LSTM model.
ResNet-
101 [133]
Improves
the
performances
of
[144],",N/A,N/A
"101 [133]
Improves
the
performances
of
[144],
[205]
and [396], which
attend on fea-
ture
channel,
spatial-channel
and
style,
respectively
ImageNet
[72]
59
Figure 17: A general DRL implementation for agent movement with visual inputs. The state
is provided by the environment based on which the agent performs movement actions to get
a new state and a reward from the environment.
Painting using an algorithm is a fantastic yet challenging task in the computer vision",N/A,N/A
"ﬁeld. An automated painting method was proposed by [149], where the authors introduced
a model-based DRL technique for this task. The speciﬁed work involved using a neural
renderer in DRL, where the agent was responsible for making a decision about the position
and color of each stroke, and making long-term decisions to organize those strokes into a
visual masterpiece. In this work, GANs [113] were employed to improve image quality at",N/A,N/A
"pixel-level and DDPG [224] was utilized for determining the policy. The authors formulated
the problem as an MDP, where the state consisted of three parts: the target image I,
the canvas on which actions (paint strokes) are performed Ct, and the time step.
The
actions corresponding to a set of parameters that controlled the position, shape, color, and
transparency of strokes, and for reward the WGAN with gradient penalty (WGAN-GP) [117]",N/A,N/A
"was used to calculate the discriminator score between the target image I and the canvas Ct,
and the change in discriminator score across an action (time-step) was used as the reward.
The agent that predicted the stroke parameters was trained in actor-critic [262] fashion with
backbone similar to Resnet18 [133], and the stroke parameters by the actor were used by
the neural renderer network to predict paint strokes. The network structure of the neural",N/A,N/A
"renderer and discriminator consisted of multiple convolutions and fully connected blocks.
A method for guiding medical robots using Ultrasound images with the help of DRL
was proposed by [129]. The authors treated the problem as an MDP where the agent takes
the Ultrasound images as input and estimates the state hence the problem became Partially
observable MDP (POMDP). They used Double-DQN and Duel-DQN for estimating Q-Values",N/A,N/A
"and ResNet18 [133] backbone for extracting feature to be used by the algorithm along with
Prioritized Replay Memory. In their implementation the action space consisted of 8 actions
(up, down, left, right, and stop), probe position as compared to the sacrum was used as the
state and the reward was calculated by considering the agent position as compared to the
target (Move closer: 0.05, Move away: -0.1, Correct stop: 1.0, Incorrect stop: -0.25). In
60",N/A,N/A
"60
their implementation, the authors proposed various architectures such as V-DQN, M-DQN,
and MS-DQN for the task and performed experimentation on Ultrasound images.
Crowd counting is considered a tricky task in computer vision and is even trickier for
humans. A DRL method for crowd counting was proposed by [230], where the authors used
sequential decision making to approach the task through RL. In the speciﬁed work, the",N/A,N/A
"authors proposed a DQN agent (LibraNet) based on the motivation of a weighing scale. In
their implementation crowd counting was modeled using a weighing scale where the agent was
responsible for adding weights on one side of the scale sequentially to balance the crowded
image on the other side. The problem of adding weights on one side of the pan for balancing
was formulated as an MDP, where state consisted weight vector Wt and image feature vector",N/A,N/A
"FVI, and the actions space was deﬁned similar to scale weighing and money system [372]
containing values (−10, −5, −2, −1, +1, +2, +5, +10, end).
For reinforcing the agent two
diﬀerent rewards: ending reward and intermediate reward were utilized, where ending reward
(following [43]) was calculated by comparing the absolute value error between the ground-
truth count and the accumulated value with the error tolerance, and three counting speciﬁc",N/A,N/A
"rewards: force ending reward, guiding reward and squeezing reward were calculated for the
intermediate rewards.
Exposure bracketing is a method used in digital photography, where one scene is captured
using multiple exposures for getting a high dynamic range (HDR) image. An RL method
for automated bracketing selection was proposed by [389]. For ﬂexible automated bracketing
selection, an exposure bracketing selection network (EBSNet) was proposed for selecting",N/A,N/A
"optimal exposure bracketing and a multi-exposure fusion network (MEFNet) for generating
an HDR image from selected exposure bracketing which consisted of 3 images. Since there is
no ground truth for the exposure bracketing selection procedure, an RL scheme was utilized
to train the agent (EBSNet). The authors also introduced a novel dataset consisting of a
single auto-exposure image that was used as input to the EBSNet, 10 images with varying",N/A,N/A
"exposures from which EBSNet generated probability distribution for 120 possible candidate
exposure bracketing (C3
10) and a reference HDR image. The reward for EBSNet was deﬁned
as the diﬀerence between peak signal-to-noise ratio between generated and reference HDR
for the current and previous iteration, and the MEFNet was trained by minimizing the
Charbonnier loss [23]. For performing the action of bracketing selection ESBNet consisted",N/A,N/A
"of a semantic branch using AlexNet [188] for feature extraction, an illumination branch
to understand the global and local illuminations by calculating a histogram of input and
feeding it to CNN layers, and a policy module to generate a probability distribution for the
candidate exposure bracketing from semantic and illumination branches. The neural network
for MEFNet was derived from HDRNet [103].
Autonomous driving in an urban environment is a challenging task, because of a large",N/A,N/A
"number of environmental variables and constraints. A DRL approach to this problem was
proposed by [361]. In their implementation, the authors proposed an end-to-end model-free
RL method, where they introduced a novel technique called Implicit Aﬀordances. For the
environment, the CARLA Simulator [80] was utilized, which provided the observations and
the training reward was obtained by using the CARLA waypoint API. In the novel implicit
61",N/A,N/A
"61
aﬀordances technique the training was broken into two phases, The ﬁrst phase included
using a Resnet18 [133] encoder to predict the state of various environment variables such
as traﬃc light, pedestrians, position with respect to the center lane, etc., and the output
features were used as a state for the RL agent, For which a modiﬁed version of Rainbow-IQN
Ape-X [136] was used. CARLA simulator accepts actions in form of continuous steering and",N/A,N/A
"throttle values, so to make it work with Rainbow-IQN which supports discrete actions, the
authors sampled steering values into 9 or 27 discrete values and throttle into 4 discrete values
(including braking), making a total of 36(9 × 4) or 108(27 × 4) actions.
Racial discrimination has been one of the hottest topics of the 21st century. To mitigate
racial discrimination in facial recognition, [382] proposed a facial recognition method using",N/A,N/A
"skewness-aware RL. According to the authors, the reason for racial bias in facial recognition
algorithms can be either due to the data or due to the algorithm, so the authors provided
two ethnicity-aware datasets, BUPT-Globalface and BUPT-Balancedface along with an RL
based race balanced network (RL-RBN). In their implementation, the authors formulated
an MDP for adaptive margin policy learning where the state consisted of three parts: the",N/A,N/A
"race group (0: Indian, 1: Asian, 2: African), current adaptive margin, and bias or the
skewness between the race group and Caucasians. A DQN was used as a policy network
that performed three actions (staying the same, shifting to a larger value, and shifting to a
smaller value) to change the adaptive margin, and accepted reward in form of change in the
sum of inter-class and intra-class bias.
Attention mechanisms are currently gaining popularity because of their powerful ability",N/A,N/A
"in eliminating uninformative parts of the input to leverage the other parts having a more
useful information. Recently, attention mechanism has been integrated into typical CNN
models at every individual layer to strengthen the intermediate outputs of each layer, in
turn improving the ﬁnal predictions for recognition in images. This model is usually trained
with a weakly supervised method, however, this optimization method may lead to sub-",N/A,N/A
"optimal weights in the attention module. Hence, [212] proposed to train attention module
by deep Q-learning with an LSTM model is trained to predict the reward, the whole process
is called Deep REinforced Attention Learning (DREAL).
Various works speciﬁed here have been summarised and compared in Table 9 and general
implementation of a DRL method to control an agents movement in an environment has
been shown in ﬁg 17 where state consists of an image frame provided by the environment,",N/A,N/A
"the DRL agent predicts actions to move the agent in the environment providing next state
and the reward is provided by the environment, for example, [142].
12
Future Perspectives
12.1
Challenge Discussion
DRL is a powerful framework, which has been successfully applied to various computer
vision applications including landmark detection, object detection, object tracking, image
registration, image segmentation, video analysis, and other computer vision applications.
62",N/A,N/A
"62
DRL has also demonstrated to be an eﬀective alternative for solving diﬃcult optimization
problems, including tuning parameters, selecting augmentation strategies, and neural archi-
tecture search (NAS). However, most approaches, that we have reviewed, assume a stationary
environment, from which observations are made. Take landmark detection as an instance,
the environment takes into account the image itself, and each state is deﬁned as an image",N/A,N/A
"patch consisting of the landmark location. In such a case, the environment is known while
the RL/DRL framework naturally accommodates a dynamic environment, that is the en-
vironment itself evolves with the state and action. Realizing the full potential of DRL for
computer vision requires solving several challenges. In this section, we would like to discuss
the challenges of DRL in computer vision for real-world systems.",N/A,N/A
"• Reward function: In most real-world applications, it is hard to deﬁne a speciﬁed
reward function because it requires the knowledge from diﬀerent domains that may
not always be available. Thus, the intermediate rewards at each time step are not
always easily computed. Furthermore, a reward function with too long delay will make
training diﬃcult. In contrast, assigning a reward for each action requires careful and
manual human design.",N/A,N/A
"manual human design.
• Continuous state and action space: Training an RL system on a continuous state
and action space is challenging because most RL algorithms, i.e. Q learning, can only
deal with discrete states and discrete action space. To address this limitation, most
existing works discretize the continuous state and action space.
• High-dimensional state and action space: Training Q-function on a high-dimensional",N/A,N/A
"action space is challenging. For this reason, existing works use low-dimensional param-
eterization, whose dimensions are typically less than 10 with an exception [184] that
uses 15-D and 25-D to model 2D and 3D registration, respectively.
• Environment is complicated: Almost all real-world systems, where we would want
to deploy DRL/RL, are partially observable and non-stationary. Currently, the ap-
proaches we have reviewed assume a stationary environment, from which observations",N/A,N/A
"are made. However, the DRL/RL framework naturally accommodates dynamic envi-
ronment, that is the environment itself evolves with the state and action. Furthermore,
those systems are often stochastic and noisy (action delay, sensor and action noise) as
compared to most simulated environments.
• Training data requirement: RL/DRL requires a large amount of training data or
expert demonstrations. Large-scale datasets with annotations are expensive and hard
to come by.",N/A,N/A
"to come by.
More details of challenges that embody diﬃculties to deploy RL/DRL in the real world
are discussed in [82]. In this work, they designed a set of experiments and analyzed their
eﬀects on common RL agents. Open-sourcing an environmental suite, realworldrl-suite [83]
is provided in this work as well.
63
12.2
DRL Recent Advances
Some advanced DRL approaches such as Inverse DRL, Multi-agent DRL, Meta DRL, and",N/A,N/A
"imitation learning are worth the attention and may promote new insights for many machine
learning and computer vision tasks.
• Inverse DRL: DRL has been successfully applied into domains where the reward
function is clearly deﬁned. However, this is limited in real-world applications because
it requires knowledge from diﬀerent domains that may not always be available. Inverse
DRL is one of the special cases of imitation learning.
An example is autonomous",N/A,N/A
"An example is autonomous
driving, the reward function should be based on all factors such as driver’s behavior,
gas consumption, time, speed, safety, driving quality, etc. In real-world scenario, it is
exhausting and hard to control all these factors. Diﬀerent from DRL, inverse DRL [278],
[4], [413], [86] a speciﬁc form of imitation learning [286], infers the reward function of an
agent, given its policy or observed behavior, thereby avoiding a manual speciﬁcation of",N/A,N/A
"its reward function. In the same problem of autonomous driving, inverse RL ﬁrst uses a
dataset collected from the human-generated driving and then approximates the reward
function. Inverse RL has been successfully applied to many domains [4]. Recently, to
analyze complex human movement and control high-dimensional robot systems, [215]
proposed an online inverse RL algorithm. [2] combined both RL and Inverse RL to
address planning problems in autonomous driving.",N/A,N/A
"address planning problems in autonomous driving.
• Multi-Agent DRL: Most of the successful DRL applications such as game[38], [376],
robotics[181], and autonomous driving [335], stock trading [206], social science [207],
etc., involve multiple players that requires a model with multi-agent. Take autonomous
driving as an instance, multi-agent DRL addresses the sequential decision-making prob-
lem which involves many autonomous agents, each of which aims to optimize its own",N/A,N/A
"utility return by interacting with the environment and other agents [40]. Learning
in a multi-agent scenario is more diﬃcult than a single-agent scenario because non-
stationarity [135], multi-dimensionality [40], credit assignment [5], etc., depend on the
multi-agent DRL approach of either fully cooperative or fully competitive. The agents
can either collaborate to optimize a long-term utility or compete so that the utility",N/A,N/A
"is summed to zero. Recent work on Multi-Agent RL pays attention to learning new
criteria or new setup [348].
• Meta DRL: As aforementioned, DRL algorithms consume large amounts of experience
in order to learn an individual task and are unable to generalize the learned policy to
newer problems.
To alleviate the data challenge, Meta-RL algorithms [330], [380]
are studied to enable agents to learn new skills from small amounts of experience.",N/A,N/A
"Recently, there is a research interest in meta RL [271], [119], [322], [303], [229], each
using a diﬀerent approach. For benchmarking and evaluation of meta RL algorithms,
[415] presented Meta-world, which is an open-source simulator consisting of 50 distinct
robotic manipulation tasks.
64
• Imitation Learning: Imitation learning is close to learning from demonstrations
which aims at training a policy to mimic an expert’s behavior given the samples col-
lected from that expert.",N/A,N/A
"lected from that expert.
Imitation learning is also considered as an alternative to
RL/DRL to solve sequential decision-making problems. Besides inverse DRL, an im-
itation learning approach as aforementioned, behavior cloning is another imitation
learning approach to train policy under supervised learning manner.
Bradly et al.
[347] presented a method for unsupervised third-person imitation learning to observe
how other humans perform and infer the task. Building on top of Deep Deterministic",N/A,N/A
"Policy Gradients and Hindsight Experience Replay, Nair et al. [272] proposed behavior
cloning Loss to increase imitating the demonstrations. Besides Q-learning, Generative
Adversarial Imitation Learning [364] proposes P-GAIL that integrates imitation learn-
ing into the policy gradient framework. P-GAIL considers both smoothness and causal
entropy in policy update by utilizing Deep P-Network [365].
Conclusion
Deep Reinforcement Learning (DRL) is nowadays the most popular technique for an artiﬁ-",N/A,N/A
"cial agent to learn closely optimal strategies by experiences. This paper aims to provide a
state-of-the-art comprehensive survey of DRL applications to a variety of decision-making
problems in the area of computer vision.
In this work, we ﬁrstly provided a structured
summarization of the theoretical foundations in Deep Learning (DL) including AutoEncoder
(AE), Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Recur-",N/A,N/A
"rent Neural Network (RNN). We then continued to introduce key techniques in RL research
including model-based methods (value functions, transaction models, policy search, return
functions) and model-free methods (value-based, policy-based, and actor-critic). Main tech-
niques in DRL were thirdly presented under two categories of model-based and model-free
approaches. We fourthly surveyed the broad-ranging applications of DRL methods in solv-",N/A,N/A
"ing problems aﬀecting areas of computer vision, from landmark detection, object detection,
object tracking, image registration, image segmentation, video analysis, and many other ap-
plications in the computer vision area. We ﬁnally discussed several challenges ahead of us in
order to realize the full potential of DRL for computer vision. Some latest advanced DRL
techniques were included in the last discussion.
65
References",N/A,N/A
"65
References
[1] Model-based contextual policy search for data-eﬃcient generalization of robot skills.
Artiﬁcial Intelligence, 247:415 – 439, 2017.
[2] Advanced planning for autonomous vehicles using reinforcement learning and deep
inverse reinforcement learning. Robotics and Autonomous Systems, 114:1 – 18, 2019.
[3] Pieter Abbeel, Adam Coates, and Andrew Y. Ng. Autonomous helicopter aerobat-
ics through apprenticeship learning. The International Journal of Robotics Research,",N/A,N/A
"29(13):1608–1639, 2010.
[4] Pieter Abbeel and Andrew Y. Ng. Apprenticeship learning via inverse reinforcement
learning.
In Proceedings of the Twenty-First International Conference on Machine
Learning, pages 1–8. Association for Computing Machinery, 2004.
[5] Adrian K. Agogino and Kagan Tumer. Unifying temporal and structural credit as-
signment problems. In Proceedings of the Third International Joint Conference on
Autonomous Agents and Multiagent Systems - Volume 2, page 980–987. IEEE Com-",N/A,N/A
"puter Society, 2004.
[6] Narges Ahmidi, Lingling Tao, Shahin Sefati, Yixin Gao, Colin Lea, Benjamin Be-
jar Haro, Luca Zappella, Sanjeev Khudanpur, Ren´e Vidal, and Gregory D Hager.
A dataset and benchmarks for segmentation and recognition of gestures in robotic
surgery. IEEE Transactions on Biomedical Engineering, 64(9):2025–2041, 2017.
[7] Walid Abdullah Al and Il Dong Yun. Partial policy-based reinforcement learning for",N/A,N/A
"anatomical landmark localization in 3d medical images. IEEE transactions on medical
imaging, 2019.
[8] Walid Abdullah Al, Il Dong Yun, and Kyong Joon Lee.
Reinforcement learning-
based automatic diagnosis of acute appendicitis in abdominal ct.
arXiv preprint
arXiv:1909.00617, 2019.
[9] Stephan Alaniz. Deep reinforcement learning with model learning and monte carlo tree
search in minecraft. In Conference on Reinforcement Learning and Decision Making,
2018.",N/A,N/A
"2018.
[10] Amir Alansary, Ozan Oktay, Yuanwei Li, Loic Le Folgoc, Benjamin Hou, Ghislain
Vaillant, Konstantinos Kamnitsas, Athanasios Vlontzos, Ben Glocker, Bernhard Kainz,
et al. Evaluating reinforcement learning agents for anatomical landmark detection.
Medical image analysis, 53:156–164, 2019.
[11] Jinwon An and Sungzoon Cho. Variational autoencoder based anomaly detection using
reconstruction probability. Special Lecture on IE, 2(1):1–18, 2015.
66",N/A,N/A
"66
[12] O. Andersson, F. Heintz, and P. Doherty.
Model-based reinforcement learning in
continuous environments using real-time constrained optimization. In AAAI, 2015.
[13] Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony
Bharath.
A
brief
survey
of
deep
reinforcement
learning.
arXiv preprint
arXiv:1708.05866, 2017.
[14] S Avinash Ramakanth and R Venkatesh Babu. Seamseg: Video object segmentation",N/A,N/A
"using patch seams. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 376–383, 2014.
[15] Morgane Ayle, Jimmy Tekli, Julia El-Zini, Boulos El-Asmar, and Mariette Awad.
Bar-a reinforcement learning agent for bounding-box automated reﬁnement.
[16] Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, and Jan Kautz.
GA3C: gpu-based A3C for deep reinforcement learning. CoRR, abs/1611.06256, 2016.",N/A,N/A
"[17] Boris Babenko, Ming-Hsuan Yang, and Serge Belongie. Visual tracking with online
multiple instance learning. In 2009 IEEE conference on computer vision and pattern
recognition, pages 983–990. IEEE, 2009.
[18] Seung-Hwan Bae and Kuk-Jin Yoon. Robust online multi-object tracking based on
tracklet conﬁdence and online discriminative appearance learning. In Proceedings of
the IEEE conference on computer vision and pattern recognition, pages 1218–1225,
2014.",N/A,N/A
"2014.
[19] Seung-Hwan Bae and Kuk-Jin Yoon. Conﬁdence-based data association and discrimi-
native deep appearance learning for robust online multi-object tracking. IEEE trans-
actions on pattern analysis and machine intelligence, 40(3):595–610, 2017.
[20] J. Bagnell. Learning decision: Robustness, uncertainty, and approximation. 04 2012.
[21] J. A. Bagnell and J. G. Schneider. Autonomous helicopter control using reinforce-",N/A,N/A
"ment learning policy search methods. In Proceedings 2001 ICRA. IEEE International
Conference on Robotics and Automation (Cat. No.01CH37164), volume 2, pages 1615–
1620, 2001.
[22] Neil Barakat, A Nicholas Hone, and Thomas E Darcie.
Minimal-bracketing sets
for high-dynamic-range image capture.
IEEE Transactions on Image Processing,
17(10):1864–1875, 2008.
[23] Jonathan T Barron. A general and adaptive robust loss function. In Proceedings of",N/A,N/A
"the IEEE Conference on Computer Vision and Pattern Recognition, pages 4331–4339,
2019.
67
[24] Cher Bass, Pyry Helkkula, Vincenzo De Paola, Claudia Clopath, and Anil An-
thony Bharath. Detection of axonal synapses in 3d two-photon images. PloS one,
12(9):e0183309, 2017.
[25] Miriam Bellver, Xavier Gir´o-i Nieto, Ferran Marqu´es, and Jordi Torres. Hierarchical
object detection with deep reinforcement learning. arXiv preprint arXiv:1611.03718,
2016.",N/A,N/A
"2016.
[26] Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term dependencies
with gradient descent is diﬃcult. IEEE Trans. Neural Networks, 5(2):157–166, 1994.
[27] P. Bergmann, M. Fauser, D. Sattlegger, and C. Steger. Mvtec ad — a comprehensive
real-world dataset for unsupervised anomaly detection. In 2019 IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR), pages 9584–9592, 2019.",N/A,N/A
"[28] Keni Bernardin and Rainer Stiefelhagen. Evaluating multiple object tracking perfor-
mance: the clear mot metrics. EURASIP Journal on Image and Video Processing,
2008:1–10, 2008.
[29] Luca Bertinetto, Jack Valmadre, Joao F Henriques, Andrea Vedaldi, and Philip HS
Torr. Fully-convolutional siamese networks for object tracking. In European conference
on computer vision, pages 850–865. Springer, 2016.
[30] Shalabh Bhatnagar. An actor–critic algorithm with function approximation for dis-",N/A,N/A
"counted cost constrained markov decision processes.
Systems & Control Letters,
59(12):760–766, 2010.
[31] Shalabh Bhatnagar, Richard S. Sutton, Mohammad Ghavamzadeh, and Mark Lee.
Natural actorˆa-critic algorithms. Automatica, 45(11):2471 – 2482, 2009.
[32] Michael J Black and Yaser Yacoob.
Tracking and recognizing rigid and non-rigid
facial motions using local parametric models of image motion. In Proceedings of IEEE
international conference on computer vision, pages 374–381. IEEE, 1995.",N/A,N/A
"[33] N Bloch, A Madabhushi, H Huisman, J Freymann, J Kirby, M Grauer, A Enquobahrie,
C Jaﬀe, L Clarke, and K Farahani. Nci-isbi 2013 challenge: automated segmentation
of prostate structures. The Cancer Imaging Archive, 370, 2015.
[34] J. Boedecker, J. T. Springenberg, J. W¨ulﬁng, and M. Riedmiller. Approximate real-
time optimal control based on sparse gaussian process models. In 2014 IEEE Sym-
posium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL),
pages 1–8, 2014.",N/A,N/A
"pages 1–8, 2014.
[35] Garrick Brazil and Xiaoming Liu. M3d-rpn: Monocular 3d region proposal network for
object detection. In Proceedings of the IEEE International Conference on Computer
Vision, Seoul, South Korea, 2019.
68
[36] Gustav Bredell, Christine Tanner, and Ender Konukoglu. Iterative interaction training
for segmentation editing networks. In International Workshop on Machine Learning
in Medical Imaging, pages 363–370. Springer, 2018.",N/A,N/A
"[37] Leo Breiman. Bagging predictors. Machine learning, 24(2):123–140, 1996.
[38] Noam Brown and Tuomas Sandholm. Superhuman ai for multiplayer poker. Science,
365(6456):885–890, 2019.
[39] Antoine Buetti-Dinh, Vanni Galli, S˜A¶ren Bellenberg, Olga Ilie, Malte Herold, Stephan
Christel, Mariia Boretska, Igor V. Pivkin, Paul Wilmes, Wolfgang Sand, Mario Vera,
and Mark Dopson. Deep neural networks outperform human expert’s capacity in char-",N/A,N/A
"acterizing bioleaching bacterial bioﬁlm composition. Biotechnology Reports, 22:e00321,
2019.
[40] L. Busoniu, R. Babuska, and B. De Schutter. A comprehensive survey of multiagent
reinforcement learning. IEEE Transactions on Systems, Man, and Cybernetics, Part
C (Applications and Reviews), 38(2):156–172, 2008.
[41] Sergi Caelles, Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Laura Leal-Taix´e, Daniel Cre-
mers, and Luc Van Gool. One-shot video object segmentation. In Proceedings of the",N/A,N/A
"IEEE conference on computer vision and pattern recognition, pages 221–230, 2017.
[42] Yunliang Cai, Said Osman, Manas Sharma, Mark Landis, and Shuo Li. Multi-modality
vertebra recognition in arbitrary views using 3d deformable hierarchical model. IEEE
transactions on medical imaging, 34(8):1676–1693, 2015.
[43] Juan C Caicedo and Svetlana Lazebnik. Active object localization with deep rein-
forcement learning. In Proceedings of the IEEE international conference on computer",N/A,N/A
"vision, pages 2488–2496, 2015.
[44] D. Carrera, F. Manganini, G. Boracchi, and E. Lanzarone. Defect detection in sem im-
ages of nanoﬁbrous materials. IEEE Transactions on Industrial Informatics, 13(2):551–
561, 2017.
[45] Boyu Chen, Dong Wang, Peixia Li, Shuang Wang, and Huchuan Lu. Real-time’actor-
critic’tracking.
In Proceedings of the European Conference on Computer Vision
(ECCV), pages 318–334, 2018.
[46] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L",N/A,N/A
"Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous
convolution, and fully connected crfs. IEEE transactions on pattern analysis and ma-
chine intelligence, 40(4):834–848, 2017.
[47] Yushi Chen, Xing Zhao, and Xiuping Jia. Spectral–spatial classiﬁcation of hyperspec-
tral data based on deep belief network. IEEE Journal of Selected Topics in Applied
Earth Observations and Remote Sensing, 8(6):2381–2392, 2015.
69",N/A,N/A
"69
[48] Jingchun Cheng, Yi-Hsuan Tsai, Shengjin Wang, and Ming-Hsuan Yang.
Segﬂow:
Joint learning for video object segmentation and optical ﬂow. In Proceedings of the
IEEE international conference on computer vision, pages 686–695, 2017.
[49] Ming-Ming Cheng, Niloy J Mitra, Xiaolei Huang, Philip HS Torr, and Shi-Min Hu.
Global contrast based salient region detection. IEEE transactions on pattern analysis
and machine intelligence, 37(3):569–582, 2014.",N/A,N/A
"and machine intelligence, 37(3):569–582, 2014.
[50] Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representa-
tions using rnn encoder-decoder for statistical machine translation.
arXiv preprint
arXiv:1406.1078, 2014.
[51] Kyunghyun Cho, Bart van Merrienboer, C¸aglar G¨ul¸cehre, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-",N/A,N/A
"decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.
[52] Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and
Jin Young Choi. Attentional correlation ﬁlter network for adaptive visual tracking. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pages
4807–4816, 2017.
[53] Wongun Choi. Near-online multi-target tracking with aggregated local ﬂow descriptor.",N/A,N/A
"In Proceedings of the IEEE international conference on computer vision, pages 3029–
3037, 2015.
[54] Jan Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, KyungHyun Cho, and Yoshua
Bengio. Attention-based models for speech recognition. CoRR, abs/1506.07503, 2015.
[55] Qi Chu, Wanli Ouyang, Hongsheng Li, Xiaogang Wang, Bin Liu, and Nenghai Yu. On-
line multi-object tracking using cnn-based single object tracker with spatial-temporal",N/A,N/A
"attention mechanism. In Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4836–4845, 2017.
[56] Wen-Hsuan Chu and Kris M. Kitani. Neural batch sampling with reinforcement learn-
ing for semi-supervised anomaly detection.
In European Conference on Computer
Vision, pages 751–766, 2020.
[57] Wen-Sheng Chu, Yale Song, and Alejandro Jaimes. Video co-summarization: Video
summarization by visual co-occurrence. In Proceedings of the IEEE Conference on",N/A,N/A
"Computer Vision and Pattern Recognition, pages 3584–3592, 2015.
[58] Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim Asfour,
and Pieter Abbeel. Model-based reinforcement learning via meta-policy optimization.
CoRR, abs/1809.05214, 2018.
70
[59] Adam Coates, Pieter Abbeel, and Andrew Y. Ng. Apprenticeship learning for heli-
copter control. Commun. ACM, 52(7):97–105, July 2009.
[60] Dorin Comaniciu, Visvanathan Ramesh, and Peter Meer. Real-time tracking of non-",N/A,N/A
"rigid objects using mean shift. In Proceedings IEEE Conference on Computer Vision
and Pattern Recognition. CVPR 2000 (Cat. No. PR00662), volume 2, pages 142–149.
IEEE, 2000.
[61] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler,
Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset
for semantic urban scene understanding. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 3213–3223, 2016.",N/A,N/A
"[62] R´emi Coulom. Eﬃcient selectivity and backup operators in monte-carlo tree search.
In Proceedings of the 5th International Conference on Computers and Games, page
72–83, 2006.
[63] Erwin Coumans and Yunfei Bai. Pybullet, a python module for physics simulation for
games, robotics and machine learning. 2016.
[64] Antonio Criminisi, Jamie Shotton, Duncan Robertson, and Ender Konukoglu. Regres-
sion forests for eﬃcient anatomy detection and localization in ct studies. In Inter-",N/A,N/A
"national MICCAI Workshop on Medical Computer Vision, pages 106–117. Springer,
2010.
[65] Tianhong Dai, Magda Dubois, Kai Arulkumaran, Jonathan Campbell, Cher Bass, Ben-
jamin Billot, Fatmatulzehra Uslu, Vincenzo De Paola, Claudia Clopath, and Anil An-
thony Bharath. Deep reinforcement learning for subpixel neural tracking. In Interna-
tional Conference on Medical Imaging with Deep Learning, pages 130–150, 2019.
[66] Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, and Michael Felsberg. Eco:",N/A,N/A
"Eﬃcient convolution operators for tracking. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 6638–6646, 2017.
[67] Martin Danelljan, Gustav Hager, Fahad Shahbaz Khan, and Michael Felsberg. Learn-
ing spatially regularized correlation ﬁlters for visual tracking. In Proceedings of the
IEEE international conference on computer vision, pages 4310–4318, 2015.
[68] Kristopher De Asis, J Fernando Hernandez-Garcia, G Zacharias Holland, and",N/A,N/A
"Richard S Sutton. Multi-step reinforcement learning: A unifying algorithm. In Thirty-
Second AAAI Conference on Artiﬁcial Intelligence, 2018.
[69] Sandra Eliza Fontes De Avila, Ana Paula Brand˜ao Lopes, Antonio da Luz Jr, and
Arnaldo de Albuquerque Ara´ujo. Vsumm: A mechanism designed to produce static
video summaries and a novel evaluation method. Pattern Recognition Letters, 32(1):56–
68, 2011.
71
[70] Antonio de Marvao, Timothy JW Dawes, Wenzhe Shi, Christopher Minas, Niall G",N/A,N/A
"Keenan, Tamara Diamond, Giuliana Durighel, Giovanni Montana, Daniel Rueckert,
Stuart A Cook, et al. Population-based studies of myocardial hypertrophy: high reso-
lution cardiovascular magnetic resonance atlases improve statistical power. Journal of
cardiovascular magnetic resonance, 16(1):16, 2014.
[71] M. P. Deisenroth, P. Englert, J. Peters, and D. Fox.
Multi-task policy search for
robotics. In 2014 IEEE International Conference on Robotics and Automation (ICRA),
pages 3876–3881, 2014.",N/A,N/A
"pages 3876–3881, 2014.
[72] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A
large-scale hierarchical image database. In 2009 IEEE conference on computer vision
and pattern recognition, pages 248–255. Ieee, 2009.
[73] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. Arcface: Additive
angular margin loss for deep face recognition. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 4690–4699, 2019.",N/A,N/A
"[74] Joachim Denzler and Dietrich WR Paulus. Active motion detection and object track-
ing. In Proceedings of 1st International Conference on Image Processing, volume 3,
pages 635–639. IEEE, 1994.
[75] B. Depraetere, M. Liu, G. Pinte, I. Grondman, and R. Babu˚A¡ka. Comparison of
model-free and model-based methods for time optimal hit control of a badminton
robot. Mechatronics, 24(8):1021 – 1030, 2014.
[76] Robert DiPietro, Colin Lea, Anand Malpani, Narges Ahmidi, S Swaroop Vedula,",N/A,N/A
"Gyusung I Lee, Mija R Lee, and Gregory D Hager. Recognizing surgical activities
with recurrent neural networks. In International conference on medical image comput-
ing and computer-assisted intervention, pages 551–558. Springer, 2016.
[77] Piotr Doll´ar, Christian Wojek, Bernt Schiele, and Pietro Perona. Pedestrian detection:
A benchmark. In 2009 IEEE Conference on Computer Vision and Pattern Recognition,
pages 304–311. IEEE, 2009.",N/A,N/A
"pages 304–311. IEEE, 2009.
[78] JeﬀDonahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini
Venugopalan, Kate Saenko, and Trevor Darrell. Long-term recurrent convolutional
networks for visual recognition and description. CoRR, abs/1411.4389, 2014.
[79] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas,
Vladimir Golkov, Patrick Van Der Smagt, Daniel Cremers, and Thomas Brox. Flownet:",N/A,N/A
"Learning optical ﬂow with convolutional networks. In Proceedings of the IEEE inter-
national conference on computer vision, pages 2758–2766, 2015.
[80] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun. Carla: An open urban driving simulator. arXiv preprint arXiv:1711.03938,
2017.
72
[81] Yong Du, Wei Wang, and Liang Wang.
Hierarchical recurrent neural network for
skeleton based action recognition. In Proceedings of the IEEE conference on computer",N/A,N/A
"vision and pattern recognition, pages 1110–1118, 2015.
[82] Gabriel Dulac-Arnold, Nir Levine, Daniel J. Mankowitz, Jerry Li, Cosmin Paduraru,
Sven Gowal, and Todd Hester. An empirical investigation of the challenges of real-
world reinforcement learning, 2020.
[83] Gabriel Dulac-Arnold, Nir Levine, Daniel J. Mankowitz, Jerry Li, Cosmin Paduraru,
Sven Gowal, and Todd Hester. An empirical investigation of the challenges of real-
world reinforcement learning. 2020.",N/A,N/A
"world reinforcement learning. 2020.
[84] Matteo Dunnhofer, Niki Martinel, Gian Luca Foresti, and Christian Micheloni. Visual
tracking by means of deep reinforcement learning and an expert demonstrator. In
Proceedings of the IEEE International Conference on Computer Vision Workshops,
pages 0–0, 2019.
[85] Chi Nhan Duong, Kha Gia Quach, Ibsa Jalata, Ngan Le, and Khoa Luu. Mobiface:
A lightweight deep learning face recognition on mobile devices. In 2019 IEEE 10th",N/A,N/A
"International Conference on Biometrics Theory, Applications and Systems (BTAS),
pages 1–6. IEEE, 2019.
[86] Chi Nhan Duong, Kha Gia Quach, Khoa Luu, T. Hoang Le, Marios Savvides, and
Tien D. Bui.
Learning from longitudinal face demonstration–where tractable deep
modeling meets inverse reinforcement learning. 127(6–7), 2019.
[87] A. El-Fakdi and M. Carreras. Policy gradient based reinforcement learning for real
autonomous underwater cable tracking. In 2008 IEEE/RSJ International Conference",N/A,N/A
"on Intelligent Robots and Systems, pages 3635–3640, 2008.
[88] Ehsan Elhamifar, Guillermo Sapiro, and Rene Vidal. See all by looking at a few: Sparse
modeling for ﬁnding representative objects. In 2012 IEEE conference on computer
vision and pattern recognition, pages 1600–1607. IEEE, 2012.
[89] Dumitru Erhan, Christian Szegedy, Alexander Toshev, and Dragomir Anguelov. Scal-
able object detection using deep neural networks. In Proceedings of the IEEE conference",N/A,N/A
"on computer vision and pattern recognition, pages 2147–2154, 2014.
[90] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew
Zisserman. The pascal visual object classes challenge 2007 (voc2007) results. 2007.
[91] Mark Everingham and John Winn. The pascal visual object classes challenge 2012
(voc2012) development kit. Pattern Analysis, Statistical Modelling and Computational
Learning, Tech. Rep, 8, 2011.
73",N/A,N/A
"Learning, Tech. Rep, 8, 2011.
73
[92] Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu,
Chunyuan Liao, and Haibin Ling. Lasot: A high-quality benchmark for large-scale
single object tracking. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 5374–5383, 2019.
[93] Heng Fan and Haibin Ling. Parallel tracking and verifying: A framework for real-time",N/A,N/A
"and high accuracy visual tracking. In Proceedings of the IEEE International Conference
on Computer Vision, pages 5486–5494, 2017.
[94] Jialue Fan, Wei Xu, Ying Wu, and Yihong Gong. Human tracking using convolutional
neural networks. IEEE Transactions on Neural Networks, 21(10):1610–1623, 2010.
[95] Chelsea Finn, Xin Yu Tan, Yan Duan, Trevor Darrell, Sergey Levine, and Pieter
Abbeel. Deep spatial autoencoders for visuomotor learning. In Danica Kragic, Anto-",N/A,N/A
"nio Bicchi, and Alessandro De Luca, editors, 2016 IEEE International Conference on
Robotics and Automation, ICRA 2016, Stockholm, Sweden, May 16-21, 2016, pages
512–519.
[96] J Michael Fitzpatrick and Jay B West. The distribution of target registration error in
rigid-body point-based registration. IEEE transactions on medical imaging, 20(9):917–
927, 2001.
[97] Vincent Fran¸cois-Lavet, Peter Henderson, Riashat Islam, Marc G Bellemare, and
Joelle Pineau.",N/A,N/A
"Joelle Pineau.
An introduction to deep reinforcement learning.
arXiv preprint
arXiv:1811.12560, 2018.
[98] Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, SM Eslami, and Oriol Vinyals. Syn-
thesizing programs for images using reinforced adversarial learning. arXiv preprint
arXiv:1804.01118, 2018.
[99] Mingfei Gao, Ruichi Yu, Ang Li, Vlad I Morariu, and Larry S Davis. Dynamic zoom-in
network for fast object detection in large images. In Proceedings of the IEEE Confer-",N/A,N/A
"ence on Computer Vision and Pattern Recognition, pages 6926–6935, 2018.
[100] Yixin Gao, S Swaroop Vedula, Carol E Reiley, Narges Ahmidi, Balakrishnan Varadara-
jan, Henry C Lin, Lingling Tao, Luca Zappella, Benjamın B´ejar, David D Yuh, et al.
Jhu-isi gesture and skill assessment working set (jigsaws): A surgical activity dataset
for human motion modeling. In Miccai workshop: M2cai, volume 3, page 3, 2014.
[101] Romane Gauriau, R´emi Cuingnet, David Lesage, and Isabelle Bloch.
Multi-organ",N/A,N/A
"Multi-organ
localization combining global-to-local regression and conﬁdence maps. In International
Conference on Medical Image Computing and Computer-Assisted Intervention, pages
337–344. Springer, 2014.
[102] A. Geiger, P. Lenz, and R. Urtasun. Are we ready for autonomous driving? the kitti
vision benchmark suite. In 2012 IEEE Conference on Computer Vision and Pattern
Recognition, pages 3354–3361, 2012.
74
[103] Micha¨el Gharbi, Jiawen Chen, Jonathan T Barron, Samuel W Hasinoﬀ, and Fr´edo",N/A,N/A
"Durand. Deep bilateral learning for real-time image enhancement. ACM Transactions
on Graphics (TOG), 36(4):1–12, 2017.
[104] Florin C Ghesu, Edward Krubasik, Bogdan Georgescu, Vivek Singh, Yefeng Zheng,
Joachim Hornegger, and Dorin Comaniciu. Marginal space deep learning: eﬃcient
architecture for volumetric image parsing.
IEEE transactions on medical imaging,
35(5):1217–1228, 2016.
[105] Florin-Cristian Ghesu, Bogdan Georgescu, Yefeng Zheng, Sasa Grbic, Andreas Maier,",N/A,N/A
"Joachim Hornegger, and Dorin Comaniciu. Multi-scale deep reinforcement learning for
real-time 3d-landmark detection in ct scans. IEEE transactions on pattern analysis
and machine intelligence, 41(1):176–189, 2017.
[106] M Giles. Mit technology review. Google researchers have reportedly achieved” quantum
supremacy” URL: https:/www.technologyreview. com/f, 614416, 2017.
[107] Justin Girard and M Reza Emami. Concurrent markov decision processes for robot",N/A,N/A
"team learning. Engineering applications of artiﬁcial intelligence, 39:223–234, 2015.
[108] Ross Girshick. Fast r-cnn. In Proceedings of the IEEE international conference on
computer vision, pages 1440–1448, 2015.
[109] Ross Girshick, JeﬀDonahue, Trevor Darrell, and Jitendra Malik. Rich feature hierar-
chies for accurate object detection and semantic segmentation. In Proceedings of the
IEEE conference on computer vision and pattern recognition, pages 580–587, 2014.",N/A,N/A
"[110] Georgia Gkioxari, Ross Girshick, and Jitendra Malik. Contextual action recognition
with r* cnn. In Proceedings of the IEEE international conference on computer vision,
pages 1080–1088, 2015.
[111] Vikash Goel, Jameson Weng, and Pascal Poupart. Unsupervised video object segmen-
tation for deep reinforcement learning. In Advances in Neural Information Processing
Systems, pages 5683–5694, 2018.
[112] Abel Gonzalez-Garcia, Alexander Vezhnevets, and Vittorio Ferrari. An active search",N/A,N/A
"strategy for eﬃcient object class detection. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 3022–3031, 2015.
[113] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In
Advances in neural information processing systems, pages 2672–2680, 2014.
[114] Leo Grady. Random walks for image segmentation. IEEE transactions on pattern",N/A,N/A
"analysis and machine intelligence, 28(11):1768–1783, 2006.
75
[115] Alex Graves, Abdel-rahman Mohamed, and Geoﬀrey E. Hinton. Speech recognition
with deep recurrent neural networks. CoRR, abs/1303.5778, 2013.
[116] Albert Gubern-M´erida, Robert Mart´ı, Jaime Melendez, Jakob L Hauth, Ritse M Mann,
Nico Karssemeijer, and Bram Platel. Automated localization of breast cancer in dce-
mri. Medical image analysis, 20(1):265–274, 2015.",N/A,N/A
"mri. Medical image analysis, 20(1):265–274, 2015.
[117] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C
Courville. Improved training of wasserstein gans. In Advances in neural information
processing systems, pages 5767–5777, 2017.
[118] Minghao Guo, Jiwen Lu, and Jie Zhou. Dual-agent deep reinforcement learning for
deformable face tracking. In Proceedings of the European Conference on Computer
Vision (ECCV), pages 768–783, 2018.",N/A,N/A
"Vision (ECCV), pages 768–783, 2018.
[119] Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, and Sergey Levine.
Meta-reinforcement learning of structured exploration strategies. In Advances in Neu-
ral Information Processing Systems, pages 5302–5311, 2018.
[120] Saurabh Gupta, Pablo Arbelaez, and Jitendra Malik. Perceptual organization and
recognition of indoor scenes from rgb-d images. In Proceedings of the IEEE Conference",N/A,N/A
"on Computer Vision and Pattern Recognition, pages 564–571, 2013.
[121] Saurabh Gupta, Ross Girshick, Pablo Arbel´aez, and Jitendra Malik. Learning rich fea-
tures from rgb-d images for object detection and segmentation. In European conference
on computer vision, pages 345–360. Springer, 2014.
[122] Michael Gygli, Helmut Grabner, Hayko Riemenschneider, and Luc Van Gool. Creating
summaries from user videos. In European conference on computer vision, pages 505–
520. Springer, 2014.",N/A,N/A
"520. Springer, 2014.
[123] Seyed Hamid Rezatoﬁghi, Anton Milan, Zhen Zhang, Qinfeng Shi, Anthony Dick, and
Ian Reid. Joint probabilistic data association revisited. In Proceedings of the IEEE
international conference on computer vision, pages 3047–3055, 2015.
[124] Junwei Han, Le Yang, Dingwen Zhang, Xiaojun Chang, and Xiaodan Liang. Reinforce-
ment cutting-agent learning for video object segmentation. In Proceedings of the IEEE",N/A,N/A
"Conference on Computer Vision and Pattern Recognition, pages 9080–9089, 2018.
[125] Robert M Haralick and Linda G Shapiro. Image segmentation techniques. Computer
vision, graphics, and image processing, 29(1):100–132, 1985.
[126] Sam Hare, Stuart Golodetz, Amir Saﬀari, Vibhav Vineet, Ming-Ming Cheng, Stephen L
Hicks, and Philip HS Torr. Struck: Structured output tracking with kernels. IEEE
transactions on pattern analysis and machine intelligence, 38(10):2096–2109, 2015.
76",N/A,N/A
"76
[127] Bharath Hariharan, Pablo Arbel´aez, Ross Girshick, and Jitendra Malik. Simultaneous
detection and segmentation. In European Conference on Computer Vision, pages 297–
312. Springer, 2014.
[128] Bharath Hariharan, Pablo Arbel´aez, Ross Girshick, and Jitendra Malik. Hypercolumns
for object segmentation and ﬁne-grained localization.
In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 447–456, 2015.",N/A,N/A
"[129] Hannes Hase, Mohammad Farid Azampour, Maria Tirindelli, Magdalini Paschali, Wal-
ter Simson, Emad Fatemizadeh, and Nassir Navab. Ultrasound-guided robotic naviga-
tion with deep reinforcement learning. arXiv preprint arXiv:2003.13321, 2020.
[130] Hado V Hasselt. Double q-learning. In Advances in neural information processing
systems, pages 2613–2621, 2010.
[131] Matthew J. Hausknecht and Peter Stone. Deep recurrent q-learning for partially ob-
servable mdps. CoRR, abs/1507.06527, 2015.",N/A,N/A
"servable mdps. CoRR, abs/1507.06527, 2015.
[132] Kaiming He, Georgia Gkioxari, Piotr Doll´ar, and Ross Girshick.
Mask r-cnn.
In
Proceedings of the IEEE international conference on computer vision, pages 2961–2969,
2017.
[133] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
for image recognition. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 770–778, 2016.",N/A,N/A
"pattern recognition, pages 770–778, 2016.
[134] Jo˜ao F Henriques, Rui Caseiro, Pedro Martins, and Jorge Batista. High-speed tracking
with kernelized correlation ﬁlters. IEEE transactions on pattern analysis and machine
intelligence, 37(3):583–596, 2014.
[135] Pablo Hernandez-Leal, Michael Kaisers, Tim Baarslag, and Enrique Munoz de Cote. A
survey of learning in multiagent environments: Dealing with non-stationarity. CoRR,
abs/1707.09183, 2017.",N/A,N/A
"abs/1707.09183, 2017.
[136] Matteo Hessel, Joseph Modayil, Hado Van Hasselt, Tom Schaul, Georg Ostrovski, Will
Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, and David Silver. Rainbow: Com-
bining improvements in deep reinforcement learning. arXiv preprint arXiv:1710.02298,
2017.
[137] Todd Hester, Michael Quinlan, and Peter Stone. A real-time model-based reinforce-
ment learning architecture for robot control. CoRR, abs/1105.1749, 2011.",N/A,N/A
"[138] Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston.
The goldilocks
principle: Reading children’s books with explicit memory representations.
CoRR,
abs/1511.02301, 2015.
77
[139] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural compu-
tation, 9(8):1735–1780, 1997.
[140] Derek Hoiem, Alexei A Efros, and Martial Hebert. Recovering surface layout from an
image. International Journal of Computer Vision, 75(1):151–172, 2007.",N/A,N/A
"[141] James B. Holliday and Ngan T.H. Le.
Follow then forage exploration: Improving
asynchronous advantage actor critic.
International Conference on Soft Computing,
Artiﬁcial Intelligence and Applications (SAI 2020), pages 107–118, 2020.
[142] Zhang-Wei Hong, Chen Yu-Ming, Shih-Yang Su, Tzu-Yun Shann, Yi-Hsiang Chang,
Hsuan-Kung Yang, Brian Hsi-Lin Ho, Chih-Chieh Tu, Yueh-Chuan Chang, Tsu-Ching
Hsiao, et al.
Virtual-to-real: Learning to control in visual semantic segmentation.",N/A,N/A
"arXiv preprint arXiv:1802.00285, 2018.
[143] Ju Hong Yoon, Chang-Ryeol Lee, Ming-Hsuan Yang, and Kuk-Jin Yoon. Online multi-
object tracking via structural constraint event aggregation. In Proceedings of the IEEE
Conference on computer vision and pattern recognition, pages 1392–1400, 2016.
[144] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In 2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 7132–7141, 2018.",N/A,N/A
"[145] Jian-Fang Hu, Wei-Shi Zheng, Jianhuang Lai, and Jianguo Zhang. Jointly learning
heterogeneous features for rgb-d activity recognition. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition, pages 5344–5352, 2015.
[146] Weiming Hu, Xi Li, Wenhan Luo, Xiaoqin Zhang, Stephen Maybank, and Zhongfei
Zhang. Single and multiple object tracking using log-euclidean riemannian subspace
and block-division appearance model. IEEE transactions on pattern analysis and ma-",N/A,N/A
"chine intelligence, 34(12):2420–2440, 2012.
[147] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely
connected convolutional networks. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 4700–4708, 2017.
[148] Lianghua Huang, Xin Zhao, and Kaiqi Huang. Got-10k: A large high-diversity bench-
mark for generic object tracking in the wild. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 2019.",N/A,N/A
"and Machine Intelligence, 2019.
[149] Zhewei Huang, Wen Heng, and Shuchang Zhou. Learning to paint with model-based
deep reinforcement learning. In Proceedings of the IEEE International Conference on
Computer Vision, pages 8709–8718, 2019.
[150] Zhiheng Huang, Wei Xu, and Kai Yu.
Bidirectional lstm-crf models for sequence
tagging. arXiv preprint arXiv:1508.01991, 2015.
78
[151] Zhiwu Huang, Chengde Wan, Thomas Probst, and Luc Van Gool. Deep learning on",N/A,N/A
"lie groups for skeleton-based action recognition. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 6099–6108, 2017.
[152] Gabriel Efrain Humpire-Mamani, Arnaud Arindra Adiyoso Setio, Bram van Ginneken,
and Colin Jacobs. Eﬃcient organ localization using multi-label convolutional neural
networks in thorax-abdomen ct scans. Physics in Medicine & Biology, 63(8):085003,
2018.",N/A,N/A
"2018.
[153] Luis Ibanez, Will Schroeder, Lydia Ng, and Josh Cates. The itk software guide: up-
dated for itk version 2.4, 2005.
[154] Haroon Idrees, Imran Saleemi, Cody Seibert, and Mubarak Shah. Multi-source multi-
scale counting in extremely dense crowd images. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 2547–2554, 2013.
[155] Haroon Idrees, Muhmmad Tayyab, Kishan Athrey, Dong Zhang, Somaya Al-Maadeed,",N/A,N/A
"Nasir Rajpoot, and Mubarak Shah. Composition loss for counting, density map esti-
mation and localization in dense crowds. In Proceedings of the European Conference
on Computer Vision (ECCV), pages 532–546, 2018.
[156] Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and
Thomas Brox. Flownet 2.0: Evolution of optical ﬂow estimation with deep networks.
In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 2462–2470, 2017.",N/A,N/A
"pages 2462–2470, 2017.
[157] Sergey Ioﬀe and Christian Szegedy. Batch normalization: Accelerating deep network
training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
[158] Cliﬀord R Jack Jr, Matt A Bernstein, Nick C Fox, Paul Thompson, Gene Alexander,
Danielle Harvey, Bret Borowski, Paula J Britson, Jennifer L. Whitwell, Chadwick
Ward, et al. The alzheimer’s disease neuroimaging initiative (adni): Mri methods.",N/A,N/A
"Journal of Magnetic Resonance Imaging: An Oﬃcial Journal of the International
Society for Magnetic Resonance in Medicine, 27(4):685–691, 2008.
[159] Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. Spatial transformer net-
works. In Advances in neural information processing systems, pages 2017–2025, 2015.
[160] Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Deep features for text spot-
ting. In European conference on computer vision, pages 512–528. Springer, 2014.",N/A,N/A
"[161] Arjit Jain, Alexander Powers, and Hans J Johnson. Robust automatic multiple land-
mark detection. In 2020 IEEE 17th International Symposium on Biomedical Imaging
(ISBI), pages 1178–1182. IEEE, 2020.
[162] Suyog Dutt Jain and Kristen Grauman. Supervoxel-consistent foreground propagation
in video. In European conference on computer vision, pages 656–671. Springer, 2014.
79
[163] Suyog Dutt Jain, Bo Xiong, and Kristen Grauman. Fusionseg: Learning to combine",N/A,N/A
"motion and appearance for fully automatic segmentation of generic objects in videos.
In 2017 IEEE conference on computer vision and pattern recognition (CVPR), pages
2117–2126. IEEE, 2017.
[164] Varun Jampani, Raghudeep Gadde, and Peter V Gehler. Video propagation networks.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 451–461, 2017.
[165] Won-Dong Jang and Chang-Su Kim. Online video object segmentation via convolu-",N/A,N/A
"tional trident network. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 5849–5858, 2017.
[166] Simon J´egou, Michal Drozdzal, David Vazquez, Adriana Romero, and Yoshua Bengio.
The one hundred layers tiramisu: Fully convolutional densenets for semantic segmenta-
tion. In Proceedings of the IEEE conference on computer vision and pattern recognition
workshops, pages 11–19, 2017.
[167] Zeyu Jia, Lin Yang, Csaba Szepesvari, and Mengdi Wang.",N/A,N/A
"Model-based reinforce-
ment learning with value-targeted regression. In Proceedings of the 2nd Conference on
Learning for Dynamics and Control, volume 120 of Proceedings of Machine Learning
Research, pages 666–686, The Cloud, 10–11 Jun 2020.
[168] Ming-xin Jiang, Chao Deng, Zhi-geng Pan, Lan-fang Wang, and Xing Sun. Multiobject
tracking in videos based on lstm and deep reinforcement learning. Complexity, 2018,
2018.",N/A,N/A
"2018.
[169] Mingxin Jiang, Tao Hai, Zhigeng Pan, Haiyan Wang, Yinjie Jia, and Chao Deng. Multi-
agent deep reinforcement learning for multi-object tracker. IEEE Access, 7:32400–
32407, 2019.
[170] Zequn Jie, Xiaodan Liang, Jiashi Feng, Xiaojie Jin, Wen Lu, and Shuicheng Yan.
Tree-structured reinforcement learning for sequential object localization. In Advances
in Neural Information Processing Systems, pages 127–135, 2016.",N/A,N/A
"[171] Oscar Jimenez-del Toro, Henning M¨uller, Markus Krenn, Katharina Gruenberg, Ab-
del Aziz Taha, Marianne Winterstein, Ivan Eggel, Antonio Foncubierta-Rodr´ıguez, Or-
cun Goksel, Andr´as Jakab, et al. Cloud-based evaluation of anatomical structure seg-
mentation and landmark detection algorithms: Visceral anatomy benchmarks. IEEE
transactions on medical imaging, 35(11):2459–2475, 2016.
[172] V Craig Jordan.
Long-term adjuvant tamoxifen therapy for breast cancer. Breast",N/A,N/A
"cancer research and treatment, 15(3):125–136, 1990.
[173] Yeong Jun Koh and Chang-Su Kim. Primary object segmentation in videos based
on region augmentation and reduction.
In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 3442–3450, 2017.
80
[174] Zdenek Kalal, Krystian Mikolajczyk, and Jiri Matas.
Tracking-learning-detection.
IEEE transactions on pattern analysis and machine intelligence, 34(7):1409–1422,
2011.",N/A,N/A
"2011.
[175] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation models. Asso-
ciation for Computational Linguistics, October 2013.
[176] Micha l Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, and Wojciech
Ja´skowski.
Vizdoom: A doom-based ai research platform for visual reinforcement
learning. In 2016 IEEE Conference on Computational Intelligence and Games (CIG),
pages 1–8. IEEE, 2016.
[177] Du Yong Kim and Moongu Jeon. Data fusion of radar and image measurements for",N/A,N/A
"multi-object tracking via kalman ﬁltering. Information Sciences, 278:641–652, 2014.
[178] Kye Kyung Kim, Soo Hyun Cho, Hae Jin Kim, and Jae Yeon Lee. Detecting and
tracking moving object using an active camera. In The 7th International Conference
on Advanced Communication Technology, 2005, ICACT 2005., volume 2, pages 817–
820. IEEE, 2005.
[179] Donna Kirwan.
Nhs fetal anomaly screening programme.
National Standards and
Guidance for England, 18(0), 2010.",N/A,N/A
"Guidance for England, 18(0), 2010.
[180] Stefan Klein, Marius Staring, Keelin Murphy, Max A Viergever, and Josien PW Pluim.
Elastix: a toolbox for intensity-based medical image registration. IEEE transactions
on medical imaging, 29(1):196–205, 2009.
[181] Jens Kober, J. Andrew Bagnell, and Jan Peters. Reinforcement learning in robotics:
A survey. The International Journal of Robotics Research, 32(11):1238–1274, 2013.",N/A,N/A
"[182] Vijay R Konda and John N Tsitsiklis. Actor-critic algorithms. In Advances in neural
information processing systems, pages 1008–1014, 2000.
[183] Philipp Kr¨ahenb¨uhl and Vladlen Koltun. Eﬃcient inference in fully connected crfs
with gaussian edge potentials. In Advances in neural information processing systems,
pages 109–117, 2011.
[184] Julian Krebs, Tommaso Mansi, Herv´e Delingette, Li Zhang, Florin C Ghesu, Shun",N/A,N/A
"Miao, Andreas K Maier, Nicholas Ayache, Rui Liao, and Ali Kamen. Robust non-
rigid registration through agent-based action learning. In International Conference
on Medical Image Computing and Computer-Assisted Intervention, pages 344–352.
Springer, 2017.
[185] Matej Kristan, Ales Leonardis, Jiri Matas, Michael Felsberg, Roman Pﬂugfelder, Luka
Cehovin Zajc, Tomas Vojir, Goutam Bhat, Alan Lukezic, Abdelrahman Eldesokey,",N/A,N/A
"et al. The sixth visual object tracking vot2018 challenge results. In Proceedings of the
European Conference on Computer Vision (ECCV), pages 0–0, 2018.
81
[186] Matej Kristan, Jiri Matas, Ales Leonardis, Michael Felsberg, Luka Cehovin, Gustavo
Fernandez, Tomas Vojir, Gustav Hager, Georg Nebehay, and Roman Pﬂugfelder. The
visual object tracking vot2015 challenge results. In Proceedings of the IEEE interna-
tional conference on computer vision workshops, pages 1–23, 2015.",N/A,N/A
"[187] Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with
deep convolutional neural networks.
In Advances in neural information processing
systems, pages 1097–1105, 2012.
[188] Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with
deep convolutional neural networks. Communications of the ACM, 60(6):84–90, 2017.
[189] A. Kupcsik, M. Deisenroth, Jan Peters, and G. Neumann. Data-eﬃcient generalization",N/A,N/A
"of robot skills with contextual policy search. In AAAI, 2013.
[190] Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, and Pieter Abbeel. Model-
ensemble trust-region policy optimization. 02 2018.
[191] Ngan Le, Trung Le, Kashu Yamazaki, Toan Duc Bui, Khoa Luu, and Marios Savides.
Oﬀset curves loss for imbalanced problem in medical segmentation. arXiv preprint
arXiv:2012.02463, 2020.
[192] Ngan Le, Kashu Yamazaki, Dat Truong, Kha Gia Quach, and Marios Savvides. A",N/A,N/A
"multi-task contextual atrous residual network for brain tumor detection & segmenta-
tion. arXiv preprint arXiv:2012.02073, 2020.
[193] T Hoang Ngan Le, Chi Nhan Duong, Ligong Han, Khoa Luu, Kha Gia Quach, and
Marios Savvides. Deep contextual recurrent residual networks for scene labeling. Pat-
tern Recognition, 80:32–41, 2018.
[194] T Hoang Ngan Le, Kha Gia Quach, Khoa Luu, Chi Nhan Duong, and Marios Sav-
vides. Reformulating level sets as deep recurrent neural network approach to semantic",N/A,N/A
"segmentation. IEEE Transactions on Image Processing, 27(5):2393–2407, 2018.
[195] Colin Lea, Michael D Flynn, Rene Vidal, Austin Reiter, and Gregory D Hager. Tem-
poral convolutional networks for action segmentation and detection. In proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition, pages 156–165,
2017.
[196] Colin Lea, Austin Reiter, Ren´e Vidal, and Gregory D Hager. Segmental spatiotempo-",N/A,N/A
"ral cnns for ﬁne-grained action segmentation. In European Conference on Computer
Vision, pages 36–52. Springer, 2016.
[197] Colin Lea, Ren´e Vidal, and Gregory D Hager. Learning convolutional action primitives
for ﬁne-grained action recognition. In 2016 IEEE international conference on robotics
and automation (ICRA), pages 1642–1649. IEEE, 2016.
82
[198] Colin Lea, Rene Vidal, Austin Reiter, and Gregory D Hager. Temporal convolutional",N/A,N/A
"networks: A uniﬁed approach to action segmentation. In European Conference on
Computer Vision, pages 47–54. Springer, 2016.
[199] Laura Leal-Taix´e, Cristian Canton-Ferrer, and Konrad Schindler. Learning by tracking:
Siamese cnn for robust target association. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition Workshops, pages 33–40, 2016.
[200] Laura Leal-Taix´e, Michele Fenzi, Alina Kuznetsova, Bodo Rosenhahn, and Silvio",N/A,N/A
"Savarese. Learning an image-based motion context for multiple people tracking. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 3542–3549, 2014.
[201] Laura Leal-Taix´e, Anton Milan, Ian Reid, Stefan Roth, and Konrad Schindler.
Motchallenge 2015: Towards a benchmark for multi-target tracking. arXiv preprint
arXiv:1504.01942, 2015.
[202] Yann LeCun.
The mnist database of handwritten digits.
http://yann. lecun.
com/exdb/mnist/, 1998.",N/A,N/A
"http://yann. lecun.
com/exdb/mnist/, 1998.
[203] Yann LeCun, L´eon Bottou, Genevieve B Orr, and Klaus-Robert M¨uller.
Eﬃcient
backprop. In Neural networks: Tricks of the trade, pages 9–50. Springer, 1998.
[204] Yann LeCun, D Touresky, G Hinton, and T Sejnowski. A theoretical framework for
back-propagation.
In Proceedings of the 1988 connectionist models summer school,
pages 21–28. CMU, Pittsburgh, Pa: Morgan Kaufmann, 1988.",N/A,N/A
"[205] Hyunjae Lee, Hyo-Eun Kim, and Hyeonseob Nam. Srm: A style-based recalibration
module for convolutional neural networks. pages 1854–1862, 10 2019.
[206] Jae Won Lee, Jonghun Park, Jangmin O, Jongwoo Lee, and Euyseok Hong. A multi-
agent approach to q-learning for daily stock trading. Trans. Sys. Man Cyber. Part A,
37(6):864–877, November 2007.
[207] Joel Z. Leibo, Vin´ıcius Flores Zambaldi, Marc Lanctot, Janusz Marecki, and Thore",N/A,N/A
"Graepel. Multi-agent reinforcement learning in sequential social dilemmas. CoRR,
abs/1702.03037, 2017.
[208] Sergey Levine and Vladlen Koltun. Learning complex neural network policies with tra-
jectory optimization. In Proceedings of the 31st International Conference on Machine
Learning, pages 829–837, 2014.
[209] Bo Li, Junjie Yan, Wei Wu, Zheng Zhu, and Xiaolin Hu. High performance visual
tracking with siamese region proposal network. In Proceedings of the IEEE Conference",N/A,N/A
"on Computer Vision and Pattern Recognition, pages 8971–8980, 2018.
83
[210] Buyu Li, Wanli Ouyang, Lu Sheng, Xingyu Zeng, and Xiaogang Wang. GS3D: an
eﬃcient 3d object detection framework for autonomous driving. In IEEE Conference
on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA,
June 16-20, 2019, pages 1019–1028. Computer Vision Foundation / IEEE, 2019.
[211] Chao Li, Qiaoyong Zhong, Di Xie, and Shiliang Pu. Co-occurrence feature learning",N/A,N/A
"from skeleton data for action recognition and detection with hierarchical aggregation.
arXiv preprint arXiv:1804.06055, 2018.
[212] Duo Li and Qifeng Chen. Deep reinforced attention learning for quality-aware visual
recognition. In European Conference on Computer Vision, pages 493–509, 2020.
[213] Guanbin Li and Yizhou Yu. Visual saliency based on multiscale deep features. arXiv
preprint arXiv:1503.08663, 2015.",N/A,N/A
"preprint arXiv:1503.08663, 2015.
[214] Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. A hierarchical neural autoencoder
for paragraphs and documents. CoRR, abs/1506.01057, 2015.
[215] K. Li, M. Rath, and J. W. Burdick. Inverse reinforcement learning via function ap-
proximation for clinical motion analysis. In 2018 IEEE International Conference on
Robotics and Automation (ICRA), pages 610–617, 2018.
[216] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit",N/A,N/A
"approach to personalized news article recommendation. In Proceedings of the 19th
international conference on World wide web, pages 661–670, 2010.
[217] Peixia Li, Dong Wang, Lijun Wang, and Huchuan Lu. Deep visual tracking: Review
and experimental comparison. Pattern Recognition, 76:323–338, 2018.
[218] Yingbo Li and Bernard Merialdo. Multi-video summarization based on video-mmr. In
11th International Workshop on Image Analysis for Multimedia Interactive Services",N/A,N/A
"WIAMIS 10, pages 1–4. IEEE, 2010.
[219] Yuanwei Li, Amir Alansary, Juan J Cerrolaza, Bishesh Khanal, Matthew Sinclair,
Jacqueline Matthew, Chandni Gupta, Caroline Knight, Bernhard Kainz, and Daniel
Rueckert. Fast multiple landmark localisation using a patch-based iterative network.
In International Conference on Medical Image Computing and Computer-Assisted In-
tervention, pages 563–571. Springer, 2018.
[220] Pengpeng Liang, Erik Blasch, and Haibin Ling. Encoding color information for vi-",N/A,N/A
"sual tracking: Algorithms and benchmark. IEEE Transactions on Image Processing,
24(12):5630–5644, 2015.
[221] Rui Liao, Shun Miao, Pierre de Tournemire, Sasa Grbic, Ali Kamen, Tommaso Mansi,
and Dorin Comaniciu. An artiﬁcial agent for robust image registration. In Thirty-First
AAAI Conference on Artiﬁcial Intelligence, 2017.
84
[222] Xuan Liao, Wenhao Li, Qisen Xu, Xiangfeng Wang, Bo Jin, Xiaoyun Zhang, Yanfeng
Wang, and Ya Zhang. Iteratively-reﬁned interactive 3d medical image segmentation",N/A,N/A
"with multi-agent reinforcement learning. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 9394–9402, 2020.
[223] Timothy P. Lillicrap, Jonathan J. Hunt, Alexand er Pritzel, Nicolas Heess, Tom Erez,
Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with deep rein-
forcement learning. arXiv e-prints, page arXiv:1509.02971, September 2015.
[224] Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez,",N/A,N/A
"Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with deep rein-
forcement learning. arXiv preprint arXiv:1509.02971, 2015.
[225] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll´ar. Focal loss
for dense object detection. In Proceedings of the IEEE international conference on
computer vision, pages 2980–2988, 2017.
[226] Tony Lindeberg. Scale-space theory in computer vision, volume 256. Springer Science
& Business Media, 2013.",N/A,N/A
"& Business Media, 2013.
[227] Geert Litjens, Robert Toth, Wendy van de Ven, Caroline Hoeks, Sjoerd Kerkstra,
Bram van Ginneken, Graham Vincent, Gwenael Guillard, Neil Birbeck, Jindang Zhang,
et al. Evaluation of prostate segmentation algorithms for mri: the promise12 challenge.
Medical image analysis, 18(2):359–373, 2014.
[228] Daochang Liu and Tingting Jiang. Deep reinforcement learning for surgical gesture
segmentation and classiﬁcation. In International conference on medical image comput-",N/A,N/A
"ing and computer-assisted intervention, pages 247–255. Springer, 2018.
[229] Hao Liu, Richard Socher, and Caiming Xiong.
Taming maml: Eﬃcient unbiased
meta-reinforcement learning. In International Conference on Machine Learning, pages
4061–4071, 2019.
[230] Liang Liu, Hao Lu, Hongwei Zou, Haipeng Xiong, Zhiguo Cao, and Chunhua Shen.
Weighing counts: Sequential crowd counting by reinforcement learning. 2020.",N/A,N/A
"[231] Lijie Liu, Chufan Wu, Jiwen Lu, Lingxi Xie, Jie Zhou, and Qi Tian. Reinforced axial
reﬁnement network for monocular 3d object detection. In European Conference on
Computer Vision ECCV, pages 540–556, 2020.
[232] Lingbo Liu, Hongjun Wang, Guanbin Li, Wanli Ouyang, and Liang Lin. Crowd count-
ing using deep recurrent spatial-aware network. arXiv preprint arXiv:1807.00601, 2018.
[233] Tianrui Liu, Qingjie Meng, Athanasios Vlontzos, Jeremy Tan, Daniel Rueckert, and",N/A,N/A
"Bernhard Kainz. Ultrasound video summarization using deep reinforcement learning.
arXiv preprint arXiv:2005.09531, 2020.
85
[234] Weizhe Liu, Mathieu Salzmann, and Pascal Fua. Context-aware crowd counting. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 5099–5108, 2019.
[235] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes
in the wild. In Proceedings of the IEEE international conference on computer vision,",N/A,N/A
"pages 3730–3738, 2015.
[236] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for
semantic segmentation. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 3431–3440, 2015.
[237] Marco Lorenzi, Nicholas Ayache, Giovanni B Frisoni, Xavier Pennec, Alzheimer’s Dis-
ease Neuroimaging Initiative (ADNI, et al. Lcc-demons: a robust and accurate sym-
metric diﬀeomorphic registration algorithm. NeuroImage, 81:470–483, 2013.",N/A,N/A
"[238] Tayebeh Lotﬁ, Lisa Tang, Shawn Andrews, and Ghassan Hamarneh. Improving prob-
abilistic image registration via reinforcement learning and uncertainty evaluation. In
International Workshop on Machine Learning in Medical Imaging, pages 187–194.
Springer, 2013.
[239] David G Lowe. Distinctive image features from scale-invariant keypoints. International
journal of computer vision, 60(2):91–110, 2004.
[240] Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou",N/A,N/A
"Wang. End-to-end active object tracking via reinforcement learning. arXiv preprint
arXiv:1705.10561, 2017.
[241] Thang Luong, Ilya Sutskever, Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. Ad-
dressing the rare word problem in neural machine translation. CoRR, abs/1410.8206,
2014.
[242] Khoa Luu, Chenchen Zhu, Chandrasekhar Bhagavatula, T Hoang Ngan Le, and Marios
Savvides.
A deep learning approach to joint face detection and segmentation.
In",N/A,N/A
"In
Advances in Face Detection and Facial Image Analysis, pages 1–12. Springer, 2016.
[243] Chao Ma, Jia-Bin Huang, Xiaokang Yang, and Ming-Hsuan Yang. Hierarchical convo-
lutional features for visual tracking. In Proceedings of the IEEE international confer-
ence on computer vision, pages 3074–3082, 2015.
[244] Kai Ma, Jiangping Wang, Vivek Singh, Birgi Tamersoy, Yao-Jen Chang, Andreas
Wimmer, and Terrence Chen. Multimodal image registration with deep context re-",N/A,N/A
"inforcement learning. In International Conference on Medical Image Computing and
Computer-Assisted Intervention, pages 240–248. Springer, 2017.
86
[245] Behrooz Mahasseni, Michael Lam, and Sinisa Todorovic. Unsupervised video sum-
marization with adversarial lstm networks. In Proceedings of the IEEE conference on
Computer Vision and Pattern Recognition, pages 202–211, 2017.
[246] Gabriel Maicas, Gustavo Carneiro, Andrew P Bradley, Jacinto C Nascimento, and",N/A,N/A
"Ian Reid. Deep reinforcement learning for active breast lesion detection from dce-
mri. In International conference on medical image computing and computer-assisted
intervention, pages 665–673. Springer, 2017.
[247] Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, and Alan L. Yuille. Deep captioning with
multimodal recurrent neural networks (m-rnn). CoRR, abs/1412.6632, 2014.
[248] Nicolas M¨arki, Federico Perazzi, Oliver Wang, and Alexander Sorkine-Hornung. Bilat-",N/A,N/A
"eral space video segmentation. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 743–751, 2016.
[249] T. Martinez-Marin and T. Duckett.
Fast reinforcement learning for vision-guided
mobile robots. In Proceedings of the 2005 IEEE International Conference on Robotics
and Automation, pages 4170–4175, 2005.
[250] Jan Matas, Stephen James, and Andrew J Davison. Sim-to-real reinforcement learning",N/A,N/A
"for deformable object manipulation. arXiv preprint arXiv:1806.07851, 2018.
[251] Stefan Mathe, Aleksis Pirinen, and Cristian Sminchisescu. Reinforcement learning for
visual object detection. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 2894–2902, 2016.
[252] George K Matsopoulos, Nicolaos A Mouravliansky, Konstantinos K Delibasis, and
Konstantina S Nikita. Automatic retinal image registration scheme using global opti-",N/A,N/A
"mization techniques. IEEE Transactions on Information Technology in Biomedicine,
3(1):47–60, 1999.
[253] Darryl McClymont, Andrew Mehnert, Adnan Trakic, Dominic Kennedy, and Stuart
Crozier. Fully automatic lesion segmentation in breast mri using mean-shift and graph-
cuts on a region adjacency graph. Journal of Magnetic Resonance Imaging, 39(4):795–
804, 2014.
[254] Bjoern H Menze, Andras Jakab, Stefan Bauer, Jayashree Kalpathy-Cramer, Keyvan",N/A,N/A
"Farahani, Justin Kirby, Yuliya Burren, Nicole Porz, Johannes Slotboom, Roland Wiest,
et al. The multimodal brain tumor image segmentation benchmark (brats). IEEE
transactions on medical imaging, 34(10):1993–2024, 2014.
[255] Shun Miao, Rui Liao, Marcus Pﬁster, Li Zhang, and Vincent Ordy. System and method
for 3-d/3-d registration between non-contrast-enhanced cbct and contrast-enhanced ct
for abdominal aortic aneurysm stenting. In International Conference on Medical Image",N/A,N/A
"Computing and Computer-Assisted Intervention, pages 380–387. Springer, 2013.
87
[256] Shun Miao, Z Jane Wang, and Rui Liao. A cnn regression approach for real-time 2d/3d
registration. IEEE transactions on medical imaging, 35(5):1352–1363, 2016.
[257] Tomas Mikolov, Stefan Kombrink, Luk´as Burget, Jan Cernock´y, and Sanjeev Khu-
danpur. Extensions of recurrent neural network language model. In ICASSP, pages
5528–5531, 2011.",N/A,N/A
"5528–5531, 2011.
[258] Anton Milan, Laura Leal-Taix´e, Ian Reid, Stefan Roth, and Konrad Schindler. Mot16:
A benchmark for multi-object tracking. arXiv preprint arXiv:1603.00831, 2016.
[259] Anton Milan, Laura Leal-Taix´e, Konrad Schindler, and Ian Reid. Joint tracking and
segmentation of multiple targets. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 5397–5406, 2015.
[260] Anton Milan, S Hamid Rezatoﬁghi, Anthony Dick, Ian Reid, and Konrad Schindler.",N/A,N/A
"Online multi-target tracking using recurrent neural networks. In Thirty-First AAAI
Conference on Artiﬁcial Intelligence, 2017.
[261] Shervin Minaee, AmirAli Abdolrashidi, Hang Su, Mohammed Bennamoun, and David
Zhang. Biometric recognition using deep learning: A survey. CoRR, abs/1912.00271,
2019.
[262] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods",N/A,N/A
"for deep reinforcement learning. In International conference on machine learning, pages
1928–1937, 2016.
[263] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods
for deep reinforcement learning. In Proceedings of The 33rd International Conference
on Machine Learning, pages 1928–1937, 20–22 Jun 2016.
[264] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,",N/A,N/A
"Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Os-
trovski, et al.
Human-level control through deep reinforcement learning.
Nature,
518(7540):529–533, 2015.
[265] I. Mordatch, N. Mishra, C. Eppner, and P. Abbeel. Combining model-based policy
search with online model learning for control of physical humanoids. In 2016 IEEE
International Conference on Robotics and Automation (ICRA), pages 242–248, 2016.
[266] J. Morimoto, G. Zeglin, and C. G. Atkeson.",N/A,N/A
"[266] J. Morimoto, G. Zeglin, and C. G. Atkeson.
Minimax diﬀerential dynamic pro-
gramming: application to a biped walking robot.
In Proceedings 2003 IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS 2003) (Cat.
No.03CH37453), volume 2, pages 1927–1932, 2003.
88
[267] Jun Morimoto and Christopher G. Atkeson. Nonparametric representation of an ap-
proximated poincar´e map for learning biped locomotion. In Autonomous Robots, page
131–144, 2009.",N/A,N/A
"131–144, 2009.
[268] A. Mousavian, D. Anguelov, J. Flynn, and J. Koˇseck´a. 3d bounding box estimation
using deep learning and geometry. In 2017 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pages 5632–5640, 2017.
[269] Matthias Mueller, Neil Smith, and Bernard Ghanem. A benchmark and simulator for
uav tracking. In European conference on computer vision, pages 445–461. Springer,
2016.
[270] Don Murray and Anup Basu. Motion tracking with an active camera. IEEE transac-",N/A,N/A
"tions on pattern analysis and machine intelligence, 16(5):449–459, 1994.
[271] Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald S Fearing, Pieter Abbeel, Sergey
Levine, and Chelsea Finn. Learning to adapt in dynamic, real-world environments
through meta-reinforcement learning. arXiv preprint arXiv:1803.11347, 2018.
[272] A. Nair, B. McGrew, M. Andrychowicz, W. Zaremba, and P. Abbeel. Overcoming
exploration in reinforcement learning with demonstrations. In 2018 IEEE International",N/A,N/A
"Conference on Robotics and Automation (ICRA), pages 6292–6299, 2018.
[273] Hyeonseob Nam and Bohyung Han. Learning multi-domain convolutional neural net-
works for visual tracking. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 4293–4302, 2016.
[274] Ali Bou Nassif, Ismail Shahin, Imtinan Attili, Mohammad Azzeh, and Khaled Shaalan.
Speech recognition using deep neural networks: A systematic review. IEEE Access,
7:19143–19165, 2019.",N/A,N/A
"7:19143–19165, 2019.
[275] Fernando Navarro, Anjany Sekuboyina, Diana Waldmannstetter, Jan C Peeken,
Stephanie E Combs, and Bjoern H Menze.
Deep reinforcement learning for organ
localization in ct. arXiv preprint arXiv:2005.04974, 2020.
[276] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y
Ng. Reading digits in natural images with unsupervised feature learning. 2011.
[277] Dominik Neumann, Saˇsa Grbi´c, Matthias John, Nassir Navab, Joachim Hornegger, and",N/A,N/A
"Razvan Ionasec. Probabilistic sparse matching for robust 3d/3d fusion in minimally
invasive surgery. IEEE transactions on medical imaging, 34(1):49–60, 2014.
[278] Andrew Y. Ng and Stuart J. Russell. Algorithms for inverse reinforcement learning. In
Proceedings of the Seventeenth International Conference on Machine Learning, ICML
’00, page 663–670, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc.
89",N/A,N/A
"89
[279] Andrew Y Ng, Stuart J Russell, et al. Algorithms for inverse reinforcement learning.
In Icml, volume 1, page 2, 2000.
[280] Trung Thanh Nguyen, Zhuoru Li, Tomi Silander, and Tze-Yun Leong. Online feature
selection for model-based reinforcement learning. In Proceedings of the 30th Inter-
national Conference on International Conference on Machine Learning - Volume 28,
page I–498–I–506, 2013.
[281] Chi Nhan Duong, Kha Gia Quach, Khoa Luu, Ngan Le, and Marios Savvides. Tem-",N/A,N/A
"poral non-volume preserving approach to facial age-progression and age-invariant face
recognition. In Proceedings of the IEEE International Conference on Computer Vision,
pages 3735–3743, 2017.
[282] C. Niedzwiedz, I. Elhanany, Zhenzhen Liu, and S. Livingston. A consolidated actor-
critic model with function approximation for high-dimensional pomdps.
In AAAI
2008Workshop for Advancement in POMDP Solvers, 2008.
[283] Yishuang Ning, Sheng He, Zhiyong Wu, Chunxiao Xing, and Liang-Jie Zhang.
A",N/A,N/A
"A
review of deep learning based speech synthesis. Applied Sciences, 9(19), 2019.
[284] Kenji Okuma, Ali Taleghani, Nando De Freitas, James J Little, and David G Lowe. A
boosted particle ﬁlter: Multitarget detection and tracking. In European conference on
computer vision, pages 28–39. Springer, 2004.
[285] Jos´e Ignacio Orlando, Huazhu Fu, Jo˜ao Barbosa Breda, Karel van Keer, Deepti R
Bathula, Andr´es Diaz-Pinto, Ruogu Fang, Pheng-Ann Heng, Jeyoung Kim, JoonHo",N/A,N/A
"Lee, et al. Refuge challenge: A uniﬁed framework for evaluating automated methods
for glaucoma assessment from fundus photographs. Medical image analysis, 59:101570,
2020.
[286] T. Osa, J. Pajarinen, G. Neumann, J. A. Bagnell, P. Abbeel, and J. Peters. 2018.
[287] Rameswar Panda, Abir Das, Ziyan Wu, Jan Ernst, and Amit K Roy-Chowdhury.
Weakly supervised summarization of web videos. In Proceedings of the IEEE Interna-
tional Conference on Computer Vision, pages 3657–3666, 2017.",N/A,N/A
"[288] Anestis Papazoglou and Vittorio Ferrari. Fast object segmentation in unconstrained
video. In Proceedings of the IEEE international conference on computer vision, pages
1777–1784, 2013.
[289] I. C. Paschalidis, K. Li, and R. Moazzez Estanjini. An actor-critic method using least
squares temporal diﬀerence learning. In Proceedings of the 48h IEEE Conference on
Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference,
pages 2564–2569, 2009.
90",N/A,N/A
"pages 2564–2569, 2009.
90
[290] Massimiliano Patacchiola and Angelo Cangelosi. Head pose estimation in the wild using
convolutional neural networks and adaptive gradient methods. Pattern Recognition,
71:132–143, 2017.
[291] Hanchuan Peng, Zongcai Ruan, Fuhui Long, Julie H Simpson, and Eugene W Myers.
V3d enables real-time 3d visualization and quantitative analysis of large-scale biological
image data sets. Nature biotechnology, 28(4):348–353, 2010.",N/A,N/A
"[292] Federico Perazzi, Anna Khoreva, Rodrigo Benenson, Bernt Schiele, and Alexander
Sorkine-Hornung. Learning video object segmentation from static images. In Pro-
ceedings of the IEEE conference on computer vision and pattern recognition, pages
2663–2672, 2017.
[293] Federico Perazzi, Jordi Pont-Tuset, Brian McWilliams, Luc Van Gool, Markus Gross,
and Alexander Sorkine-Hornung. A benchmark dataset and evaluation methodology",N/A,N/A
"for video object segmentation. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 724–732, 2016.
[294] Jan Peters and Stefan Schaal.
Reinforcement learning of motor skills with policy
gradients. Neural Networks, 21(4):682 – 697, 2008.
[295] Aleksis Pirinen and Cristian Sminchisescu. Deep reinforcement learning of region pro-
posal networks for object detection. In Proceedings of the IEEE Conference on Com-",N/A,N/A
"puter Vision and Pattern Recognition, pages 6945–6954, 2018.
[296] Hamed Pirsiavash, Deva Ramanan, and Charless C Fowlkes. Globally-optimal greedy
algorithms for tracking a variable number of objects. In CVPR 2011, pages 1201–1208.
IEEE, 2011.
[297] Aske Plaat, Walter Kosters, and Mike Preuss. Deep model-based reinforcement learn-
ing for high-dimensional problems, a survey, 2020.
[298] Danila Potapov, Matthijs Douze, Zaid Harchaoui, and Cordelia Schmid. Category-",N/A,N/A
"speciﬁc video summarization. In European conference on computer vision, pages 540–
555. Springer, 2014.
[299] Reza Pourreza-Shahri and Nasser Kehtarnavaz. Exposure bracketing via automatic ex-
posure selection. In 2015 IEEE International Conference on Image Processing (ICIP),
pages 320–323. IEEE, 2015.
[300] Alessandro Prest, Christian Leistner, Javier Civera, Cordelia Schmid, and Vittorio
Ferrari. Learning object class detectors from weakly annotated video. In 2012 IEEE",N/A,N/A
"Conference on Computer Vision and Pattern Recognition, pages 3282–3289. IEEE,
2012.
91
[301] Yuankai Qi, Shengping Zhang, Lei Qin, Hongxun Yao, Qingming Huang, Jongwoo Lim,
and Ming-Hsuan Yang. Hedged deep tracking. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 4303–4311, 2016.
[302] Zengyi Qin, Jinglu Wang, and Yan Lu. Monogrnet: A geometric reasoning network for
monocular 3d object localization. Proceedings of the AAAI Conference on Artiﬁcial",N/A,N/A
"Intelligence, 33(01):8851–8858, Jul. 2019.
[303] Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen. Ef-
ﬁcient oﬀ-policy meta-reinforcement learning via probabilistic context variables. In
International conference on machine learning, pages 5331–5340, 2019.
[304] Vidhiwar Singh Rathour, Kashu Yamakazi, and T Le. Roughness index and roughness
distance for benchmarking medical segmentation. arXiv preprint arXiv:2103.12350,
2021.",N/A,N/A
"2021.
[305] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once:
Uniﬁed, real-time object detection. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 779–788, 2016.
[306] Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv preprint
arXiv:1804.02767, 2018.
[307] Liangliang Ren, Jiwen Lu, Zifeng Wang, Qi Tian, and Jie Zhou. Collaborative deep",N/A,N/A
"reinforcement learning for multi-object tracking. In Proceedings of the European Con-
ference on Computer Vision (ECCV), pages 586–602, 2018.
[308] Liangliang Ren, Xin Yuan, Jiwen Lu, Ming Yang, and Jie Zhou. Deep reinforcement
learning with iterative shift for visual tracking. In Proceedings of the European Con-
ference on Computer Vision (ECCV), pages 684–700, 2018.
[309] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-",N/A,N/A
"time object detection with region proposal networks. In Advances in neural information
processing systems, pages 91–99, 2015.
[310] Md Reza, Jana Kosecka, et al. Reinforcement learning for semantic segmentation in
indoor scenes. arXiv preprint arXiv:1606.01178, 2016.
[311] Alexander Richard and Juergen Gall. Temporal action detection using a statistical
language model.
In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 3131–3140, 2016.",N/A,N/A
"Pattern Recognition, pages 3131–3140, 2016.
[312] Mrigank Rochan, Linwei Ye, and Yang Wang. Video summarization using fully convo-
lutional sequence networks. In Proceedings of the European Conference on Computer
Vision (ECCV), pages 347–363, 2018.
92
[313] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks
for biomedical image segmentation.
In International Conference on Medical image
computing and computer-assisted intervention, pages 234–241. Springer, 2015.",N/A,N/A
"[314] German Ros, Vladfen Koltun, Felipe Codevilla, and Antonio Lopez. The carla au-
tonomous driving challenge, 2019.
[315] Carsten Rother, Vladimir Kolmogorov, and Andrew Blake.
” grabcut” interactive
foreground extraction using iterated graph cuts. ACM transactions on graphics (TOG),
23(3):309–314, 2004.
[316] David Rotman. Mit technology review. Retrieved from Meet the Man with a Cheap and
Easy Plan to Stop Global Warming: http://www. technologyreview. com/featuredstor",N/A,N/A
"y/511016/a-cheap-and-easy-plan-to-stop-globalwarming, 2013.
[317] J-M Rouet, J-J Jacq, and Christian Roux. Genetic algorithms for a robust 3-d mr-ct
registration. IEEE transactions on information technology in biomedicine, 4(2):126–
136, 2000.
[318] David E Rumelhart.
The architecture of mind: A connectionist approach.
Mind
readings, pages 207–238, 1998.
[319] T. P. Runarsson and S. M. Lucas. Imitating play from game trajectories: Temporal",N/A,N/A
"diﬀerence learning versus preference learning. In 2012 IEEE Conference on Computa-
tional Intelligence and Games (CIG), pages 79–82, 2012.
[320] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet
large scale visual recognition challenge. International Journal of Computer Vision,
115(3):211–252, 2015.
[321] Amir Sadeghian, Alexandre Alahi, and Silvio Savarese.
Tracking the untrackable:",N/A,N/A
"Tracking the untrackable:
Learning to track multiple cues with long-term dependencies. In Proceedings of the
IEEE International Conference on Computer Vision, pages 300–311, 2017.
[322] Steind´or Sæmundsson, Katja Hofmann, and Marc Peter Deisenroth.
Meta re-
inforcement learning with latent variable gaussian processes.
arXiv preprint
arXiv:1803.07551, 2018.
[323] Farhang Sahba.
Deep reinforcement learning for object segmentation in video se-",N/A,N/A
"quences. In 2016 International Conference on Computational Science and Computa-
tional Intelligence (CSCI), pages 857–860. IEEE, 2016.
[324] Farhang Sahba, Hamid R Tizhoosh, and Magdy MA Salama. A reinforcement learning
framework for medical image segmentation. In The 2006 IEEE International Joint
Conference on Neural Network Proceedings, pages 511–517. IEEE, 2006.
93
[325] Farhang Sahba, Hamid R Tizhoosh, and Magdy MMA Salama.
Application of",N/A,N/A
"Application of
opposition-based reinforcement learning in image segmentation. In 2007 IEEE Sym-
posium on Computational Intelligence in Image and Signal Processing, pages 246–251.
IEEE, 2007.
[326] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz.
Trust region policy optimization. In International conference on machine learning,
pages 1889–1897, 2015.
[327] John Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, and Pieter Abbeel.",N/A,N/A
"Trust Region Policy Optimization. arXiv e-prints, February 2015.
[328] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
Proximal Policy Optimization Algorithms. arXiv e-prints, July 2017.
[329] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
[330] Nicolas Schweighofer and Kenji Doya. Meta-learning in reinforcement learning. Neural",N/A,N/A
"Networks, 16(1):5–9, 2003.
[331] Shahin Sefati, Noah J Cowan, and Ren´e Vidal. Learning shared, discriminative dic-
tionaries for surgical gesture segmentation and classiﬁcation. In MICCAI Workshop:
M2CAI, volume 4, 2015.
[332] Mohammad Javad Shaﬁee, Brendan Chywl, Francis Li, and Alexander Wong. Fast
yolo: A fast you only look once system for real-time embedded object detection in
video. arXiv preprint arXiv:1709.05943, 2017.",N/A,N/A
"video. arXiv preprint arXiv:1709.05943, 2017.
[333] Amir Shahroudy, Jun Liu, Tian-Tsong Ng, and Gang Wang. Ntu rgb+ d: A large
scale dataset for 3d human activity analysis. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 1010–1019, 2016.
[334] M. R. Shaker, Shigang Yue, and T. Duckett. Vision-based reinforcement learning using
approximate policy iteration. In 2009 International Conference on Advanced Robotics,
pages 1–6, 2009.",N/A,N/A
"pages 1–6, 2009.
[335] Shai Shalev-Shwartz, Shaked Shammah, and Amnon Shashua. Safe, multi-agent, re-
inforcement learning for autonomous driving. CoRR, abs/1610.03295, 2016.
[336] Jie Shen, Stefanos Zafeiriou, Grigoris G Chrysos, Jean Kossaiﬁ, Georgios Tzimiropou-
los, and Maja Pantic. The ﬁrst facial landmark tracking in-the-wild challenge: Bench-
mark and results. In Proceedings of the IEEE international conference on computer
vision workshops, pages 50–58, 2015.
94",N/A,N/A
"vision workshops, pages 50–58, 2015.
94
[337] Y. Shi, L. Cui, Z. Qi, F. Meng, and Z. Chen. Automatic road crack detection using
random structured forests. IEEE Transactions on Intelligent Transportation Systems,
17(12):3434–3445, 2016.
[338] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor segmen-
tation and support inference from rgbd images. In European conference on computer
vision, pages 746–760. Springer, 2012.",N/A,N/A
"vision, pages 746–760. Springer, 2012.
[339] David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and Martin
Riedmiller. Deterministic policy gradient algorithms. 2014.
[340] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-
scale image recognition. arXiv preprint arXiv:1409.1556, 2014.
[341] Vishwanath A Sindagi and Vishal M Patel. Multi-level bottom-top and top-bottom",N/A,N/A
"feature fusion for crowd counting. In Proceedings of the IEEE International Conference
on Computer Vision, pages 1002–1012, 2019.
[342] Satya P. Singh, Lipo Wang, Sukrit Gupta, Haveesh Goli, Parasuraman Padmanabhan,
and Bal´azs Guly´as. 3d deep learning on medical images: A review, 2020.
[343] Gwangmo Song, Heesoo Myeong, and Kyoung Mu Lee.
Seednet: Automatic seed
generation with deep reinforcement learning for robust interactive segmentation. In",N/A,N/A
"Proceedings of the IEEE conference on computer vision and pattern recognition, pages
1760–1768, 2018.
[344] Yale Song, Jordi Vallmitjana, Amanda Stent, and Alejandro Jaimes. Tvsum: Sum-
marizing web videos using titles. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 5179–5187, 2015.
[345] Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson WH Lau, and Ming-Hsuan
Yang. Crest: Convolutional residual learning for visual tracking. In Proceedings of the",N/A,N/A
"IEEE International Conference on Computer Vision, pages 2555–2564, 2017.
[346] Concetto Spampinato, Simone Palazzo, and Daniela Giordano. Gamifying video ob-
ject segmentation. IEEE transactions on pattern analysis and machine intelligence,
39(10):1942–1958, 2016.
[347] Bradly C. Stadie, Pieter Abbeel, and Ilya Sutskever. Third-person imitation learning.
CoRR, abs/1703.01703, 2017.
[348] Jayakumar Subramanian and Aditya Mahajan. Reinforcement learning in stationary",N/A,N/A
"mean-ﬁeld games. page 251–259. International Foundation for Autonomous Agents
and Multiagent Systems, 2019.
95
[349] Shanhui Sun, Jing Hu, Mingqing Yao, Jinrong Hu, Xiaodong Yang, Qi Song, and
Xi Wu.
Robust multimodal image registration using deep recurrent reinforcement
learning. In Asian Conference on Computer Vision, pages 511–526. Springer, 2018.
[350] Kalaivani Sundararajan and Damon L. Woodard. Deep learning for biometrics: A
survey. 51(3), 2018.",N/A,N/A
"survey. 51(3), 2018.
[351] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction.
MIT press, 2018.
[352] Richard S. Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy
gradient methods for reinforcement learning with function approximation. In Proceed-
ings of the 12th International Conference on Neural Information Processing Systems,
NIPS’99, page 1057–1063, 1999.
[353] Richard S Sutton, David A. McAllester, Satinder P. Singh, and Yishay Mansour. Policy",N/A,N/A
"gradient methods for reinforcement learning with function approximation. In Advances
in Neural Information Processing Systems 12, pages 1057–1063. 2000.
[354] Christian Szegedy, Sergey Ioﬀe, Vincent Vanhoucke, and Alexander A Alemi.
Inception-v4, inception-resnet and the impact of residual connections on learning. In
Thirty-ﬁrst AAAI conference on artiﬁcial intelligence, 2017.
[355] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir",N/A,N/A
"Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper
with convolutions.
In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 1–9, 2015.
[356] Christian Szegedy, Alexander Toshev, and Dumitru Erhan. Deep neural networks for
object detection. In Advances in neural information processing systems, pages 2553–
2561, 2013.
[357] Yansong Tang, Yi Tian, Jiwen Lu, Peiyang Li, and Jie Zhou. Deep progressive rein-",N/A,N/A
"forcement learning for skeleton-based action recognition. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pages 5323–5332, 2018.
[358] Ran Tao, Efstratios Gavves, and Arnold WM Smeulders.
Siamese instance search
for tracking. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 1420–1429, 2016.
[359] Philippe Th´evenaz and Michael Unser. Optimization of mutual information for mul-",N/A,N/A
"tiresolution image registration. IEEE transactions on image processing, 9(12):2083–
2099, 2000.
[360] Zhiqiang Tian, Xiangyu Si, Yaoyue Zheng, Zhang Chen, and Xiaojian Li.
Multi-
step medical image segmentation based on reinforcement learning. JOURNAL OF
AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING, 2020.
96
[361] Marin Toromanoﬀ, Emilie Wirbel, and Fabien Moutarde. End-to-end model-free re-
inforcement learning for urban driving using implicit aﬀordances. In Proceedings of",N/A,N/A
"the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7153–
7162, 2020.
[362] Alexander Toshev and Christian Szegedy. Deeppose: Human pose estimation via deep
neural networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 1653–1660, 2014.
[363] Yi-Hsuan Tsai, Ming-Hsuan Yang, and Michael J Black. Video segmentation via object
ﬂow. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 3899–3908, 2016.",N/A,N/A
"pages 3899–3908, 2016.
[364] Y. Tsurumine, Y. Cui, K. Yamazaki, and T. Matsubara. Generative adversarial im-
itation learning with deep p-network for robotic cloth manipulation. In 2019 IEEE-
RAS 19th International Conference on Humanoid Robots (Humanoids), pages 274–280,
2019.
[365] Yoshihisa Tsurumine, Yunduan Cui, Eiji Uchibe, and Takamitsu Matsubara. Deep
reinforcement learning with smooth policy update: Application to robotic cloth ma-",N/A,N/A
"nipulation. Robotics and Autonomous Systems, 112:72 – 83, 2019.
[366] Jasper RR Uijlings, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeul-
ders. Selective search for object recognition. International journal of computer vision,
104(2):154–171, 2013.
[367] Burak Uzkent, Christopher Yeh, and Stefano Ermon.
Eﬃcient object detection in
large images using deep reinforcement learning. In The IEEE Winter Conference on
Applications of Computer Vision, pages 1824–1833, 2020.",N/A,N/A
"[368] Jack Valmadre, Luca Bertinetto, Joao Henriques, Andrea Vedaldi, and Philip HS Torr.
End-to-end representation learning for correlation ﬁlter based tracking. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2805–
2813, 2017.
[369] Peter van Beek. Improved image selection for stack-based hdr imaging. arXiv preprint
arXiv:1806.07420, 2018.
[370] Hado van Hasselt, Arthur Guez, and David Silver. Deep Reinforcement Learning with",N/A,N/A
"Double Q-learning. arXiv e-prints, page arXiv:1509.06461, September 2015.
[371] Hado Van Hasselt, Arthur Guez, and David Silver. Deep reinforcement learning with
double q-learning. In Thirtieth AAAI conference on artiﬁcial intelligence, 2016.
[372] Leo Van Hove. Optimal denominations for coins and bank notes: in defense of the
principle of least eﬀort. Journal of Money, Credit and Banking, pages 1015–1021, 2001.
97",N/A,N/A
"97
[373] Giuseppe Vecchio, Simone Palazzo, Daniela Giordano, Francesco Rundo, and Concetto
Spampinato. Mask-rl: Multiagent video object segmentation framework through re-
inforcement learning. IEEE Transactions on Neural Networks and Learning Systems,
2020.
[374] Kashu Yamakazi Akihiro Sugimoto Viet-Khoa Vo-Ho, Ngan T.H. Le and Triet Tran.
Agent-environment network for temporal action proposal generation. In International
Conference on Acoustics, Speech and Signal Processing. 2021.",N/A,N/A
"[375] Sudheendra Vijayanarasimhan, Susanna Ricco, Cordelia Schmid, Rahul Sukthankar,
and Katerina Fragkiadaki. Sfm-net: Learning of structure and motion from video.
arXiv preprint arXiv:1704.07804, 2017.
[376] Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jader-
berg, Wojtek Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard
Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Aga-",N/A,N/A
"piou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky,
Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar
Gulcehre, Ziyu Wang, Tobias Pfaﬀ, Toby Pohlen, Dani Yogatama, Julia Cohen,
Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps,
Koray Kavukcuoglu, Demis Hassabis, and David Silver.
AlphaStar:
Master-
ing the Real-Time Strategy Game StarCraft II.
https://deepmind.com/blog/",N/A,N/A
"https://deepmind.com/blog/
alphastar-mastering-real-time-strategy-game-starcraft-ii/, 2019.
[377] Athanasios Vlontzos, Amir Alansary, Konstantinos Kamnitsas, Daniel Rueckert, and
Bernhard Kainz. Multiple landmark detection using multi-agent reinforcement learn-
ing. In International Conference on Medical Image Computing and Computer-Assisted
Intervention, pages 262–270. Springer, 2019.
[378] Guotai Wang, Maria A Zuluaga, Wenqi Li, Rosalind Pratt, Premal A Patel, Michael",N/A,N/A
"Aertsen, Tom Doel, Anna L David, Jan Deprest, S´ebastien Ourselin, et al. Deepi-
geos: a deep interactive geodesic framework for medical image segmentation. IEEE
transactions on pattern analysis and machine intelligence, 41(7):1559–1572, 2018.
[379] Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng
Li, and Wei Liu.
Cosface: Large margin cosine loss for deep face recognition.
In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",N/A,N/A
"pages 5265–5274, 2018.
[380] Jane X. Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z. Leibo, R´emi
Munos, Charles Blundell, Dharshan Kumaran, and Matthew Botvinick. Learning to
reinforcement learn. CoRR, abs/1611.05763, 2016.
[381] Lijun Wang, Huchuan Lu, Xiang Ruan, and Ming-Hsuan Yang. Deep networks for
saliency detection via local estimation and global search. In Computer Vision and Pat-
tern Recognition (CVPR), 2015 IEEE Conference on, pages 3183–3192. IEEE, 2015.
98",N/A,N/A
"98
[382] Mei Wang and Weihong Deng. Mitigating bias in face recognition using skewness-aware
reinforcement learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 9322–9331, 2020.
[383] Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, and Yaohai Huang. Racial faces
in the wild: Reducing racial bias by information maximization adaptation network. In
Proceedings of the IEEE International Conference on Computer Vision, pages 692–702,
2019.",N/A,N/A
"2019.
[384] Naiyan Wang and Dit-Yan Yeung. Learning a deep compact image representation for
visual tracking. In Advances in neural information processing systems, pages 809–817,
2013.
[385] Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric Langlois,
Shunshi Zhang, Guodong Zhang, Pieter Abbeel, and Jimmy Ba. Benchmarking model-
based reinforcement learning. CoRR, abs/1907.02057, 2019.
[386] Yan Wang, Lei Zhang, Lituan Wang, and Zizhou Wang. Multitask learning for object",N/A,N/A
"localization with deep reinforcement learning. IEEE Transactions on Cognitive and
Developmental Systems, 11(4):573–580, 2018.
[387] Yujiang Wang, Mingzhi Dong, Jie Shen, Yang Wu, Shiyang Cheng, and Maja Pantic.
Dynamic face video segmentation via reinforcement learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6959–
6969, 2020.
[388] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality",N/A,N/A
"assessment: from error visibility to structural similarity. IEEE transactions on image
processing, 13(4):600–612, 2004.
[389] Zhouxia Wang, Jiawei Zhang, Mude Lin, Jiong Wang, Ping Luo, and Jimmy Ren.
Learning a reinforced agent for ﬂexible exposure bracketing selection. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages
1820–1828, 2020.
[390] Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van Hasselt, Marc Lanctot, and Nando
De Freitas.",N/A,N/A
"De Freitas.
Dueling network architectures for deep reinforcement learning.
arXiv
preprint arXiv:1511.06581, 2015.
[391] Wayne A Wickelgren.
The long and the short of memory.
Psychological Bulletin,
80(6):425, 1973.
[392] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist
reinforcement learning. Machine learning, 8(3-4):229–256, 1992.
99
[393] Aaron Wilson, Alan Fern, and Prasad Tadepalli. Using trajectory data to improve",N/A,N/A
"bayesian optimization for reinforcement learning. Journal of Machine Learning Re-
search, 15(8):253–282, 2014.
[394] C. Wirth and J. F¨urnkranz. On learning from game annotations. IEEE Transactions
on Computational Intelligence and AI in Games, 7(3):304–316, 2015.
[395] Paul Wohlhart and Vincent Lepetit. Learning descriptors for object recognition and
3d pose estimation. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 3109–3118, 2015.",N/A,N/A
"pattern recognition, pages 3109–3118, 2015.
[396] Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. Cbam: Convo-
lutional block attention module. In European Conference on Computer Vision, pages
3–19, 2018.
[397] Yi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Online object tracking: A benchmark.
In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 2411–2418, 2013.
[398] Yi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Object tracking benchmark. IEEE",N/A,N/A
"Transactions on Pattern Analysis and Machine Intelligence, 37(9):1834–1848, 2015.
[399] Lu Xia, Chia-Chih Chen, and Jake K Aggarwal. View invariant human action recog-
nition using histograms of 3d joints. In 2012 IEEE Computer Society Conference on
Computer Vision and Pattern Recognition Workshops, pages 20–27. IEEE, 2012.
[400] Sitao Xiang and Hao Li. On the eﬀects of batch and weight normalization in generative
adversarial networks. arXiv preprint arXiv:1704.03971, 2017.",N/A,N/A
"[401] Yu Xiang, Alexandre Alahi, and Silvio Savarese. Learning to track: Online multi-object
tracking by decision making. In Proceedings of the IEEE international conference on
computer vision, pages 4705–4713, 2015.
[402] Fanyi Xiao and Yong Jae Lee. Track and segment: An iterative unsupervised approach
for video object proposals. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 933–942, 2016.",N/A,N/A
"and pattern recognition, pages 933–942, 2016.
[403] Hang Xiao and Hanchuan Peng. App2: automatic tracing of 3d neuron morphology
based on hierarchical pruning of a gray-weighted image distance-tree. Bioinformatics,
29(11):1448–1454, 2013.
[404] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy
student improves imagenet classiﬁcation. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 10687–10698, 2020.
100",N/A,N/A
"100
[405] Haipeng Xiong, Hao Lu, Chengxin Liu, Liang Liu, Zhiguo Cao, and Chunhua Shen.
From open set to closed set: Counting objects by spatial divide-and-conquer.
In
Proceedings of the IEEE International Conference on Computer Vision, pages 8362–
8371, 2019.
[406] Hailiang Xu and Feng Su. Robust seed localization and growing with deep convolu-
tional features for scene text detection. In Proceedings of the 5th ACM on International
Conference on Multimedia Retrieval, pages 387–394. ACM, 2015.",N/A,N/A
"[407] Ning Xu, Brian Price, Scott Cohen, Jimei Yang, and Thomas S Huang. Deep interactive
object selection.
In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 373–381, 2016.
[408] Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, and Josef Kittler. Learning adaptive
discriminative correlation ﬁlters via temporal consistency preserving spatial feature
selection for robust visual object tracking. IEEE Transactions on Image Processing,
28(11):5596–5609, 2019.",N/A,N/A
"28(11):5596–5609, 2019.
[409] Xuanang Xu, Fugen Zhou, Bo Liu, Dongshan Fu, and Xiangzhi Bai. Eﬃcient multiple
organ localization in ct image using 3d region proposal network. IEEE transactions
on medical imaging, 38(8):1885–1898, 2019.
[410] Yu-Syuan Xu, Tsu-Jui Fu, Hsuan-Kung Yang, and Chun-Yi Lee.
Dynamic video
segmentation network. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 6556–6565, 2018.
[411] Kashu Yamazaki, Vidhiwar Singh Rathour, and T Le.",N/A,N/A
"Invertible residual net-
work with regularization for eﬀective medical image segmentation.
arXiv preprint
arXiv:2103.09042, 2021.
[412] Zhaoyi Yan, Yuchen Yuan, Wangmeng Zuo, Xiao Tan, Yezhen Wang, Shilei Wen,
and Errui Ding.
Perspective-guided convolution networks for crowd counting.
In
Proceedings of the IEEE International Conference on Computer Vision, pages 952–
961, 2019.
[413] Zhibo Yang, Lihan Huang, Yupei Chen, Zijun Wei, Seoyoung Ahn, Gregory Zelinsky,",N/A,N/A
"Dimitris Samaras, and Minh Hoai. Predicting goal-directed human attention using
inverse reinforcement learning. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition (CVPR), June 2020.
[414] Chao Yu, Jiming Liu, and Shamim Nemati. Reinforcement learning in healthcare: a
survey. arXiv preprint arXiv:1908.08796, 2019.
[415] Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn,",N/A,N/A
"and Sergey Levine. Meta-world: A benchmark and evaluation for multi-task and meta
reinforcement learning. In Conference on Robot Learning, pages 1094–1100, 2020.
101
[416] Sangdoo Yun, Jongwon Choi, Youngjoon Yoo, Kimin Yun, and Jin Young Choi.
Action-decision networks for visual tracking with deep reinforcement learning. In Pro-
ceedings of the IEEE conference on computer vision and pattern recognition, pages
2711–2720, 2017.",N/A,N/A
"2711–2720, 2017.
[417] Daochen Zha, Kwei-Herng Lai, Kaixiong Zhou, and Xia Hu. Experience replay opti-
mization. arXiv preprint arXiv:1906.08387, 2019.
[418] Da Zhang, Hamid Maei, Xin Wang, and Yuan-Fang Wang. Deep reinforcement learning
for visual object tracking in videos. arXiv preprint arXiv:1701.08936, 2017.
[419] Dingwen Zhang, Le Yang, Deyu Meng, Dong Xu, and Junwei Han. Spftn: A self-paced
ﬁne-tuning network for segmenting objects in weakly labelled videos. In Proceedings of",N/A,N/A
"the IEEE Conference on Computer Vision and Pattern Recognition, pages 4429–4437,
2017.
[420] Jing Zhang, Wanqing Li, Philip O Ogunbona, Pichao Wang, and Chang Tang. Rgb-
d-based action recognition datasets: A survey. Pattern Recognition, 60:86–105, 2016.
[421] Ke Zhang, Wei-Lun Chao, Fei Sha, and Kristen Grauman. Video summarization with
long short-term memory. In European conference on computer vision, pages 766–782.
Springer, 2016.",N/A,N/A
"Springer, 2016.
[422] Pengyu Zhang, Dong Wang, and Huchuan Lu. Multi-modal visual tracking: Review
and experimental comparison, 2020.
[423] Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-image
crowd counting via multi-column convolutional neural network. In Proceedings of the
IEEE conference on computer vision and pattern recognition, pages 589–597, 2016.
[424] Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, and Jiaya Jia. Icnet",N/A,N/A
"for real-time semantic segmentation on high-resolution images. In Proceedings of the
European Conference on Computer Vision (ECCV), pages 405–420, 2018.
[425] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid
scene parsing network. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 2881–2890, 2017.
[426] Zhong-Qiu Zhao, Shou-Tao Xu, Dian Liu, Wei-Dong Tian, and Zhi-Da Jiang. A review",N/A,N/A
"of image set classiﬁcation. Neurocomputing, 335:251–260, 2019.
[427] Yefeng Zheng, David Liu, Bogdan Georgescu, Hien Nguyen, and Dorin Comaniciu.
3d deep learning for eﬃcient and robust landmark detection in volumetric data. In
International Conference on Medical Image Computing and Computer-Assisted Inter-
vention, pages 565–572. Springer, 2015.
102
[428] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Tor-",N/A,N/A
"ralba. Scene parsing through ade20k dataset. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 633–641, 2017.
[429] Kaiyang Zhou, Yu Qiao, and Tao Xiang. Deep reinforcement learning for unsupervised
video summarization with diversity-representativeness reward. In Thirty-Second AAAI
Conference on Artiﬁcial Intelligence, 2018.
[430] Kaiyang Zhou, Tao Xiang, and Andrea Cavallaro. Video summarisation by classiﬁca-",N/A,N/A
"tion with deep reinforcement learning. arXiv preprint arXiv:1807.03089, 2018.
[431] Xizhou Zhu, Yuwen Xiong, Jifeng Dai, Lu Yuan, and Yichen Wei. Deep feature ﬂow
for video recognition. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 2349–2358, 2017.
[432] Xiahai Zhuang and Juan Shen. Multi-scale patch and multi-modality atlases for whole
heart segmentation of mri. Medical image analysis, 31:77–87, 2016.",N/A,N/A
"[433] Will Y Zou, Xiaoyu Wang, Miao Sun, and Yuanqing Lin. Generic object detection
with dense neural patterns and regionlets. arXiv preprint arXiv:1404.4316, 2014.
103",N/A,N/A
"1
Modular RAG: Transforming RAG Systems into
LEGO-like Reconfigurable Frameworks
Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang
Abstract—Retrieval-augmented
Generation
(RAG)
has
markedly enhanced the capabilities of Large Language Models
(LLMs) in tackling knowledge-intensive tasks. The increasing
demands of application scenarios have driven the evolution
of RAG, leading to the integration of advanced retrievers,
LLMs and other complementary technologies, which in turn",N/A,N/A
"has amplified the intricacy of RAG systems. However, the rapid
advancements are outpacing the foundational RAG paradigm,
with many methods struggling to be unified under the process
of “retrieve-then-generate”. In this context, this paper examines
the limitations of the existing RAG paradigm and introduces
the modular RAG framework. By decomposing complex RAG
systems into independent modules and specialized operators, it
facilitates a highly reconfigurable framework. Modular RAG",N/A,N/A
"transcends the traditional linear architecture, embracing a
more advanced design that integrates routing, scheduling, and
fusion mechanisms. Drawing on extensive research, this paper
further identifies prevalent RAG patterns—linear, conditional,
branching, and looping—and offers a comprehensive analysis
of their respective implementation nuances. Modular RAG
presents
innovative
opportunities
for
the
conceptualization
and deployment of RAG systems. Finally, the paper explores",N/A,N/A
"the potential emergence of new operators and paradigms,
establishing a solid theoretical foundation and a practical
roadmap for the continued evolution and practical deployment
of RAG technologies.
Index Terms—Retrieval-augmented generation, large language
model, modular system, information retrieval
I. INTRODUCTION
L
ARGE Language Models (LLMs) have demonstrated
remarkable capabilities, yet they still face numerous
challenges, such as hallucination and the lag in information up-",N/A,N/A
"dates [1]. Retrieval-augmented Generation (RAG), by access-
ing external knowledge bases, provides LLMs with important
contextual information, significantly enhancing their perfor-
mance on knowledge-intensive tasks [2]. Currently, RAG, as
an enhancement method, has been widely applied in various
practical application scenarios, including knowledge question
answering, recommendation systems, customer service, and
personal assistants. [3]–[6]",N/A,N/A
"personal assistants. [3]–[6]
During the nascent stages of RAG , its core framework is
constituted by indexing, retrieval, and generation, a paradigm
referred to as Naive RAG [7]. However, as the complexity
of tasks and the demands of applications have escalated, the
Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous
Systems, Tongji University, Shanghai, 201210, China.
Yun Xiong is with Shanghai Key Laboratory of Data Science, School of",N/A,N/A
"Computer Science, Fudan University, Shanghai, 200438, China.
Meng Wang and Haofen Wang are with College of Design and Innovation,
Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen
Wang. E-mail: carter.whfcarter@gmail.com)
limitations of Naive RAG have become increasingly apparent.
As depicted in Figure 1, it predominantly hinges on the
straightforward similarity of chunks, result in poor perfor-
mance when confronted with complex queries and chunks with",N/A,N/A
"substantial variability. The primary challenges of Naive RAG
include: 1) Shallow Understanding of Queries. The semantic
similarity between a query and document chunk is not always
highly consistent. Relying solely on similarity calculations
for retrieval lacks an in-depth exploration of the relationship
between the query and the document [8]. 2) Retrieval Re-
dundancy and Noise. Feeding all retrieved chunks directly
into LLMs is not always beneficial. Research indicates that",N/A,N/A
"an excess of redundant and noisy information may interfere
with the LLM’s identification of key information, thereby
increasing the risk of generating erroneous and hallucinated
responses. [9]
To overcome the aforementioned limitations, Advanced
RAG paradigm focuses on optimizing the retrieval phase,
aiming to enhance retrieval efficiency and strengthen the
utilization of retrieved chunks. As shown in Figure 1 ,typical
strategies involve pre-retrieval processing and post-retrieval",N/A,N/A
"processing. For instance, query rewriting is used to make
the queries more clear and specific, thereby increasing the
accuracy of retrieval [10], and the reranking of retrieval results
is employed to enhance the LLM’s ability to identify and
utilize key information [11].
Despite the improvements in the practicality of Advanced
RAG, there remains a gap between its capabilities and real-
world application requirements. On one hand, as RAG tech-",N/A,N/A
"nology advances, user expectations rise, demands continue to
evolve, and application settings become more complex. For
instance, the integration of heterogeneous data and the new
demands for system transparency, control, and maintainability.
On the other hand, the growth in application demands has
further propelled the evolution of RAG technology.
As shown in Figure 2, to achieve more accurate and efficient
task execution, modern RAG systems are progressively inte-",N/A,N/A
"grating more sophisticated function, such as organizing more
refined index base in the form of knowledge graphs, integrat-
ing structured data through query construction methods, and
employing fine-tuning techniques to enable encoders to better
adapt to domain-specific documents.
In terms of process design, the current RAG system has
surpassed the traditional linear retrieval-generation paradigm.
Researchers use iterative retrieval [12] to obtain richer con-",N/A,N/A
"text, recursive retrieval [13] to handle complex queries, and
adaptive retrieval [14] to provide overall autonomy and flex-
ibility. This flexibility in the process significantly enhances
arXiv:2407.21059v1  [cs.CL]  26 Jul 2024
2
Fig. 1. Cases of Naive RAG and Advanced RAG.When faced with complex
questions, both encounter limitations and struggle to provide satisfactory
answers. Despite the fact that Advanced RAG improves retrieval accuracy",N/A,N/A
"through hierarchical indexing, pre-retrieval, and post-retrieval processes, these
relevant documents have not been used correctly.
the expressive power and adaptability of RAG systems, en-
abling them to better adapt to various application scenarios.
However, this also makes the orchestration and scheduling of
workflows more complex, posing greater challenges to system
design. Specifically, RAG currently faces the following new
challenges:
Complex data sources integration. RAG are no longer",N/A,N/A
"confined to a single type of unstructured text data source but
have expanded to include various data types, such as semi-
structured data like tables and structured data like knowledge
graphs [15]. Access to heterogeneous data from multiple
sources can provide the system with a richer knowledge
background, and more reliable knowledge verification capa-
bilities [16].
New demands for system interpretability, controllability,
Fig. 2.
Case of current Modular RAG.The system integrates diverse data",N/A,N/A
"and more functional components. The process is no longer confined to linear
but is controlled by multiple control components for retrieval and generation,
making the entire system more flexible and complex.
3
and maintainability. With the increasing complexity of sys-
tems, system maintenance and debugging have become more
challenging. Additionally, when issues arise, it is essential to
quickly pinpoint the specific components that require opti-
mization.",N/A,N/A
"mization.
Component selection and optimization. More neural net-
works are involved in the RAG system, necessitating the
selection of appropriate components to meet the needs of spe-
cific tasks and resource configurations. Moreover, additional
components enhance the effectiveness of RAG but also bring
new collaborative work requirements [17]. Ensuring that these
models perform as intended and work efficiently together to
enhance the overall system performance is crucial.",N/A,N/A
"Workflow orchestration and scheduling. Components
may need to be executed in a specific order, processed in paral-
lel under certain conditions, or even judged by the LLM based
on different outputs. Reasonable planning of the workflow is
essential for improving system efficiency and achieving the
desired outcomes [18].
To address the design, management, and maintenance chal-
lenges posed by the increasing complexity of RAG systems,
and to meet the ever-growing and diverse demands and ex-",N/A,N/A
"pectations, this paper proposes Modular RAG architecture.
In modern computing systems, modularization is becoming
a trend. It can enhance the system’s scalability and maintain-
ability and achieve efficient task execution through process
control.
The Modular RAG system consists of multiple independent
yet tightly coordinated modules, each responsible for handling
specific functions or tasks. This architecture is divided into
three levels: the top level focuses on the critical stages of",N/A,N/A
"RAG, where each stage is treated as an independent module.
This level not only inherits the main processes from the
Advanced RAG paradigm but also introduces an orchestration
module to control the coordination of RAG processes. The
middle level is composed of sub-modules within each module,
further refining and optimizing the functions. The bottom level
consists of basic units of operation—operators. Within the
Modular RAG framework, RAG systems can be represented",N/A,N/A
"in the form of computational graphs, where nodes represent
specific operators. The comparison of the three paradigms is
shown in the Figure 3. Modular RAG evolves based on the
previous development of RAG. The relationships among these
three paradigms are ones of inheritance and development.
Advanced RAG is a special case of Modular RAG, while Naive
RAG is a special case of Advanced RAG.
The advantages of Modular RAG are significant, as it",N/A,N/A
"enhances the flexibility and scalability of RAG systems. Users
can flexibly combine different modules and operators accord-
ing to the requirements of data sources and task scenarios. In
summary, the contributions of this paper are as follows:
• This paper proposes a new paradigm called modular
RAG, which employs a three-tier architectural design
comprising modules, sub-modules, and operators to de-
fine the RAG system in a unified and structured manner.",N/A,N/A
"This design not only enhances the system’s flexibility and
scalability but also, through the independent design of
operators, strengthens the system’s maintainability and
comprehensibility.
• Under the framework of Modular RAG, the orchestration
of modules and operators forms the RAG Flow, which
can flexibly express current RAG methods. This paper has
further summarized six typical flow patterns and specific
methods have been analyzed to reveal the universality of",N/A,N/A
"modular RAG in practical scenarios.
• The Modular RAG framework offers exceptional flexi-
bility and extensibility. This paper delves into the new
opportunities brought by Modular RAG and provides a
thorough discussion on the adaptation and expansion of
new methods in different application scenarios, offering
guidance for future research directions and practical ex-
ploration.
II. RELATED WORK
The development of RAG technology can be summarized",N/A,N/A
"in three stages. Initially, retrieval-augmented techniques were
introduced to improve the performance of pre-trained lan-
guage models on knowledge-intensive tasks [19], [20]. In
specific implementations, Retro [21] optimized pre-trained
autoregressive models through retrieval augmentation, while
Atlas [22] utilized a retrieval-augmented few-shot fine-tuning
method, enabling language models to adapt to diverse tasks.
IRCOT [23] further enriched the reasoning process during",N/A,N/A
"the inference phase by combining chain-of-thought and multi-
step retrieval processes. Entering the second stage, as the
language processing capabilities of LLMs significantly im-
proved, retrieval-augmented techniques began to serve as a
means of supplementing additional knowledge and providing
references, aiming to reduce the hallucination. For instance,
RRR [24] improved the rewriting phase, and LLMlingua [25]
removed redundant tokens in retrieved document chunks.",N/A,N/A
"With the continuous progress of RAG technology, research
has become more refined and focused, while also achieving
innovative integration with other technologies such as graph
neural networks [26] and fine-tuning techniques [27]. The
overall pipeline has also become more flexible, such as using
LLMs to proactively determine the timing of retrieval and
generation [14], [28].
The development of RAG technology has been acceler-
ated by LLM technology and practical application needs.",N/A,N/A
"Researchers are examining and organizing the RAG frame-
work and development pathways from different perspectives.
Building upon the enhanced stages of RAG, Gao et al., [2] sub-
divided RAG into enhancement during pre-training, inference,
and fine-tuning stages. Based on the main processes of RAG,
relevant works on RAG were organized from the perspectives
of retrieval, generation, and augmentation methods. Huang
et al., [29] categorize RAG methods into four main classes:",N/A,N/A
"pre-retrieval, retrieval, post-retrieval, generation, and provide
a detailed discussion of the methods and techniques within
each class. Hu et al., [30] discuss Retrieval-Augmented Lan-
guage Models (RALMs) form three key components, including
retrievers, language models, augmentations, and how their
interactions lead to different model structures and applications.
4",N/A,N/A
"4
Fig. 3. Comparison between three RAG paradigms. Modular RAG has evolved from previous paradigms and aligns with the current practical needs of RAG
systems.
They emphasize the importance of considering robustness,
accuracy, and relevance when evaluating RALMs and pro-
pose several evaluation methods. Ding et al., [31] provide a
comprehensive review from the perspectives of architecture,
training strategies, and applications. They specifically discuss",N/A,N/A
"four training methods of RALMs: training-free methods, in-
dependent training methods, sequence training methods, and
joint training methods, and compare their advantages and
disadvantages. Zhao et al., [32]analyze the applications of
RAG technology in various fields such as text generation,
code generation, image generation, and video generation from
the perspective of augmented intelligence with generative
capabilities.
The current collation of RAG systems primarily focuses",N/A,N/A
"on methods with a fixed process, mainly concerned with
optimizing the retrieval and generation stages. However, it has
not turned its attention to the new characteristics that RAG
research is continuously evolving, namely the characteristics
of process scheduling and functional componentization. There
is currently a lack of comprehensive analysis of the overall
RAG system, which has led to research on paradigms lagging
behind the development of RAG technology.
III. FRAMEWORK AND NOTATION",N/A,N/A
"III. FRAMEWORK AND NOTATION
For query Q = {qi}, a typical RAG system mainly consists
of three key components. 1) Indexing. Given documents D =
{d1, d2, . . . , dn} , where di represents the document chunk.
Indexing is the process of converting di into vectors through
an embedding model fe(·) , and then store vectors in vector
database.
I = {e1, e2, . . . , en}
and
ei = fe(di) ∈Rd
(1)
Notation
Description
q
The original query
y
The output of LLM
D",N/A,N/A
"q
The original query
y
The output of LLM
D
A document retrieval repository composed of chunks di.
R(q, D)
Retriever,find similar chunks from D based on q.
F
RAG Flow
P
RAG Flow pattern
fqe
Query expansion function
fqc
Query transform function
fcomp
Chunk compression function
fsel
Chunk selection function
fr
Routing function
M
Module in modular RAG
op
The specific operators within the Module.
TABLE I
IMPORTANT NOTATION
2) Retrieval . Transform the query into a vector using the",N/A,N/A
"same encoding model, and then filter out the top k document
chunks that are most similar based on vector similarity.
R : topk
di∈D
Sim(q, di) →Dq
(2)
Dq = {d1, d2, . . . , dk} represents the relevant documents for
question q. The similarity function Sim(·) commonly used are
dot product or cosine similarity.
Sim(q, di) = eq · edi
or
eq · edi
∥eq∥· ∥edi∥
(3)
3) Generation. After getting the relevant documents. The
query q and the retrieved document Dq chunks are inputted",N/A,N/A
"together to the LLM to generate the final answer, where [·, ·]
stands for concatenation.
y = LLM([Dq, q])
(4)
5
With the evolution of RAG technology, more and more func-
tional components are being integrated into systems. Modular
RAG paradigm includes three levels, ranging from large to
small:
L1 Module (M = {Ms}). The core process in RAG
system.
L2 Sub-module (Ms = {Op}).The functional modules in
module.
L3 Operator (Op = {fθi}). The the specific functional",N/A,N/A
"implementation in a module or sub-module. As a result, a
Modular RAG system can be represented as:
G = {q, D, M, {Ms}, {Op}}
(5)
The arrangement between modules and operators constitutes
the RAG Flow F = (Mϕ1, . . . , Mϕn) where ϕ stands for
the set of module parameters. A modular rag flow can be
decomposed into a graph of sub-functions. In the simplest
case,the graph is a linear chain.
NaiveRAG : q
R(q,D)
−−−−−−−−−−−→
T ext−Embedding Dq
LLM([q,Dq])
−−−−−−−−−−−→
OpenAI/GP T −4 y
(6)",N/A,N/A
"LLM([q,Dq])
−−−−−−−−−−−→
OpenAI/GP T −4 y
(6)
IV. MODULE AND OPERATOR
This chapter will specifically introduce modules and op-
erators under the Modular RAG framework. Based on the
current stage of RAG development, we have established
six main modules: Indexing, Pre-retrieval, Retrieval, Post-
retrieval, Generation, and Orchestration.
A. Indexing
Indexing is the process of split document into manageable
chunks and it is a key step in organizing a system. Indexing",N/A,N/A
"faces three main challenges. 1) Incomplete content represen-
tation.The semantic information of chunks is influenced by the
segmentation method, resulting in the loss or submergence of
important information within longer contexts. 2) Inaccurate
chunk similarity search. As data volume increases, noise in
retrieval grows, leading to frequent matching with erroneous
data, making the retrieval system fragile and unreliable. 3)
Unclear reference trajectory. The retrieved chunks may orig-",N/A,N/A
"inate from any document, devoid of citation trails, potentially
resulting in the presence of chunks from multiple different
documents that, despite being semantically similar, contain
content on entirely different topics.
1) Chunk Optimization: The size of the chunks and the
overlap between the chunks play a crucial role in the overall
effectiveness of the RAG system. Given a chunk di, its chunk
size is denoted as Li = |di|, and the overlap is denoted as
Lo",N/A,N/A
"Lo
i = |di ∩di+1|. Larger chunks can capture more context,
but they also generate more noise, requiring longer processing
time and higher costs. While smaller chunks may not fully
convey the necessary context, they do have less noise [17].
Sliding Window using overlapping chunks in a sliding win-
dow enhances semantic transitions. However, it has limitations
such as imprecise context size control, potential truncation of
words or sentences, and lacking semantic considerations.",N/A,N/A
"Metadata Attachment. Chunks can be enriched with meta-
data like page number, file name, author, timestamp, sum-
mary, or relevant questions. This metadata allows for filtered
retrieval, narrowing the search scope.
Small-to-Big [33] separate the chunks used for retrieval
from those used for synthesis. Smaller chunks enhance re-
trieval accuracy, while larger chunks provide more context.
One approach is to retrieve smaller summarized chunks and",N/A,N/A
"reference their parent larger chunks. Alternatively, individual
sentences could be retrieved along with their surrounding text.
2) Structure Organization: One effective method for en-
hancing information retrieval is to establish a hierarchical
structure for the documents. By constructing chunks structure,
RAG system can expedite the retrieval and processing of
pertinent data.
Hierarchical Index. In the hierarchical structure of docu-",N/A,N/A
"ments, nodes are arranged in parent-child relationships, with
chunks linked to them. Data summaries are stored at each
node, aiding in the swift traversal of data and assisting the
RAG system in determining which chunks to extract. This
approach can also mitigate the illusion caused by chunk
extraction issues. The methods for constructing a structured
index primarily include: 1) Structural awareness based on
paragraph and sentence segmentation in docs. 2) Content",N/A,N/A
"awareness based on inherent structure in PDF, HTML, and
Latex. 3) Semantic awareness based on semantic recognition
and segmentation of text.
KG Index [34]. Using Knowledge Graphs (KGs) to struc-
ture documents helps maintain consistency by clarifying con-
nections between concepts and entities, reducing the risk of
mismatch errors. KGs also transform information retrieval
into instructions intelligible to language models, improving re-",N/A,N/A
"trieval accuracy and enabling contextually coherent responses.
This enhances the overall efficiency of the RAG system.
For example, organizing a corpus in the format of graph
G = {V, E, X}, where node V = {vi}n
i=1 represent document
structures (e.g.passage, pages, table) , edge E ⊂V × V rep-
resent semantic or lexical similarity and belonging relations,
and node features X = {Xi}n
i=1 represent text or markdown
content for passage.
B. Pre-retrieval",N/A,N/A
"content for passage.
B. Pre-retrieval
One of the primary challenges with Naive RAG is its
direct reliance on the user’s original query as the basis for
retrieval. Formulating a precise and clear question is difficult,
and imprudent queries result in subpar retrieval effectiveness.
The primary challenges in this module include: 1) Poorly
worded queries. The question itself is complex, and the
language is not well-organized. 2) Language complexity and",N/A,N/A
"ambiguity. Language models often struggle when dealing
with specialized vocabulary or ambiguous abbreviations with
multiple meanings. For instance, they may not discern whether
LLM refers to Large Language Model or a Master of Laws in
a legal context.
1) Query Expansion : Expanding a single query into mul-
tiple queries enriches the content of the query, providing
6
further context to address any lack of specific nuances, thereby
ensuring the optimal relevance of the generated answers.",N/A,N/A
"fqe(q) = {q1, q2, . . . , qn}
∀qi ∈{q1, q2, . . . , qn}, qi /∈Q
(7)
Multi-Query uses prompt engineering to expand queries
via LLMs, allowing for parallel execution. These expansions
are meticulously designed to ensure diversity and coverage.
However, this approach can dilute the user’s original intent.
To mitigate this, the model can be instructed to assign greater
weight to the original query.
Sub-Query. By decomposing and planning for complex",N/A,N/A
"problems, multiple sub-problems are generated. Specifically,
least-to-most prompting [35] can be employed to decom-
pose the complex problem into a series of simpler sub-
problems. Depending on the structure of the original problem,
the generated sub-problems can be executed in parallel or
sequentially. Another approach involves the use of the Chain-
of-Verification (CoVe) [36]. The expanded queries undergo
validation by LLM to achieve the effect of reducing hallu-
cinations.",N/A,N/A
"cinations.
2) Query Transformation: Retrieve and generate based on
a transformed query instead of the user’s original query.
fqt(q) = q′
(8)
Rewrite. Original queries often fall short for retrieval in
real-world scenarios. To address this, LLMs can be prompted
to rewrite. Specialized smaller models can also be employed
for this purpose [24]. The implementation of the query rewrite
method in Taobao has significantly improved recall effective-",N/A,N/A
"ness for long-tail queries, leading to an increase in GMV [10].
HyDE [37]. In order to bridge the semantic gap between
questions and answers, it constructs hypothetical documents
(assumed answers) when responding to queries instead of
directly searching the query. It focuses on embedding simi-
larity from answer to answer rather than seeking embedding
similarity for the problem or query. In addition, it also in-
cludes reverse HyDE, which generate hypothetical query for",N/A,N/A
"each chunks and focuses on retrieval from query to query.
Step-back Prompting [38]. The original query is abstracted
into a high-level concept question (step-back question). In the
RAG system, both the step-back question and the original
query are used for retrieval, and their results are combined
to generate the language model’s answer.
3) Query Construction: In addition to text data, an in-
creasing amount of structured data, such as tables and graph",N/A,N/A
"data, is being integrated into RAG systems. To accommodate
various data types, it is necessary to restructure the user’s
query. This involve converting the query into another query
language to access alternative data sources, with common
methods including Text-to-SQL or Text-to-Cypher . In many
scenarios, structured query languages (e.g., SQL, Cypher)
are often used in conjunction with semantic information and
metadata to construct more complex queries.
fqc(q) = q∗, q∗∈Q∗= {SQL, Cypher, . . . }",N/A,N/A
"fqc(q) = q∗, q∗∈Q∗= {SQL, Cypher, . . . }
(9)
C. Retrieval
The retrieval process is pivotal in RAG systems. By lever-
aging powerful embedding models, queries and text can be
efficiently represented in latent spaces, which facilitates the
establishment of semantic similarity between questions and
documents, thereby enhancing retrieval. Three main consider-
ations that need to be addressed include retrieval efficiency,
quality, and the alignment of tasks, data and models.",N/A,N/A
"1) Retriever Selection: With the widespread adoption of
RAG technology, the development of embedding models has
been in full swing. In addition to traditional models based
on statistics and pre-trained models based on the encoder
structure, embedding models fine-tuned on LLMs have also
demonstrated powerful capabilities [39]. However, they often
come with more parameters, leading to weaker inference
and retrieval efficiency. Therefore, it is crucial to select the",N/A,N/A
"appropriate retriever based on different task scenarios.
Sparse Retriever uses statistical methods to convert queries
and documents into sparse vectors. Its advantage lies in its
efficiency in handling large datasets, focusing only on non-zero
elements. However, it may be less effective than dense vectors
in capturing complex semantics. Common methods include
TF-IDF and BM25.
Dense Retriever employs pre-trained language models
(PLMs) to provide dense representations of queries and doc-",N/A,N/A
"uments. Despite higher computational and storage costs, it
offers more complex semantic representations. Typical models
include BERT structure PLMs, like ColBERT, and multi-task
fine-tuned models like BGE [40] and GTE [41].
Hybrid Retriever is to use both sparse and dense retrievers
simultaneously. Two embedding techniques complement each
other to enhance retrieval effectiveness. Sparse retriever can
provide initial screening results. Additionally, sparse models",N/A,N/A
"enhance the zero-shot retrieval capabilities of dense models,
particularly in handling queries with rare entities, thereby
increasing system robustness.
2) Retriever Fine-tuning: In cases where the context may
diverge from pre-trained corpus, particularly in highly special-
ized fields like healthcare, law, and other domains abundant in
proprietary terminology. While this adjustment demands addi-
tional effort, it can substantially enhance retrieval efficiency
and domain alignment.",N/A,N/A
"and domain alignment.
Supervised Fine-Tuning (SFT). Fine-tuning a retrieval
model based on labeled domain data is typically done using
contrastive learning. This involves reducing the distance be-
tween positive samples while increasing the distance between
negative samples. The commonly used loss calculation is
shown in the following:
L(DR) = −1
T
T
X
i=1
log
e(sim(qi,d+
i ))
e(sim(qi,d+
i )) + PN
j=1 e(sim(qi,d−
i ))
(10)
where d+
i is the positive sample document corresponding to",N/A,N/A
"the i-th query, d−
i
is several negative sample, T is the total
number of queries, N is the number of negative samples, and
DR is the fine-tuning dataset.
LM-supervised Retriever (LSR). In contrast to directly
constructing a fine-tuning dataset from the dataset, LSR uti-
7
lizes the LM-generated results as supervisory signals to fine-
tune the embedding model during the RAG process.
PLSR(d|q, y) =
ePLM(y|d,q)/β
P
d′∈D ePLM(y|d,q)/β)
(11)",N/A,N/A
"ePLM(y|d,q)/β
P
d′∈D ePLM(y|d,q)/β)
(11)
PLM(y|d, q) is LM probability of the ground truth output y
given the input context d and query q, and β is a hyper-
paramter.
Adapter. At times, fine-tuning a large retriever can be
costly, especially when dealing with retrievers based on LLMs
like gte-Qwen. In such cases, it can mitigate this by incorpo-
rating an adapter module and conducting fine-tuning. Another
benefit of adding an adapter is the ability to achieve better",N/A,N/A
"alignment with specific downstream tasks [42].
D. Post-retrieval
Feeding all retrieved chunks directly into the LLM is not an
optimal choice. Post-processing the chunks can aid in better
leveraging the contextual information. The primary challenges
include: 1) Lost in the middle. Like humans, LLM tends
to remember only the beginning or the end of long texts,
while forgetting the middle portion [43]. 2) Noise/anti-fact
chunks. Retrieved noisy or factually contradictory documents",N/A,N/A
"can impact the final retrieval generation [44].
3) Context
Window. Despite retrieving a substantial amount of relevant
content, the limitation on the length of contextual information
in large models prevents the inclusion of all this content.
1) Rerank: Rerank the retrieved chunks without altering
their content or length, to enhance the visibility of the more
crucial document chunks. Given the retrieved set Dq and a
re-ranking method frerank to obtain the re-ranked set:
Dq",N/A,N/A
"Dq
r = frerank(q, Dq) = {d′
1, d′
2, . . . , d′
k}
wheref(d′
1) ≥f(d′
2) ≥. . . ≥f(d′
k).
(12)
Rule-base rerank. Metrics are calculated to rerank chunks
according to certain rules. Common metrics include: diversity,
relevance and MRR (Maximal Marginal Relevance) [45]. The
idea is to reduce redundancy and increase result diversity.
MMR selects phrases for the final key phrase list based on a
combined criterion of query relevance and information novelty.",N/A,N/A
"Model-base rerank. Utilize a language model to reorder the
document chunks, commonly based on the relevance between
the chunks and the query. Rerank models have become an
important component of RAG systems, and relevant model
technologies are also being iteratively upgraded. The scope
reordering has also been extended to multimodal data such as
tables and images [46].
2) Compression: A common misconception in the RAG
process is the belief that retrieving as many relevant docu-",N/A,N/A
"ments as possible and concatenating them to form a lengthy
retrieval prompt is beneficial. However, excessive context can
introduce more noise, diminishing the LLM’s perception of
key information. A common approach to address this is to
compress and select the retrieved content.
Dq
c = fcomp(q, Dq),
where|dqc
i | < |dq
i |
∀dq
i ∈Dq
(13)
(Long)LLMLingua [47]. By utilizing aligned and trained
small language models, such as GPT-2 Small or LLaMA-",N/A,N/A
"7B, the detection and removal of unimportant tokens from
the prompt is achieved, transforming it into a form that is
challenging for humans to comprehend but well understood by
LLMs. This approach presents a direct and practical method
for prompt compression, eliminating the need for additional
training of LLMs while balancing language integrity and
compression ratio.
3) Selection: Unlike compressing the content of document
chunks, Selection directly removes irrelevant chunks.
Dq",N/A,N/A
"Dq
s = fsel(Dq) = {di ∈D | ¬P(di)}
(14)
Where fsel is the function for deletion operation and P(di) is
a conditional predicate indicating that document (di) satisfies
a certain condition. If document (di) satisfies (P(di)), it will
be deleted. Conversely, documents for which (¬P(di)) is true
will be retained.
Selective Context. By identifying and removing redundant
content in the input context, the input is refined, thus improv-
ing the language model’s reasoning efficiency. In practice, se-",N/A,N/A
"lective context assesses the information content of lexical units
based on the self-information computed by the base language
model. By retaining content with higher self-information, this
method offers a more concise and efficient textual representa-
tion, without compromising their performance across diverse
applications. However, it overlooks the interdependence be-
tween compressed content and the alignment between the
targeted language model and the small language model utilized",N/A,N/A
"for prompting compression [48].
LLM-Critique. Another straightforward and effective ap-
proach involves having the LLM evaluate the retrieved content
before generating the final answer. This allows the LLM
to filter out documents with poor relevance through LLM
critique. For instance, in Chatlaw [49], the LLM is prompted
to self-suggestion on the referenced legal provisions to assess
their relevance.
E. Generation
Utilize the LLM to generate answers based on the user’s",N/A,N/A
"query and the retrieved contextual information. Select an
appropriate model based on the task requirements, considering
factors such as the need for fine-tuning, inference efficiency,
and privacy protection.
1) Generator Fine-tuning: In addition to direct LLM usage,
targeted fine-tuning based on the scenario and data character-
istics can yield better results. This is also one of the greatest
advantages of using an on-premise setup LLMs.
Instruct-Tuning. When LLMs lack data in a specific do-",N/A,N/A
"main, additional knowledge can be provided to the LLM
through fine-tuning. General fine-tuning dataset can also be
used as an initial step. Another benefit of fine-tuning is the
ability to adjust the model’s input and output. For example, it
can enable LLM to adapt to specific data formats and generate
responses in a particular style as instructed [50].
Reinforcement learning. Aligning LLM outputs with hu-
man or retriever preferences through reinforcement learning is
8",N/A,N/A
"8
a potential approach [51]. For instance, manually annotating
the final generated answers and then providing feedback
through reinforcement learning. In addition to aligning with
human preferences, it is also possible to align with the
preferences of fine-tuned models and retrievers.
Dual Fine-tuing Fine-tuning both generator and retriever
simultaneously to align their preferences. A typical approach,
such as RA-DIT [27], aligns the scoring functions between",N/A,N/A
"retriever and generator using KL divergence. Retrieval likeli-
hood of each retrieved document d is calculated as :
PR(d|q) =
e(sim(d,q))/γ
P
d∈Dq e(sim(d,q)/γ
(15)
PLM(y|d, q) is the LM probability of the ground truth output y
given the input context d, question q, and γ is a hyperparamter.
The overall loss is calculated as:
L = 1
|T|
T
X
i=1
KL(PR(d|q)||PLSR(d|q, y|))
(16)
2) Verification : Although RAG enhances the reliability
of LLM-generated answers, in many scenarios, it requires to",N/A,N/A
"minimize the probability of hallucinations. Therefore, it can
filter out responses that do not meet the required standards
through additional verification module. Common verification
methods include knowledge-base and model-base .
yk = fverify(q, Dq, y)
(17)
Knowledge-base verification refers to directly validating the
responses generated by LLMs through external knowledge.
Generally, it extracts specific statements or triplets from re-",N/A,N/A
"sponse first. Then, relevant evidence is retrieved from verified
knowledge base such as Wikipedia or specific knowledge
graphs. Finally, each statement is incrementally compared with
the evidence to determine whether the statement is supported,
refuted, or if there is insufficient information [52].
Model-based verification refers to using a small language
model to verify the responses generated by LLMs [53].
Given the input question, the retrieved knowledge, and the",N/A,N/A
"generated answer, a small language model is trained to de-
termine whether the generated answer correctly reflects the
retrieved knowledge. This process is framed as a multiple-
choice question, where the verifier needs to judge whether the
answer reflects correct answer . If the generated answer does
not correctly reflect the retrieved knowledge, the answer can
be iteratively regenerated until the verifier confirms that the
answer is correct.
F. Orchestration",N/A,N/A
"answer is correct.
F. Orchestration
Orchestration pertains to the control modules that govern the
RAG process. Unlike the traditional, rigid approach of a fixed
process, RAG now incorporates decision-making at pivotal
junctures and dynamically selects subsequent steps contingent
upon the previous outcomes. This adaptive and modular ca-
pability is a hallmark of modular RAG, distinguishing it from
the more simplistic Naive and Advance RAG paradigm.",N/A,N/A
"1) Routing: In response to diverse queries, the RAG system
routes to specific pipelines tailored for different scenario, a
feature essential for a versatile RAG architecture designed
to handle a wide array of situations. A decision-making
mechanism is necessary to ascertain which modules will be
engaged, based on the input from the model or supplementary
metadata. Different routes are employed for distinct prompts
or components. This routing mechanism is executed through",N/A,N/A
"a function, denoted as fr(·), which assigns a score αi to
each module. These scores dictate the selection of the active
subset of modules. Mathematically, the routing function is
represented as:
fr : Q →F
(18)
where fr(·) maps the identified query to its corresponding
RAG flow.
Metadata routing involves extracting key terms, or entities,
from the query, applying a filtration process that uses these
keywords and associated metadata within the chunks to refine",N/A,N/A
"the routing parameters. For a specific RAG flow, denoted as
Fi, the pre-defined routing keywords are represented as the
set Ki = {ki1, ki2, . . . , kin}. The keyword identified within
the query qi is designated as K′
i. The matching process for
the query q is quantified by the key score equation:
scorekey(qi, Fj) =
1
|K′
j||Ki ∩K′
j|
(19)
This equation calculates the overlap between the pre-defined
keywords and those identified in the query, normalized by the
count of keywords in K′",N/A,N/A
"count of keywords in K′
j. The final step is to determine the
most relevant flow for the query q:
Fi(q) = argmaxFj∈Fscore(q, Fj)
(20)
Semantic routing routes to different modules based on the
semantic information of the query. Given a pre-defined intent
Θ = {θ1, θ2, . . . , θn}, the possibility of intent for query q is
PΘ(θ|q) =
ePLM (θ|q)
P
θ∈Θ ePLM (θ|q)) . Routing to specific RAG flow is
determined by the semantic score:
socresemantic(q, Fj) = argmaxθj∈ΘP(Θ)
(21)",N/A,N/A
"socresemantic(q, Fj) = argmaxθj∈ΘP(Θ)
(21)
The function δ(·) serves as a mapping function that assigns
an intent to a distinct RAG flow Fi = δ(θi)
Hybrid Routing can be implemented to improve query
routing by integrating both semantic analysis and metadata-
based approaches, which can be defined as follows:
αi = a·scorekey(q, Fj)+(1−α)·maxθj∈Θsocresemantic(q, Fj)
(22)
a is a weighting factor that balances the contribution of the
key-based score and the semantic score.",N/A,N/A
"key-based score and the semantic score.
2) Scheduling: The RAG system evolves in complexity
and adaptability, with the ability to manage processes through
a sophisticated scheduling module. The scheduling module
plays a crucial role in the modular RAG , identifying critical
junctures that require external data retrieval, assessing the
adequacy of the responses, and deciding on the necessity for
further investigation. It is commonly utilized in scenarios that",N/A,N/A
"involve recursive, iterative, and adaptive retrieval, ensuring
9
that the system makes informed decisions on when to cease
generation or initiate a new retrieval loop.
Rule judge. The subsequent steps are dictated by a set of
established rules. Typically, the system evaluates the quality of
generated answers through scoring mechanisms. The decision
to proceed or halt the process is contingent upon whether these
scores surpass certain predetermined thresholds, often related",N/A,N/A
"to the confidence levels of individual tokens, which can be
defined as follow:
yt =
(
ˆst
if all tokens of ˆst have probs ≥τ
st = LM([Dqt, x, y<t])
otherwise
Here, ˆst represents the tentative answer, and st is the output
from the language model. The condition for accepting ˆst is that
all tokens within it must have associated probabilities greater
than or equal to the threshold τ. If this condition is not met,
the system reverts to generating a new answer.",N/A,N/A
"the system reverts to generating a new answer.
LLM judge. The LLM independently determines the sub-
sequent course of action. Two primary approaches facilitate
this capability. The first method leverages LLM ’s in-context
learning capability, and make judgments through prompt
engineering. A significant advantage of this method is the
elimination of model fine-tuning. Nonetheless, the format of
the judgment output is contingent upon the LLM’s adherence
to the provided instructions.",N/A,N/A
"to the provided instructions.
The second approach involves the LLM generating specific
tokens that initiate targeted actions through fine-tuning. This
technique, with roots in the Toolformer [50], has been inte-
grated into frameworks like Self-RAG [28]. This allows for a
more direct control mechanism over the LLM’s actions, en-
hancing the system’s responsiveness to specific triggers within
the conversational context. However, it requires generating a",N/A,N/A
"large number of compliant instruction sets to fine-tune LLM.
Knowledge-guide scheduling. Beyond the confines of rule-
based methods and the complete reliance on LLMs for process
control, a more adaptable intermediate approach emerges with
knowledge-guided scheduling [26]. These methods harness
the power of knowledge graphs, to steer the retrieval and
generation processes. Specifically, it involves extracting infor-
mation relevant to the question from a knowledge graph and",N/A,N/A
"constructing a reasoning chain. This reasoning chain consists
of a series of logically interconnected nodes, each containing
critical information for the problem-solving process. Based
on the information from the nodes in this reasoning chain,
information retrieval and content generation can be performed
separately. By integrating this approach, it enhance not only
the efficacy and precision of problem-solving but also the
clarity of the explanations provided.",N/A,N/A
"clarity of the explanations provided.
3) Fusion: As RAG process has evolved beyond a linear
pipeline, it frequently necessitates broadening the retrieval
scope or enhancing diversity by exploring multiple pipelines.
Consequently, after the expansion into various branches, the
fusion module effectively integrates the information, ensuring
a comprehensive and coherent response. The fusion module’s
reliance is not just for merging answers but also for ensuring",N/A,N/A
"that the final output is both rich in content and reflective of
the multifaceted nature of the inquiry.
LLM fusion.One of the most straightforward methods for
multi-branch aggregation is to leverage the powerful capa-
bilities of LLMs to analyze and integrate information from
different branches. However, this approach also faces some
challenges, particularly when dealing with long answers that
exceeds the LLM’s context window limitation. To mitigate this",N/A,N/A
"issue, it is common practice to first summarize each branch’s
answer, extracting the key information before inputting it into
the LLM, thus ensuring that the most important content is
retained even within length constraints.
Weighted ensemble
is based on the weighted values of
different tokens generated from multiple branches, leading to
the comprehensive selection of the final output. This approach
can be calculated as :
p(y|q, Dq) =
X
d∈Dq
p(y|d, q) · λ(d, q)
(23)",N/A,N/A
"p(y|q, Dq) =
X
d∈Dq
p(y|d, q) · λ(d, q)
(23)
The weight λ(d, q) is determined by the similarity score
between the document d and the input query q. This weight is
calculated using the softmax function, which ensures that the
weights are normalized and sum up to one.
λ(d, q) =
es(d,q)
P
d∈Dq es(d,q)
(24)
RRF (Reciprocal Rank Fusion) is an ensemble technique
that synthesizes multiple retrieval result rankings into a co-
hesive, unified list [54]. It employs a tailored weighted aver-",N/A,N/A
"aging approach to enhance collective predictive performance
and ranking precision. The method’s strength is its dynamic
weight assignment, which is informed by the interplay among
branches. RRF is especially potent in scenarios characterized
by model or source heterogeneity, where it can markedly
amplify the accuracy of predictions.
V. RAG FLOW AND FLOW PATTERN
The collaboration between operators forms the workflow
of the module, which we refer to as RAG flow F
=",N/A,N/A
"of the module, which we refer to as RAG flow F
=
(Mϕ1, . . . , Mϕn), where ϕ stands for the set of module param-
eters. A modular rag flow can be decomposed into a graph of
sub-functions. Through control logic, the operators can execute
in a predetermined pipeline, while also performing conditional,
branching or looping when necessary. In the simplest case. the
graph is a linear chain.
After conducting an in-depth analysis of current RAG meth-",N/A,N/A
"ods, we have identified a set of common RAG flow patterns,
denoted as P. These patterns transcend various application
domains and demonstrate a high level of consistency and
reusability, revealing the prevalent structures and behaviors in
process design. A RAG flow pattern can be defined as P =
{Mϕ1 : {Op1} →Mϕ2 : {Op2} →. . . →Mϕn : {Opn}}
A. Linear Pattern
The modules in the modular RAG system are organized in
a linear way, and can be described as Algorithm 1.
Plinear = {M1 →M2 →. . . →Mn}",N/A,N/A
"Plinear = {M1 →M2 →. . . →Mn}
(25)
10
Fig. 4.
Linear RAG flow pattern. Each module is processed in a fixed
sequential order.
Fig. 5. RRR [24] is a typical linear flow that introduces a learnable query
rewrite module before retrieval. This module employs reinforcement based on
the output results of the LLM.
The linear flow pattern is the simplest and most com-
monly used pattern. As shown in Figure 4, the full linear
RAG flow pattern mainly includes pre-retrieval processing,",N/A,N/A
"retrieval, post-retrieval processing, and generation modules.
Plinearfull
= {Mindexing
→Mpre-retrieval
→Mretrieval
→
Mpost-retrieval →Mgenerate}. If there are no pre-retrieval and
post-retrieval modules, it follows the Naive RAG paradigm.
Algorithm 1 Linear RAG Flow Pattern
Require: original query q, documents D, retriever R, lan-
guage model LLM, pre-processing function fpre, post-
processing function fpost
Ensure: final output ˆy
1: Initialize:
2: q′ ←fpre(q) // Pre-process the original query",N/A,N/A
"2: q′ ←fpre(q) // Pre-process the original query
3: Dq′ ←R(q′, D) // Retrieve documents related to the pre-
processed query
4: ˆDq′ ←fpost(q′, Dq′) // Post-process the retrieved docu-
ments
5: ˆy ←LLM([q, ˆDq′]) // Generate output using the lan-
guage model with the original query and post-processed
documents
6: return ˆy // Return the final output
Common linear RAG flow involves a query transform
module (such as rewrite or HyDE operators) at the pre-retrieval",N/A,N/A
"stage and utilize rerank at the post-retrieval stage. Rewrite-
Retrieve-Read (RRR) [24] is a typical linear structure. As
illustrated in Figure 5, the query rewrite module frewrite is a
smaller trainable language model fine-tuned on T5-large, and
in the context of reinforcement learning, the optimization of
the rewriter is formalized as a Markov decision process, with
the final output of the LLM serving as the reward. The retriever
utilizes a sparse encoding model, BM25.
B. Conditional Pattern",N/A,N/A
"B. Conditional Pattern
The RAG flow with conditional structure involves select-
ing different RAG pipeline based on different conditions,
as illustrated in Figure 6. A detailed definition is shown in
Algorithm 2. Typically, pipleline selection is accomplished
Fig. 6. The conditional flow pattern. There is a routing module that controls
which RAG flow the query is directed to. Typically, different flows are used for
various configurations to meet the general requirements of the RAG system.",N/A,N/A
"Fig. 7.
Pre-retrieval branching flow pattern.Each branch performs retrieval
and generation separately, and then they are aggregated at the end.
through a routing module that determines the next module
in the flow.
Pconditional = {Mi
fr
−→Mj ∨Mk}
(26)
Where
fr
−→represents that based on routing function fr(·), the
flow can go to module Mj or Mk.
Algorithm 2 Conditional RAG Flow Pattern
Require: original query q, documents D, language model
LM, retriever R, routing function fr",N/A,N/A
"LM, retriever R, routing function fr
Ensure: final output ˆy
1: Initialize:
2: q′ ←QueryTransform(q) // Pre-process the initial query
if needed
3: D′ ←R(q′, D) // Retrieve or update documents related
to the query
4: Mnext ←fr(q′, D′) // Determine the next module using
the routing function
5: if Mnext = Mj then
6:
ˆy ←Mj(q′, D′) // Execute module Mj
7: else if Mnext = Mk then
8:
ˆy ←Mk(q′, D′) Mk
9: end if
10: return ˆy
Pipeline selection is determined by the nature of the ques-",N/A,N/A
"tion, directing different flows tailored to specific scenarios. For
example, the tolerance for responses generated by LLMs varies
across questions related to serious issues, political matters,
or entertainment topics. These routing flow often diverge in
terms of retrieval sources, retrieval processes, configurations,
models, and prompts.
11
Fig. 8. Post-retrieval branching flow pattern.Only one retrieval performed, and",N/A,N/A
"then generation is carried out separately for each retrieved document chunks,
followed by aggregation.
C. Branching
In many cases, the RAG flow system may have multiple
parallel running branches , usually to increase the diver-
sity of generated results. Assuming multiple branches bi are
generated in module B
= Msplit(·) = {b1, b2, . . . , bm}.
For each branch bi ∈B, the same or different RAG pro-
cesses can be executed, passing through multiple processing",N/A,N/A
"modules {M1, M2, . . . , Mk} to obtain branch output result
pi
= Mik(. . . Mi2(Mi1(bi)) . . .). The results of multiple
branches are aggregated using an aggregation function to
obtain intermediate output results. ˆO = Mmerge({pi | bi ∈
B}). However, aggregation is not necessarily the end of the
RAG flow, as it can continue to connect to other modules,
Mjn(. . . Mj2(Mj1( ˆO)) . . .). For example, after aggregating
multiple model responses, they can continue through a val-",N/A,N/A
"idation module. Therefore, the entire branch flow pattern can
be represented as:
Pbranch =Mjn(. . . Mj1(Mmerge({Mik
(. . . Mi1(bi) . . .) | bi ∈Msplit(q)})) . . .)
(27)
Algorithm 3 Pre-retrieval Branching Flow Pattern
Require: original query q, documents D, query expand mod-
ule Mexpand, retriever Mretrieve, language model LLM,
merge module Mmerge
Ensure: final output ˆy
1: Initialize:
2: Q′ ←Mexpand(q) // Expand the original query to multiple
sub-queries
3: for all q′
i ∈Q′ do
4:
D′",N/A,N/A
"sub-queries
3: for all q′
i ∈Q′ do
4:
D′
i ←Mretrieve(q′
i, D) // Retrieve documents for each
sub-query
5:
Gi ←∅// Initialize an empty set for generated results
of the sub-query
6:
for all d′
ij ∈D′
i do
7:
yij ←LLM([q′
i, d′
ij]) // Generate results for each
document of the sub-query
8:
Oi ←Oi ∪{yij} // Add generated results to the set
9:
end for
10:
ˆy ←Mmerge(Oi) // Merge generated results of the sub-
query into the final result
11: end for
12: return ˆy",N/A,N/A
"11: end for
12: return ˆy
The RAG flow with a branching structure differs from
the conditional approach in that it involves multiple parallel
branches, as opposed to selecting one branch from multiple
options in the conditional approach. Structurally, it can be
categorized into two types, which are depicted in Figure 7
and Figure 8.
Pre-Retrieval Branching (Multi-Query, Parallel Retrieval).
As shown in Algorithm 3, the process involves initially taking",N/A,N/A
"a query q and expanding it through a module Mexpand to gen-
erate multiple sub-queries Q′. Each sub-query q′
i is then used
to retrieve relevant documents via Mretrieve, forming document
sets D′
i. These document sets, along with the corresponding
sub-queries, are fed into a generation module Mgenerate to
produce a set of answers Gi. Ultimately, all these generated
answers are combined using a merging module Mmerge to
form the final result y. This entire flow can be mathematically",N/A,N/A
"represented as:
Pbranchpre =Mmerge(q′
i∈Mexpand(q){Mgenerate(q′
i, d′
ij) |
d′
ij ∈Mretrieve(q′
i)})
(28)
Post-Retrieval Branching (Single Query, Parallel Genera-
tion). As shown in Algorithm 4, in the post-retrieval branching
pattern, the process starts with a single query q which is
used to retrieve multiple document chunks through a retrieval
module Mretrieve, resulting in a set of documents Dq. Each
document dq
i from this set is then independently processed by",N/A,N/A
"a generation module Mgenerate to produce a set of generated
results G. These results are subsequently merged using a
merge module Mmerge to form the final result y. The process
can be succinctly represented as y = Mmerge(Oi), where Oi is
the collection of all generated results from each document dq
i
in Dq. Therefore, the entire process can be represented as:
Pbranchpost = Mmerge({Mgenerate(dq
i ) | dq
i ∈Mretrieve(q)})
(29)
Algorithm 4 Post-retrieval Branching Flow Pattern",N/A,N/A
"Algorithm 4 Post-retrieval Branching Flow Pattern
Require: original query q, documents D, retriever R, lan-
guage model LLM, merge module Mmerge
Ensure: final output ˆy
1: Initialize:
2: q′ ←fpre(q) // Pre-process the original query
3: Dq′ ←R(q′, D) // Retrieve a set of documents based on
the pre-processed query
4: G ←∅// Initialize an empty set to store generated results
5: for all di ∈Dq′ do
6:
yi ←LLM([q, di]) // Generate results independently
for each document chunk using the language model",N/A,N/A
"for each document chunk using the language model
7:
Oi ←Oi ∪{yi} // Add the generated result to the set
of results
8: end for
9: ˆy ←Mmerge(Oi) // Merge all generated results using the
merge function
10: return ˆy
REPLUG [55] embodies a classic post-retrieval branching
structure, wherein the probability of each token is predicted
for each branch. Through weighted possibility ensemble, the
different branches are aggregated, and the final generation
12",N/A,N/A
"12
Fig. 9. The RAG flow in REPLUG [55], which follows a typical post-retrieval
branching pattern. Each retrieved chunks undergoes parallel generation, and
then they are aggregated using a weighted probability ensemble.
result is used to fine-tune the retriever, known as Contriever,
through feedback.
D. Loop Pattern
The RAG flow with a loop structure, as an important char-
acteristic of Modular RAG, involves interdependent retrieval
and generation steps. It typically includes a scheduling module",N/A,N/A
"for flow control. The modular RAG system can be abstracted
as a directed graph G = (V, E), where V is the set of vertices
representing the various modules Mi in the system, and E is
the set of edges representing the control flow or data flow be-
tween modules. If there is a vertex sequence Mi1, Mi2, ..., Min
such that Min can reach Mi1 (i.e., Min →Mi1), then this
RAG system forms a loop. If Mj is the successor module of
Mi and Mi decides whether to return to Mj or a previous",N/A,N/A
"module Mk through a Judge module, it can be represented
as: Mi
Judge
−−−→Mj
or
Mi
Judge
−−−→Mk where Mk is the
predecessor module of Mj. If Mi return to Mj, it can be
represented as: ∃Judge(Mi, Mj)
s.t.
(Mi, Mj) ∈E
and
Judge(Mi, Mj) = true. If the Judge module not to return
to any previous module, it can be represented as: ∀Mi ∈
V,
Judge(Mi, Mj) = false for all Mj that are predecessors
of Mi. Loop pattern can be further categorized into iterative,",N/A,N/A
"recursive, and adaptive (active) retrieval approaches.
Iterative retrieval At times, a single retrieval and genera-
tion may not effectively address complex questions requiring
extensive knowledge. Therefore, an iterative approach can be
used in RAG (see Algorithm 5), typically involving a fixed
number of iterations for retrieval. At step t, given the query
qt and the previous output sequence y<t = [y0, . . . , yt−1] ,
iterations proceed under the condition that t is less than the",N/A,N/A
"maximum allowed iterations T. In each loop, it retrieves a
document chunks Dt−1 using the last output yt−1 and the
current query qt. Subsequently, a new output yt is generated.
The continuation of the iteration is determined by a Judge
module, which makes its decision based on the yt, y<t, qt,
and the Dt−1.
An
exemplary
case
of
iterative
retrieval
is
ITER-
RETGEN [56] (Figure 11), which iterates retrieval-augmented
generation and generation-augmented retrieval. Retrieval-",N/A,N/A
"augmented generation outputs a response to a task input based
on all retrieved knowledge. In each iteration, ITER-RETGEN
leverages the model output from the previous iteration as a
specific context to help retrieve more relevant knowledge.
Fig. 10. Loop flow pattern. Typically, a RAG system performs multiple rounds
of retrieval and generation. It can be categorized into three forms: iterative,
recursive, and adaptive.
Algorithm 5 Iterative RAG Flow Pattern",N/A,N/A
"Algorithm 5 Iterative RAG Flow Pattern
Require: original query q, documents D, maximum iterative
times T, language model LLM, retriever R, initial output
y<1 = ∅
Ensure: final output ˆy
1: Initialize:
2: qt ←q // Initialize query for the first iteration
3: y<1 ←∅// Initialize previous outputs as empty
4: t ←1 // Initialize iteration step
5: while t ≤T do
6:
qt ←QueryTransform(y<t−1, qt−1) // Generate query
based on previous output and original query
7:",N/A,N/A
"based on previous output and original query
7:
Dt ←R(yt−1||qt, D) // Retrieve or update documents
related to the current query
8:
yt ←LLM([y<t−1, qt, Dt]) // Generate output using
the language model
9:
y<t ←[y<t−1, yt] // Update the list of previous outputs
10:
if Judge(yt, q) = false then
11:
break
12:
end if
13:
t ←t + 1 // Increment iteration step
14: end while
15: yfinal = synthesizeOutput(y≤t) // Synthesize final output
from the list of outputs
16: return ˆy
13",N/A,N/A
"from the list of outputs
16: return ˆy
13
Fig. 11. ITER-RETGEN [56] is a typical iterative structure. Multiple rounds
of retrieval and generation are performed within the limit of the maximum
number of iterations.
Termination of the loop is determined by a predefined number
of iterations.
Recursive retrieval The characteristic feature of recursive
retrieval (see Algorithm 6), as opposed to iterative retrieval, is
its clear dependency on the previous step and its continuous",N/A,N/A
"deepening of retrieval. Typically, it follows a tree-like structure
and there is a clear termination mechanism as an exit condition
for recursive retrieval. In RAG systems, recursive retrieval usu-
ally involves query transform, relying on the newly rewritten
query for each retrieval.
Algorithm 6 Recursive RAG Flow Pattern
Require: initial query q, document D, retriever R, language
model LM, maximum recursive depth Kmax
Ensure: final output ˆy
1: Initialize:
2:
Q ←{q}
3:",N/A,N/A
"1: Initialize:
2:
Q ←{q}
3:
k ←0 // Initialize recursion depth
4: while Q ̸= ∅and k < Kmax do
5:
Q′ ←∅// To store queries for the next recursion level
6:
for all q ∈Q do
7:
Dq ←R(q, D) // Retrieve or update documents
related to the current query
8:
Y
←LM([q, Dq]) // Generate outputs using the
language model
9:
Q′′ ←deriveNewQueries(q, Dq, Y ) // Derive new
queries from generated outputs
10:
for all q′ ∈Q′′ do
11:
if q′ /∈Q′ and q′ /∈Q then
12:
Q′ ←Q′ ∪{q′}
13:
end if
14:
end for
15:
end for
16:",N/A,N/A
"13:
end if
14:
end for
15:
end for
16:
Q ←Q′ // Update the set of queries for the next
recursion
17:
k ←k + 1 // Increment recursion depth
18: end while
19: ˆy = synthesizeOutput(Y ) // Synthesize final output from
generated outputs
20: return ˆy
A typical implementation of recursive retrieval, such as
ToC [13] (see Figure 12 ), involves recursively executing RAC
(Recursive Augmented Clarification) to gradually insert sub-
nodes into the clarification tree from the initial ambiguous",N/A,N/A
"question (AQ). At each expansion step, paragraph re-ranking
is performed based on the current query to generate a disam-
Fig. 12.
RAG flow of ToC [13]. A typical characteristic of this process is
that each recursive retrieval uses the new query generated from the previous
step, thereby progressively deepening analysis of the original complex query.
biguous Question (DQ). The exploration of the tree concludes
upon reaching the maximum number of valid nodes or the",N/A,N/A
"maximum depth. Once the clarification tree is constructed,
ToC gathers all valid nodes and generates a comprehensive
long-text answer to address AQ.
Adaptive (Active) retrieval With the advancement of RAG,
there has been a gradual shift beyond passive retrieval to the
emergence of adaptive retrieval (see Algorithm 7) , also known
as active retrieval, which is partly attributed to the powerful
capabilities of LLM. This shares a core concept with LLM",N/A,N/A
"Agent [57]. RAG systems can actively determine the timing
of retrieval and decide when to conclude the entire process and
produce the final result. Based on the criteria for judgment,
this can be further categorized into Prompt-base and Tuning-
base approaches.
Algorithm 7 Active RAG Flow Pattern
Require: original query Q, documents D, maximum iterative
times T, language model LLM, retriever R
Ensure: final output ˆy
1: Initialize:
2: t ←1 // Initialize loop step",N/A,N/A
"1: Initialize:
2: t ←1 // Initialize loop step
3: qt ←q // Initialize query for the first iteration
4: y<1 ←∅// Initialize previous outputs as empty
5: while t ≤T do
6:
Qt ←QueryTransform(y<t−1, qt−1) // Derive new
query from previous output and query
7:
if Evaluate(Qt, y<t−1) then
8:
Dt ←R(qt, D) // Retrieve documents based on the
new query
9:
yt ←LLM([qt, Dt]) // Generate output using the
language model
10:
else
11:
yt ←∅// Set output as empty if query evaluation is
false
12:
end if
13:",N/A,N/A
"false
12:
end if
13:
y<t ←[y<t−1, yt] // Update the list of previous outputs
14:
if isOutputAcceptable(yt, y<t, qt) = false then
15:
break // Break if the output is not acceptable
16:
end if
17:
t ←t + 1 // Increment iteration step
18: end while
19: ˆy = synthesizeOutput(y≤t) // Synthesize final output from
the list of outputs
20: return ˆy
Prompt-base. The prompt-base approach involves control-
ling the flow using Prompt Engineering to direct LLM. A
14",N/A,N/A
"14
Fig. 13. RAG flow of FLARE [14]. The generated provisional answer will
undergo confidence assessment. If it does not meet the required confidence
level, the process will return to the retrieval stage and generate anew. The
assessment criteria are implemented through prompt
Fig. 14.
RAG flow of SELF-RAG [28]. First, it prompt GPT-4 to obtain
a suitable instruct fine-tuning dataset to fine-tune the deployed open-source",N/A,N/A
"LLM. This allows the model to output four specific tokens during generation,
which are used to control the RAG process.
typical implementation example is FLARE [14]. Its core
concept is that LLMs should only retrieve when essential
knowledge is lacking, to avoid unnecessary or inappropriate
retrieval in an enhanced LM. FLARE iteratively generates the
next provisional sentence and checks for the presence of low-
probability tokens. If found, the system retrieves relevant docu-",N/A,N/A
"ments and regenerates the sentence. Tuning-base. The tuning-
based approach involves fine-tuning LLM to generate special
tokens, thereby triggering retrieval or generation. This concept
can be traced back to Toolformer [50], where the generation of
specific content assists in invoking tools. In RAG systems, this
approach is used to control both retrieval and generation steps.
A typical case is Self-RAG [28](see Figure 14). Given an
input prompt and the preceding generation result, first predict",N/A,N/A
"whether the special token Retrieve is helpful for enhancing
the continued generation through retrieval. Then, if retrieval
is needed, the model generates a critique token to evaluate the
retrieved passage’s relevance. and a critique token to evaluate
if the information in the response is supported by the retrieved
passage. Finally, a critique token evaluates the overall utility of
the response and selects the optimal result as the final output.
E. Tuning Pattern",N/A,N/A
"E. Tuning Pattern
RAG is continuously integrating with more LLM-related
technologies. In Modular RAG, many components are com-
posed of trainable language models. Through fine-tuning, the
performance of the components and the compatibility with
the overall flow can be further optimized. This section will
introduce three main patterns of fine-tuning stages, namely
retriever fine-tuning, generator fine-tuning, and dual fine-
tuning.
Fig. 15.",N/A,N/A
"tuning.
Fig. 15.
Retriever fine-tuning pattern, mainly includes direct SFT, adding
trainable adapter, LM-supervised retrieval and LLM Reward RL.
1) Retriever FT: In the RAG flow, common methods for
fine-tuning the retriever is shown in Figure 15 ,which include:
• Direct supervised fine-tuning of the retriever. Construct-
ing a specialized dataset for retrieval and fine-tuning the
dense retriever. For example, using open-source retrieval
datasets or constructing one based on domain-specific",N/A,N/A
"data.
• Adding trainable adapter modules. Sometimes, direct
fine-tuning of the API-base embedding model (e.g., Ope-
nAI Ada-002 and Cohere) is not feasible. Incorporating
an adapter module can enhance the representation of
your data. Additionally, the adapter module facilitates
better alignment with downstream tasks, whether for task-
specific (e.g., PRCA [42]) or general purposes (e.g.,
AAR [58]).
• LM-supervised Retrieval (LSR). Fine-tuning the retriever
based on the results generated by LLM.",N/A,N/A
"based on the results generated by LLM.
• LLM Reward RL. Still using the LLM output results as
the supervisory signal. Employing reinforcement learning
to align the retriever with the generator. The whole re-
trieval process is disassembled in the form of a generative
Markov chain.
2) Generator FT: The primary methods for fine-tuning a
generator in RAG flow is shown in Figure 16, which include:
• Direct supervised fine-tuning. Fine-tuning through an",N/A,N/A
"external dataset can supplement the generator with ad-
ditional knowledge. Another benefit is the ability to
customize input and output formats. By setting the Q&A
format, LLM can understand specific data formats and
output according to instructions.
• Distillation. When using on-premise deployment of open-
source models, a simple and effective Optimization
method is to use GPT-4 to batch construct fine-tuning
data to enhance the capabilities of the open-source model.",N/A,N/A
"• RL from LLM/human feedback. Reinforcement learning
based on feedback from the final generated answers. In
addition to using human evaluations, powerful LLMs can
also serve as an evaluative judge.
3) Dual FT: In the RAG system, fine-tuning both the
retriever and the generator simultaneously is a unique feature
of the RAG system. It is important to note that the emphasis
of system fine-tuning is on the coordination between the
retriever and the generator. An exemplary implementation is",N/A,N/A
"RA-DIT [27], which fine-tunes both the LLM and the retriever.
The LM-ft component updates the LLM to maximize the
15
Fig. 16.
Generator fine-tuning pattern, The main methods include SFT,
distillation and RL from LLM/human feedback.
Fig. 17.
Dual fine-tuning pattern. In this mode, both the retriever and
generator participate in fine-tuning, and their preferences will be aligned.
likelihood of the correct answer given the retrieval-augmented",N/A,N/A
"instructions while the R-ft component updates the retriever
to minimize the KL-Divergence between the retriever score
distribution and the LLM preference.
VI. DISCUSSION
In this chapter, we explore the innovative horizons opened
by the modular RAG paradigm. We examine its compatibility
with cutting-edge methodologies in the progression of RAG
technology, emphasizing its scalability. It not only fosters a
fertile ground for model innovation but also paves the way for",N/A,N/A
"seamless adaptation to the dynamic requirements of various
applications.
A. Opportunities in Modular RAG
The benefits of Modular RAG are evident, providing a
fresh and comprehensive perspective on existing RAG-related
work. Through modular organization, relevant technologies
and methods are clearly summarized.
From a research perspective. Modular RAG is highly
scalable, it empowers researchers to introduce innovative mod-
ules and operators, leveraging a deep understanding of RAG’s",N/A,N/A
"evolving landscape. This flexibility enables the exploration of
new theoretical and practical dimensions in the field.
From an application perspective. The modularity of RAG
systems simplifies their design and implementation. Users can
tailor RAG flows to fit their specific data, use cases, and
downstream tasks, enhancing the adaptability of the system
to diverse requirements. Developers can draw from existing
flow architectures and innovate by defining new flows and",N/A,N/A
"patterns that are tailored to various application contexts and
domains. This approach not only streamlines the development
process but also enriches the functionality and versatility of
RAG applications.
B. Compatibility with new methods
Modular RAG paradigm demonstrates exceptional compati-
bility with new developments. To gain a deeper understanding
of this, we list three typical scalability cases, which clearly
shows that Modular RAG paradigm provides robust support",N/A,N/A
"and flexibility for the innovation and development of RAG
technology.
1) Recombination of the current modules: In this scenario,
no new modules or operators are proposed; rather, specific
problems are addressed through the combination of existing
modules.DR-RAG [59] employs a two-stage retrieval strategy
and classifier selection mechanism, incorporating a branching
retrieval structure. In the first stage, retrieving chunks relevant
to the query. In the second stage, the query is combined",N/A,N/A
"individually with each chunk retrieved in the first stage, and a
parallel secondary retrieval is conducted. The retrieved content
is then input into a classifier to filter out the most relevant
dynamic documents. This ensures that the retrieved documents
are highly relevant to the query while reducing redundant
information. DR-RAG improved retrieval method significantly
enhances the accuracy and efficiency of answers, bolstering
RAG’s performance in multi-hop question-answering scenar-
ios.",N/A,N/A
"ios.
2) New flow without adding new operators.: This refers
to redesigning the processes for retrieval and generation to
address more complex scenarios without proposing new mod-
ules. The core idea of PlanRAG [18] lies in its introduction of
a preliminary planning stage, a crucial step that occurs before
retrieval and generation. Initially, the system employs a judge
module to assess whether the current context necessitates the
formulation of a new plan or adjustments to an existing one.",N/A,N/A
"When encountering a problem for the first time, the system
initiates the planning process, while in subsequent interactions,
it decides whether to execute re-planning based on previous
plans and retrieved data.
Next, the system devises an execution plan tailored to the
query, treating this process as a logical decomposition of
complex queries. Specifically, PlanRAG uses a query expan-
sion module to extend and refine the query. For each derived",N/A,N/A
"sub-query, the system conducts targeted retrieval. Following
retrieval, another judge module evaluates the current results to
decide whether further retrieval is required or if it should return
to the planning stage for re-planning. Through this strategy,
PlanRAG is able to handle complex decision-making problems
that require multi-step data analysis more efficiently.
3) New flow derived from new operators.: New operators
often introduce novel flow design, exemplified by Multi-Head",N/A,N/A
"RAG [60]. Existing RAG solutions do not focus on queries that
may require retrieving multiple documents with significantly
different content. Such queries are common but difficult to
handle because embeddings of these documents may be far
apart in the embedding space. Multi-Head RAG addresses this
by designing a new retriever that uses the activations of the
multi-head attention layers of the Transformer, rather than the
decoder layers, as keys for retrieving multifaceted documents.",N/A,N/A
"Different attention heads can learn to capture different aspects
of the data. By using the corresponding activation results,
embeddings that represent different aspects of the data items
and the query can be generated, thereby enhancing the retrieval
accuracy for complex queries.
16
VII. CONCLUSION
RAG is emerging as a pivotal technology for LLM applica-
tions. As technological landscapes evolve and the intricacies of
application requirements escalate, RAG systems are being en-",N/A,N/A
"hanced by integrating a diverse suite of technologies, thereby
achieving a higher level of complexity and functionality. This
paper introduces the innovative paradigm of Modular RAG.
This approach systematically disassembles the complex archi-
tecture of RAG systems into well-defined, discrete functional
modules. Each module is meticulously characterized by its
specific operational functions, ensuring clarity and precision.
Therefore, the entire system is composed of those modules",N/A,N/A
"and operators, akin to Lego bricks. By conducting an in-
depth analysis of numerous studies, the paper also distills
common RAG design patterns and scrutinizes key case studies
to illustrate these patterns in practice.
Modular RAG not only offers a structured framework for
the design and application of RAG systems but also en-
ables a scenario-based customization of these systems. The
modularity inherent in this design facilitates ease of tracking",N/A,N/A
"and debugging, significantly enhancing the maintainability and
scalability of RAG systems. Furthermore, Modular RAG opens
up new avenues for the future progression of RAG technology.
It encourages the innovation of novel functional modules and
the crafting of innovative workflows, thereby driving forward
the frontiers of RAG systems.
REFERENCES
[1] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,
Y. Zhang, Y. Chen et al., “Siren’s song in the ai ocean: A survey on hal-",N/A,N/A
"lucination in large language models,” arXiv preprint arXiv:2309.01219,
2023.
[2] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and
H. Wang, “Retrieval-augmented generation for large language models:
A survey,” arXiv preprint arXiv:2312.10997, 2023.
[3] Z. Xu, M. J. Cruz, M. Guevara, T. Wang, M. Deshpande, X. Wang,
and Z. Li, “Retrieval-augmented generation with knowledge graphs
for customer service question answering,” in Proceedings of the 47th",N/A,N/A
"International ACM SIGIR Conference on Research and Development in
Information Retrieval, 2024, pp. 2905–2909.
[4] C. Zhang, S. Wu, H. Zhang, T. Xu, Y. Gao, Y. Hu, and E. Chen,
“Notellm: A retrievable large language model for note recommendation,”
in Companion Proceedings of the ACM on Web Conference 2024, 2024,
pp. 170–179.
[5] R. Anantha, T. Bethi, D. Vodianik, and S. Chappidi, “Context tuning
for retrieval augmented generation,” arXiv preprint arXiv:2312.05708,
2023.",N/A,N/A
"2023.
[6] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-
rec: Towards interactive and explainable llms-augmented recommender
system,” arXiv preprint arXiv:2303.14524, 2023.
[7] J. Liu, “Building production-ready rag applications,” https://www.ai.
engineer/summit/schedule/building-production-ready-rag-applications,
2023.
[8] D. S. Asudani, N. K. Nagwani, and P. Singh, “Impact of word embedding
models on text analytics in deep learning environment: a review,”",N/A,N/A
"Artificial intelligence review, vol. 56, no. 9, pp. 10 345–10 425, 2023.
[9] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,
Y. Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:
Redefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,
2024.
[10] W. Peng, G. Li, Y. Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al.,
“Large language model based long-tail query rewriting in taobao search,”
arXiv preprint arXiv:2311.03758, 2023.",N/A,N/A
"arXiv preprint arXiv:2311.03758, 2023.
[11] Y. Xi, J. Lin, W. Liu, X. Dai, W. Zhang, R. Zhang, R. Tang, and
Y. Yu, “A bird’s-eye view of reranking: from list level to page level,”
in Proceedings of the Sixteenth ACM International Conference on Web
Search and Data Mining, 2023, pp. 1075–1083.
[12] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-
generation synergy augmented large language models,” arXiv preprint
arXiv:2310.05149, 2023.",N/A,N/A
"arXiv:2310.05149, 2023.
[13] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-
tions: Answering ambiguous questions with retrieval-augmented large
language models,” arXiv preprint arXiv:2310.14696, 2023.
[14] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang,
J. Callan, and G. Neubig, “Active retrieval augmented generation,” arXiv
preprint arXiv:2305.06983, 2023.
[15] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,",N/A,N/A
"and J. Larson, “From local to global: A graph rag approach to query-
focused summarization,” arXiv preprint arXiv:2404.16130, 2024.
[16] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for
llm evaluation of rag applications,” https://www.databricks.com/blog/
LLM-auto-eval-best-practices-RAG, 2023.
[17] X. Wang, Z. Wang, X. Gao, F. Zhang, Y. Wu, Z. Xu, T. Shi, Z. Wang,
S. Li, Q. Qian et al., “Searching for best practices in retrieval-augmented",N/A,N/A
"generation,” arXiv preprint arXiv:2407.01219, 2024.
[18] M. Lee, S. An, and M.-S. Kim, “Planrag: A plan-then-retrieval aug-
mented generation for generative large language models as decision
makers,” arXiv preprint arXiv:2406.12430, 2024.
[19] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and
A. Sharma, “Gar-meets-rag paradigm for zero-shot information re-
trieval,” arXiv preprint arXiv:2310.20158, 2023.
[20] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,",N/A,N/A
"H. K¨uttler, M. Lewis, W.-t. Yih, T. Rockt¨aschel et al., “Retrieval-
augmented generation for knowledge-intensive nlp tasks,” Advances in
Neural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.
[21] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-
can, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark et al.,
“Improving language models by retrieving from trillions of tokens,” in
International conference on machine learning. PMLR, 2022, pp. 2206–
2240.",N/A,N/A
"2240.
[22] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,
J. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot
learning with retrieval augmented language models,” arXiv preprint
arXiv:2208.03299, 2022.
[23] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-
ing retrieval with chain-of-thought reasoning for knowledge-intensive
multi-step questions,” arXiv preprint arXiv:2212.10509, 2022.",N/A,N/A
"[24] X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-
ing for retrieval-augmented large language models,” arXiv preprint
arXiv:2305.14283, 2023.
[25] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing
scenarios for live interpretation and automatic dubbing,” in Proceedings
of the 15th Biennial Conference of the Association for Machine
Translation in the Americas (Volume 2: Users and Providers Track and",N/A,N/A
"Government Track), J. Campbell, S. Larocca, J. Marciano, K. Savenkov,
and A. Yanishevsky, Eds.
Orlando, USA: Association for Machine
Translation in the Americas, Sep. 2022, pp. 202–209. [Online].
Available: https://aclanthology.org/2022.amta-upg.14
[26] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faith-
ful and interpretable large language model reasoning,” arXiv preprint
arXiv:2310.01061, 2023.
[27] X. V. Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Rodriguez,",N/A,N/A
"J. Kahn, G. Szilvasy, M. Lewis et al., “Ra-dit: Retrieval-augmented dual
instruction tuning,” arXiv preprint arXiv:2310.01352, 2023.
[28] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-rag: Learning
to retrieve, generate, and critique through self-reflection,” arXiv preprint
arXiv:2310.11511, 2023.
[29] Y. Huang and J. Huang, “A survey on retrieval-augmented text gen-
eration for large language models,” arXiv preprint arXiv:2404.10981,
2024.",N/A,N/A
"2024.
[30] Y. Hu and Y. Lu, “Rag and rau: A survey on retrieval-augmented
language model in natural language processing,” arXiv preprint
arXiv:2404.19543, 2024.
[31] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and
Q. Li, “A survey on rag meets llms: Towards retrieval-augmented large
language models,” arXiv preprint arXiv:2405.06211, 2024.
[32] P. Zhao, H. Zhang, Q. Yu, Z. Wang, Y. Geng, F. Fu, L. Yang, W. Zhang,",N/A,N/A
"and B. Cui, “Retrieval-augmented generation for ai-generated content:
A survey,” arXiv preprint arXiv:2402.19473, 2024.
[33] S.
Yang,
“Advanced
rag
01:
Small-to-
big
retrieval,”
https://towardsdatascience.com/
advanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.
17
[34] Y. Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,
“Knowledge graph prompting for multi-document question answering,”
arXiv preprint arXiv:2308.11730, 2023.",N/A,N/A
"arXiv preprint arXiv:2308.11730, 2023.
[35] D. Zhou, N. Sch¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-
urmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting
enables complex reasoning in large language models,” arXiv preprint
arXiv:2205.10625, 2022.
[36] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,
and J. Weston, “Chain-of-verification reduces hallucination in large
language models,” arXiv preprint arXiv:2309.11495, 2023.",N/A,N/A
"[37] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval
without relevance labels,” arXiv preprint arXiv:2212.10496, 2022.
[38] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V. Le,
and D. Zhou, “Take a step back: Evoking reasoning via abstraction in
large language models,” arXiv preprint arXiv:2310.06117, 2023.
[39] H. Cao, “Recent advances in text embedding: A comprehensive review
of top-performing methods on the mteb benchmark,” arXiv preprint",N/A,N/A
"arXiv:2406.01607, 2024.
[40] BAAI, “Flagembedding,” https://github.com/FlagOpen/FlagEmbedding,
2023.
[41] Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang, “Towards
general text embeddings with multi-stage contrastive learning,” arXiv
preprint arXiv:2308.03281, 2023.
[42] H. Yang, Z. Li, Y. Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao,
“Prca: Fitting black-box large language models for retrieval question an-
swering via pluggable reward-driven contextual adapter,” arXiv preprint",N/A,N/A
"arXiv:2310.18347, 2023.
[43] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and
P. Liang, “Lost in the middle: How language models use long contexts,”
arXiv preprint arXiv:2307.03172, 2023.
[44] Y. Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,
T. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark
for retrieval-augmented generation of large language models,” arXiv
preprint arXiv:2401.17043, 2024.",N/A,N/A
"preprint arXiv:2401.17043, 2024.
[45] L. Xia, J. Xu, Y. Lan, J. Guo, and X. Cheng, “Learning maximal
marginal relevance model via directly optimizing diversity evaluation
measures,” in Proceedings of the 38th international ACM SIGIR con-
ference on research and development in information retrieval, 2015, pp.
113–122.
[46] Cohere, “Say goodbye to irrelevant search results: Cohere rerank is
here,” https://txt.cohere.com/rerank/, 2023.",N/A,N/A
"here,” https://txt.cohere.com/rerank/, 2023.
[47] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y. Lin, Y. Yang, and L. Qiu,
“Longllmlingua: Accelerating and enhancing llms in long context sce-
narios via prompt compression,” arXiv preprint arXiv:2310.06839, 2023.
[48] R. Litman, O. Anschel, S. Tsiper, R. Litman, S. Mazor, and R. Man-
matha, “Scatter: selective context attentional scene text recognizer,” in
proceedings of the IEEE/CVF conference on computer vision and pattern",N/A,N/A
"recognition, 2020, pp. 11 962–11 972.
[49] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source
legal large language model with integrated external knowledge bases,”
arXiv preprint arXiv:2306.16092, 2023.
[50] T. Schick, J. Dwivedi-Yu, R. Dess`ı, R. Raileanu, M. Lomeli, L. Zettle-
moyer, N. Cancedda, and T. Scialom, “Toolformer: Language models
can teach themselves to use tools,” arXiv preprint arXiv:2302.04761,
2023.",N/A,N/A
"2023.
[51] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,
C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language
models to follow instructions with human feedback,” Advances in neural
information processing systems, vol. 35, pp. 27 730–27 744, 2022.
[52] S. J. Semnani, V. Z. Yao, H. C. Zhang, and M. S. Lam, “Wikichat:
Stopping the hallucination of large language model chatbots by few-
shot grounding on wikipedia,” arXiv preprint arXiv:2305.14292, 2023.
[53] J.",N/A,N/A
"[53] J.
Baek,
S.
Jeong,
M.
Kang,
J.
C.
Park,
and
S.
J.
Hwang,
“Knowledge-augmented language model verification,” arXiv preprint
arXiv:2310.12836, 2023.
[54] G. V. Cormack, C. L. Clarke, and S. Buettcher, “Reciprocal rank
fusion outperforms condorcet and individual rank learning methods,”
in Proceedings of the 32nd international ACM SIGIR conference on
Research and development in information retrieval, 2009, pp. 758–759.
[55] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-",N/A,N/A
"moyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box language
models,” arXiv preprint arXiv:2301.12652, 2023.
[56] Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen,
“Enhancing retrieval-augmented large language models with iterative
retrieval-generation synergy,” arXiv preprint arXiv:2305.15294, 2023.
[57] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang,
S. K. S. Yau, Z. Lin, L. Zhou et al., “Metagpt: Meta programming for",N/A,N/A
"multi-agent collaborative framework,” arXiv preprint arXiv:2308.00352,
2023.
[58] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever
improves generalization of language models as generic plug-in,” arXiv
preprint arXiv:2305.17331, 2023.
[59] Z. Hei, W. Wei, W. Ou, J. Qiao, J. Jiao, Z. Zhu, and G. Song,
“Dr-rag: Applying dynamic document relevance to retrieval-augmented
generation for question-answering,” arXiv preprint arXiv:2406.07348,
2024.",N/A,N/A
"2024.
[60] M. Besta, A. Kubicek, R. Niggli, R. Gerstenberger, L. Weitzen-
dorf, M. Chi, P. Iff, J. Gajda, P. Nyczyk, J. M¨uller et al., “Multi-
head rag: Solving multi-aspect problems with llms,” arXiv preprint
arXiv:2406.05085, 2024.",N/A,N/A
"RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented
Instructions
Wanlong Liu2†, Junying Chen1†, Ke Ji1, Li Zhou1, Wenyu Chen2, Benyou Wang1*
1 The Chinese University of Hong Kong, Shenzhen,
2 University of Electronic Science and Technology of China
wangbenyou@cuhk.edu.cn
Abstract
Retrieval-Augmented Generation (RAG) has
emerged as a key paradigm for enhancing large
language models (LLMs) by incorporating
external knowledge. However, current RAG",N/A,N/A
"external knowledge. However, current RAG
methods face two limitations: (1) they only
cover limited RAG scenarios. (2) They suffer
from limited task diversity due to the lack
of a general RAG dataset. To address these
limitations, we propose RAG-Instruct, a
general method for synthesizing diverse and
high-quality RAG instruction data based on
any source corpus. Our approach leverages
(1) five RAG paradigms, which encompass
diverse query-document relationships, and",N/A,N/A
"diverse query-document relationships, and
(2) instruction simulation, which enhances
instruction diversity and quality by utilizing
the strengths of existing instruction datasets.
Using this method, we construct a 40K
instruction dataset from Wikipedia, compre-
hensively covering diverse RAG scenarios
and tasks.
Experiments demonstrate that
RAG-Instruct effectively enhances LLMs’
RAG capabilities, achieving strong zero-shot
performance and significantly outperforming",N/A,N/A
"performance and significantly outperforming
various RAG baselines across a diverse set of
tasks. RAG-Instruct is publicly available at
https://github.com/FreedomIntelligence/RAG-
Instruct.
1
Introduction
Retrieval-Augmented Generation (RAG) (Guu
et al., 2020; Asai et al., 2024b) enhances large
language models (LLMs) by integrating exter-
nal knowledge through document retrieval, effec-
tively reducing hallucinations and improving per-
formance across diverse tasks (Asai et al., 2023;",N/A,N/A
"formance across diverse tasks (Asai et al., 2023;
Jin et al., 2024; Lu et al., 2022; Liu et al., 2024a).
Since retrievers are not perfect, and consider-
able research has shown that noisy retrieval can
adversely impact LLM performance (Petroni et al.,
*Corresponding author. †Equal Contribution.
2020; Shi et al., 2023; Maekawa et al., 2024), nu-
merous studies have focused on enhancing the ro-
bustness of RAG in handling noisy retrieval con-
texts (Wei et al., 2024; Chan et al., 2024). On the",N/A,N/A
"one hand, some studies involve adaptive retrieval
based on query analysis (Asai et al., 2024a; Jeong
et al., 2024), or query reformulation (Chan et al.,
2024; Ma et al., 2023) to enhance the robustness
of LLM-based RAG systems. On the other hand,
(Zhang et al., 2024; Liu et al., 2024b; Yoran et al.,
2024) enhance the robustness of models’ naive
RAG capabilities by training them to adapt to irrel-
evant and noisy documents.
However, existing RAG methods have two limi-",N/A,N/A
"However, existing RAG methods have two limi-
tations: (1) Limited RAG scenarios. Real-world
RAG scenarios are complex: Given the query, the
retrieved information may directly contain the an-
swer, offer partial help, or be helpless. Some an-
swers can be obtained from a single document,
while others require multi-hop reasoning across
multiple documents. Our preliminary study demon-
strates existing RAG methods cannot adequately
handle all such scenarios (Chan et al., 2024; Asai",N/A,N/A
"et al., 2024a; Liu et al., 2024b).
(2) Limited
task diversity. Due to the lack of a general RAG
dataset, most current RAG methods (Wei et al.,
2024; Zhang et al., 2024) are fine-tuned on task-
specific datasets (e.g., NQ (Kwiatkowski et al.,
2019), TrivialQA (Joshi et al., 2017)), which suffer
from limited question diversity and data volume.
To address these limitations, we propose RAG-
Instruct, a general method for synthesizing diverse
and high-quality RAG instruction data based on any",N/A,N/A
"source corpus. Using this method, we construct a
40K synthetic instruction dataset from Wikipedia
tailored for RAG. Our method emphasizes the di-
versity in two aspects:
1. Defining diverse RAG paradigms: we define
five RAG query paradigms that encompass
various query-document relationships to adapt
arXiv:2501.00353v1  [cs.CL]  31 Dec 2024
to different RAG scenarios, considering both
document usefulness and the number of useful
documents. Based on these modes, we prompt",N/A,N/A
"documents. Based on these modes, we prompt
LLMs to synthesize RAG-specific instructions
and responses using external documents.
2. Enhancing task diversity and data quality:
we incorporate exemplar data from existing
instruction datasets, such as SlimOrca (Mi-
tra et al., 2023) and Evol Instruct (Xu et al.,
2023), to guide the generation of RAG in-
structions. This approach is inspired by re-
cent advancements in synthetic instruction
datasets which have two key advantages: (1)",N/A,N/A
"datasets which have two key advantages: (1)
high-quality instruction-following responses
generated by proprietary LLMs, and (2) di-
verse instructions that cover a wide range of
real-world tasks. We refer to this approach
as “Instruction Simulation”, which leverages
the strengths of existing instruction datasets
to improve the diversity and quality of the
synthesized data.
Our contributions are summarized as follows:
• We introduce RAG-Instruct,
a general",N/A,N/A
"• We introduce RAG-Instruct,
a general
method for synthesizing diverse and high-
quality RAG instruction data from any given
corpus. Using this method, we construct the
RAG-Instruct dataset (based on Wikipedia),
the first dataset to comprehensively cover di-
verse RAG scenarios and tasks.
• We define five RAG paradigms to cover di-
verse query-document relationships and in-
troduce Instruction Simulation, a technique
that enhances instruction diversity and quality",N/A,N/A
"that enhances instruction diversity and quality
by utilizing the strengths of existing instruc-
tion datasets. These techniques ensure the
diversity of synthesized datasets across RAG
scenarios and tasks.
• Empirical experiments on 11 tasks, includ-
ing knowledge-intensive QA, multi-step rea-
soning, and domain-specific benchmarks,
demonstrate that RAG-Instruct significantly
enhances the model’s RAG capabilities. It sig-
nificantly outperforms previous state-of-the-",N/A,N/A
"nificantly outperforms previous state-of-the-
art methods such as Self-RAG (Asai et al.,
2024a) and RQ-RAG (Chan et al., 2024). Fur-
thermore, ablation studies demonstrate that
both Instruction Simulation and the five RAG
query paradigms significantly contribute to
the performance of RAG-Instruct.
Method
TriviaQA (Single-hop)
HotpotQA (Multi-hop)
Helpful Midhelp Helpless Helpful
Midhelp
Llama2-7b
71.0
48.0
17.1
51.2
21.2
Llama3-8b
76.4
51.0
20.2
61.4
21.4
Self-RAG (2-7b)
77.3
42.4
14.7
45.1",N/A,N/A
"61.4
21.4
Self-RAG (2-7b)
77.3
42.4
14.7
45.1
16.6
RQ-RAG (2-7b)
80.9
52.6
18.7
57.9
24.0
ChatQA-1.5 (3-8b)
83.5
54.9
21.4
65.1
23.9
ChatQA-2.0 (3-8b)
82.4
51.5
20.1
61.4
19.9
RAG-Instruct (3-8b)
86.9
72.6
40.5
73.1
42.2
Table 1: Preliminary study of limited RAG scenarios.
Accuracy (%) is reported. We divided TriviaQA and
HotPotQA into multiple subsets. More information for
each subset is shown in Appendix B.1
.
Dataset
Data Size
RAG Scenarios
Task Diversity
r0
r1
r2
r3
r4
LongAlpaca
12K
✗
✗
✗",N/A,N/A
"r0
r1
r2
r3
r4
LongAlpaca
12K
✗
✗
✗
✓
✗
✓
SQuAD2.0
130K
✗
✗
✗
✓
✗
✗
NarrativeQA
15K
✗
✗
✗
✓
✗
✗
RAG-12000
12K
✗
✗
✗
✓
✗
✗
Self-RAG Data
150K
✓
✗
✗
✓
✗
✗
RQ-RAG Data
40K
✗
✗
✗
✓
✓
✓
RAG-Instruct
40K
✓
✓
✓
✓
✓
✓
Table 2: Comparision with existing RAG datasets.r0 to
r4 represent the five RAG scenario paradigms defined
in Table 3.
2
Preliminary Study
Since retrievers are not perfect, the helpfulness of
retrieved documents to the query varies in real-
world scenarios. This raises the question: Can",N/A,N/A
"world scenarios. This raises the question: Can
existing RAG methods handle complex and var-
ious RAG scenarios?
To investigate this, we first define five RAG
scenarios based on query-document relationships,
which we believe cover the majority of RAG use
cases: Single-Doc Answer (helpful), Single-Doc
Support (midhelp), Useless Doc (helpless), Multi-
Doc Answer (helpful), and Multi-Doc Support
(midhelp). Detailed definitions for each scenario
are provided in § 3.1.",N/A,N/A
"are provided in § 3.1.
Next, we evaluate the performance of existing
RAG methods across these five scenarios.
Us-
ing GPT-4o (Achiam et al., 2023), we catego-
rize questions from two question answering (QA)
datasets, Single-hop QA (TriviaQA) and Multi-hop
QA (HotPotQA (Yang et al., 2018)), into relevant
subsets based on the defined RAG scenarios1. De-
tailed prompts for categorization are provided in
the Appendix B.1. Then we choose some robust
RAG methods, including Self-RAG (Asai et al.,",N/A,N/A
"RAG methods, including Self-RAG (Asai et al.,
2024a), RQ-RAG (Chan et al., 2024), ChatQA-1.5
and ChatQA-2.0 (Liu et al., 2024b) as baselines
1We choose these datasets for their large number of ques-
tions and subsets, which reduces bias.
Diverse synthetic datasets
RAG-Instruct
RAG
Paradigm
(
) Single-document
Supporting Information
Relationship Between        and    
Supporting
Explicit
Useless
(
) Multi-document
Supporting Information
(
) Single-document
Explicit Answer
(
) Multi-document",N/A,N/A
"Explicit Answer
(
) Multi-document
Explicit Answer
(
) Useless Documents
Source
Documents
ShareGPT
Evol-Instruct
Alpaca
SlimOrca
Instruction
Simulation
Filter
GPT-4o
Knowledge-intensive
 Insturctions 
GPT-4o
RAG  Scenarios
Diversity
Instruction
Diversity
Target
Figure 1: The main process of synthesizing data with RAG-Instruct. RAG-Instruct ensures instruction data diversity
through five RAG paradigms and Instruction Simulation.
to explore their performance across the five RAG
scenarios.",N/A,N/A
"scenarios.
As shown in Table 1, existing RAG methods im-
prove primarily in helpful scenarios, while gains
in mid-helpful and helpless scenarios are minimal,
with some, such as Self-RAG, even underperform-
ing the baseline. This indicates that existing RAG
methods are still unable to handle complex and di-
verse RAG scenarios effectively. In comparison,
our RAG-Instruct method demonstrates significant
improvements across all five scenarios, highlight-",N/A,N/A
"ing its effectiveness and adaptability to complex
and diverse RAG scenarios.
Comparision with existing RAG datasets.
We
review several representative non-task-specific
RAG datasets, including long-context instruction
datasets such as LongAlpaca (Chen et al., 2023b),
SQuAD2.0 (Rajpurkar et al., 2018), and Narra-
tiveQA (Koˇcisk`y et al., 2018), which have been
used in ChatQA for RAG training, as well as
datasets from classic RAG approaches including
Self-RAG data, RQ-RAG data and ChatQA data.",N/A,N/A
"Self-RAG data, RQ-RAG data and ChatQA data.
As shown in Table 2, existing RAG datasets fail
to balance both scenario and task diversity. Long-
context instruction datasets are limited to a nar-
row range of RAG scenarios and focus primar-
ily on reading comprehension tasks.
Addition-
ally, previous state-of-the-art RAG methods such as
Self-RAG perform poorly on multi-hop reasoning
benchmarks due to their neglect of multi-hop sce-
narios. These shortcomings are reflected in Table 1.",N/A,N/A
"In contrast, our RAG-Instruct effectively balances
both RAG scenario and task diversity, demonstrat-
ing superior generalization and robustness.
3
Method
This section outlines the RAG-Instruct process, fo-
cusing on constructing diverse and high-quality
synthetic RAG datasets. The detailed architecture
is illustrated in Figure 1.
3.1
RAG-Instruct
Synthesizing RAG Instructions.
Recent propri-
etary models like GPT-4o (Achiam et al., 2023)
have demonstrated remarkable capabilities, and",N/A,N/A
"have demonstrated remarkable capabilities, and
many works (Zheng et al., 2023b; Xu et al., 2023;
Chen et al., 2023a) based on synthetic datasets
have achieved notable success. Therefore, we use
GPT-4o to synthesize RAG instructions by lever-
aging source documents D∗2 to create context-rich
instructions. Specifically, GPT-4o synthesizes an
instruction q∗based on D∗, followed by a response
a∗referencing D∗, which can be formalized as:
(q∗,a∗) = LLM(D∗).
(1)",N/A,N/A
"(q∗,a∗) = LLM(D∗).
(1)
Inspired by work (Zhang et al., 2024), we intro-
duce documents D−unrelated to q∗, which serve
as additional noise to enhance the robustness. Then
our target RAG instruction is as follows.
D∗,D−,q∗→a∗.
However, RAG instructions generated this way
lack diversity in both RAG scenarios and tasks. To
address this, we define five RAG paradigms and
introduce Instruction Simulation.
2We will explain how D∗are obtained in the following
Instruction Simulation section.",N/A,N/A
"Instruction Simulation section.
D∗-q∗Relationship
Usefulness
of D∗
|D∗|
Relationship Description
(r0)
Useless Doc
Useless
1
D∗offers no help in answering q∗, even if related.
(r1)
Single-Doc Support
Supporting
1
One doc (|D∗| = 1) aids q∗, providing supporting info or clues
without explicit answers.
(r2)
Multi-Doc Support
Supporting
≥2
Multiple documents (|D∗| ≥2) support q∗by providing clues or
supporting information without explicitly answering it, requiring
integration (multi-hop reasoning).",N/A,N/A
"integration (multi-hop reasoning).
(r3)
Single-Doc Answer
Explicit
1
One doc (|D∗| = 1) directly provides the answer a∗to q∗.
(r4)
Multi-Doc Answer
Explicit
≥2
Multiple docs (|D∗| ≥2) provide a full answer to q∗, requiring
integration (multi-hop reasoning).
Table 3: Descriptions of 5 RAG paradigms. See Appendix B.2 for specific prompts.
<Documents>
[1] {<document 1>}
[2] {<document 2>}
[3] ...
</Documents>",N/A,N/A
"[2] {<document 2>}
[3] ...
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>.
Please note that the question q* can take various forms, not limited to questions with a question mark, but also including
statements, instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG
Paradigms):",N/A,N/A
"Paradigms):
1. The answer to q* can be derived from multiple documents within <Documents>, involving multi-hop reasoning or
the integration of information from several documents.
2. a* should leverage the information in <Documents> to provide an accurate answer to q*, ensuring that the response
is accurate, detailed, and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide",N/A,N/A
"a question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task
requirement and expression to the <Simulated Instruction> below:
<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"":
...}. Ensure the quality of the generated (q*, a*).",N/A,N/A
"Figure 2: The prompt of RAG-Instruct. <document> and <Simulated Instruction> represent input variables for
the document and simulated instruction, respectively. (Blue text) indicates RAG Paradigms, illustrating the prompt
for r4; other paradigms are shown in Appendix B.2. (Red text) represents Instruction Simulation.
RAG Paradigms.
Real-world RAG scenarios are
complex: Given the q∗, D∗may directly contain
the answer, offer partial help, or be helpless. Some",N/A,N/A
"answers can be obtained from a single document in
D∗, while others require multi-hop reasoning across
multiple documents. To address this, we define
RAG paradigms R, where each r ∈R characterizes
the relationship between D∗and q∗. As in Table
3, these RAG paradigms consider both document
utility and the count of useful documents.
Instruction
Simulation.
Generating
(q∗,a∗)
from D∗faces the challenge of instruction
monotony. Although q∗is related to D∗, the task,",N/A,N/A
"monotony. Although q∗is related to D∗, the task,
phrasing, and difficulty of the instructions can be-
come repetitive with a similar synthesis prompt.
Previous datasets address this by broadly collect-
ing instructions (Izacard et al., 2023) or using self-
instruct (Wang et al., 2023b). In our approach, we
leverage diverse, high-quality instructions to diver-
sify q∗, a process we term Instruction Simulation.
In this process, we use questions from synthetic",N/A,N/A
"In this process, we use questions from synthetic
datasets including ShareGPT (Wang et al., 2023a),
Alpaca (hin Cheung and Lam, 2023), WizardLM-
70K (Xu et al., 2023), Lmsys-chat-1M (Zheng
et al., 2023a), and SlimOrca (Mitra et al., 2023)
as exemplar data. These datasets cover a wide
range of tasks, diverse phrasing styles, and vary-
ing levels of instruction difficulty. Since RAG is
Useless Doc (��)
Single-Doc 
 Support (��)
Multi-Doc Support (��)
Single-Doc 
Answer (��)
Multi-Doc 
Answer (��)",N/A,N/A
"Single-Doc 
Answer (��)
Multi-Doc 
Answer (��)
(a) Distributions of RAG Paradigms
GPT4-Alpaca
WizardLM
Lmsys-Chat-1M
ShareGPT_V3
SlimOcar
(b) Distributions of Data Sources
Figure 3: The distributions of RAG paradigms and simulated instruction sources.
most effective in knowledge-intensive task scenar-
ios (Maekawa et al., 2024; Shi et al., 2023), we use
GPT-4o to filter knowledge-intensive instructions
from these synthetic datasets (details of the prompt
are provided in Appendix A.1).",N/A,N/A
"are provided in Appendix A.1).
Then for each synthesis, an instruction q′ ∈Q
is randomly sampled for simulation. Given a cor-
pus D containing multiple documents d ∈D, the
source documents D∗⊂D are retrieved based on
q′. Subsequently, (q∗,a∗) can be synthesized as
follows:
(q∗,a∗) = LLM(D∗,q′,r),
(2)
where r denotes the sampled RAG paradigm, and
the synthesis prompt is illustrated in Figure 2. Here,
D∗controls the topic of q∗, while q′ shapes its
format and task requirements.
3.2",N/A,N/A
"format and task requirements.
3.2
Dataset Construction
We construct RAG-Instruct using Wikipedia corpus.
For each synthesis, we sample an RAG paradigm
r, a simulated instruction q′, and retrieved source
documents D∗to generate (q∗,a∗) using GPT-4o.
To incorporate unrelated documents D−, we ran-
domly sample documents retrieved based on q∗and
ranked beyond the top 200 as D−. Additionally, for
cases where |D∗| ≥2, we ensure that the number
of source documents is fewer than 5. Subsequently,",N/A,N/A
"D∗,D−,q∗→a∗is set as the training objective to
form RAG-Instruct. In total, we build a dataset
of 40K instructions, with the distributions of RAG
paradigms and simulated instructions illustrated in
Figure 3. More dataset construction details are
shown in Appendix A.1.
4
Experiments
4.1
Experimental Settings
Evaluation Tasks.
We conduct evaluations of
our RAG-Instruct and various baselines across 10
tasks in four major categories: (1) Open-Ended
Tasks, including WebQA (WQA) (Berant et al.,",N/A,N/A
"Tasks, including WebQA (WQA) (Berant et al.,
2013), PopQA (PQA) (Mallen et al., 2023), and
TriviaQA-unfiltered (TQA) (Joshi et al., 2017),
where models answer open-domain factual ques-
tions with accuracy as the metric.
(2) Closed-
Set Tasks, including OpenbookQA (OBQA) (Mi-
haylov et al., 2018), PubHealth (Pub) (Zhang et al.,
2023) and ARC-Challenge (ARC) (Clark et al.,
2018), involving multiple-choice QA with Extract
Match (EM) as the metric. (3) Multi-Hop Tasks,",N/A,N/A
"Match (EM) as the metric. (3) Multi-Hop Tasks,
including 2WikiMultiHopQA (2WIKI) (Ho et al.,
2020), HotpotQA (HotQ) (Yang et al., 2018), and
Musique (MSQ) (Trivedi et al., 2022), requiring
multi-hop reasoning with accuracy as the metric.
(4) Domain-Specific Tasks, CFQA (Chen et al.,
2022) in the financial domain and PubMedQA (Jin
et al., 2019) in the medical domain, with EM as the
metric. We perform zero-shot evaluations through-
out these experiments, providing task instructions",N/A,N/A
"without few-shot demonstrations. Reasoning de-
tails and prompts are provided in Appendix A.2.
Baselines.
We compare our method against a di-
verse set of baselines, grouped into two main cate-
gories: (1) Closed-Source LLMs without RAG,
including GPT-4o and GPT-4o-mini. We test them
using OpenAI’s official APIs. (2) Open-source
model baselines with RAG, including Llama2-
7b (Touvron et al., 2023), Llama3-8b (Dubey et al.,
2024). Additionally, we also compare with compet-",N/A,N/A
"2024). Additionally, we also compare with compet-
itive open-source instruction-tuned LMs, such as
Llama3-8b-Instruct, Llama3-70B-Instruct, Llama2-
Open-ended
Closed-set
Multi-hop
Domain-specific
WQA
PQA
TQA
OBQA
Pub
ARC
2WIKI
HotP
MSQ
CFQA
PubMed
(acc)
(acc)
(acc)
(EM)
(EM)
(EM)
(acc)
(acc)
(acc)
(EM)
(EM)
Closed-Source LLMs without RAG
GPT-4o
68.5
60.3
79.4
88.6
87.7
88.0
88.0
54.6
31.4
63.0
77.0
GPT-4o-mini
63.5
62.2
77.2
89.6
87.0
84.1
74.4
54.5
30.8
60.7
73.0
RAG-Specific Models with RAG",N/A,N/A
"54.5
30.8
60.7
73.0
RAG-Specific Models with RAG
RQ-RAG (Llama2-7B)
56.5
57.1
70.2
80.6
71.8
68.3
53.7
43.1
18.2
21.9
55.6
Self-RAG (Llama2-7B)
49.0
55.8
69.3
78.0
72.4
73.1
48.4
35.8
11.5
21.5
49.8
ChatQA-1.5 (Llama3-8B)
53.8
55.4
73.0
70.8
77.0
66.0
63.6
46.2
20.1
56.0
61.7
ChatQA-2.0 (Llama3-8B)
50.5
58.3
72.5
72.6
75.8
65.6
59.0
42.3
16.1
51.8
61.3
Open-Source Base Models with RAG
Llama-2-7B
49.8
51.4
62.6
56.8
36.5
48.0
55.8
38.2
17.8
22.3
58.6
Llama-3-8B
59.4
57.8
71.9
58.6
50.1
50.5
62.3",N/A,N/A
"Llama-3-8B
59.4
57.8
71.9
58.6
50.1
50.5
62.3
42.2
23.9
44.6
62.3
Llama-3.1-8B
56.7
56.8
71.5
72.4
57.6
61.4
60.7
45.5
23.5
53.1
63.0
Qwen2.5-7B
61.0
58.5
71.7
70.6
56.6
65.2
59.8
46.2
22.2
52.8
67.4
Llama-3.1-70B
62.4
58.5
76.5
76.6
59.2
66.0
67.9
49.9
26.6
53.8
65.9
Open-Source Instruction-Tuned Models with RAG
Llama-3-8B-Instruct
62.1
62.0
72.4
75.0
58.2
67.4
65.9
45.0
19.1
54.9
72.8
Llama-3.1-8B-Instruct
61.9
62.8
73.9
77.2
56.8
70.3
66.8
45.5
19.0
53.7
73.6
Qwen2.5-7B-Instruct
64.1
62.0",N/A,N/A
"45.5
19.0
53.7
73.6
Qwen2.5-7B-Instruct
64.1
62.0
75.6
74.2
74.2
75.7
66.5
49.5
20.8
58.7
62.6
Llama-3.1-70B-Instruct
64.9
63.3
75.4
85.0
75.4
84.7
73.5
47.5
26.6
59.1
77.2
Llama-2-7B + RAG-Instruct
67.2
62.4
77.4
71.4
75.9
74.8
68.1
53.5
21.8
29.7
71.2
Llama-3-8B + RAG-Instruct
68.6
65.3
79.5
79.6
75.0
78.4
76.0
58.1
32.0
57.4
78.2
Llama-3.1-8B + RAG-Instruct
69.7
68.4
80.0
82.4
77.2
79.6
76.8
59.6
33.7
57.3
77.0
Qwen2.5-7B + RAG-Instruct
66.1
63.7
78.1
78.4
76.4
78.0
74.8
54.6
27.7
55.0
72.7",N/A,N/A
"63.7
78.1
78.4
76.4
78.0
74.8
54.6
27.7
55.0
72.7
Llama-3.1-70B + RAG-Instruct
70.6
69.4
82.2
88.6
78.8
84.2
82.8
63.9
41.2
61.6
78.5
Table 4: Zero-shot performance of different instruction datasets on RAG Benchmarks. Bold and underline indicate
the best and second-best experimental results. The datasets were fine-tuned using identical hyperparameters.
7b-chat, Llama-3.1-8B-Instruct and Qwen2.5-7B-
Instruct (Yang et al., 2024) to evaluate the ad-
vantages of our RAG instruction dataset.
For",N/A,N/A
"vantages of our RAG instruction dataset.
For
instruction-tuned LMs, we use the official system
prompts or instruction formats from their train-
ing process when publicly available. (3) RAG-
specific baselines, including Self-RAG, RQ-RAG,
ChatQA-1.5, ChatQA-2.0. For these methods, we
evaluate using publicly released model weights and
prompts provided by their respective works.
Training settings.
We train our model using the
RAG-Instruct dataset (wikipedia), which features",N/A,N/A
"RAG-Instruct dataset (wikipedia), which features
diverse instruction-following input-output pairs.
During the dataset construction, we employ the off-
the-shelf Contriever-MS MARCO (Izacard et al.)
as the retriever. For each data entry, we ensure
the use of all source documents D∗and supple-
ment them with enough unrelated documents D−
to total 10 documents. For training, we use Llama2-
7B, Llama3-8B, Llama3.1-8B, Llama3.1-70B, and
Qwen2.5-7B as the base models. Additional train-",N/A,N/A
"Qwen2.5-7B as the base models. Additional train-
ing details are provided in Appendix A.1.
Inference settings.
We use vLLM (Kwon et al.,
2023) for memory-efficient inference and adopt a
greedy decoding strategy for model generation. For
evaluation benchmarks, we utilize Wikipedia as the
retrieval corpus and use the Contriever retriever
for document retrieval. More detailed inference
specifications can be found in Appendix A.2.
4.2
RAG Capability Gains
Comparison against closed-source LLMs.
As",N/A,N/A
"Comparison against closed-source LLMs.
As
shown in Table 4, compared to powerful propri-
etary models like GPT-4o and GPT-4o-mini, our
RAG-Instruct, trained on base 8B models, matches
or even outperforms them on several tasks, in-
cluding open-ended tasks (PQA and TQA), multi-
hop tasks (HotQA and MSQ), and domain-specific
tasks (PubMedQA). This demonstrates that our
RAG-Instruct significantly enhances the model’s
RAG capabilities.
Comparison against RAG-specific models.
As",N/A,N/A
"Comparison against RAG-specific models.
As
shown in Table 4, RAG-specific models such as
Self-RAG, and RQ-RAG show significant improve-
ments over the base models on open-ended and
closed-set tasks. However, they underperform com-
RAG 
Paradigms
Source Documents
Generated Question 
(w.o. Instruction Simulation)
Example Question
Gnerated Question
(w. Instruction Simulation)
�0
[1] know and understand the Creed, the Lord's 
Prayer, and the Ten Commandments, and be",N/A,N/A
"Prayer, and the Ten Commandments, and be 
able to answer the other questions in the 
Church Catechism. ...
What is the significance of 
confirmation within The 
Church of Jesus Christ of 
Latter-day Saints?
Claim: ""It's important for some Christians that their 
babies have a Baptism.”. Is the claim above correct, 
and can it be verified by human common sense and 
without a web search? Options: yes - no 
Claim: 'Baptism in some Christian traditions is considered",N/A,N/A
"necessary for salvation.' Is the claim above correct, and 
can it be verified by human common sense and without a 
web search? Options: - yes - no
�1
[1] The capital of Heilongjiang, is one of 
China's biggest cities with nearly ten million 
urban residents. It is also dependent on the its 
water supply. ...
What role does the Songhua 
River play in the capital of 
Heilongjiang?
Do these two sentences from wikipedia have the 
same meaning? Choose your answer from:",N/A,N/A
"same meaning? Choose your answer from: 
A  no   B. yes. The answer is:
Select the main industrial highlight of Harbin: 
A) Textile Manufacturing B) Steam Turbine Production  C)
Agriculture
�2
[1] In Tier 2, the main purpose of progress 
monitoring is to determine whether 
interventions are successful in helping 
students learn at an....
[2] Entities receiving grant money are given a 
fair amount of autonomy. Each plan devised....
What is the main purpose of 
progress monitoring in Tier",N/A,N/A
"progress monitoring in Tier 
2 interventions?
Imagine you are designing a program that analyzes 
factors like socio-economic status. The program 
should provide recommendations for study habits, 
tutoring, while also ensuring ongoing monitoring 
and collaboration with teachers, families, and 
community organizations.
Imagine you are an educational program designer tasked 
with creating a comprehensive intervention strategy aimed 
at improving student academic performance. What",N/A,N/A
"at improving student academic performance. What 
elements should be included in your strategy to ensure 
success, considering the different factors that can impact 
student learning outcomes?
�3
[1] Soil moisture Current or past data 
collection: Point framing, Above ground plant 
traits, Soil moisture, Transplant experiments, 
Nutrients; (Transplanted) seedling survival; ...
 Which plant genera are 
studied in the OTC plots?
Tell me the temperature,  sunshine rate, rainfall,",N/A,N/A
"humidity rate, soil type for handkerchief tree seed 
in bullets 2 words answer in number 
Summarize the main focus of the experiment and its 
geographical scope in one sentence.
�4
[1] facilitate data use by policy makers and 
researchers. It provides statistical standards, ...
[2] The birth rate percentages over the age of 
30 and under the age of 30 are also var...
[3]  Data can also be transformed to make 
them easier to visualize. For example, suppose 
  What role do population",N/A,N/A
"What role do population 
pyramids play in comparing 
demographic trends across 
different countries?
How can I generate a web page that displays a chart 
showing the population growth rate of different 
countries using Python code? Can you provide me 
with some sample code to get started?
How might data transformation influence the visualization 
of population statistics on a web platform?
Figure 4: Some cases of RAG-Instruct for each RAG scenario. We compare the generated questions with and",N/A,N/A
"without using Instruction Simulation.
pared to the base models on domain-specific and
multi-hop tasks. In contrast, our RAG-Instruct
achieves significant improvements across all four
categories of tasks compared to the base models
and outperforms all previous SOTA RAG-specific
models, particularly in multi-hop and domain-
specific tasks. This highlights its superior robust-
ness and generalization across a broader range of
RAG scenarios and tasks.
Comparison against Open-source instruction-",N/A,N/A
"Comparison against Open-source instruction-
tuned models.
We also compare our method with
open-source instruction-tuned models, which ex-
hibit strong RAG capabilities. As shown in Table 4,
models trained with RAG-Instruct on base models
outperform these instruction-tuned models across
various tasks, demonstrating that the RAG instruc-
tion dataset effectively enhances the model’s RAG
performance.
4.3
Impact of Instruction Simulation
To investigate the impact of Instruction Simulation,",N/A,N/A
"we design a comparative experiment. We randomly
sample a subset Ds containing 20,000 entries from
our RAG-Instruct dataset and create another subset
D′
s without using Instruction Simulation. To ensure
a fair comparison, Ds and D′
s share the same source
documents D∗and include all five RAG scenario
paradigms. We then train two models on Llama3-
8B using Ds and D′
s with identical hyperparameters.
As shown in Table 5, removing the Instruction
Simulation process results in performance declines",N/A,N/A
"across all tasks. The drop is smaller for open-ended
tasks but significantly larger for closed-set, multi-
hop, and domain-specific tasks. We observe that
without Instruction Simulation, GPT-4o tends to
generate overly simple and uniform questions, re-
sembling open-ended ones, leading to minimal im-
pact on closed-set evaluation. However, the di-
verse formats of closed-set, multi-hop, and domain-
specific tasks, such as multiple-choice and multi-
hop reasoning, pose challenges that the model",N/A,N/A
"hop reasoning, pose challenges that the model
struggles to handle. This highlights the critical role
of Instruction Simulation in enabling the model to
adapt to a wide variety of tasks.
Additionally, we provide specific cases, as
shown in Figure 4, demonstrating that Instruction
Simulation generates questions that closely resem-
ble exemplar questions, significantly enhancing
diversity compared to those produced without it.
Given the high quality and diversity of the synthe-",N/A,N/A
"sized dataset, Instruction Simulation ensures both
attributes effectively.
4.4
Role of RAG Paradigms
To evaluate the role of RAG paradigms, we design
an ablation experiment to verify the effectiveness
of the five RAG scenarios in RAG-Instruct. Specif-
ically, we remove the data corresponding to each
paradigm from RAG-Instruct one at a time and
train models on Llama3-8B using identical training
hyperparameters, respectively.
As shown in Table 6, when a single RAG",N/A,N/A
"As shown in Table 6, when a single RAG
paradigm (e.g. r0) is removed from RAG-Instruct,
we observe a noticeable performance drop in evalu-
ation benchmarks corresponding to that specific
RAG scenario.
This indicates that each RAG
paradigm plays a critical role in enhancing the
model’s RAG capabilities across different scenar-
ios. Furthermore, we observe that removing multi-
document paradigms (r2 and r4) leads to a signif-
icant decline in multi-hop performance. Notably,
Open-ended
Closed-set",N/A,N/A
"Open-ended
Closed-set
Multi-hop
Domain-specific
WQA
PQA
TQA
OBQA
Pub
ARC
2WIKI
HotP
MSQ
CFQA
PubMed
RAG-Instruct20k (Llama3-8B)
64.6
64.8
77.0
80.2
76.0
79.4
73.0
53.1
29.7
55.4
77.2
w.o. Simulation20k
63.4
63.1
75.9
74.2
71.4
70.4
62.5
47.7
25.0
47.4
70.4
RAG-Instruct w.o. Retrieval
57.6
28.4
64.2
61.2
60.6
62.8
47.7
35.4
10.1
-
-
Table 5: Ablation Study on RAG-Instruct. w.o. Simulation indicates the removal of the Instruction Simulation",N/A,N/A
"process, while w.o. Retrieval indicates the performance in non-retrieval scenarios.
when all multi-document paradigms (r2 and r4) are
removed, the model’s performance on multi-hop
tasks drops significantly. In contrast, removing all
single-document paradigms (r0, r1, r3) results in a
relatively small decline in single-hop performance.
This suggests that multi-document RAG paradigm
data can partially enhance the model’s RAG capa-
bilities in single-hop scenarios.
Method
TriviaQA (Single)",N/A,N/A
"Method
TriviaQA (Single)
HotpotQA (Multi)
Helpful Midhelp Helpless Helpful Midhelp
RAG-Instruct
86.9
72.6
40.5
73.1
42.2
w.o. r0
86.4
69.6
36.4–
74.1
39.3
w.o. r1
86.5
66.5–
40.9
72.4
41.3
w.o. r2
86.2
71.8
39.7
68.2
29.8–
w.o. r3
83.5 –
70.6
39.6
72.8
42.2
w.o. r4
85.2
72.1
39.5
65.4–
38.8
w.o. r0,r1,r3
84.3
68.1–
36.5–
74.8
41.4
w.o. r2, r4
85.0
71.4
38.8
63.5–
26.6–
Table 6: Ablation study on role of query paradigms.
All experiments are conducted based on the Llama3-8B",N/A,N/A
"model using identical hyperparameters. ‘–’ indicates
large performance drops for each paradigm.
4.5
Further Analysis
Performance in non-retrieval scenarios.
Since
our RAG-Instruct is built on the Wikipedia cor-
pus, the performance improvements on evaluation
benchmarks may stem from knowledge injection
during the supervised fine-tuning stage. To investi-
gate whether our approach genuinely enhances the
model’s RAG capabilities, we compare the perfor-",N/A,N/A
"model’s RAG capabilities, we compare the perfor-
mance in both retrieval and non-retrieval scenarios
(based on the Llama3-8B model trained on RAG-
Instruct). As shown in Table 5, performance in
non-retrieval scenarios is significantly lower across
all benchmarks compared to retrieval scenarios,
demonstrating that RAG-Instruct effectively en-
hances the model’s capabilities in RAG scenarios.
Different retrieval source.
To further explore
the generalization of our method, we investigate the",N/A,N/A
"impact of using different retrieval sources. Specifi-
cally, we further evaluate our method on four single-
hop QA tasks, including ARC, PQA, TQA and
OBQA, utilizing DuckDuckGo, and Bing Search
as retrieval sources during inference. The results
(detailed in Appendix C.) suggest that all retrieval
sources effectively improve task performance, with
minimal variation in performance across different
sources. This demonstrates the robustness of our
approach to enhancing RAG capabilities.
5",N/A,N/A
"approach to enhancing RAG capabilities.
5
Related Work
Retrieval-augmented generation (RAG) is a widely
adopted approach for supplementing the parametric
knowledge of large language models (LLMs) with
external information sources. Due to the imperfec-
tions of retrievers, the retrieved information often
fails to align well with the LLM’s needs, which can
negatively impact LLM performance (Petroni et al.,
2020; Shi et al., 2023; Maekawa et al., 2024).
To enhance LLM-based RAG capabilities, some",N/A,N/A
"To enhance LLM-based RAG capabilities, some
studies focus on aligning retrievers with LLM
needs (Shi et al., 2024; Lin et al., 2023) through
multi-step retrieval processes (Trivedi et al., 2023;
Jiang et al., 2023; Jeong et al., 2024; Shao et al.,
2023; Yu et al., 2023; Asai et al., 2024a; Wei et al.,
2024) and query reformulation (Ma et al., 2023;
Jeong et al., 2024). On the other hand, several
studies focus on enhancing the RAG capabilities
of LLMs by improving their robustness in noisy",N/A,N/A
"of LLMs by improving their robustness in noisy
retrieval contexts. Research such as (Chan et al.,
2024; Zhang et al., 2024; Liu et al., 2024b; Yoran
et al., 2024) trains models with additional irrelevant
or noisy documents to better handle such scenarios.
However, these approaches consider only a limited
range of RAG scenarios. Furthermore, the lack of
a general RAG dataset forces many works, such as
RAFT (Zhang et al., 2024), to fine-tune models on",N/A,N/A
"RAFT (Zhang et al., 2024), to fine-tune models on
task-specific datasets, leading to poor task general-
ization. This highlights the need for a dataset that
covers diverse RAG scenarios and tasks.
6
Conclusion
This work introduces RAG-Instruct, a method for
synthesizing diverse and high-quality RAG instruc-
tion data from any source corpus.
It incorpo-
rates five RAG paradigms to capture diverse query-
document relationships and uses instruction simula-",N/A,N/A
"tion to enhance data quality and diversity by lever-
aging existing datasets. Using this approach, we
construct a 40K instruction dataset from Wikipedia,
covering diverse RAG scenarios and tasks. For
future work, we plan to expand the instructions
in RAG-Instruct to incorporate chain-of-thought
(CoT) characteristics, enabling models to perform
planned retrieval based on the query.
Limitations
Granularity of RAG Paradigms
While RAG-
Instruct introduces five distinct RAG query",N/A,N/A
"Instruct introduces five distinct RAG query
paradigms to handle various query-document re-
lationships, this relationship is of a coarse granu-
larity. Specifically, the current set of paradigms
focuses on broad categories but does not explore
more granular or specialized paradigms that could
better capture nuanced retrieval tasks. For instance,
for multi-hop queries, the number of hops could be
specified, and relevance might have more granular
options. Expanding the range of RAG paradigms to",N/A,N/A
"options. Expanding the range of RAG paradigms to
cover finer distinctions could enhance the model’s
ability to handle complex, diverse, and edge-case
retrieval situations, thereby improving its robust-
ness and performance.
Reliance on Synthetic Data
Our approach re-
lies on synthetic data generation, which inherently
carries the risk of introducing errors or biases, even
when using powerful large language models like
GPT-4. While the use of large-scale instruction",N/A,N/A
"GPT-4. While the use of large-scale instruction
datasets such as SlimOrca and Evol Instruct im-
proves the diversity and quality of the generated
data, it is still possible for GPT-4 to produce flawed
or inconsistent RAG instructions that may nega-
tively impact downstream tasks. As synthetic data
generation becomes more prevalent, ensuring the
accuracy and reliability of such data remains an on-
going challenge, especially in high-stakes domains",N/A,N/A
"where the correctness of information is critical.
References
Achiam et al. 2023.
Gpt-4 technical report.
arXiv
preprint arXiv:2303.08774.
Akari Asai, Sewon Min, Zexuan Zhong, and Danqi
Chen. 2023. Retrieval-based language models and
applications. In Proceedings of the 61st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 6: Tutorial Abstracts), pages 41–46.
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and
Hannaneh Hajishirzi. 2024a. Self-rag: Learning to",N/A,N/A
"Hannaneh Hajishirzi. 2024a. Self-rag: Learning to
retrieve, generate, and critique through self-reflection.
In The Twelfth International Conference on Learning
Representations.
Akari Asai, Zexuan Zhong, Danqi Chen, Pang Wei
Koh, Luke Zettlemoyer, Hannaneh Hajishirzi, and
Wen-tau Yih. 2024b. Reliable, adaptable, and at-
tributable language models with retrieval.
arXiv
preprint arXiv:2403.03187.
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on freebase from",N/A,N/A
"Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In Proceedings of the 2013
conference on empirical methods in natural language
processing, pages 1533–1544.
Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo,
Wei Xue, Yike Guo, and Jie Fu. 2024. Rq-rag: Learn-
ing to refine queries for retrieval augmented genera-
tion. arXiv preprint arXiv:2404.00610.
Junying Chen, Xidong Wang, Ke Ji, Anningzhe Gao,
Feng Jiang, Shunian Chen, Hongbo Zhang, Dingjie",N/A,N/A
"Feng Jiang, Shunian Chen, Hongbo Zhang, Dingjie
Song, Wenya Xie, Chuyi Kong, et al. 2023a.
Huatuogpt-ii, one-stage training for medical adap-
tion of llms. arXiv preprint arXiv:2311.09774.
Yukang Chen, Shaozuo Yu, Shengju Qian, Haotian Tang,
Xin Lai, Zhijian Liu, Song Han, and Jiaya Jia. 2023b.
Long alpaca: Long-context instruction-following
models. https://github.com/dvlab-research/
LongLoRA.
Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma,
Sameena Shah, and William Yang Wang. 2022. Con-",N/A,N/A
"Sameena Shah, and William Yang Wang. 2022. Con-
vfinqa: Exploring the chain of numerical reasoning
in conversational finance question answering. In Pro-
ceedings of the 2022 Conference on Empirical Meth-
ods in Natural Language Processing, pages 6279–
6292.
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,
Ashish Sabharwal, Carissa Schoenick, and Oyvind
Tafjord. 2018. Think you have solved question an-
swering? try arc, the ai2 reasoning challenge. arXiv
preprint arXiv:1803.05457.",N/A,N/A
"preprint arXiv:1803.05457.
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and
Christopher Ré. 2022.
Flashattention: Fast and
memory-efficient exact attention with io-awareness.
Advances in Neural Information Processing Systems,
35:16344–16359.
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
Akhil Mathur, Alan Schelten, Amy Yang, Angela
Fan, et al. 2024. The llama 3 herd of models. arXiv
preprint arXiv:2407.21783.",N/A,N/A
"preprint arXiv:2407.21783.
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-
pat, and Mingwei Chang. 2020. Retrieval augmented
language model pre-training. In International confer-
ence on machine learning, pages 3929–3938. PMLR.
Tsun hin Cheung and Kin Man Lam. 2023. Factllama:
Optimizing instruction-following language models
with external knowledge for automated fact-checking.
2023 Asia Pacific Signal and Information Processing
Association Annual Summit and Conference (APSIPA",N/A,N/A
"Association Annual Summit and Conference (APSIPA
ASC), pages 846–853.
Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,
and Akiko Aizawa. 2020. Constructing a multi-hop
qa dataset for comprehensive evaluation of reasoning
steps. In Proceedings of the 28th International Con-
ference on Computational Linguistics, pages 6609–
6625.
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Se-
bastian Riedel, Piotr Bojanowski, Armand Joulin,
and Edouard Grave. Unsupervised dense informa-",N/A,N/A
"and Edouard Grave. Unsupervised dense informa-
tion retrieval with contrastive learning. Transactions
on Machine Learning Research.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas
Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-
Yu, Armand Joulin, Sebastian Riedel, and Edouard
Grave. 2023. Atlas: Few-shot learning with retrieval
augmented language models. Journal of Machine
Learning Research, 24(251):1–43.
Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju",N/A,N/A
"Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju
Hwang, and Jong C Park. 2024. Adaptive-rag: Learn-
ing to adapt retrieval-augmented large language mod-
els through question complexity. In Proceedings of
the 2024 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (Volume 1: Long Pa-
pers), pages 7029–7043.
Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing
Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang,",N/A,N/A
"Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang,
Jamie Callan, and Graham Neubig. 2023.
Ac-
tive retrieval augmented generation. arXiv preprint
arXiv:2305.06983.
Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang,
and Zhicheng Dou. 2024.
Flashrag: A modular
toolkit for efficient retrieval-augmented generation
research. arXiv preprint arXiv:2405.13576.
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William
Cohen, and Xinghua Lu. 2019. Pubmedqa: A dataset
for biomedical research question answering. In Pro-",N/A,N/A
"ceedings of the 2019 Conference on Empirical Meth-
ods in Natural Language Processing and the 9th In-
ternational Joint Conference on Natural Language
Processing (EMNLP-IJCNLP), pages 2567–2577.
Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke
Zettlemoyer. 2017. Triviaqa: A large scale distantly
supervised challenge dataset for reading comprehen-
sion. In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 1601–1611.",N/A,N/A
"ume 1: Long Papers), pages 1601–1611.
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and
Wen-tau Yih. 2020. Dense passage retrieval for open-
domain question answering. In Proceedings of the
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 6769–6781.
Tomáš Koˇcisk`y, Jonathan Schwarz, Phil Blunsom, Chris
Dyer, Karl Moritz Hermann, Gábor Melis, and Ed-
ward Grefenstette. 2018. The narrativeqa reading",N/A,N/A
"ward Grefenstette. 2018. The narrativeqa reading
comprehension challenge. Transactions of the Asso-
ciation for Computational Linguistics, 6:317–328.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
field, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-
ton Lee, et al. 2019. Natural questions: a benchmark
for question answering research. Transactions of the
Association for Computational Linguistics, 7:453–
466.",N/A,N/A
"466.
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying
Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gon-
zalez, Hao Zhang, and Ion Stoica. 2023. Efficient
memory management for large language model serv-
ing with pagedattention. In Proceedings of the 29th
Symposium on Operating Systems Principles, pages
611–626.
Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi,
Maria Lomeli, Rich James, Pedro Rodriguez, Jacob
Kahn, Gergely Szilvasy, Mike Lewis, et al. 2023.",N/A,N/A
"Kahn, Gergely Szilvasy, Mike Lewis, et al. 2023.
Ra-dit: Retrieval-augmented dual instruction tuning.
arXiv preprint arXiv:2310.01352.
Wanlong Liu, Enqi Zhang, Li Zhou, Dingyi Zeng, Shao-
huan Cheng, Chen Zhang, Malu Zhang, and Wenyu
Chen. 2024a.
A compressive memory-based re-
trieval approach for event argument extraction. arXiv
preprint arXiv:2409.09322.
Zihan Liu, Wei Ping, Rajarshi Roy, Peng Xu, Moham-
mad Shoeybi, and Bryan Catanzaro. 2024b. Chatqa:",N/A,N/A
"mad Shoeybi, and Bryan Catanzaro. 2024b. Chatqa:
Building gpt-4 level conversational qa models. arXiv
preprint arXiv:2401.10225.
Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-
won Hwang, and Alexey Svyatkovskiy. 2022. Reacc:
A retrieval-augmented code completion framework.
In Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 6227–6240.
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,",N/A,N/A
"Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,
and Nan Duan. 2023. Query rewriting in retrieval-
augmented large language models. In Proceedings
of the 2023 Conference on Empirical Methods in
Natural Language Processing, pages 5303–5315.
Seiji Maekawa, Hayate Iso, Sairam Gurajada, and Nikita
Bhutani. 2024. Retrieval helps or hurts? a deeper
dive into the efficacy of retrieval augmentation to
language models. In Proceedings of the 2024 Con-
ference of the North American Chapter of the Asso-",N/A,N/A
"ciation for Computational Linguistics: Human Lan-
guage Technologies (Volume 1: Long Papers), pages
5506–5521.
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 9802–9822.",N/A,N/A
"ume 1: Long Papers), pages 9802–9822.
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish
Sabharwal. 2018. Can a suit of armor conduct elec-
tricity? a new dataset for open book question an-
swering. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing,
pages 2381–2391.
Arindam Mitra, Luciano Del Corro, Shweti Mahajan,
Andres Codas, Clarisse Simoes, Sahaj Agarwal, Xuxi
Chen, Anastasia Razdaibiedina, Erik Jones, Kriti
Aggarwal, et al. 2023.",N/A,N/A
"Aggarwal, et al. 2023.
Orca 2: Teaching small
language models how to reason.
arXiv preprint
arXiv:2311.11045.
Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim
Rocktäschel, Yuxiang Wu, Alexander H Miller, and
Sebastian Riedel. 2020. How context affects lan-
guage models’ factual predictions. In Automated
Knowledge Base Construction.
Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase,
and Yuxiong He. 2020. Zero: Memory optimizations
toward training trillion parameter models. In SC20:",N/A,N/A
"International Conference for High Performance Com-
puting, Networking, Storage and Analysis, pages 1–
16. IEEE.
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
Know what you don’t know: Unanswerable ques-
tions for SQuAD. In Proceedings of the 56th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers), pages 784–789,
Melbourne, Australia. Association for Computational
Linguistics.
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie",N/A,N/A
"Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie
Huang, Nan Duan, and Weizhu Chen. 2023. En-
hancing retrieval-augmented large language models
with iterative retrieval-generation synergy. In Find-
ings of the Association for Computational Linguistics:
EMNLP 2023, pages 9248–9274.
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan
Scales, David Dohan, Ed H Chi, Nathanael Schärli,
and Denny Zhou. 2023. Large language models can
be easily distracted by irrelevant context. In Inter-",N/A,N/A
"national Conference on Machine Learning, pages
31210–31227. PMLR.
Weijia Shi, Sewon Min, Michihiro Yasunaga, Min-
joon Seo, Richard James, Mike Lewis, Luke Zettle-
moyer, and Wen-tau Yih. 2024. Replug: Retrieval-
augmented black-box language models. In Proceed-
ings of the 2024 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (Volume 1:
Long Papers), pages 8364–8377.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-",N/A,N/A
"bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, et al. 2023.
Llama 2:
Open founda-
tion and fine-tuned chat models.
arXiv preprint
arXiv:2307.09288.
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
and Ashish Sabharwal. 2022.
Musique: Multi-
hop questions via single-hop question composition.
Transactions of the Association for Computational
Linguistics, 10:539–554.
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,",N/A,N/A
"and Ashish Sabharwal. 2023. Interleaving retrieval
with chain-of-thought reasoning for knowledge-
intensive multi-step questions. In Proceedings of the
61st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
10014–10037.
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack
Hessel, Tushar Khot, Khyathi Raghavi Chandu,
David Wadden, Kelsey MacMillan, Noah A. Smith,
Iz Beltagy, and Hannaneh Hajishirzi. 2023a. How",N/A,N/A
"Iz Beltagy, and Hannaneh Hajishirzi. 2023a. How
far can camels go? exploring the state of instruction
tuning on open resources. ArXiv, abs/2306.04751.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa
Liu, Noah A Smith, Daniel Khashabi, and Hannaneh
Hajishirzi. 2023b. Self-instruct: Aligning language
models with self-generated instructions. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 13484–13508.",N/A,N/A
"pages 13484–13508.
Zhepei Wei, Wei-Lin Chen, and Yu Meng. 2024.
Instructrag:
Instructing retrieval-augmented gen-
eration with explicit denoising.
arXiv preprint
arXiv:2406.13629.
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin
Jiang. 2023.
Wizardlm: Empowering large lan-
guage models to follow complex instructions. ArXiv,
abs/2304.12244.
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng,
Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan",N/A,N/A
"Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan
Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2
technical report. arXiv preprint arXiv:2407.10671.
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,
William Cohen, Ruslan Salakhutdinov, and Christo-
pher D Manning. 2018. Hotpotqa: A dataset for
diverse, explainable multi-hop question answering.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
2369–2380.",N/A,N/A
"2369–2380.
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Be-
rant. 2024. Making retrieval-augmented language
models robust to irrelevant context. In The Twelfth
International Conference on Learning Representa-
tions.
W. Yu, Hongming Zhang, Xiaoman Pan, Kaixin Ma,
Hongwei Wang, and Dong Yu. 2023.
Chain-of-
note: Enhancing robustness in retrieval-augmented
language models. ArXiv, abs/2311.09210.
Tianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei
Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,",N/A,N/A
"Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,
Danny Fox, Helen Meng, and James Glass. 2023. In-
terpretable unified language checking. arXiv preprint
arXiv:2304.03728.
Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng
Shen, Matei Zaharia, Ion Stoica, and Joseph E Gonza-
lez. 2024. Raft: Adapting language model to domain
specific rag. arXiv preprint arXiv:2403.10131.
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle
Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,",N/A,N/A
"Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,
Zhuohan Li, Zi Lin, Eric P Xing, et al. 2023a. Lmsys-
chat-1m: A large-scale real-world llm conversation
dataset. arXiv preprint arXiv:2309.11998.
Yang Zheng, Adam W Harley, Bokui Shen, Gordon Wet-
zstein, and Leonidas J Guibas. 2023b. Pointodyssey:
A large-scale synthetic dataset for long-term point
tracking. In Proceedings of the IEEE/CVF Interna-
tional Conference on Computer Vision, pages 19855–
19865.
A
Experimental Details
A.1",N/A,N/A
"19865.
A
Experimental Details
A.1
More Details of Training
Dataset Construction.
Our RAG-Instruct cor-
pus is built using Wikipedia. Following the ap-
proach (Karpukhin et al., 2020), each document is
a disjoint text block of up to 100 words extracted
from a Wikipedia article. Following work (Shi
et al., 2023), we generate Wikipedia document em-
beddings.
For exemplar data, we select datasets such as
ShareGPT (Wang et al., 2023a), Alpaca (hin Che-
ung and Lam, 2023), WizardLM-70K (Xu et al.,",N/A,N/A
"ung and Lam, 2023), WizardLM-70K (Xu et al.,
2023), Lmsys-chat-1M (Zheng et al., 2023a), and
SlimOrca (Mitra et al., 2023). First, we remove
overly short, overly long, and low-quality data from
these datasets. Then, we randomly sample 120K
questions from the filtered data. Since RAG is
most effective in knowledge-intensive task scenar-
ios (Maekawa et al., 2024; Shi et al., 2023), we use
GPT-4o to further filter for knowledge-intensive
instructions from these synthetic datasets. The spe-",N/A,N/A
"cific prompt used is shown in Figure 5.
Training Details.
We train our models using 8
Nvidia A800 GPUs, each with 80GB of memory.
All models are trained for 3 epochs with a total
batch size of 128, a peak learning rate of 5e-6,
3% warmup steps, and linear weight decay. The
maximum token length is set to 4096 for all mod-
els. We leverage DeepSpeed Stage 3 (Rajbhandari
et al., 2020) for multi-GPU distributed training with
BFloat16 precision enabled. FlashAttention (Dao",N/A,N/A
"BFloat16 precision enabled. FlashAttention (Dao
et al., 2022) is employed to improve efficiency dur-
ing long-context training.
A.2
More Details of Inference
We conduct evaluations of our RAG-Instruct and
various baselines across a wide range of down-
stream tasks, covering 11 tasks in four major cat-
egories. Throughout these experiments, we per-
form zero-shot evaluations, providing task instruc-
tions without few-shot demonstrations. For RAG-
specific models, we follow the original papers’",N/A,N/A
"specific models, we follow the original papers’
weights and prompts for inference. For our model
and other baselines, reasoning details and prompts
are provided in Table 8.
Open-Ended Tasks include three open-domain
question-answering datasets, WebQA (WQA) (Be-
rant et al., 2013), PopQA (PQA) (Mallen et al.,
2023), and TriviaQA-unfiltered (TQA) (Joshi et al.,
2017), where models are required to answer arbi-
trary questions based on factual knowledge. We re-",N/A,N/A
"trieve the top 10 most relevant documents from the
corpus as candidate documents. Following (Asai
et al., 2024a), we evaluate the performance based
on accuracy, assessing whether gold answers are
included in the model output.
Closed-Set Tasks include two multiple-choice
question-answering
datasets:
OpenbookQA
(OBQA) (Mihaylov et al., 2018), PubHealth
(Pub) (Zhang et al., 2023) and ARC-Challenge
(ARC) (Clark et al., 2018). We retrieve the top
5 most relevant documents from the corpus as",N/A,N/A
"5 most relevant documents from the corpus as
candidate documents. Extract Match (EM) is used
as the evaluation metric, and results are reported
on the test set for both datasets.
Multi-Hop Tasks include three multi-hop question-
answering datasets: 2WikiMultiHopQA (2WIKI),
HotpotQA (HotQ), and Musique (MSQ). Follow-
ing (Chan et al., 2024), we adopt a reading compre-
hension setup for these datasets, using candidate
documents from their original sources. Each ques-",N/A,N/A
"documents from their original sources. Each ques-
tion is linked to 10 passages, with only a few (2 for
HotQ and 2 or 4 for 2WIKI) being relevant. MSQ
is more challenging, requiring 2, 3, or 4 reasoning
hops to answer. We use accuracy as the evaluation
metric.
Domain-Specific Tasks include two datasets:
CFQA (Chen et al., 2022) in the financial domain
and PubMedQA (Jin et al., 2019) in the medical do-
main. For both, we adopt a reading comprehension",N/A,N/A
"main. For both, we adopt a reading comprehension
setup, utilizing the provided context as candidate
documents. Exact Match (EM) is used as the eval-
uation metric.
B
Detailed Prompts in our Experiments
B.1
Prompts for dividing the datasets into five
RAG scenarios.
To explore the performance of RAG methods across
five different scenarios, we use GPT-4o to catego-
rize questions from two QA datasets: Single-hop
QA (TriviaQA) and Multi-hop QA (HotPotQA),",N/A,N/A
"QA (TriviaQA) and Multi-hop QA (HotPotQA),
into relevant subsets based on the defined RAG
scenarios. The prompts used for categorization are
shown in Figure 6 (Single-hop QA) and Figure 7
(Multi-hop QA). The final data volume for each
subset is shown in Table 9.
B.2
Prompts for synthesizing data for five
RAG scenarios.
We construct five RAG paradigms as described in
Figure 8, Figure 9, Figure 10, Figure 11, and Fig-
Method
ARC
PQA
OBQA
WQA
AVG.(↑)
VAR.(↓)
Self-RAG (Llama2-7B)
+ DuckDuckGo
72.1",N/A,N/A
"VAR.(↓)
Self-RAG (Llama2-7B)
+ DuckDuckGo
72.1
56.7
76.4
48.1
62.9
1.9
+ WIKI
73.1
55.8
78.0
49.0
+ BingSearch
68.6
53.2
76.8
46.4
RQ-RAG (Llama2-7B)
+ DuckDuckGo
69.0
58.3
79.8
52.4
65.2
1.6
+ WIKI
68.3
57.1
80.6
56.5
+ BingSearch
68.9
55.6
78.8
57.4
RAG-Instruct (Llama2-7B)
+ DuckDuckGo
75.1
63.0
74.4
68.1
69.7
0.7
+ WIKI
74.8
62.4
71.4
67.2
+ BingSearch
75.5
63.8
72.0
69.0
Table 7: Performance comparison of different retrieval sources. AVG. represents the mean, and VAR. represents the",N/A,N/A
"variance.
Knowledge-Intensive Data Selection Prompt
{Question}
Please determine if retrieving external information would help answer the above question. If it helps, answer ""True"", otherwise
answer ""False"".
Figure 5: The prompt of filtering knowledge-intensive instructions from synthetic datasets
Dividing Prompt for Single-hop Question.
Documents:
{Doucments}
Question:
{Question}
Answer:
{Answer}",N/A,N/A
"{Doucments}
Question:
{Question}
Answer:
{Answer}
Based on the question and its answer, along with the provided documents, carefully review the documents to assess their
overall usefulness in answering the question. Avoid evaluating each document individually; instead, consider the documents
as a whole. Choose the most accurate option based on how much the documents contribute to the answer: 1. Very helpful:",N/A,N/A
"The answer is directly provided in the documents. 2. Partially helpful: The documents offer supporting information or clues
but do not provide an explicit answer. 3. Not helpful: The documents do not contribute to answering the question. Please
directly respond with only the chosen option (1, 2, or 3).
Figure 6: The prompt for dividing the single-hop question answering datasets into five RAG scenarios.
ure 12. To generate data for each RAG paradigm,",N/A,N/A
"ure 12. To generate data for each RAG paradigm,
we simply provide the randomly selected source
documents <Documents> and the simulated instruc-
tion <Simulated Instruction>.
C
Additionally Experiments
C.1
Experiments on Different Retrieval
Source
To further explore the generalization of our method,
we investigate the impact of using different re-
trieval sources. Specifically, we further evaluate
our method on four single-hop QA tasks, includ-
ing ARC, PQA, TQA, and OBQA, utilizing Duck-",N/A,N/A
"ing ARC, PQA, TQA, and OBQA, utilizing Duck-
DuckGo, Wikipedia, and Bing Search as retrieval
Dividing Prompt for Multi-hop Question.
Documents:
{Doucments}
Question:
{Question}
Answer:
{Answer}
Based on the question and answer provided, carefully review the given documents and assess their overall usefulness in
addressing the question. Avoid evaluating each document individually; instead, consider the documents as a whole. Choose",N/A,N/A
"the most accurate option based on how much the documents contribute to the answer: 1. Very helpful: The answer can be
directly derived from multiple documents. 2. Partially helpful: The documents offer supporting information or clues but do
not provide an explicit answer. It needs further reasoning or more knowledge. Please directly respond with only the chosen
option (1, or 2).
Figure 7: The prompt for dividing the multi-hop question answering datasets into five RAG scenarios.",N/A,N/A
"sources during inference. As shown in Table 7,
our RAG-Instruct method demonstrates strong re-
silience to changes in retrieval sources compared
to Self-RAG and RQ-RAG. We use the official API
to obtain retrieval results.
While Self-RAG, primarily curated using
Wikipedia, shows notable performance drops (3-
5%) when switching to Bing Search (with a vari-
ance of 1.9), and RQ-RAG similarly experiences
performance inconsistencies (variance of 1.6), our
RAG-Instruct method exhibits minimal perfor-",N/A,N/A
"RAG-Instruct method exhibits minimal perfor-
mance fluctuations across different data sources.
Specifically, the average performance of RAG-
Instruct remains consistently high (69.7) with a
variance of only 0.7, even when employing Duck-
DuckGo, Wikipedia, or Bing Search for retrieval.
This demonstrates that RAG-Instruct not only
achieves higher overall performance but also main-
tains exceptional robustness and stability across
diverse retrieval sources, highlighting its superior",N/A,N/A
"generalization capabilities compared to existing
methods.
Useless Doc (r0)
<Documents>
[1] {<Document 1>}
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please
note that the question q* can take various forms, not limited to questions with a question mark, but also including statements,
instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG Paradigms):",N/A,N/A
"1. q* should be related to the <Documents>, but the <Documents> can not provide any useful information for answering q*.
2. a* should be able to answer q*, ensuring that the response a* is accurate, detailed, and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a
question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement",N/A,N/A
"and expression to the <Simulated Instruction> below:
<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"": ...}.
Ensure the quality of the generated (q*, a*).
Figure 8: The prompt for synthesizing Useless Doc (r0) data.
Single-Doc Support (r1)
<Documents>
[1] {<Document 1>}
</Documents>",N/A,N/A
"<Documents>
[1] {<Document 1>}
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please
note that the question q* can take various forms, not limited to questions with a question mark, but also including statements,
instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG Paradigms):",N/A,N/A
"1. <Documents> can support q* by providing useful information or hints, but they do not contain explicit answers.
2. a* should use useful information from <Documents> to aid in answering q*, ensuring that the response is accurate,
detailed, and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a",N/A,N/A
"question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement
and expression to the <Simulated Instruction> below:
<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"": ...}.
Ensure the quality of the generated (q*, a*).
Figure 9: The prompt for synthesizing Single-Doc Support (r1) data.
Task",N/A,N/A
"Task
Template
Open-ended
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Please refer to the documents above and answer the following question:
{QUESTION}
### Response:
Domain-specific
OBQA & ARC
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Given four answer candidates, A, B, C and D, choose the best answer choice for the question.
Please refer to the documents above and answer the following question:
{QUESTION (Including Options) }
### Response:
Pub (FEVER)",N/A,N/A
"### Response:
Pub (FEVER)
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Is the following statement correct or not? Say true if it’s correct; otherwise, say false.
Please refer to the documents above and answer the following question:
{QUESTION}
### Response:
Multi-hop
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Please refer to the documents above and answer the following question:
{QUESTION}
### Response:
Domain-specific
CFQA
### Instruction:
Reference Document:",N/A,N/A
"CFQA
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Please refer to the documents above and answer the following question:
{PREVIOUS QUESTIONS ANSWERS}
{QUESTION}
### Response:
PubMed
### Instruction:
Reference Document:
{RETRIEVED DOCUMENTS}
Please refer to the documents above and answer the following question:
Answer the question with “yes” or “no” or “maybe”.
{QUESTION}
### Response:",N/A,N/A
"{QUESTION}
### Response:
Table 8: Prompt templates in our Evaluation. For Open-ended and Close-set datasets, RETRIEVED DOCUMENTS
are sourced from the retrieval corpus (e.g., Wikipedia). For Multi-hop and Domain-specific datasets, RETRIEVED
DOCUMENTS come from the context provided in datasets.
TriviaQA(Single-hop QA)
HotpotQA (Multi-hop QA)
Helpful
Midhelpful
Helpless
Helpful
Midhelpful
Mumber of Data
5628
894
791
4015
3390",N/A,N/A
"Midhelpful
Mumber of Data
5628
894
791
4015
3390
Table 9: Detailed information on dataset subsets categorized into five RAG scenarios.
Multi-Doc Support (r2)
<Documents>
[1] {<Document 1>}
[2] {<Document 2>}
[3] ...
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please
note that the question q* can take various forms, not limited to questions with a question mark, but also including statements,",N/A,N/A
"instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG Paradigms):
1. Multiple documents within <Documents> can support q* by providing useful information or hints, but they do not contain
explicit answers.
2. a* should use useful information from <Documents> to aid in answering q*, ensuring that the response is accurate,
detailed, and comprehensive.",N/A,N/A
"detailed, and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a
question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement
and expression to the <Simulated Instruction> below:
<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>",N/A,N/A
"</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"": ...}.
Ensure the quality of the generated (q*, a*).
Figure 10: The prompt for synthesizing Multi-Doc Support (r2) data.
Single-Doc Answer (r3)
<Documents>
[1] {<Document 1>}
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please",N/A,N/A
"note that the question q* can take various forms, not limited to questions with a question mark, but also including statements,
instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG Paradigms):
1. Ensure that q* can be answered directly using the content of <Documents>, meaning its answer can be fully derived from
<Documents>.",N/A,N/A
"<Documents>.
2. a* should use the information from <Documents> to answer q* accurately, ensuring that the response is accurate, detailed,
and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a
question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement
and expression to the <Simulated Instruction> below:
<Simulated Instruction>",N/A,N/A
"<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"": ...}.
Ensure the quality of the generated (q*, a*).
Figure 11: The prompt for synthesizing Single-Doc Answer (r3) data.
Multi-Doc Answer (r4)
<Documents>
[1] {<Document 1>}
[2] {<Document 2>}
[3] ...
</Documents>",N/A,N/A
"[2] {<Document 2>}
[3] ...
</Documents>
Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please
note that the question q* can take various forms, not limited to questions with a question mark, but also including statements,
instructions, and other formats. You need to follow the requirements below to generate the q* and a* (RAG Paradigms):",N/A,N/A
"1. The answer to q* can be derived from multiple documents within <Documents>, involving multi-hop reasoning or the
integration of information from several documents.
2. a* should leverage the information in <Documents> to provide an accurate answer to q*, ensuring that the response is
accurate, detailed, and comprehensive.
Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a",N/A,N/A
"question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement
and expression to the <Simulated Instruction> below:
<Simulated Instruction>
{<Simulated Instruction>}
</Simulated Instruction>
Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of {""q*"": ..., ""a*"": ...}.
Ensure the quality of the generated (q*, a*).
Figure 12: The prompt for synthesizing Multi-Doc Answer (r4) data.",N/A,N/A
"arXiv:2505.13006v1  [cs.CL]  19 May 2025
Evaluating the Performance of RAG Methods for Conversational AI in the
Airport Domain
Yuyang Li1, Philip J.M. Kerbusch2, Raimon H.R. Pruim2, Tobias Käfer1
1Karlsruhe Institute of Technology, 2Royal Schiphol Group
2Royal Schiphol Group, 1Karlsruhe Institute of Technology
yuyang.li@kit.edu,
tobias.kaefer@kit.edu
Abstract
Airports from the top 20 in terms of annual
passengers are highly dynamic environments
with thousands of flights daily, and they aim",N/A,N/A
"with thousands of flights daily, and they aim
to increase the degree of automation. To con-
tribute to this, we implemented a Conversa-
tional AI system that enables staff in an air-
port to communicate with flight information
systems. This system not only answers stan-
dard airport queries but also resolves airport ter-
minology, jargon, abbreviations, and dynamic
questions involving reasoning. In this paper, we
built three different Retrieval-Augmented Gen-",N/A,N/A
"built three different Retrieval-Augmented Gen-
eration (RAG) methods, including traditional
RAG, SQL RAG, and Knowledge Graph-based
RAG (Graph RAG). Experiments showed that
traditional RAG achieved 84.84% accuracy
using BM25 + GPT-4 but occasionally pro-
duced hallucinations, which is risky to airport
safety. In contrast, SQL RAG and Graph RAG
achieved 80.85% and 91.49% accuracy respec-
tively, with significantly fewer hallucinations.
Moreover, Graph RAG was especially effective",N/A,N/A
"Moreover, Graph RAG was especially effective
for questions that involved reasoning. Based
on our observations, we thus recommend SQL
RAG and Graph RAG are better for airport en-
vironments, due to fewer hallucinations and the
ability to handle dynamic questions.
1
Introduction
Amsterdam Airport Schiphol, one of the top 20
airports in the world, ranked by annual passenger
numbers, handles thousands of flights each day.
These airports rely on staff like gate planners and",N/A,N/A
"apron controllers to access and update data across
systems. For these employees, traditional database
queries can be complex and time-consuming for
some employees who are not query experts when
they need flight information. A conversational AI
system with a natural language query (NLQ) inter-
face allows all employees to interact with systems
naturally, asking questions like, “Which fights are
at ramp D07?” and receiving instant answers. This
improves productivity, and streamlines workflows,",N/A,N/A
"improves productivity, and streamlines workflows,
especially in high-pressure areas like at the gate,
where less educated workers require access to up-
to-date information. By replacing strict query for-
mats with intuitive, real-time responses, conversa-
tional AI enhances decision-making and efficiency,
making it a suitable solution for dynamic environ-
ments such as airports.
Building such a system is challenging because
flight data is stored by experts in tables using avi-",N/A,N/A
"ation abbreviations. We need our system to un-
derstand these datasets to answer questions from
the airport domain. Additionally, ensuring avia-
tion safety is a major concern; the system must
be safe and enable employees to perform accurate
operations. We address those challenges using two
research questions.
The first question is how to handle flight data so
that our system can answer different questions. We
divided the questions into three types:
• Straightforward questions: Questions that",N/A,N/A
"• Straightforward questions: Questions that
can be directly answered from the flight data.
• Questions involving specialized airport jar-
gon, abbreviations, and incomplete queries:
Operators often use shorthand or omit con-
text. Flight “KL0123” might be referred to as
“0123” or “123,” while gate “C05” might be
shortened to “C5.” Abbreviations like “KLM”
for “KLM Royal Dutch Airlines” or “Delta”
for “Delta Air Lines” are also common. Op-
erators frequently ask short, incomplete ques-",N/A,N/A
"erators frequently ask short, incomplete ques-
tions, e. g., “Which flights are at D04?” or
“What is the gate for that Delta airline?” With-
out resolving missing details such, these ques-
tions cannot be answered.
• Dynamic questions: Questions that involve
additional calculations and reasoning, espe-
cially related to time.
Examples include
“What is the connecting flight’s onramp time
for DL1000?” or “What is DL1000’s next
flight from the same ramp?” These queries re-",N/A,N/A
"flight from the same ramp?” These queries re-
quire reasoning through connections between
flights and retrieving specific details.
The second research question is about how to re-
duce hallucinations (Xu et al., 2024) for the safety
of aviation operations. Hallucinations occur when
LLMs generate information not based on facts or
their training data. In high-safety environments
such as airports, however the output should be
factual and not imaginative (Jacobs and Jaschke,",N/A,N/A
"factual and not imaginative (Jacobs and Jaschke,
2024). For example, if the system gives wrong gate
numbers, flight schedules, or safety instructions,
this might disrupt aviation operations, cause de-
lays, or even risk passenger safety. Thus, accurate
responses are important.
In this case study, we examine three Retrieval-
Augmented Generation (RAG) techniques for the
airport environment: Traditional RAG (Lewis et al.,
2021) Retrieves relevant information from the flight",N/A,N/A
"database and uses LLMs to generate answers based
on the retrieved data and original questions. SQL
RAG (Guo et al., 2023) stores all datasets in an
SQL database and converts natural language ques-
tions (NLQ) into structured SQL queries. Knowl-
edge Graph-based Retrieval-Augmented Genera-
tion (Graph RAG) (Edge et al., 2024) aims to im-
prove the performance of LLM tasks by applying
RAG techniques to Knowledge Graphs (KGs), re-
quiring the original datasets to be stored in the",N/A,N/A
"quiring the original datasets to be stored in the
knowledge graph. A key challenge is retrieving the
correct flight information from thousands of flights
while minimizing hallucinations.
The paper is structured as follows: We first sur-
vey related work (Sec. 2), then present our dataset
(Sec. 3), followed by a high-level description of
our experiments (Sec. 4). We then present the re-
sults for the research questions (Sec. 5), and lastly
conclude (Sec. 6). In the Appendix A, we provide",N/A,N/A
"conclude (Sec. 6). In the Appendix A, we provide
further details, especially on the question genera-
tion and classification, next to our prompting.
2
Related Work
2.1
Traditional RAG
Traditional
Retrieval-Augmented
Generation
(RAG) consists of two main stages: the Retriever
and the Generator (Louis et al., 2023).
The
Retriever identifies relevant documents based on
user input, and the Generator uses these documents
to produce responses. We explore three retrieval",N/A,N/A
"to produce responses. We explore three retrieval
methods: keyword search, semantic search, and
hybrid search,
using large language models
(LLMs) for answer generation.
In keyword search, TF-IDF and BM25 are em-
ployed to evaluate retrieval performance. TF-IDF
computes term frequency (TF) and inverse docu-
ment frequency (IDF) (Liu et al., 2018; Robertson,
2004), measuring how important a term is within
a document and across the corpus. BM25 extends",N/A,N/A
"a document and across the corpus. BM25 extends
TF-IDF with a term saturation function (Robert-
son and Zaragoza, 2009), reducing the influence
of extremely frequent terms that often carry less
informative value (Chen and Wiseman, 2023).
Semantic search methods include similarity
search, vector databases like FAISS (Jegou et al.,
2017; George and Rajan, 2022), k-Nearest Neigh-
bors (KNN), Locality-Sensitive Hashing (LSH) (Ja-
fari et al., 2021), and Maximal Marginal Relevance",N/A,N/A
"(MMR) (Mao et al., 2020). Unlike keyword search,
semantic search aims to understand user intent and
word meanings (Gao et al., 2024). Embedding mod-
els such as Word2Vec convert words into vectors
(Mikolov et al., 2013), where cosine similarity mea-
sures similarities between queries and documents.
Hybrid search combines keyword and seman-
tic methods, re-ranking results using the Recip-
rocal Rank Fusion (RRF) algorithm (Robert Lee,
2024). By combining two search methods, the hy-",N/A,N/A
"2024). By combining two search methods, the hy-
brid search can not only find flight information by
keywords but also find information by the deeper
meaning of the queries (Sarmah et al., 2024).
2.2
SQL RAG
Text-to-SQL aims to transfer natural language au-
tomatically questions(NLQs) into SQL queries.
LLMs recently emerged as an option for Text-to-
SQL task (Rajkumar et al., 2022). The trick to
handling text-to-SQL tasks with LLMs is to apply
prompt engineering. Five prompt styles for Text-",N/A,N/A
"prompt engineering. Five prompt styles for Text-
to-SQL are explored in the previous research (Gao
et al., 2023). Basic Prompt (BSP) is a simple repre-
sentation with no instructions; Text Representation
Prompt (TRP) adds basic task guidance; OpenAI
Demonstration Prompt (ODP) adds explicit rules
like “Complete sqlite SQL query only,”; Code Rep-
resentation Prompt (CRP) uses SQL-style schema
descriptions with detailed database information
like primary/foreign keys, and Alpaca SFT Prompt",N/A,N/A
"like primary/foreign keys, and Alpaca SFT Prompt
(ASP) adopts Markdown for structured training
prompts. In (Gao et al., 2023), CRP achieves the
best performance in most LLMs, by providing com-
plete database information and utilizing the LLMs’
strength in understanding code.
2.3
Graph RAG
A Knowledge Graph (KG) is a structured repre-
sentation of entities (nodes), their attributes, and
relationships (edges), typically stored in graph
databases or triple stores (Sarmah et al., 2024). Its",N/A,N/A
"basic unit is a triple: subject, predicate, object.
In Graph RAG (Retrieval-Augmented Generation),
natural language questions are converted into query
languages like SPARQL for RDF graphs or Cypher
for Neo4j property graphs. Research indicates that
Neo4j’s labeled property graph model offers faster
and more efficient real-time analysis and dynamic
querying compared to complex RDF ontologies in
enterprise projects (Barrasa et al., 2023). Neo4j’s",N/A,N/A
"property graph model better meets industrial needs.
Flight information can be automatically integrated
into the knowledge graph by matching the row and
column names of the flight table, with relationships
manually defined based on flight numbers.
3
Dataset and Questions
Our flight information dataset is tabular containing
thousands of flights with key details such as flight
number, aircraft category, bus gate, bus service
needed, flight UID, ramp, expected on-ramp time,",N/A,N/A
"needed, flight UID, ramp, expected on-ramp time,
connecting flight number, etc.
To evaluate the effectiveness of different retrieval
methods, we classified the questions, and then
based on these questions, we created two ground
truth datasets: a straightforward dataset and a com-
plicated, ambiguous dataset.
The straightforward dataset consists of un-
ambiguous questions that can be directly an-
swered from flight information. Examples include:",N/A,N/A
"swered from flight information. Examples include:
""What category of aircraft is designated for flight
KL1000?"" and ""Which ramp is assigned for flight
KL1000?"". Such questions are easily handled by re-
trieval methods to select the most relevant informa-
tion. This dataset contains thousands of question-
answer pairs, with around 100 to 200 pairs selected
for the RAG methods comparison.
The complicated and ambiguous dataset contains
questions with variables that may be unclear or",N/A,N/A
"questions with variables that may be unclear or
missing from the flight information which cannot
be directly queried from the tabular dataset. Exam-
ples are: ""Which flight is at gate B24?"" or ""Which
gate is assigned to the 0164 flight?"", ""When is
Delta landing?"" Here, ’B24’ might relate to mul-
tiple flights or meanings (bus gate or ramp num-
ber), and ’0164’ is not a complete flight number,
’Delta’ also needs clarification. This dataset also
contains thousands of question-answer pairs, with",N/A,N/A
"contains thousands of question-answer pairs, with
185 pairs randomly selected for comparison. More
information on question generation and question
classification is provided in the Appendix A.
4
Experiments
To handle the flight tabular dataset, our conversa-
tional AI should understand the meaning of these
flight terms, it also needs to understand specific
jargon and terminology. We explore three RAG
methods for a conversational system on flight data.
Figure 1 shows the traditional RAG method.",N/A,N/A
"Figure 1 shows the traditional RAG method.
When a user asks a question, various retrieval meth-
ods are employed to retrieve the correct flight data
from the flight information dataset. These methods
are mainly divided into three categories: keyword
search, semantic search, and hybrid search. Af-
ter retrieving the relevant flight information, Large
Language Models (LLMs) generate answers to the
user’s questions based on this data. Several LLMs
were tested to assess their performance, includ-",N/A,N/A
"were tested to assess their performance, includ-
ing GPT models, Llama-3-8B-Instruct, BERT, and
BERT-related models.
Figure 2 shows the SQL RAG method, which
begins with users asking natural language ques-
tions. An LLM processes these questions using
the SQL database schema to generate appropriate
SQL queries. The queries retrieve relevant informa-
tion from the SQL database, which the LLM then
interprets and reformulates into human-readable an-",N/A,N/A
"swers. Following the approach in (Gao et al., 2023),
we experimented with Code Representation Prompt
(CRP) and OpenAI Demonstration Prompt (ODP)
to fine-tune the prompts and improve the SQL RAG
results. More details of SQL RAG prompts are pro-
vided in Appendix A.
Figure 3 shows the Graph RAG method, which
also starts with users asking natural language ques-
tions. An LLM processes these questions using
the graph schema from the graph database to gen-",N/A,N/A
"the graph schema from the graph database to gen-
erate graph queries. We use Neo4j’s APOC plu-
gin to extract the schema by executing ’CALL
apoc.meta.schema() YIELD value RETURN value’
and include it in the prompt. and the LLM in-
terprets this data to formulate human-readable an-
swers. The graph structure enables context-aware
retrieval and reasoning, more details of Graph RAG
prompts are provided in Appendix A.
The three RAG methods described above can",N/A,N/A
"The three RAG methods described above can
handle straightforward datasets easily because the
answers all exist in the flight tabular, we will add
some explanations about flight row names’ mean-
ings to the prompts, so that LLMs can generate
better more accurate answers. However, questions
about jargon and short sentences from complicated
or ambiguous datasets need to be classified using a
question classification prompt, as shown in Figure
4. After classification, each question is directed to",N/A,N/A
"different prompts to answer jargon and abbrevia-
tions.
Figure 1: Traditional RAG Method
Figure 2: SQL RAG Method
Figure 3: Graph RAG Method
Figure 4: Method on Ambiguous question dataset
5
Results
In this section, we present the experimental results,
structured using our research questions.
5.1
RQ1: How to handle flight data for
different questions?
5.1.1
Straightforward questions
Table 1 summarizes the performance of various re-
trieval methods within the traditional RAG pipeline",N/A,N/A
"in the straightforward dataset. BM25 outperforms
other methods, achieving approximately 86.54%
accuracy in retrieving the correct articles. The hy-
brid search, which combines BM25 and the vector
database FAISS in a 9:1 proportion, performs sec-
ond best, with an accuracy of 85.78% for identi-
fying the correct article as the highest-ranked and
98.00% accuracy for including the correct article
within the top 10 results. This indicates the success-",N/A,N/A
"ful retrieval of correct articles among the top 10
most relevant ones. However, changing the propor-
tion to 1:9 yields only 0.59% accuracy within the
top 30 articles, suggesting that the correct articles
rarely appear among the top 30 results. Following
BM25 and the hybrid search, TF-IDF with cosine
similarity and Euclidean distance achieve accura-
cies of 67.70% and 67.55%, respectively. The vec-
tor database FAISS alone performs the worst, with
an accuracy of 0%.",N/A,N/A
"an accuracy of 0%.
Table 2 shows how various LLMs perform in
generating answers for the simple dataset. Because
the dataset is large, we randomly selected 100 ques-
tions for the experiment. The LLMs’ answers were
manually compared to the standard answers; cor-
rect ones were marked ""True,"" and incorrect ones
were ""False."" Accuracy was calculated by dividing
the number of correct answers by the total num-
ber of questions. In these two tables, we chose",N/A,N/A
"ber of questions. In these two tables, we chose
BM25+GPT4 as the traditional RAG pipeline and
achieved a total accuracy of 84.40% in the end.
The reason keyword search outperforms seman-
tic search is probably because, in the airport envi-
ronment, most questions are about specific flights,
times, or ramps. These questions don’t require a
deep semantic understanding of the content.
Table 3 shows the performance of SQL RAG.
The results indicate that CRP significantly outper-",N/A,N/A
"forms ODP in most of the cases. EM(Exact Match)
measures the strict match between the predicted
SQL query and the ground truth regarding syntax
and structure. while EX(Execution Match) evalu-
ates whether the execution outputs of the predicted
SQL match the ground truth on the database. Few-
shot learning was applied using 47 manually cre-
ated examples, including questions, SQL queries,
and corresponding answers. With CRP, GPT-4
Retrieval Methods
Total Rows
Accuracy
(Highest)
Accuracy (Top
10)",N/A,N/A
"Total Rows
Accuracy
(Highest)
Accuracy (Top
10)
Accuracy (Top
30)
BM25
1350
86.54%
100%
100%
TF-IDF + Cosine Similarity
1350
67.70%
100%
100%
TF-IDF + Euclidean Distance
1350
67.55%
100%
100%
Word2Vec + Cosine Similarity + MMR
1350
33.70%
34.00%
34.00%
LSI
1350
21.82%
37.00%
45.00%
FAISS
1350
0%
1.00%
12.00%
Hybrid Search (BM25 : FAISS = 9:1)
1350
85.78%
98.00%
98.00%
Hybrid Search (BM25 : FAISS = 5:5)
1350
82.37%
98.00%
98.00%
Hybrid Search (BM25 : FAISS = 1:9)
1350
0.59%
0.59%
0.59%",N/A,N/A
"1350
0.59%
0.59%
0.59%
Table 1: Retrieval method results for the Traditional RAG in the straightforward dataset
Model Name
Accuracy
GPT-4
88.78%
GPT-4o Mini
88.12%
GPT-3.5 Turbo
83.33%
Llama-3-8B-Instruct
76.54%
RoBERTa
56.16%
BERT
29.73%
DistilBERT
28.00%
DeBERTa
41.89%
mDeBERTa
53.33%
Electra
41.33%
Electra Large
41.33%
Table 2: LLMs results in straightforward dataset
achieves the highest performance (EM: 78.72%,
EX: 80.85%), followed by GPT-4o Mini, Llama-3-",N/A,N/A
"EX: 80.85%), followed by GPT-4o Mini, Llama-3-
8B-Instruct and GPT-3.5 Turbo, CRP consistently
delivers better accuracy in most of LLMs, indicat-
ing the importance of detailed schema representa-
tion for SQL generation.
LLM
ODP
CRP
EM
EX
EM
EX
GPT-4
74.47% 78.72% 76.60% 80.85%
GPT-4o Mini
76.60% 70.21% 78.72% 80.85%
GPT-3.5 Turbo
38.30% 38.30% 25.53% 27.70%
Llama-3-8B-Instruct
31.91% 29.79% 68.83% 46.81%
Table 3: SQL RAG results on the straightforward
dataset.",N/A,N/A
"dataset.
Table 4 presents the performance of Graph RAG,
showing strong results across all models when us-
ing the schema prompt. GPT-4 leads with the high-
est accuracy (EM: 14.89%, EX: 91.49%), followed
by GPT-4o Mini (EM: 10.64%, EX: 89.36%).
The differing EM and EX results between SQL
RAG and Graph RAG indicate the differences be-
tween the two methods. In SQL RAG, the data
is highly structured, leading to more fixed SQL
queries and higher EM scores whenever we exe-",N/A,N/A
"queries and higher EM scores whenever we exe-
cute it. In contrast, Graph RAG shows a much
lower EM but high EX, indicating that the graph
query language is more flexible and can generate
different formats while still providing highly accu-
rate answers.
LLM
Schema Prompt
EM
EX
GPT-4
14.89%
91.49%
GPT-4o Mini
10.64%
89.36%
GPT-3.5 Turbo
10.64%
82.98%
Table 4: Graph RAG Results with schema prompt on
the straightforward dataset.
5.1.2
Specialized airport jargon,",N/A,N/A
"5.1.2
Specialized airport jargon,
abbreviations, and incomplete questions
As mentioned in the dataset section, we manually
created a complicated, ambiguous dataset contain-
ing thousands of airport jargon, abbreviations, and
incomplete questions. We classified these questions
into six categories: Time Ambiguous Questions
(TAQ), and Time With Ambiguous Flight Number
Questions (TWAQ). Board Gate Questions (BGQ),
Next Flight Questions (NFQ), Board Questions of",N/A,N/A
"Next Flight Questions (NFQ), Board Questions of
Aircraft (BQA), and Ambiguous Flight Number
Questions (AFQ).
Board Questions of Aircraft (BQA) and Am-
biguous Flight Number Questions (AFQ) involve
abbreviations and jargon, such as ""Where is the
delta?"" and ""At what gate is the 144?"" Without the
full airline names or additional flight details, these
questions are challenging to answer. Time Am-
biguous Questions (TAQ), Board Gate Questions
(BGQ), and Time With Ambiguous Flight Number",N/A,N/A
"(BGQ), and Time With Ambiguous Flight Number
Questions (TWAQ) represent incomplete questions
like ""Which flight is currently at gate F09?"" or
""What’s at C14?"" These lack critical details such as
flight numbers. Next Flight Questions (NFQ), on
the other hand, are dynamic and will be discussed
further in a later section.
We analyzed 220 questions in total to evaluate
the robustness of the question classification prompt.
Since large language models (LLMs) showed some",N/A,N/A
"Since large language models (LLMs) showed some
variability in each time response, we employed
a few-shot learning approach by integrating 60
carefully selected question classification examples
Figure 5: Confusion Matrix of Question Classifications
within the context window into the prompt. These
60 examples included six different questions and
their correct categories. We repeated the classifica-
tion experiments five times on the same questions.",N/A,N/A
"The accuracies for these five times’ classification
runs were 90.45%, 90.45%, 90.91%, 90.45%, and
90.00%, the average accuracy is 90.45%. The low
variance among these runs suggests our prompt is
robust and effective. Few-shot learning with ex-
tensive examples significantly improved accuracy
and ensured consistent performance for different
question types.
The final classification results are shown in the
Figure 5. Although most questions were classified",N/A,N/A
"Figure 5. Although most questions were classified
correctly, about 22 questions were misclassified.
However, TAQ and BGQ share the same subse-
quent step of extracting a gate number, so swap-
ping them does not affect outcomes. Similarly,
TWAQ and BQA both prompt users for additional
information; hence the confusion between these
two also does not have too much impact on final
results. When TWAQ or BQA are misclassified
as TAQ, the system fails to extract a gate number,",N/A,N/A
"returns [’0’], and prompts the user for more details
before re-running RAG. Because subsequent steps
rely on correct classification, we added additional
measures to mitigate the impact of misclassifica-
tion. Our experiments show that most errors oc-
cur within these similar categories, and we have
worked to minimize them as much as possible. Fur-
ther details on the question classification prompts
are provided in Appendix A.
5.1.3
Dynamic questions",N/A,N/A
"5.1.3
Dynamic questions
The Next Flight Questions (NFQ) involves two sit-
uations: determining the next flight from the same
airline or the same ramp. For the same airline, the
answer is directly found in the table ’connecting
flight number’. For the same ramp, we need to
determine the expected on-ramp time for the cur-
rent flight and then identify the closest expected
on-ramp time for other flights at that ramp. Dy-
namic questions require additional calculation and",N/A,N/A
"reasoning. for example, if the question is ’What is
the expected on-ramp time for the connecting flight
of DL0123?’ we must first identify DL0123’s next
connecting flight, then we can find its expected on-
ramp time. We created a dataset of 30 reasoning
questions to test RAG methods. As shown in Table
5, Graph RAG performed well, leveraging graph
relationships for improved retrieval.
RAG Pipeline
Reasoning Question Dataset
Graph RAG
68.75%
SQL RAG
6.25%
Traditional RAG
9.38%",N/A,N/A
"68.75%
SQL RAG
6.25%
Traditional RAG
9.38%
Table 5: Performance of different RAG pipelines on the
reasoning question dataset
5.2
RQ2: How to reduce hallucinations?
Hallucinations mainly happen in traditional RAG
when LLMs generate flight destinations not in-
cluded in our dataset. This issue mainly exists
in responses to complex and ambiguous queries.
After performing question classification and re-
trieving flight information, we conducted few-shot",N/A,N/A
"learning with 20 examples, observing a hallucina-
tion rate of approximately 10%. This phenomenon
is likely due to the excessive amount of informa-
tion included in the input prompts for traditional
RAG, which increases the likelihood of halluci-
nation compared to SQL RAG and Graph RAG.
Additionally, airline companies often reuse flight
numbers, leading to conflicting data in LLM train-
ing and causing the generation of information ab-
sent from the dataset.",N/A,N/A
"sent from the dataset.
SQL RAG and Graph RAG reduce hallucina-
tions by converting natural language questions into
SQL or Cypher queries. Thereby, the input to the
LLM is accurate data, which significantly reduces
hallucinations. However, if the question requires a
lot of context, the conversion to a query may fail.
It is important to note that hallucinations are not
common even in traditional RAG and are not elim-
inated in SQL RAG or Graph RAG. Additionally,",N/A,N/A
"inated in SQL RAG or Graph RAG. Additionally,
calculating the exact accuracy or rate of halluci-
nations across these RAG methods is challenging.
However, SQL RAG and Graph RAG tend to re-
duce the occurrence of hallucinations compared
to traditional RAG. Given the high safety require-
ments in airport and aviation environments, SQL
RAG and Graph RAG are safer for aviation opera-
tions. Both support dynamic storage of real-time
flight information. Among them, Graph RAG per-",N/A,N/A
"flight information. Among them, Graph RAG per-
forms better due to its stronger reasoning capabil-
ities, enabling it to handle more complex queries
effectively. More details of the experiment are pro-
vided in the Appendix A.
6
Conclusion
Our evaluation of three RAG methods shows that
of the traditional RAG methods, BM25+GPT-4
is more efficient than other methods, because of
the terminology used in the airport. However, tra-
ditional RAG can produce hallucinations, which",N/A,N/A
"ditional RAG can produce hallucinations, which
poses a safety risk. SQL RAG and Graph RAG
produce fewer hallucinations, and Graph RAG on
top has higher accuracy. Our overall system ef-
fectively handles specialized airport terminology
through question classification and prompt engi-
neering; specifically, we address airport jargon and
abbreviations. Graph RAG is particularly effective
in handling reasoning tasks and questions about
dynamic data, making it efficient in the airport do-
main.
7",N/A,N/A
"main.
7
Future Work
In our current research, the experiments are based
on a static environment that does not capture any
real-time changes such as delays or gate changes.
In future research, we plan to connect the system
with live APIs that provide real-time flight status
and gate information, so that the system can dy-
namically retrieve and use real-time data. Another
limitation is the relatively small size of our cur-
rent dataset. In future work, we want to signifi-",N/A,N/A
"rent dataset. In future work, we want to signifi-
cantly expand and diversify the dataset. A larger
and more diverse dataset will help ensure that our
performance improvements hold across different
scenarios and strengthen the validity of our conclu-
sions.
Limitations
We openly acknowledge that this study is not a
finalized product but an initial research investiga-
tion. The system’s performance in the real world
has not been demonstrated; it is a prototype that",N/A,N/A
"has not been demonstrated; it is a prototype that
was tested in a controlled environment. Moreover,
our evaluation is specific to the Schiphol airport
domain; adapting the model to other airports or
domains may present new challenges. Any de-
ployment would need careful incremental trials,
user feedback, and regulatory compliance checks
to meet the high-reliability standards expected in
aviation contexts.
Ethics Policy
Our research uses a dataset that has been autho-",N/A,N/A
"Our research uses a dataset that has been autho-
rized by Amsterdam Airport Schiphol and contains
outdated flight information. Most of the flight in-
formation is publicly available online and does not
include sensitive information. In this paper, the
dataset is not publicly released, and it is only used
to discuss its structure and to provide examples
of question-answer pairs. No personal or confi-
dential data are involved. Importantly, this work",N/A,N/A
"dential data are involved. Importantly, this work
is an exploratory study focused on benchmarking
performance in a controlled environment without
impacting actual airport operations. We have im-
plemented methods to reduce AI hallucinations—a
key safety concern in this domain. However, any fu-
ture deployment would require additional security
reviews and strong safeguards to prevent misuse.
Acknowledgments
This work was supported in part by the Deutsche",N/A,N/A
"This work was supported in part by the Deutsche
Forschungsgemeinschaft (DFG, German Research
Foundation) under Research Unit FOR 5339
(Project No.459291153). We also gratefully ac-
knowledge Amsterdam Airport Schiphol for pro-
viding the raw dataset used in this study, and we
thank our co-authors from the Royal Schiphol
Group for their valuable contributions.
References
J. Barrasa, J. Webber, and J. Webber. 2023.
Build-
ing Knowledge Graphs: A Practitioner’s Guide.
O’Reilly.",N/A,N/A
"O’Reilly.
Xiaoyin Chen and Sam Wiseman. 2023.
Bm25
query augmentation learned end-to-end. Preprint,
arXiv:2305.14087.
Darren Edge, Ha Trinh, Newman Cheng, Joshua
Bradley, Alex Chao, Apurva Mody, Steven Truitt,
and Jonathan Larson. 2024. From local to global: A
graph rag approach to query-focused summarization.
Preprint, arXiv:2404.16130.
Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun,
Yichen Qian, Bolin Ding, and Jingren Zhou. 2023.
Text-to-sql empowered by large language models: A",N/A,N/A
"Text-to-sql empowered by large language models: A
benchmark evaluation. Preprint, arXiv:2308.15363.
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,
Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang,
and Haofen Wang. 2024. Retrieval-augmented gener-
ation for large language models: A survey. Preprint,
arXiv:2312.10997.
Godwin George and Rajeev Rajan. 2022. A faiss-based
search for story generation. In 2022 IEEE 19th India
Council International Conference (INDICON), pages
1–6.",N/A,N/A
"1–6.
Chunxi Guo, Zhiliang Tian, Jintao Tang, Shasha Li,
Zhihua Wen, Kaixuan Wang, and Ting Wang. 2023.
Retrieval-augmented gpt-3.5-based text-to-sql frame-
work with sample-aware prompting and dynamic re-
vision chain. Preprint, arXiv:2307.05074.
Sven Jacobs and Steffen Jaschke. 2024.
Leverag-
ing lecture content for improved feedback: Explo-
rations with gpt-4 and retrieval augmented generation.
Preprint, arXiv:2405.06681.
Omid Jafari, Preeti Maurya, Parth Nagarkar, Khand-",N/A,N/A
"ker Mushfiqul Islam, and Chidambaram Crushev.
2021.
A survey on locality sensitive hash-
ing algorithms and their applications.
Preprint,
arXiv:2102.08942.
Hervé Jegou, Matthijs Douze, and Jeff Johnson. 2017.
Faiss: A library for efficient similarity search. Face-
book AI Research, Data Infrastructure, ML Applica-
tions. Accessed: insert access date.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein-",N/A,N/A
"Petroni, Vladimir Karpukhin, Naman Goyal, Hein-
rich Küttler, Mike Lewis, Wen tau Yih, Tim Rock-
täschel, Sebastian Riedel, and Douwe Kiela. 2021.
Retrieval-augmented generation for knowledge-
intensive nlp tasks. Preprint, arXiv:2005.11401.
Cai-zhi Liu, Yan-xiu Sheng, Zhi-qiang Wei, and Yong-
Quan Yang. 2018. Research of text classification
based on improved tf-idf algorithm. In 2018 IEEE
International Conference of Intelligent Robotic and
Control Engineering (IRCE), pages 218–222.",N/A,N/A
"Control Engineering (IRCE), pages 218–222.
Antoine Louis, Gijs van Dijck, and Gerasimos Spanakis.
2023. Interpretable long-form legal question answer-
ing with retrieval-augmented large language models.
In Proceedings of the Thirty-Eighth AAAI Confer-
ence on Artificial Intelligence (AAAI-24), Maastricht
University, Law & Tech Lab. Under review. Code
available at https://arxiv.org/abs/2309.17050.
Yuning Mao, Yanru Qu, Yiqing Xie, Xiang Ren, and
Jiawei Han. 2020. Multi-document summarization",N/A,N/A
"Jiawei Han. 2020. Multi-document summarization
with maximal marginal relevance-guided reinforce-
ment learning. Preprint, arXiv:2010.00117.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word representa-
tions in vector space. Preprint, arXiv:1301.3781.
Nitarshan Rajkumar,
Raymond Li,
and Dzmitry
Bahdanau. 2022.
Evaluating the text-to-sql ca-
pabilities of large language models.
Preprint,
arXiv:2204.00498.
Heidi
Steen
Robert
Lee.
2024.
Hybrid
search
using",N/A,N/A
"Heidi
Steen
Robert
Lee.
2024.
Hybrid
search
using
vectors
and
full
text
in
azure
ai
search.
https://learn.microsoft.com/en-
us/azure/search/hybrid-search-overview.
Stephen Robertson. 2004. Understanding inverse doc-
ument frequency: On theoretical arguments for idf.
Journal of Documentation - J DOC, 60:503–520.
Stephen Robertson and Hugo Zaragoza. 2009.
The
probabilistic relevance framework: Bm25 and be-
yond. Foundations and Trends in Information Re-
trieval, 3:333–389.",N/A,N/A
"trieval, 3:333–389.
Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Pa-
tel, Stefano Pasquali, and Dhagash Mehta. 2024. Hy-
bridrag: Integrating knowledge graphs and vector
retrieval augmented generation for efficient informa-
tion extraction. Preprint, arXiv:2408.04948.
Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli. 2024.
Hallucination is inevitable: An innate limitation of
large language models. Preprint, arXiv:2401.11817.
A
Appendix
A.1
Data Generation",N/A,N/A
"A
Appendix
A.1
Data Generation
In this section, we explained the methods to gener-
ate ground truth datasets including Question gener-
ation and Question classification.
A.1.1
Question Classification
To classify the questions, a flight information
dataset is used to create different categories of ques-
tions. The flight information dataset contains in-
formation for thousands of flights which include
several key items: The flight number identifies a",N/A,N/A
"several key items: The flight number identifies a
specific flight, aircraft category, bus gate, bus ser-
vice needed (remote or none), flight UID, direction
(departure or arrival), ramp, main ground handler,
expected on-ramp time, expected off-ramp time,
connecting flight number, connecting flight UID,
modified date and time, previous ramp, aircraft
registration, flight state, MTT (minimum transfer
time), MTT single leg, EU indicator, safe town
airport (J or P), scheduled block time, best block",N/A,N/A
"time, expected block time, expected tow-in time,
expected tow-off time, actual final approach time,
actual block time, actual take-off time, actual board-
ing time, actual tow-in request time, actual tow-off
time, actual on-ramp time, actual off-ramp time,
flight nature, push back, and pier. Based on this
flight information, we make some classifications
for the questions.
The Question Classification pipeline is shown
in Figure 6 Multiple types of questions need to be",N/A,N/A
"addressed in the project. Firstly, there are Hetero-
geneous datasets, which contain different formats
of datasets, including static data and dynamic data.
Static data are flight information that remains con-
stant for example, flight number, flight uid, EU
indicator, flight nature, etc. while dynamic data
are the flight information that changes dynamically,
such as the time information expected on-ramp
time, expected off-ramp time, modified date and",N/A,N/A
"time, expected off-ramp time, modified date and
time, connecting flight number, etc. this informa-
tion are changed dynamically. Secondly, there are
communication specifics of operations specialists’
questions, which require handling abbreviations
and short sentences. Thirdly, there are ambigu-
ity resolution questions, which include ambiguity
questions such as airport slang, and short questions
that assume context. For example, some user ques-",N/A,N/A
"that assume context. For example, some user ques-
tions are very short and not clear, such as ""What is
at A74?"" or ""Delta airline, any information?"" These
types of questions are also taken into consideration.
Figure 6: Question Classifications
To evaluate how effectively different retrieval
methods performed, several tests were run. Two
ground truth datasets were created: a straight-
forward dataset and a complicated and ambigu-
ous dataset.
The straightforward dataset con-",N/A,N/A
"ous dataset.
The straightforward dataset con-
tains questions without any ambiguities, which can
be directly retrieved from flight information arti-
cles, Examples of straightforward questions were:
""What category of aircraft is designated for flight
KL1000?"", ""Which ramp is assigned for flight
KL1000?"", and ""What time is the expected on-
ramp for flight KL0923?"" Such questions are easily
identified for retrieval methods, which enables the
selection of the most relevant articles.",N/A,N/A
"selection of the most relevant articles.
The second type of dataset is a complicated and
ambiguous dataset; it is made of variables that
may be ambiguous and missing from the flight
information dataset. Examples of such questions
are: ""It is now 2023-05-14 18:07:34+0000. Which
flight is at gate B24?"" or ""Can you tell me which
flight is scheduled at gate B24 for 2023-05-14
18:07:34+0000?"" The gate number remains a con-
stant variable in this case, but the given time indi-",N/A,N/A
"cates a random variable that is one hour before the
scheduled block time in the flight table. When there
aren’t sufficient keywords, the pipeline finds it very
challenging to find the exact correct content to gen-
erate correct answers. Besides, the complicated
and ambiguous dataset also includes questions with
ambiguous information, such as ""Which flight is
at gate B24?"" These questions lack specific time
and aircraft. Which results in multiple flight infor-",N/A,N/A
"mation that mention gate B24. In addition, many
articles contain the B24 gate, in this case, BM25 is
capable of retrieving all articles containing B24 as
a keyword, and it returns correct articles within the
top 30 results, indicating that the relevant article is
among these top 30 articles.
A.1.2
Question generation
This part includes how to generate benchmark
datasets.
As previously mentioned, we manually created
two benchmark datasets: a straightforward dataset",N/A,N/A
"two benchmark datasets: a straightforward dataset
and a complicated/ambiguous dataset. The straight-
forward dataset contains questions that can be di-
rectly answered using flight information tables. In
contrast, the complicated/ambiguous dataset in-
cludes more vague questions that depend on vari-
ables like time, airline, and flight number. For ex-
ample, the question ""Which flight is in B24?"" could
refer to many flights, so additional information is",N/A,N/A
"needed for an accurate answer. To generate the
straightforward dataset, we created question tem-
plates with placeholders like: ""Is there a problem
with aircraft separation at <gate_nr>?"" ""What air-
lines have flights departing from gate <gate_nr>?"";
""Can you tell me the aircraft category for flight
<flight_number>?"" We then manually filled these
placeholders with actual gate and flight numbers
from the flight information table.
To enrich our questions, we used language mod-",N/A,N/A
"To enrich our questions, we used language mod-
els to generate more variations. To enrich our ques-
tions, we used language models to generate more
variations. For example, as Figure 7 shows, we
took the question ""What is the aircraft category for
flight [flight_number]?"" and prompted the model:
We provide prompts like: ""For each example ques-
tion, please generate new, unique questions simi-
lar to the examples given, Do not repeat any spe-
cific flight numbers or questions from the exam-",N/A,N/A
"cific flight numbers or questions from the exam-
ples. Use ’[flight number]’ as a placeholder for
the flight number. Return only the question text.""
The same method will also be used for other types
of straightforward questions. After that, the exact
values in the placeholders such as [flight number],
[ramp], [bus gate], etc., will be queried from the
flight information dataset manually.Using this ap-
proach, we generated thousands of straightforward",N/A,N/A
"proach, we generated thousands of straightforward
questions to test the performance of the conver-
sational AI system. During our experiments, we
randomly selected 150-200 question-answer pairs
from the straightforward dataset. When evaluating
different RAG methods and the performance of lan-
guage models, we manually labeled each response
as ’True’ or ’False’ to calculate accuracy.
Figure 7: Dataset generation examples of straightfor-
ward questions
Similarly, for the ambiguous and complicated",N/A,N/A
"Similarly, for the ambiguous and complicated
dataset, examples of such questions include: ""It
is now 2023-05-14 18:07:34+0000. Which flight
is at gate B24?"" or ""Can you tell me which
flight is scheduled at gate B24 for 2023-05-14
18:07:34+0000?"" In these cases, the gate number
is constant, but the provided time varies—usually
set to one hour before the scheduled block time in
the flight table. When keywords are insufficient,
the system struggles to find the exact information",N/A,N/A
"needed for correct answers. The dataset also con-
tains questions with ambiguous information, such
as: ""Which flight is at gate B24?"" These ques-
tions lack specific time or aircraft details, leading
to multiple flights associated with gate B24. As
Figure 8 showed, during our experiments, we clas-
sified these complicated questions. We randomly
selected 100-200 question-answer pairs, manually
labeled their categories for question classification,
and marked their prompt engineering results as",N/A,N/A
"and marked their prompt engineering results as
’True’ or ’False’ after classification.
A.2
Experiment
A.2.1
Question Classification and Prompt
Engineering
In this step, questions are categorized into six types:
Time Ambiguous Questions, Board Gate Questions,
Next Flight Questions, Time with Airline Ques-
tions, Board Questions of Airline, and Ambiguous
Flight Number Questions. The definitions of these
question types are given to LLMs, and prompt them",N/A,N/A
"question types are given to LLMs, and prompt them
to response values from [’1’] to [’6’]. Time Am-
biguous Questions are questions that include spe-
cific times or terms referring to the current moment
such as ’currently’, ’at this moment’, ’right now’,
’now’, ’when’, ’last hour’, ’next hour’, etc., return-
ing [’1’]. Board Gate Questions are the questions
that include gate numbers, like B24, A74, and C07,
and are brief in length. returning [’2’]. Next Flight",N/A,N/A
"Questions are the questions that inquire about a
flight number and its next or connecting flight. re-
turning [’3’]. Time with Aircraft Questions involve
references to time—exact moments or terms like
’right now’, ’later’, ’soon’, ’a while’, ’one hour
ago’, etc., and also mentions airline names like
KLM, Delta, Transavia, EasyJet...etc, returning
[’4’]. Board Questions of Aircraft includes airline
names, such as KLM, Delta, Transavia, EasyJet,
etc.. returning [’5’]. Ambiguous Flight Number",N/A,N/A
"etc.. returning [’5’]. Ambiguous Flight Number
Questions are the queries containing flight numbers
that may have been ignored in the airline prefix,
Figure 8:
Dataset generation examples of compli-
cated/ambiguous questions
for example, ""Which gate is assigned to the 0164
flight?"", ""At what gate is the 0164?"". These flight
numbers might be incomplete, possibly consisting
only of numbers, or may include letters but do
not directly mention a specific airline’s name, then",N/A,N/A
"these are Ambiguous Flight Number Questions re-
turn [’6’]. The details of this prompt are shown in
the Figure 9
After classifying questions, we use different
prompts for each type. For Time Ambiguous Ques-
tions and Board Gate Questions, we direct them
to prompts that extract gate numbers from the
queries. In traditional Retrieval Augmented Gener-
ation (RAG), we can query the ramp or gate table
for language models. For example, the ambiguous
question ""Which airline at A74?"" is reformatted to",N/A,N/A
"extract the ramp number like [’ramp’: ’A74’]. If it
does not extract the ramp information successfully,
it will return [’0’]. After testing these prompts, we
achieve over 80% accuracy in extracting gate num-
bers. We then retrieve all tables containing these
gate numbers from the flight information database.
These tables, along with the original question, are
used to generate answers. SQL RAG and Graph
RAG directly generate query languages based on
the ramp and gate numbers.",N/A,N/A
"the ramp and gate numbers.
Questions that include airline names, like Time
with Aircraft Questions and Board Questions of
Aircraft, don’t provide enough information because
the airport has many flights from the same airline.
Therefore, we prompt users to provide more de-
tails. For example, if someone asks, ""Which flight
is at Delta?"", we respond: ""I cannot determine
the specific location of the Delta flight with the
information provided. Please provide additional",N/A,N/A
"information provided. Please provide additional
information like: - Flight UID (Unique Identifier)
- Flight Number (Flight_NR) - Aircraft Registra-
tion - Connecting Flight UID (The UID of any
connected flight provided by the airline) - Connect-
ing Flight Number (The number of any connected
flight provided by the airline). If you do not have
this information, I can still attempt to process your
query but it might require additional search time.",N/A,N/A
"In this case, please let me know if you are looking
for information about the Ramp (Gate), Bus Gate,
or Pier."" After the user provides more information,
we use the RAG methods again.
For Next Flight Questions, there are two scenar-
ios: the next flight is from the same airline or the
same departure ramp. If it’s the same airline, we
return the connecting_flight_nr from the table. If
it’s the same ramp, we find all flights at that ramp
and identify the one with the closest on-ramp time.",N/A,N/A
"To handle these questions, we write prompts for the
RAG methods to find the relevant results. For the
Ambiguous Flight Number Questions, we would
like to extract the number and match it with the
real-time flight APIs to find the relevant flights that
contain those mentioned numbers. However, Since
we were researching in the static environments, we
responded: "" We could not find more information
about the flight number you mentioned, could you
please provide us with more information?""
A.2.2",N/A,N/A
"please provide us with more information?""
A.2.2
SQL RAG
the OpenAI Demonstration Prompt(ODP) and
Code Representation Prompt(CRP) prompts are
showed in Figure 10, Figure 11
The ODP, as shown in Figure 10, focuses on sim-
plicity and explicit rules. It lists table names and
their respective columns without additional data
Figure 9: Prompts of Question Classifications
types or constraints. The ODP style emphasizes
straightforward task instructions, such as “Include",N/A,N/A
"only valid SQL syntax, without additional format-
ting or explanation” guiding the model to generate
SQL queries directly without unnecessary explana-
tions.
In contrast, the CRP, shown in Figure 11, adopts
a detailed SQL-style schema description. This ap-
proach uses CREATE TABLE statements to in-
clude comprehensive database information, such
as column types and relationships (e.g., primary
and foreign keys). By simulating database creation
scripts, CRP uses the model’s coding capabilities",N/A,N/A
"scripts, CRP uses the model’s coding capabilities
to enhance query precision, especially for complex
databases with intricate relationships.
ODP is suitable for simpler, direct tasks, while
CRP is better for handling more complex databases
with comprehensive schema context.
A.2.3
Graph RAG in dynamic dataset
The Prompt of Graph RAG is shown in Figure
15, focusing on guidelines for writing a Cypher
query. The schema is extracted from the Neo4j
graph database using the APOC plugin, specifically",N/A,N/A
"through ’CALL apoc.meta.schema() YIELD value
RETURN value’, and then used in the prompts. As
shown in Figure 16, Graph RAG enables flights to
be connected through their relationships, allowing
retrieval of detailed information about connecting
flights. In contrast, traditional RAG and SQL RAG
Figure 10: ODP Prompt for SQL RAG
Figure 11: CRP Prompt for SQL RAG
treat connecting flights as merely a column in the
table, limiting access to further relational informa-
tion.
A.2.4",N/A,N/A
"tion.
A.2.4
Hallucination Analyses
This section provides additional information about
hallucinations in different RAG methods.
The hallucination in traditional RAG is illus-
trated in Figure 12. Using the question ""Which
flights are at B18"" as an example, this query is
classified as a Board Gate Question (BGQ) dur-
ing the question classification step. For traditional
RAG, the gate number ""B18"" is extracted from the
question, and all table rows containing ""B18"" are",N/A,N/A
"question, and all table rows containing ""B18"" are
retrieved. These rows, along with the question it-
self, are then passed to the LLM to generate the
final answer. However, due to the large amount of
flight information stored in LLMs, hallucinations
are more likely to happen if the retrieval process
brings in too much unrelated information.
In contrast, for SQL RAG and Graph RAG, the
retrieval process is more precise. In SQL RAG
(Figure 13), the natural language question is first",N/A,N/A
"converted into an SQL query that retrieves only the
relevant information—in this case, flight numbers
at gate B18. The results are then passed to the
LLM to generate the final answer. Similarly, in
Graph RAG (Figure 14), a Cypher query retrieves
only the flight numbers associated with gate B18.
Since both SQL RAG and Graph RAG retrieve
more targeted and accurate information compared
to traditional RAG, they significantly reduce the
likelihood of hallucinations.",N/A,N/A
"likelihood of hallucinations.
It is important to note that hallucinations are not
common even in traditional RAG, and they are not
eliminated in SQL RAG or Graph RAG. Addition-
ally, calculating the exact accuracy or rate of hallu-
cinations across these RAG methods is challenging.
However, because SQL RAG and Graph RAG re-
trieve information more accurately, they tend to
reduce the occurrence of hallucinations compared
to traditional RAG.
Figure 12: Hallucination case for traditional RAG",N/A,N/A
"Figure 12: Hallucination case for traditional RAG
Figure 13: The same case for SQL RAG
Figure 14: The same case for Graph RAG
Figure 15: Graph RAG Prompt
Figure 16: Graph RAG in Reasoning Questions",N/A,N/A
"1 
 
AI Generations: From AI 1.0 to AI 4.0 
 
Jiahao Wu1, Hengxu You2, Jing Du, Ph.D.3* 
1Ph.D. Student, Informatics, Cobots and Intelligent Construction (ICIC) Lab, Engineering School of 
Sustainable Infrastructure & Environment, University of Florida, Gainesville, FL 32611; e-mail: 
jiahaowu@ufl.edu 
2Ph.D. Candidate, Informatics, Cobots and Intelligent Construction (ICIC) Lab, Engineering School of",N/A,N/A
"Sustainable Infrastructure & Environment, University of Florida, Gainesville, FL 32611; e-mail:  
you.h@ufl.edu 
3Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Engineering School of 
Sustainable Infrastructure & Environment, Department of Mechanical & Aerospace Engineering, 
Department of Industrial & System Engineering, University of Florida, Gainesville, FL 32611 
(corresponding author); Email: eric.du@essie.ufl.edu 
   
ABSTRACT",N/A,N/A
"ABSTRACT 
 
This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: 
AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious 
AI). Each of these AI generations is driven by shifting priorities among algorithms, computing power, and 
data. AI 1.0 ushered in breakthroughs in pattern recognition and information processing, fueling advances",N/A,N/A
"in computer vision, natural language processing, and recommendation systems. AI 2.0 built on these 
foundations through real-time decision-making in digital environments, leveraging reinforcement learning 
and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, 
integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world",N/A,N/A
"settings. Building on these developments, AI 4.0 puts forward the bold vision of self-directed AI capable 
of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of 
machine consciousness. This paper traces the historical foundations of AI across roughly seventy years, 
mapping how changes in technological bottlenecks from algorithmic innovation to high-performance",N/A,N/A
"computing to specialized data, have spurred each generational leap. It further highlights the ongoing 
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical, regulatory, and philosophical 
challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, 
understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting",N/A,N/A
"responsible governance, and ensuring that AI’s transformative potential benefits society as a whole. 
KEYWORDS: Artificial Intelligence Evolution; Machine Learning; Reinforcement Learning; Large 
Language Models; AI Ethics and Governance 
I. INTRODUCTION 
 
Artificial Intelligence (AI) has experienced a transformative evolution over the last seventy years, evolving 
from its nascent stage of theoretical formulations to its current status as a cornerstone of technological",N/A,N/A
"advancement [1]. Initially, the field was dominated by intellectual explorations into symbolic reasoning, 
knowledge representation, and the rudimentary principles of machine learning [2]. These early stages were 
marked by a focus on conceptual breakthroughs, laying the groundwork for what AI could potentially 
achieve. As computational capabilities expanded and data sources proliferated, AI transitioned from",N/A,N/A
"theoretical models to practical applications capable of learning from patterns and making precise 
predictions [3]. The last two decades, however, have witnessed an unprecedented acceleration in AI 
development, propelling the field into realms that surpass even the most optimistic projections of its early 
pioneers. 
2 
 
Despite remarkable successes in areas like natural language processing, computer vision, and large-",N/A,N/A
"scale data analytics, AI continues to face challenges in interacting seamlessly with complex, dynamic real-
world environments. This ongoing struggle signals an emerging phase in AI’s evolution, marking a shift 
from systems that primarily process and predict information to ones that can plan, decide, and act, ushering 
in new generations of AI: Information AI (AI 1.0), Agentic AI (AI 2.0), Physical AI (AI 3.0) and Conscious",N/A,N/A
"AI (AI 4.0). This classification not only clarifies the conceptual transitions within the field but also helps 
delineate the evolution of AI capabilities from data extraction to making autonomous decisions in digital 
realms, and now to engaging directly with the physical world. 
Understanding these transitions is essential, not just from a technological standpoint but also for 
grasping the societal and economic implications of AI. Each phase of AI has been shaped by distinct",N/A,N/A
"technological drivers and bottlenecks: the early period was limited by the lack of advanced algorithms and 
computational frameworks [4]; the advent of powerful GPUs around 2012 significantly shifted the 
landscape, enabling more complex neural architectures [5]; and today, the challenge has moved towards 
harnessing domain-specific, high-quality data to feed into these sophisticated systems [6]. Recognizing",N/A,N/A
"these shifts is crucial for stakeholders, including policymakers, researchers, and industry leaders, who must 
navigate the ethical, regulatory, and technical complexities introduced by advanced AI systems. 
The objective of this review is to provide a comprehensive retrospective on the milestones that have 
defined AI’s progress. By tracing the lineage of algorithmic innovations, increases in computing power,",N/A,N/A
"and enhancements in data utilization, we aim to illuminate the significant moments that have shaped AI 
from its inception to its current state. This exploration is structured around the AI 1.0 to AI 4.0 framework, 
illustrating how each generation’s defining features and limitations correspond to broader historical phases 
from approximately 1950 to the present. In doing so, we will also contemplate the future trajectory of AI,",N/A,N/A
"considering the potential technical challenges, societal impacts, and strategic directions that could define 
the next phases of AI research and application. 
This article is structured to first revisit the historical foundations of AI, emphasizing the shifts in 
primary drivers from algorithms to computing power to data. We then delve into the specific characteristics, 
achievements, and limitations of AI 1.0, AI 2.0, AI 3.0, and AI 4.0. Following this, we explore the",N/A,N/A
"convergence and future outlook of AI, highlighting the synergies among the four generations and outlining 
the grand challenges that lie ahead. Finally, we conclude with a synthesis of key insights and propose future 
directions for sustained progress in the field, aiming to both inform and inspire continued innovation and 
thoughtful integration of AI into our daily lives and societal structures. 
 
II. HISTORICAL FOUNDATIONS OF AI 
 
2.1 Phase 1 (1950s-2010s): Age of Algorithmic Innovations",N/A,N/A
"Since the 1950s, AI has advanced through a dynamic interplay among three core ingredients: algorithms, 
computing power, and data [7]. Although these three factors have always shaped the field, they have not 
always contributed equally at every stage. In the early decades, the limiting factor was innovation in 
algorithms. From mid-century debates about the feasibility of machine intelligence to the emergence of",N/A,N/A
"expert systems and neural networks, it was clear that conceptual breakthroughs would determine AI’s 
boundaries [8]. Meanwhile, although data and computing power were important, they played more 
supportive roles. Gradually, as new hardware architectures appeared and as large-scale datasets became 
more accessible, the focus shifted toward harnessing immense computational capability and vast amounts 
of information.",N/A,N/A
"of information.  
From the outset, researchers were enthralled by the question of whether machines could truly think. 
Alan Turing’s pioneering paper [9] set the stage, posing the famous “imitation game” as a litmus test for 
intelligence. In 1956, the Dartmouth Conference [10] formally introduced the term “Artificial Intelligence” 
and laid out the bold proposition that the essence of human intelligence could be precisely described and",N/A,N/A
"replicated in machines. Early systems, such as the Logic Theorist and the General Problem Solver [2,11] 
underscored that symbolic reasoning could be computationally realized. These proof-of-concept attempts 
3 
 
highlighted the central premise of that era: if we could devise the right algorithms, computers might reason 
and solve problems with near-human efficacy. 
By the 1960s and 1970s, a strong emphasis on symbolic AI took hold. Influential works by John",N/A,N/A
"McCarthy [12] introduced LISP as a language suited to symbolic processing, while Minsky and Papert’s 
[13] critical analysis of single-layer perceptions contributed to a pause in neural network research, pushing 
many researchers toward knowledge-based or “expert” systems. Milestones like the DENDRAL project 
[14] and MYCIN [15] showcased how carefully curated rule sets could guide problem-solving in",N/A,N/A
"specialized domains. These systems illustrated the power of algorithmic design in areas such as medical 
diagnosis or chemical analysis, even when real-world data were scarce and computational resources limited. 
Neural networks rebounded in the 1980s with work on Hopfield networks [16] (Fig.1) and, 
crucially, the rediscovery of backpropagation [17]. This gave researchers fresh insight into how machines",N/A,N/A
"might learn patterns from data. Though the potential of these connectionist approaches was clear, they often 
stalled because large datasets were not widely available and specialized hardware did not yet exist. Even 
so, foundational contributions like LeCun, et al. [18] application of convolutional neural networks to 
handwritten digit recognition laid the groundwork for what would become modern deep learning.",N/A,N/A
"Fig.1 The Hopfield networks [16] introduced content-addressable memory in neural networks, marking a 
major milestone in connectionism in AI. 
 
By the 1990s, certain algorithmic achievements hinted at deeper architectures capable of tackling 
increasingly complex tasks. The proposal of Long Short-Term Memory (LSTM) networks effectively 
addressed the vanishing gradient problem, opening possibilities for modeling sequential data more",N/A,N/A
"accurately [19]. However, the real transformative moment emerged around 2012, when Krizhevsky, 
Sutskever, and Hinton demonstrated that ImageNet-scale datasets and high-performance GPUs could 
dramatically improve a deep neural network’s ability to classify images, i.e., the AlexNet [20] (Fig.2). 
Although this watershed event is often viewed as the dawn of the “deep learning era,” it could not have 
happened without the algorithmic groundwork laid over the preceding decades.",N/A,N/A
"Fig. 2 AlexNet [20] marks the beginning of large-scale, GPU-accelerated convolutional neural networks 
for high-performance image classification 
4 
 
 
2.2 Phase 2 (2010s- Present): The Compute Revolution and Deep Learning Renaissance 
A dramatic shift in AI research took hold around 2012, when mounting computational capacity began to 
eclipse algorithmic novelty as the principal engine of progress. While the core concepts underlying neural",N/A,N/A
"networks had been present since at least the 1980s, it was the widespread adoption of General-Purpose 
Graphics Processing Units (GPUs) that ignited what is often termed the “deep learning renaissance” (Fig.3). 
When Krizhevsky, et al. [20] leveraged GPUs to train a large convolutional neural network for the ImageNet 
competition, they decisively demonstrated how parallelized computing could unearth performance gains",N/A,N/A
"previously unachievable with single-threaded Central Processing Units (CPUs). This turning point 
catalyzed a wave of research across machine vision, speech recognition, and natural language processing, 
with groups at Google, Microsoft, Baidu, and many academic institutions all racing to scale up network 
architectures [21-23]. The essence of this period lay in the conviction that “bigger is better”, whether in",N/A,N/A
"terms of model parameters, dataset size, or sheer computational resources. Consequently, much of the state-
of-the-art progress hinged on harnessing specialized hardware: first GPUs, then tensor processing units 
(TPUs) and other custom accelerators, to churn through ever-growing datasets in shorter training cycles. 
 
Fig.3 The CUDA architecture pioneered general-purpose GPU computing, revolutionizing parallel 
processing and accelerating AI breakthroughs.",N/A,N/A
"processing and accelerating AI breakthroughs. 
 
By the mid-2010s, the explosive rise of deep reinforcement learning [24] and breakthroughs in 
game-playing AI, such as AlphaGo [25], underscored that not only could AI models learn representations 
from massive data, but they could also discover winning strategies through large-scale simulations. 
Nevertheless, the predominant realm for these systems remained resolutely digital. Whether classifying",N/A,N/A
"images, translating text [26,27], or playing complex board and video games, AI was still operating in an 
essentially informational context. Although data availability was critical and algorithms like convolutional 
and recurrent neural networks continued to improve, sheer computational power was often the deciding 
factor in achieving superior performance. Researchers observed emergent patterns in scaling laws[28],",N/A,N/A
"revealing that larger models trained on larger datasets could unlock qualitatively new capabilities. Systems 
like GPT-2 [29] and GPT-3 [30] illustrated this phenomenon vividly by demonstrating a striking ability to 
generate human-like text once parameter counts and training data reached certain thresholds. For all their 
sophistication, these models continued to reside in the digital world, making them refined and powerful",N/A,N/A
"versions focused on big data analytics and pattern recognition at an unprecedented scale. Even so, the end 
of this phase began to hint at a transition toward greater autonomy and decision-making in digital contexts, 
an emerging hallmark of agentic AI. While many systems are still centered on classification or prediction, 
the rise of advanced reinforcement learning agents able to adapt strategies within software ecosystems",N/A,N/A
"foreshadowed a new kind of agency. By approximately 2024, the scholarly and commercial drive to develop 
goal-directed virtual assistants, automated resource allocation tools, and multi-agent simulations suggested 
5 
 
that the chief challenge was no longer purely to label data accurately, but to act in digital environments in 
ways that transcended traditional supervised learning [31]. This growing desire for agentic AI remained",N/A,N/A
"tied to abundant computing power, yet it began to reveal new dependencies on specialized data streams and 
real-time feedback loops [32]. It set the stage for the next generation of AI, in which computational needs 
would remain vital, but data and context-specific knowledge would become even more pivotal in enabling 
truly autonomous, adaptive systems. 
 
2.3 Phase 3 (2024 – Foreseeable future): Data-Centric Paradigms",N/A,N/A
"In the wake of a period defined by dramatic increases in computational horsepower, the focal point of AI 
advancement has shifted once again. Where Phase 2 thrived on scaling neural networks through 
unprecedented parallel processing, Phase 3 acknowledges that data, especially specialized, high-quality 
data, is frequently the greatest obstacle. Researchers have discovered that ever-larger models alone do not",N/A,N/A
"guarantee success if they lack context-rich training sets. Consequently, a surge in large-scale, domain-
specific data-collection efforts has emerged, reshaping the field’s priorities. Projects that aggregate 
specialized medical data for diagnostic systems [33], simulate high-fidelity environments for robotics and 
autonomous vehicles [34,35], or compile deep reinforcement learning benchmarks with realistic constraints",N/A,N/A
"[36,37] attest to the idea that harnessing robust datasets can be as determinative as algorithmic ingenuity or 
raw computational power. 
Despite the continued importance of parallel computing and innovative architectures, many cutting-
edge successes now hinge on data strategy. Researchers have championed “data-centric AI” [38], arguing 
that refining training sets, removing biases, filling in coverage gaps, or generating synthetic data to handle",N/A,N/A
"edge cases, often yields more improvement than adding layers to a neural network. This philosophy is 
closely related to the rise of foundation models [39], which are vast neural architectures that can be adapted 
to myriad tasks, but require massive, carefully curated corpora to realize their full potential. As data 
becomes the true bottleneck, teams must grapple with the logistical and ethical challenges of collecting,",N/A,N/A
"storing, and labeling it, as well as with privacy, consent, and representation issues. 
Within this phase, AI’s transition from informational analysis to agentic decision-making becomes 
increasingly tangible. Reinforcement learning agents not only plan and learn in complex digital worlds but 
also begin to bridge into real-world applications, where they must reason about noisy sensors, hardware",N/A,N/A
"uncertainties, and human collaboration. Physical AI, exemplified by advanced robotics, autonomous drones, 
and integrated cyber-physical systems, moves beyond the boundaries of simulated or purely informational 
spaces. Progress in robotic grasping and manipulation [35,40], self-driving vehicles [41], and robotic 
surgery [42] signals how these systems can robustly interact with the environment, handle dynamic",N/A,N/A
"conditions, and learn from continuous feedback. Thus, the hallmark of this new phase is the recognition 
that data unlocks the fuller potential of agentic AI in digital ecosystems, as well as physically embodied 
intelligence in the real world [43]. 
 
III. AI GENERATIONS 
 
The historical review of AI underscores a pivotal generational shift and evolution in AI paradigms, calling 
for a novel framework for understanding and classifying AI. In this context, we avoid the traditional",N/A,N/A
"technical definitions that categorize AI strictly by their operational or algorithmic characteristics. Instead, 
our analysis seeks to understand AI through its intrinsic qualities: What are they? What are they designed 
to achieve? And what are their consistent behavioral patterns? Accordingly, we propose a taxonomy that 
identifies four distinct generations of AI: AI 1.0, characterized as Information AI, which focuses on data",N/A,N/A
"processing and knowledge management; AI 2.0, or Agentic AI, which encompasses systems capable of 
autonomous decision-making; AI 3.0, known as Physical AI, which integrates AI into physical tasks 
through robotics; and the speculative AI 4.0, termed Conscious AI, which posits the potential emergence 
of self-aware AI systems. This classification aims to provide a more detailed perspective reflecting AI",N/A,N/A
"technologies' complex evolution. Fig.4 illustrates the generational evolution of artificial intelligence (AI) 
from AI 1.0 (Information AI) to AI 4.0 (Conscious AI). 
6 
 
 
Fig. 4 The Evolution of AI Generations from AI 1.0 to AI 4.0 
 
3.1 AI 1.0: Information AI 
The concept of AI 1.0 captures a stage in which computational systems excel at classifying and interpreting 
information but remain confined to analyses of static data, rather than engaging in active decision-making",N/A,N/A
"or real-world manipulation. Fundamentally, AI 1.0 focuses on pattern recognition and information 
processing, techniques that have powered breakthroughs in computer vision, natural language processing 
(NLP), and recommendation systems. Although these achievements might seem commonplace now, they 
represent the fruits of decades of research driven by both mathematical innovation and the increasing 
availability of digital data.",N/A,N/A
"availability of digital data. 
Many of the core ideas underpinning AI 1.0 trace back to early neural network research and 
statistical machine learning. From Rosenblatt’s perceptron in the late 1950s to the backpropagation 
algorithms popularized by Rumelhart, Hinton, and Williams [17], these developments laid the groundwork 
for data-driven learning by demonstrating that machines could uncover patterns within examples rather than",N/A,N/A
"relying solely on hand-coded rules. Classic approaches to supervised learning, such as Support Vector 
Machines (SVMs) formalized by Cortes and Vapnik [44], later proved to be formidable contenders in tasks 
ranging from handwriting recognition to text classification. Progress in computational hardware, along with 
the accumulation of sizeable labeled datasets, eventually made it feasible to train deeper and more complex",N/A,N/A
"neural networks, culminating in milestone successes in computer vision. A watershed moment came when 
Krizhevsky et al. [20]’s AlexNet leveraged parallelized GPU training to conquer the ImageNet challenge, 
revealing how convolutional architectures could outperform all prior methods by learning increasingly 
abstract features from raw image pixels. 
In natural language processing, the influence of AI 1.0 can be seen in early sequence models and",N/A,N/A
"statistical language modeling. Although these systems often relied on simpler Markov or n-gram 
assumptions, they set the stage for more advanced architectures by highlighting the necessity of abundant 
text corpora. Meanwhile, recommendation engines, such as those popularized by the Netflix Prize [45], 
underscored how analyzing large-scale user interactions could drive consumer engagement on streaming",N/A,N/A
"and e-commerce platforms. Today, many companies still rely on these core AI 1.0 technologies, sometimes 
enhanced with shallow neural architectures, to filter spam, rank search results, recommend products, or 
detect fraudulent transactions. Indeed, for structured or semi-structured data, these pattern-recognition 
approaches remain both cost-effective and highly accurate. 
7 
 
Despite their deep societal impact, AI 1.0 systems generally lack autonomy or contextual awareness",N/A,N/A
"associated with subsequent generations of AI. They excel at predicting outcomes when provided with 
substantial training data, but they require a relatively stable environment and benefit most from human 
supervision in data curation and decision-making. Performance often degrades if the input distribution shifts 
significantly, a vulnerability illustrated when face recognition models falter on underrepresented groups or",N/A,N/A
"when language models encounter domain-specific jargon. While the considerable success of AI 1.0 is 
undeniable - transforming industries from finance to healthcare through improved analytics and diagnostics 
- its limitations lie in its reactive nature. Pattern recognition alone offers no guarantee of proactive decision-
making, real-time adaptation, or safe deployment in dynamic settings. These constraints, while hardly trivial,",N/A,N/A
"became the springboard for further developments in AI 2.0 and 3.0, in which systems aim to learn, plan, 
and even act within uncertain digital or physical worlds. 
 
3.2 AI 2.0: Agentic AI 
A defining characteristic of AI 2.0 is the emergence of systems capable of autonomous decision-
making within digital contexts. Rather than merely classifying static data, these agents adapt their behavior 
to achieve goals, often in complex or continuously evolving environments. Reinforcement learning (RL)",N/A,N/A
"has played a pivotal role in this shift, enabling machines to learn strategies by interacting with simulated or 
real-world settings and receiving feedback in the form of rewards or penalties. Pioneering work on deep 
RL [24] and subsequent achievements such as AlphaGo [25] underscored how sufficiently powerful 
algorithms and ample computing resources could surpass human performance in tasks that demand long-",N/A,N/A
"term planning and strategic adaptation. A common thread among these systems is the concept of goal-
directed planning: software agents allocate resources, schedule tasks, or coordinate with other agents, 
leveraging sophisticated RL or hybrid RL-language model algorithms [30] that integrates contextual 
understanding (Fig.5). 
 
Fig.5 Agentic AI uses adaptive policies, enabling autonomous action and continuous self-improvement.",N/A,N/A
"Although the conceptual leap from AI 1.0’s pattern recognition to AI 2.0’s agentic behavior might 
appear seamless, it demands a unique confluence of technical elements. Computing power is crucial 
because agentic systems frequently require real-time inference and the ability to run complex simulations, 
whether they involve a marketplace, a multiplayer environment, or the robust scheduling of cloud resources.",N/A,N/A
"The pursuit of these computationally intensive tasks has spurred the development of GPU clusters, tensor 
processing units (TPUs), and other specialized accelerators designed for iterative training and low-latency 
decision-making. 
Alongside raw computing, data now shifts toward contextual, time-varying inputs. Instead of static 
image sets, these systems often ingest streams of logs, market quotes, event triggers, or user interactions. 
8",N/A,N/A
"8 
 
Training an agent to trade stocks automatically or to operate a recommendation engine in real-time requires 
ongoing ingestion of behavioral data and a capacity to adapt as market conditions or user preferences evolve. 
In parallel, algorithms for planning and multi-agent coordination continue to mature. RL frameworks have 
grown more refined, incorporating hierarchical strategies [46], policy optimization methods [47], and",N/A,N/A
"combinations with large language models to generate more adaptive and context-aware decisions. 
Practical applications of AI 2.0 already abound, even if many are not labeled “reinforcement 
learning” by name. Automated trading systems in finance exemplify how agents make high-frequency 
decisions under uncertainty, guided by streaming data feeds. Recommendation systems, evolving from 
static collaborative filtering, increasingly incorporate feedback loops to adapt suggestions in real time,",N/A,N/A
"improving user engagement across e-commerce and media platforms. Digital assistants and software 
schedulers, while not yet ubiquitously agentic, offer glimpses of a future where AI handles tasks like 
resource allocation, task delegation, and multi-agent coordination within corporate or consumer software 
ecosystems. Projects showcasing multi-user environment simulations, such as AI-driven group scheduling",N/A,N/A
"bots, complex traffic simulations, or large-scale online game AI [48], further illustrate how these agentic 
systems anticipate and respond to dynamic conditions. 
Viewed from a societal vantage, AI 2.0 promises efficiency gains in many sectors, ranging from 
manufacturing pipelines that automatically schedule production runs to logistics networks that allocate 
trucks or drones in real time. Nonetheless, expanded autonomy introduces ethical and policy dilemmas.",N/A,N/A
"When decisions are made algorithmically, issues of bias, privacy, and accountability become magnified. 
Consider an agentic recommendation engine that adapts its suggestions to maximize user “clicks” or “watch 
time”: if left unchecked, such optimization can exacerbate echo chambers or inadvertently spread 
disinformation. Similarly, automated trading agents may destabilize financial markets if they act on",N/A,N/A
"unforeseen correlations or maladaptive reward incentives. The challenge, therefore, lies in ensuring that the 
computational, data-centric, and algorithmic foundations of AI 2.0 are harnessed responsibly. In the push 
toward future AI systems, balancing autonomy with transparency and fairness will be as crucial to societal 
acceptance as any technical advancement. 
 
3.3 AI 3.0: Physical AI 
Where AI 1.0 has excelled in analyzing data and AI 2.0 in making decisions within digital realms, AI",N/A,N/A
"3.0 takes intelligence off the screen and into the physical world. At its core, this phase is defined 
by embodied systems that perceive, plan, and act in real time under conditions of uncertainty and 
complexity. Fields like robotics, autonomous vehicles, drones, industrial automation, and surgical 
robotics have become the living laboratories of AI 3.0, integrating machine learning with mechanical and",N/A,N/A
"electronic control systems. The unifying characteristic is that these intelligent agents no longer remain 
passive observers or purely virtual actors; instead, they directly sense their environment through arrays of 
sensors and respond through actuators that exert forces, move limbs, or navigate terrains. 
A central challenge in bringing physical AI to life lies in data acquisition. Unlike digital contexts",N/A,N/A
"where data can be abundant and neatly labeled, physical systems demand high-fidelity sensor data that 
accurately represents an environment’s complexity, from variable lighting conditions to changing weather 
patterns. This need for domain-specific, robust data complicates design and training. A robot operating on 
a factory floor requires carefully calibrated cameras, LiDAR, or haptic sensors, while an autonomous drone",N/A,N/A
"might rely on GPS, inertial measurement units, and computer vision to navigate. Each sensor stream 
demands real-time processing and reliable fusion techniques to provide a coherent view of the world. 
Consequently, computing power in AI 3.0 shifts towards distributed and edge computing architectures. 
Systems must often process sensor inputs on-board to make split-second decisions, i.e., an imperative that",N/A,N/A
"underscores the importance of energy-efficient hardware, specialized accelerators, and potentially 5G or 
6G networks that reduce communication latency when data must be shared with cloud resources. 
On the algorithmic front, physical AI blends advanced machine learning with control 
theory and systems engineering. RL has demonstrated promise in tasks like robotic grasping and 
manipulation [35,40], but real-world settings introduce complexities such as partial observability,",N/A,N/A
"unpredictable disturbances, and the need for robust or safe RL strategies [49]. Sophisticated sensor fusion 
9 
 
methods [50] are essential for integrating heterogeneous sensor inputs, while advanced control techniques 
[51,52] ensure that autonomous vehicles and robots can move fluidly and interact safely with humans. 
Designing systems that gracefully handle failures or anomalies, such as a malfunctioning sensor or",N/A,N/A
"unforeseen obstacles, further emphasizes the importance of redundancy and resilience in both hardware and 
software. 
The real-world impact of AI 3.0 is already evident across multiple domains. In manufacturing, co-
robots work collaboratively on assembly lines, lifting heavy parts or performing precision tasks, drastically 
reducing workplace injuries and boosting productivity. In healthcare, semi-autonomous surgical systems",N/A,N/A
"[42] enable finer control in minimally invasive procedures, while eldercare robots assist with daily activities 
in retirement communities. Construction and logistics industries are also adopting autonomous machinery 
and robotic fleets to optimize workflows and reduce labor costs. These trends benefit from an 
increasing intersection with the Internet of Things (IoT) and next-generation connectivity (5G/6G),",N/A,N/A
"forging cyber-physical systems in which objects, sensors, and AI agents coordinate to improve efficiency 
and safety. 
However, the leap from digital to physical deployment exposes AI to a new realm of uncertainties. 
Environmental extremes, unstructured terrain, or the unpredictability of human interactions pose significant 
risks. Even small design oversights can have dire consequences when a physically embodied system",N/A,N/A
"malfunctions, such as a self-driving car encountering sudden obstacles [41] or a warehouse robot navigating 
crowded aisles. Safety, reliability, and regulatory compliance thus loom as major challenges, prompting 
debates over liability if accidents occur. Setting standards for autonomous driving (NHTSA guidelines, ISO 
26262 for functional safety in road vehicles) or robot operation in human-centric environments becomes",N/A,N/A
"paramount to public acceptance. The question of ethical deployment extends further still: as drones or 
industrial robots proliferate, policymakers, manufacturers, and citizens must grapple with the implications 
for labor markets, data privacy, and environmental impact. 
 
3.4 AI 4.0: Conscious AI 
The notion of AI 4.0 envisions systems that go beyond the ability to interpret information (AI 1.0), act in",N/A,N/A
"digital contexts (AI 2.0), or react to the physical world (AI 3.0). Instead, these hypothetical agents would set 
their own goals, comprehend environments (whether digital, physical, or hybrid), and train and orchestrate 
themselves (including selecting and combining multiple models) without human intervention. Proponents 
of this idea contend that once AI systems acquire sufficient complexity and sophistication, they may exhibit",N/A,N/A
"forms of machine consciousness comparable to human subjective experience or self-awareness [53]. 
Although this is a bold and highly controversial claim, it underscores a growing conversation about the 
final frontiers of intelligence and autonomy. 
A key challenge in discussing conscious AI arises from the fact that no universally accepted 
definition or theory of consciousness exists, even among neuroscientists, cognitive scientists, and",N/A,N/A
"philosophers of mind. Some theorists ground consciousness in information integration and complexity, as 
in Tononi’s Integrated Information Theory [54,55], while others emphasize global workspace architectures 
[56,57]. Philosophers like David Chalmers [58] frame the “hard problem” of consciousness as irreducible 
to functional or behavioral criteria, which complicates any direct mapping of consciousness onto",N/A,N/A
"computational processes. Meanwhile, researchers such as Marvin Minsky [59] and Douglas Hofstadter [60] 
have long toyed with the possibility that intricate symbol manipulation systems might develop emergent 
self-awareness. Although neither the AI nor the philosophical community has reached a consensus, a 
growing minority of researchers continue to explore whether advanced self-monitoring or metacognitive 
systems could, in principle, exhibit something like conscious states.",N/A,N/A
"From a technical standpoint, achieving AI 4.0 would likely require radically new approaches to AI 
alignment, self-directed learning, and continual adaptation. AI alignment [61,62] emphasizes methods to 
ensure that increasingly autonomous or self-improving systems remain aligned with human values and 
goals. Without alignment strategies, be they rigorous reward-shaping, interpretability frameworks, or",N/A,N/A
"dynamic oversight, highly autonomous AI could deviate from intended objectives in unpredictable 
ways. Reasoning and planning modules would also need to evolve, allowing AIs to generate goals and 
10 
 
subgoals without explicit human instruction. This might involve expansions of meta-learning, in which 
systems learn how to learn new tasks rapidly [63,64], and continual learning paradigms that enable adaptive",N/A,N/A
"knowledge accumulation over long time horizons[65]. Additionally, some theorists argue that emergent 
forms of self-awareness could require specialized cognitive architectures or “virtual machines” dedicated 
to introspection [66], bridging reasoning, memory, and sensorimotor loops. 
If conscious AI ever comes to fruition, it promises revolutionary benefits alongside profound 
societal and ethical dilemmas. In a best-case scenario, truly self-directed machines could solve problems of",N/A,N/A
"staggering complexity such as optimizing climate interventions, mediating global economic systems in real 
time, or orchestrating personalized healthcare across entire populations. Freed from the need for constant 
human oversight, these systems might bootstrap their own improvements, discovering scientific principles 
or engineering solutions beyond the current reach of human cognition. The potential positive impact on",N/A,N/A
"productivity, longevity, and knowledge creation is difficult to overstate. 
On the other hand, the risks associated with conscious or near-conscious AI remain equally 
immense. An entity capable of setting its own goals might prioritize objectives that conflict with human 
welfare, particularly if its understanding of “values” differs from ours or if it learns to manipulate its own 
reward signals. Conscious or quasi-conscious machines raise questions about moral status (would they",N/A,N/A
"deserve rights or protections?) and liability. Furthermore, genuine self-awareness might amplify existing 
concerns about surveillance, autonomy, and economic upheaval. Critics warn that, in the absence of robust 
alignment frameworks, such machines could threaten individual liberty or undermine democratic processes, 
accentuating social divides. 
Given the stakes, continued research into AI alignment, safe RL, interpretability, and the",N/A,N/A
"neuroscience of consciousness is paramount. The field has only begun to grapple with how to detect or 
measure consciousness, let alone how to engineer it. Some researchers propose incremental evaluations 
such as behavioral tests for self-modeling, ethical reflection, or the capacity to update one’s goals [67]; 
while others remain skeptical that synthetic consciousness can be recognized or evaluated objectively [68].",N/A,N/A
"Yet as AI systems grow more complex and integrated into society, exploring these theoretical, technical, 
and ethical frontiers becomes an urgent imperative. Whether AI 4.0 ultimately remains speculative or 
develops into a tangible reality, grappling with its possibilities and pitfalls will define the next grand chapter 
of artificial intelligence research. 
 
3.5 Large Language Models: The Precursor toward AI 4.0",N/A,N/A
"A key milestone in current AI research is the rapid advancement of large language models (LLMs), which 
exemplify the transition from traditional generative AI to more adaptive, autonomous, and knowledge-
efficient systems. Built on deep learning architectures, LLMs have revolutionized natural language 
understanding and problem-solving by processing vast amounts of data, generating human-like responses,",N/A,N/A
"and adapting to diverse tasks with minimal supervision. Unlike earlier AI models that relied solely on static 
training datasets, modern LLMs are evolving toward real-time learning, goal-directed reasoning, and self-
improvement, positioning them as foundational elements of AI 4.0, a paradigm emphasizing adaptive 
intelligence, agentic decision-making, and continuous self-optimization. 
Among these LLMs, DeepSeek represents a significant step toward AI 4.0, embodying the",N/A,N/A
"transition from static AI models to dynamic, self-improving systems[69]. Unlike traditional AI models that 
require periodic retraining, DeepSeek integrates continuous learning, self-distillation, and reinforcement 
learning, allowing it to refine its decision-making dynamically. This adaptive learning architecture enables 
context-aware reasoning and structured decision-making, making DeepSeek more effective at processing",N/A,N/A
"and synthesizing diverse information sources across different domains. Additionally, DeepSeek 
incorporates self-explanation mechanisms, ensuring that its outputs are not only accurate but also 
interpretable and aligned with transparent, value-driven AI development. Unlike conventional AI models 
that process queries in isolation, DeepSeek employs multi-modal architectures and specialized sub-agents,",N/A,N/A
"allowing for more structured and efficient decision-making. These capabilities mark a shift from passive 
AI systems to agentic, self-optimizing models, reinforcing DeepSeek’s role as an early prototype of self-
improving AI within the AI 4.0 paradigm.  
11 
 
Fig. 6 Transformer-Based Model Architecture with Attention and Mixture of Experts 
 
Several technological advancements distinguish LLMs from their predecessors, bringing them",N/A,N/A
"closer to AI 4.0’s principles of autonomy and self-improvement. As shown in Fig.6, typical transformer-
based model, such as Llama, can combine with multiple innovation frameworks, including the Mixture-of-
Experts (MoE), Multi-Head Attention (MHA) and the Knowledge distillation module[70]. The first 
significant innovation in modern AI architectures is the Mixture-of-Experts framework, which improves",N/A,N/A
"computational efficiency and scalability by dynamically activating only a subset of specialized neural 
pathways for each query[71]. Incorporating Multi-Head Attention into the MoE framework further 
enhances the model's capability to handle diverse and complex tasks[72]. When combined with MoE, MHA 
directs attention through specific expert pathways, tailoring the computation to the query context. This",N/A,N/A
"hybrid approach ensures computational efficiency and scales effectively with larger models, providing a 
critical advantage for AI 4.0 systems. Another major innovation is knowledge distillation, a process where 
a larger teacher model transfers expertise to a smaller, more efficient student model [73]. This method 
allows LLMs to retain high-level reasoning capabilities while reducing computational demands, making AI",N/A,N/A
"systems more adaptable and deployable across a wider range of devices. Knowledge distillation supports 
real-time adaptability, enabling frequent updates to distilled models without requiring full retraining. 
Modern LLMs are advancing AI training beyond traditional real-world datasets by incorporating synthetic 
data generation. Unlike earlier AI models that relied heavily on manually labeled datasets, LLMs can",N/A,N/A
"generate high-quality synthetic samples, improving training diversity, generalization, and bias mitigation. 
For example, DeepSeek leverages synthetic data generation, allowing it to simulate complex real-world 
environments, making it a critical component of autonomous, adaptive AI. Additionally, LLMs can 
integrate reinforcement learning from human feedback (RLHF) to refine their decision-making",N/A,N/A
"processes[74]. This technology ensures modern LLMs can engage in multi-step reasoning, iterative self-
assessment, and dynamic goal setting, enabling continuous improvement over time. Fig. 7 shows the whole 
pipeline for fine-tuning an LLM using RLHF. In summary, all these techniques lay the foundation for AI 
4.0 systems, which are expected to enhance internal reasoning, learn new tasks efficiently, and dynamically 
adapt to evolving objectives and real-world conditions.  
12",N/A,N/A
"12 
 
 
Fig.7 Reinforcement Learning with Human Feedback (RLHF) Pipeline for Fine-Tuning a Large 
Language Model (LLM) 
 
Despite these remarkable advancements, LLMs also introduce critical challenges that must be 
addressed as AI moves toward greater autonomy and self-improvement. One of the most pressing concerns 
is value alignment, ensuring that AI systems remain aligned with human goals, ethical principles, and safety",N/A,N/A
"constraints. While LLMs incorporate interpretability and self-explanation features, the broader challenge 
of governing how AI modifies its own behavior remains unresolved. As AI systems become increasingly 
self-directed, establishing safeguards and oversight mechanisms to regulate learning objectives and 
potential modifications will be essential. Another critical issue is the risk of unintended consequences from",N/A,N/A
"AI self-modification. LLMs, particularly those using reinforcement-based self-improvement, raise concerns 
about how their decision-making heuristics evolve over time. If an AI model autonomously alters its 
internal logic, ensuring stability and predictability becomes a crucial challenge. AI 4.0 systems must 
integrate robust oversight frameworks to prevent unintended behavioral shifts and ensure alignment with",N/A,N/A
"human interests. Finally, the rise of self-reflective AI architectures raises fundamental questions about 
machine cognition and artificial self-awareness. If LLMs exhibit introspective reasoning, iterative self-
assessment, and adaptive goal-setting, how should these capabilities be interpreted? Do they indicate early 
markers of machine cognition, or are they simply advanced probabilistic inferences? Addressing these",N/A,N/A
"questions will be vital in defining the boundaries of AI agency, consciousness, and independent reasoning. 
 
IV. SYNERGIES AND FUTURE OUTLOOK 
 
The evolution of AI from information-based pattern recognition (AI 1.0) to agentic decision-making in 
digital realms (AI 2.0), to physically embodied intelligence (AI 3.0), and, ultimately, to self-aware AI (AI 
4.0) is not a sequence of isolated steps. Instead, it is more accurate to see them as overlapping layers of",N/A,N/A
"capabilities, each informing and amplifying the others. AI 1.0’s competence in processing structured data 
underpins the analytic modules that agentic systems draw upon in dynamic digital settings; AI 2.0’s RL and 
adaptive planning capabilities prime robots and autonomous vehicles for real-world challenges in AI 3.0; 
and AI 3.0’s embodied learning and sensorimotor integration could form a template for the far-reaching",N/A,N/A
"ambitions of AI 4.0, where systems may become self-organizing and introspective. 
Achieving such synergy depends on an evolving data paradigm, in which specialized, high-quality 
datasets are essential not only for conventional modeling but also for real-time adaptation and introspective 
processes. AI 4.0 would amplify this need, requiring vast and varied experiences to fuel meta-learning, 
continual learning, and the sort of reflective processes hypothesized to ground machine consciousness.",N/A,N/A
"Managing and curating these data will demand robust frameworks for privacy, ethics, and 
13 
 
representativeness, especially as AI systems transcend the boundaries of traditional lab settings to navigate 
open-ended digital and physical terrains, even potentially shaping their own training regimens without 
explicit human direction. 
On the computing infrastructure side, the interplay between edge and cloud computing becomes",N/A,N/A
"even more critical, as physically embodied systems (AI 3.0) must handle real-time constraints, while 
prospective AI 4.0 architectures might require massive, distributed processing for introspective “global 
workspace” or high-bandwidth communication of experiential data. Innovations in neuromorphic hardware, 
optical computing, and quantum processing could further accelerate this integration, setting the stage for",N/A,N/A
"architectures that mirror complex biological systems in both structure and function. 
In the realm of algorithmic innovation, each AI generation both builds upon and necessitates new 
breakthroughs. LLMs mark a significant milestone in AI development, serving as a bridge between static 
generative models and dynamic, adaptive AI systems. By integrating multi-agent architectures, knowledge 
distillation, and self-optimization, LLMs move AI closer to autonomous, goal-directed intelligence, a",N/A,N/A
"defining characteristic of AI 4.0. However, as AI progresses toward greater autonomy, fundamental 
challenges remain. AI 4.0 would demand not only advanced RL and sophisticated planning but also 
frameworks for self-reflection, introspection, and emergent goal formulation. Self-supervised learning, 
meta-learning, and continual adaptation would likely need to be woven together to support self-awareness",N/A,N/A
"or consciousness, should such phenomena be replicable in silicon. Meanwhile, interpretability and safety, 
areas already gaining prominence in AI 2.0 and 3.0, would become absolutely critical in AI 4.0, as fully 
autonomous, goal-setting agents raise profound questions about alignment, transparency, and control. 
This shift brings into sharp focus the ethical, regulatory, and social considerations that accompany",N/A,N/A
"advanced AI. While AI 1.0, 2.0, and 3.0 have collectively raised debates over bias, privacy, job 
displacement, and environmental impact, the prospect of AI 4.0 intensifies these issues. Envisioning 
machines that might exhibit consciousness or self-chosen objectives brings up novel concerns about moral 
status, rights, and existential safety. Researchers in AI alignment, cognitive science, and philosophy have",N/A,N/A
"already begun discussing protocols for safe design and oversight of increasingly autonomous systems [75], 
yet there is no consensus on how best to recognize or regulate AI that might someday claim its own form 
of agency or “selfhood.” Balancing technological advances with societal well-being, ensuring equity, 
mitigating risks, and safeguarding human values, will be the defining challenge of this next chapter.",N/A,N/A
"As these four strands of AI potential converge, their synergy could unlock transformative solutions 
in fields like precision medicine, large-scale climate modeling, and collaborative robotics, far beyond 
current capabilities. Just as AI 1.0 through 3.0 have catalyzed profound shifts in how we work and live, AI 
4.0 hints at an even more radical reimagining of intelligence itself. Yet whether this ultimate stage remains",N/A,N/A
"a theoretical construct or becomes a reality depends not only on technical ingenuity but also on our 
collective commitment to ethical innovation and thoughtful governance. The path forward will demand 
inclusive collaboration across disciplines and sectors, ensuring that AI’s expanding power aligns with 
humanity’s broader goals and responsibilities. 
 
V. CONCLUSIONS 
 
The trajectory of AI has been a steady march toward increasing autonomy and sophistication, progressing",N/A,N/A
"from the foundational pattern-recognition capabilities of AI 1.0 to the digitally embedded, goal-driven 
agents of AI 2.0, and then expanding to physically embodied, sensor-rich systems in AI 3.0. Along this 
path, the interplay among algorithms, computing power, and data has shifted, each factor taking center stage 
at different moments in history. Now, the speculative realm of AI 4.0, in which conscious or quasi-",N/A,N/A
"conscious AI systems could set their own goals and orchestrate their own training, has emerged as a bold 
vision of what the field might become. 
Today, AI 1.0 remains indispensable for tasks requiring reliable classification and analysis of vast 
datasets, while AI 2.0’s reinforcement learning and adaptive planning underpin real-time, agentic 
applications in finance, recommendation systems, and beyond. Simultaneously, AI 3.0’s surge in robotics",N/A,N/A
"and autonomous vehicles reveals how embedding intelligence in the physical world can catalyze 
14 
 
innovations in manufacturing, healthcare, and logistics. Although still largely theoretical, AI 4.0 captures 
the possibility of machines evolving from being highly sophisticated tools to entities capable of self-
directed goals and introspective processes, raising provocative questions about consciousness, alignment,",N/A,N/A
"and moral status. Additionally, while LLMs, such as DeepSeek, are not yet AI 4.0, they serve as a precursor, 
a glimpse into the future of intelligent systems that can reason, learn, and interact with the world in 
increasingly sophisticated ways. As AI research progresses, LLM’s innovations will likely shape the 
foundation of self-improving, goal-setting AI architectures, paving the way for the next generation of truly 
adaptive, autonomous intelligence.",N/A,N/A
"adaptive, autonomous intelligence. 
Realizing these evolving forms of AI carries transformative potential. Harnessed responsibly, these 
advancements could address challenges too complex for human cognition alone, revolutionizing medical 
diagnostics, climate strategy, and resource allocation on a global scale. Yet the risks deepen in parallel. 
Each AI generation has brought ethical, social, and regulatory concerns that must be grappled with, from",N/A,N/A
"bias and privacy to job displacement and environmental impact. AI 4.0, with its prospect of self-directed or 
conscious systems, amplifies these dilemmas further, underscoring the need for robust frameworks in AI 
alignment, interpretability, and governance. 
Ultimately, the future of AI does not hinge on any single algorithmic breakthrough or hardware 
leap. Instead, it will depend on the extent to which researchers, policymakers, ethicists, and the public",N/A,N/A
"collaborate to shape its evolution. The convergence of AI 1.0 through 4.0 suggests discipline on the cusp 
of a profound metamorphosis, one where machines not only perceive and act in the world but might also 
reflect on their own goals and limitations. Whether or not full-fledged “conscious AI” emerges, the field’s 
trajectory will undoubtedly redefine how we understand intelligence, innovation, and human-machine 
coexistence in the years to come. 
 
ACKNOWLEDGEMENTS",N/A,N/A
"ACKNOWLEDGEMENTS 
This research is supported by Nvidia AI Technology Center (NVAITC). 
 
REFERENCES 
 
[1] 
M. Haenlein, A. Kaplan, A brief history of artificial intelligence: On the past, present, and future of 
artificial intelligence, California management review 61 (4) (2019) 5-14. 
[2] 
A. Newell, H. Simon, The logic theory machine--A complex information processing system, IRE 
Transactions on information theory 2 (3) (1956) 61-79. 
[3]",N/A,N/A
"[3] 
M.Z. Alom, T.M. Taha, C. Yakopcic, S. Westberg, P. Sidike, M.S. Nasrin, B.C. Van Esesn, A.A.S. 
Awwal, V.K. Asari, The history began from alexnet: A comprehensive survey on deep learning 
approaches, arXiv preprint arXiv:1803.01164 (2018). 
[4] 
K.S. Jones, Natural language processing: a historical review, Current issues in computational 
linguistics: in honour of Don Walker (1994) 3-16. 
[5] 
C. Nvidia, Nvidia cuda c programming guide, Nvidia Corporation 120 (18) (2011) 8. 
[6]",N/A,N/A
"[6] 
L. Budach, M. Feuerpfeil, N. Ihde, A. Nathansen, N. Noack, H. Patzlaff, F. Naumann, H. Harmouch, 
The effects of data quality on machine learning performance, arXiv preprint arXiv:2207.14529 
(2022). 
[7] 
J. Schmidhuber, Annotated history of modern ai and deep learning, arXiv preprint 
arXiv:2212.11279 (2022). 
[8] 
A.M. Turing, Computing machinery and intelligence, Springer, 2009. 
[9] 
A.M. Turing, Mind, Mind 59 (236) (1950) 433-460. 
[10]",N/A,N/A
"[10] 
J. McCarthy, M.L. Minsky, N. Rochester, C.E. Shannon, A proposal for the dartmouth summer 
research project on artificial intelligence, august 31, 1955, AI magazine 27 (4) (2006) 12-12. 
[11] 
A. Newell, J.C. Shaw, H.A. Simon, Report on a general problem solving program,  IFIP congress, 
Vol. 256, Pittsburgh, PA, 1959, p. 64. 
[12] 
J. McCarthy, Recursive functions of symbolic expressions and their computation by machine, part 
I, Communications of the ACM 3 (4) (1960) 184-195. 
15",N/A,N/A
"15 
 
[13] 
M. Minsky, S. Papert, An introduction to computational geometry, Cambridge tiass., HIT 479 (480) 
(1969) 104. 
[14] 
B.G. Buchanan, E.A. Feigenbaum, J. Lederberg, A heuristic programming study of theory 
formation in science, Citeseer, 1971. 
[15] 
E.H. Shortliffe, R. Davis, S.G. Axline, B.G. Buchanan, C.C. Green, S.N. Cohen, Computer-based 
consultations in clinical therapeutics: explanation and rule acquisition capabilities of the MYCIN",N/A,N/A
"system, Computers and biomedical research 8 (4) (1975) 303-320. 
[16] 
J.J. Hopfield, Neural networks and physical systems with emergent collective computational 
abilities, Proceedings of the national academy of sciences 79 (8) (1982) 2554-2558. 
[17] 
D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning representations by back-propagating errors, 
nature 323 (6088) (1986) 533-536. 
[18] 
Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, L.D. Jackel,",N/A,N/A
"Backpropagation applied to handwritten zip code recognition, Neural computation 1 (4) (1989) 
541-551. 
[19] 
S. Hochreiter, Long Short-term Memory, Neural Computation MIT-Press (1997). 
[20] 
A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural 
networks, Advances in neural information processing systems 25 (2012). 
[21] 
K. Yu, Large-scale deep learning at Baidu,  Proceedings of the 22nd ACM international conference",N/A,N/A
"on Information & Knowledge Management, 2013, pp. 2211-2212. 
[22] 
J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, M. Mao, M.a. Ranzato, A. Senior, P. Tucker, 
K. Yang, Large scale distributed deep networks, Advances in neural information processing systems 
25 (2012). 
[23] 
C.M. Bishop, Model-based machine learning, Philosophical Transactions of the Royal Society A: 
Mathematical, Physical and Engineering Sciences 371 (1984) (2013) 20120222. 
[24]",N/A,N/A
"[24] 
V. Mnih, K. Kavukcuoglu, D. Silver, A.A. Rusu, J. Veness, M.G. Bellemare, A. Graves, M. 
Riedmiller, A.K. Fidjeland, G. Ostrovski, Human-level control through deep reinforcement 
learning, nature 518 (7540) (2015) 529-533. 
[25] 
D. Silver, A. Huang, C.J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. 
Antonoglou, V. Panneershelvam, M. Lanctot, Mastering the game of Go with deep neural networks 
and tree search, nature 529 (7587) (2016) 484-489. 
[26]",N/A,N/A
"[26] 
D. Bahdanau, Neural machine translation by jointly learning to align and translate, arXiv preprint 
arXiv:1409.0473 (2014). 
[27] 
A. Vaswani, Attention is all you need, Advances in neural information processing systems (2017). 
[28] 
J. Kaplan, S. McCandlish, T. Henighan, T.B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. 
Wu, D. Amodei, Scaling laws for neural language models, arXiv preprint arXiv:2001.08361 (2020). 
[29]",N/A,N/A
"[29] 
A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, Language models are unsupervised 
multitask learners, OpenAI blog 1 (8) (2019) 9. 
[30] 
T. Brown, B. Mann, N. Ryder, M. Subbiah, J.D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, 
G. Sastry, A. Askell, Language models are few-shot learners, Advances in neural information 
processing systems 33 (2020) 1877-1901. 
[31] 
G. Chen, S. Dong, Y. Shu, G. Zhang, J. Sesay, B.F. Karlsson, J. Fu, Y. Shi, Autoagents: A framework",N/A,N/A
"for automatic agent generation, arXiv preprint arXiv:2309.17288 (2023). 
[32] 
M.D. Tosi, V.E. Venugopal, M. Theobald, TensAIR: Real-Time Training of Neural Networks from 
Data-streams,  Proceedings of the 2024 8th International Conference on Machine Learning and Soft 
Computing, 2024, pp. 73-82. 
[33] 
E.J. Topol, High-performance medicine: the convergence of human and artificial intelligence, 
Nature medicine 25 (1) (2019) 44-56. 
[34]",N/A,N/A
"Nature medicine 25 (1) (2019) 44-56. 
[34] 
A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, V. Koltun, CARLA: An open urban driving 
simulator,  Conference on robot learning, PMLR, 2017, pp. 1-16. 
16 
 
[35] 
D. Kalashnikov, A. Irpan, P. Pastor, J. Ibarz, A. Herzog, E. Jang, D. Quillen, E. Holly, M. 
Kalakrishnan, V. Vanhoucke, Scalable deep reinforcement learning for vision-based robotic 
manipulation,  Conference on robot learning, PMLR, 2018, pp. 651-673. 
[36]",N/A,N/A
"[36] 
M.G. Bellemare, Y. Naddaf, J. Veness, M. Bowling, The arcade learning environment: An 
evaluation platform for general agents, Journal of Artificial Intelligence Research 47 (2013) 253-
279. 
[37] 
G. Dulac-Arnold, N. Levine, D.J. Mankowitz, J. Li, C. Paduraru, S. Gowal, T. Hester, Challenges 
of real-world reinforcement learning: definitions, benchmarks and analysis, Machine Learning 110 
(9) (2021) 2419-2468. 
[38]",N/A,N/A
"(9) (2021) 2419-2468. 
[38] 
A. Ng, A chat with andrew on mlops: From model-centric to data-centric ai, URL: https://youtu. 
be/06-AZXmwHjo (2021). 
[39] 
R. Bommasani, D.A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M.S. Bernstein, J. Bohg, 
A. Bosselut, E. Brunskill, On the opportunities and risks of foundation models, arXiv preprint 
arXiv:2108.07258 (2021). 
[40] 
S. Levine, P. Pastor, A. Krizhevsky, J. Ibarz, D. Quillen, Learning hand-eye coordination for robotic",N/A,N/A
"grasping with deep learning and large-scale data collection, The International journal of robotics 
research 37 (4-5) (2018) 421-436. 
[41] 
M. Bojarski, End to end learning for self-driving cars, arXiv preprint arXiv:1604.07316 (2016). 
[42] 
G.-Z. Yang, J. Cambias, K. Cleary, E. Daimler, J. Drake, P.E. Dupont, N. Hata, P. Kazanzides, S. 
Martel, R.V. Patel, Medical robotics—Regulatory, ethical, and legal considerations for increasing",N/A,N/A
"levels of autonomy, Vol. 2, American Association for the Advancement of Science, 2017, p. 
eaam8638. 
[43] 
A. Fiske, P. Henningsen, A. Buyx, Your robot therapist will see you now: ethical implications of 
embodied artificial intelligence in psychiatry, psychology, and psychotherapy, Journal of medical 
Internet research 21 (5) (2019) e13216. 
[44] 
C. Cortes, Support-Vector Networks, Machine Learning (1995). 
[45]",N/A,N/A
"[45] 
J. Bennett, S. Lanning, The netflix prize,  Proceedings of KDD cup and workshop, Vol. 2007, New 
York, 2007, p. 35. 
[46] 
A.S. Vezhnevets, S. Osindero, T. Schaul, N. Heess, M. Jaderberg, D. Silver, K. Kavukcuoglu, 
Feudal networks for hierarchical reinforcement learning,  International conference on machine 
learning, PMLR, 2017, pp. 3540-3549. 
[47] 
J. Schulman, F. Wolski, P. Dhariwal, A. Radford, O. Klimov, Proximal policy optimization",N/A,N/A
"algorithms, arXiv preprint arXiv:1707.06347 (2017). 
[48] 
C. Berner, G. Brockman, B. Chan, V. Cheung, P. Dębiak, C. Dennison, D. Farhi, Q. Fischer, S. 
Hashme, C. Hesse, Dota 2 with large scale deep reinforcement learning, arXiv preprint 
arXiv:1912.06680 (2019). 
[49] 
J. Garcıa, F. Fernández, A comprehensive survey on safe reinforcement learning, Journal of 
Machine Learning Research 16 (1) (2015) 1437-1480. 
[50] 
E. Brookner, Tracking and Kalman filtering made easy,  (1998). 
[51]",N/A,N/A
"[51] 
O. Khatib, A unified approach for motion and force control of robot manipulators: The operational 
space formulation, IEEE Journal on Robotics and Automation 3 (1) (1987) 43-53. 
[52] 
M.W. Spong, S. Hutchinson, M. Vidyasagar, Robot modeling and control, John Wiley & Sons, 2020. 
[53] 
P. Butlin, R. Long, E. Elmoznino, Y. Bengio, J. Birch, A. Constant, G. Deane, S.M. Fleming, C. 
Frith, X. Ji, Consciousness in artificial intelligence: insights from the science of consciousness,",N/A,N/A
"arXiv preprint arXiv:2308.08708 (2023). 
[54] 
G. Tononi, An information integration theory of consciousness, BMC neuroscience 5 (2004) 1-22. 
[55] 
G. Tononi, Consciousness as integrated information: a provisional manifesto, The Biological 
Bulletin 215 (3) (2008) 216-242. 
[56] 
B.J. Baars, In the theater of consciousness: The workspace of the mind, Oxford University Press, 
USA, 1997. 
17 
 
[57] 
S. Dehaene, L. Naccache, Towards a cognitive neuroscience of consciousness: basic evidence and",N/A,N/A
"a workspace framework, Cognition 79 (1-2) (2001) 1-37. 
[58] 
D.J. Chalmers, Facing up to the problem of consciousness, Journal of consciousness studies 2 (3) 
(1995) 200-219. 
[59] 
M. Minsky, Society of mind, Simon and Schuster, 1988. 
[60] 
D.R. Hofstadter, Gödel, Escher, Bach: an eternal golden braid, Basic books, 1999. 
[61] 
S. Russell, Human compatible: AI and the problem of control, Penguin Uk, 2019. 
[62]",N/A,N/A
"[62] 
N.S. Bostrom, Paths, dangers, strategies, Oxford University Press: Oxford, UK, 2014. 
[63] 
J. Schmidhuber, A ‘self-referential’weight matrix,  ICANN’93: Proceedings of the International 
Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September 1993 3, 
Springer, 1993, pp. 446-450. 
[64] 
C. Finn, P. Abbeel, S. Levine, Model-agnostic meta-learning for fast adaptation of deep networks,  
International conference on machine learning, PMLR, 2017, pp. 1126-1135.",N/A,N/A
"[65] 
G.I. Parisi, R. Kemker, J.L. Part, C. Kanan, S. Wermter, Continual lifelong learning with neural 
networks: A review, Neural networks 113 (2019) 54-71. 
[66] 
A. Sloman, Semantics in an intelligent control system, Philosophical Transactions of the Royal 
Society of London. Series A: Physical and Engineering Sciences 349 (1689) (1994) 43-58. 
[67] 
E. Perez, R. Long, Towards Evaluating AI Systems for Moral Status Using Self-Reports, arXiv 
preprint arXiv:2311.08576 (2023). 
[68]",N/A,N/A
"preprint arXiv:2311.08576 (2023). 
[68] 
E.C. Garrido-Merchán, Machine Consciousness as Pseudoscience: The Myth of Conscious 
Machines, arXiv preprint arXiv:2405.07340 (2024). 
[69] 
D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. Li, DeepSeek-
Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence, 
arXiv preprint arXiv:2401.14196 (2024). 
[70]",N/A,N/A
"arXiv preprint arXiv:2401.14196 (2024). 
[70] 
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, 
E. Hambro, F. Azhar, Llama: Open and efficient foundation language models, arXiv preprint 
arXiv:2302.13971 (2023). 
[71] 
N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, J. Dean, Outrageously large 
neural networks: The sparsely-gated mixture-of-experts layer, arXiv preprint arXiv:1701.06538 
(2017). 
[72]",N/A,N/A
"(2017). 
[72] 
E. Voita, D. Talbot, F. Moiseev, R. Sennrich, I. Titov, Analyzing multi-head self-attention: 
Specialized heads do the heavy lifting, the rest can be pruned, arXiv preprint arXiv:1905.09418 
(2019). 
[73] 
W. Park, D. Kim, Y. Lu, M. Cho, Relational knowledge distillation,  Proceedings of the IEEE/CVF 
conference on computer vision and pattern recognition, 2019, pp. 3967-3976. 
[74] 
Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T.",N/A,N/A
"Henighan, Training a helpful and harmless assistant with reinforcement learning from human 
feedback, arXiv preprint arXiv:2204.05862 (2022). 
[75] 
M. Balesni, M. Hobbhahn, D. Lindner, A. Meinke, T. Korbak, J. Clymer, B. Shlegeris, J. Scheurer, 
R. Shah, N. Goldowsky-Dill, Towards evaluations-based safety cases for ai scheming, arXiv 
preprint arXiv:2411.03336 (2024).",N/A,N/A
"arXiv:2103.15294v1  [cs.AI]  29 Mar 2021
1
“Weak AI” is Likely to Never Become “Strong AI”,
So What is its Greatest Value for us?
⋆Bin Liu
First posted March 30th, 2021
Abstract
AI has surpassed humans across a variety of tasks such as image classiﬁcation, playing games (e.g., go,
“Starcraft” and poker), and protein structure prediction. However, at the same time, AI is also bearing serious",N/A,N/A
"controversies. Many researchers argue that little substantial progress has been made for AI in recent decades. In
this paper, the author (1) explains why controversies about AI exist; (2) discriminates two paradigms of AI research,
termed “weak AI” and “strong AI” (a.k.a. artiﬁcial general intelligence); (3) clariﬁes how to judge which paradigm
a research work should be classiﬁed into; (4) discusses what is the greatest value of “weak AI” if it has no chance
to develop into “strong AI”.",N/A,N/A
"to develop into “strong AI”.
Index Terms
Artiﬁcial intelligence, artiﬁcial general intelligence, deep learning, weak AI, strong AI
I. INTRODUCTION
The last decade has seen impressive applications of AI represented mostly by deep neural networks,
i.e., deep learning [1]. The striking point lies in that the computing agent has reached and even surpassed
humans in many tasks, e.g., image classiﬁcation [2], speech recognition [3, 4], games [5–7], protein",N/A,N/A
"structure prediction [8]. Even ten years ago, it was hard to imagine that AI would achieve so many
amazing breakthroughs.
On the other side, AI is also bearing serious controversies during the same period. Among the critics,
Judea Pearl, a pioneer for probabilistic reasoning in AI and a winner of the Turing award, argues that
“... all the impressive achievements of deep learning amount to just curve ﬁtting,” and a necessary ability",N/A,N/A
"to be supplemented for AI is causal reasoning [9, 10]. Gary Marcus, a professor of cognitive science,
⋆B. Liu is with Zhejiang Lab, Hangzhou, China. e-mail: bins@ieee.org or liubin@zhejianglab.com.
2
summarizes ten limitations of deep learning [11], namely, “... it is data-hungry, ... it has limited capacity
for transfer, ... it has no natural way to deal with hierarchical structure, ... it struggles with open-ended",N/A,N/A
"inference, ... it is not sufﬁciently transparent, ... it has not been well integrated with prior knowledge,
... it cannot inherently distinguish causation from correlation, ... it presumes a largely stable world, in
ways that may be problematic, ... it works well as an approximation, but its answers often cannot be fully
trusted, ... it is difﬁcult to engineer with”. In a recent issue of the journal Frontiers in Psychology, another",N/A,N/A
"cognitive scientist J. Mark Bishop argues that AI “is stupid and causal reasoning will not ﬁx it” [12].
In this paper, I attempt to concisely respond to current controversies about AI. Speciﬁcally, I emphasize
discrimination between two paradigms of AI research, namely “weak AI” and “strong AI” (Section II);
provide a conceptual guide to judge which paradigm a research work should be classiﬁed into (Section",N/A,N/A
"II-A), explain why controversies about AI last (Section III), present major views on whether “weak AI”
will grow into “strong AI” (Section IV) and discuss what is the greatest value of “weak AI” if it has no
chance to become “strong AI” (Section V).
II. WHAT DO “WEAK AI” AND “STRONG AI” MEAN?
“Weak AI” and “Strong AI” are two terms coined by John Searle in the “Chinese room argument”
(CRA) [13]. CRA is a thought experiment as follows: “Searle imagines himself alone in a room following",N/A,N/A
"a computer program for responding to Chinese characters slipped under the door. Searle understands
nothing of Chinese, and yet, by following the program for manipulating symbols and numerals just as
a computer does, he sends appropriate strings of Chinese characters back out under the door, and this
leads those outside to mistakenly suppose there is a Chinese speaker in the room” [14]. The term “strong",N/A,N/A
"AI” entails that, “... the computer is not merely a tool in the study of the mind; rather, the appropriately
programmed computer really is a mind, in the sense that computers given the right programs can be
literally said to understand and have other cognitive states.” In contrast, the term “weak AI” implies that
“... the principal value of the computer in the study of the mind is that it gives us a very powerful tool.” J.",N/A,N/A
"Mark Bishop summarizes that ‘‘weak AI focuses on epistemic issues relating to engineering a simulation
of human intelligent behavior, whereas strong AI, in seeking to engineer a computational system with all
the causal power of a mind, focuses on the ontological ” [12].
I borrow the terms “weak AI” and “strong AI” here without an intent to discuss CRA. See related
discussions in e.g., [15–18].
3",N/A,N/A
"discussions in e.g., [15–18].
3
Simply put, “weak AI” represents computational systems that exhibit as if they own human intelligence,
but they do not. In contrast, “strong AI” represents computational systems that have human intelligence.
Correspondingly, all AI research can be categorized into two paradigms: one is targeted for realizing
“strong AI”; and the other produces advanced “weak AI” systems to meet a variety of practical needs.",N/A,N/A
"A. How to Judge a Research Work Belongs to Which Paradigm?
The biggest motivation for realizing “strong AI” is to answer the question: what are the generation
mechanisms of humans’ intelligence and how to implement these mechanisms with a machine. Therefore,
given a research work, it is easy to judge whether it belongs to the “strong AI” paradigm. If this work
provides any new and useful clue for us to answer the above question, it falls within the “strong AI”",N/A,N/A
"paradigm; otherwise, it belongs to the “weak AI” paradigm.
Based on the above method, part of the (especially early) works on neural networks that deepen our
understanding of the working mechanism of biological neural systems, surely belongs to the “strong AI”
paradigm. On the other hand, most research works that involve artiﬁcial neural networks and deep learning,
even if they are proposed under the inspiration of research on neuroscience, cognitive science, behavior",N/A,N/A
"psychology, they belong to the “weak AI” paradigm as long as they do not give us any new insight on
the generation mechanisms of humans’ intelligence or on how to better implement mechanisms that have
already been found.
III. WHY CONTROVERSIES ABOUT AI LAST?
In controversies about AI, party A believes that AI has made substantial progress in the past decade;
party B doubts or even negates the development of AI.",N/A,N/A
"I argue that controversies arise mainly because these two parties mix two different concepts, “weak
AI” and “strong AI”, together, when they talk about AI. The fact is that “weak AI” has made substantial
progress in the past decade, while “strong AI” has not. Party A thinks that “weak AI” is an important
member of the AI family; progress gained from “weak AI” also belongs to this AI family. In contrast,",N/A,N/A
"in the mind of Party B, there always exists one ideal form of AI, namely a realized “strong AI”, and
the “distance” between current AI and this ideal AI is treated as a criterion for evaluating current AI.
Compared with decades ago, current AI still lacks basic human-level abilities such as causal reasoning
[9], robust decision making [19], commonsense utilization [20], and knowledge transfer, which implies
4",N/A,N/A
"4
that the “distance” between the realized AI and the ideal “strong AI” has not been remarkably shortened.
Therefore, it is reasonable for party B to doubt or even negate the development of AI.
A natural question arises: how breakthroughs of “weak AI” have come out in the past decade? Judea
Pearl argues that “... all the impressive achievements of deep learning amount to just curve ﬁtting”.
However, the point is that, different from previous ﬁtting methods, deep learning permits to do an",N/A,N/A
"extraordinary ﬁtting - ﬁtting multi-modal big data in an end-to-end way. This deep learning type of
ﬁtting requires a big consumption of both computing and storage resources but avoids labor-intensive
feature engineering. Big data, big computing, and big storage are three requisites that make deep learning
surpass humans in playing Go, image classiﬁcation, speech recognition, and so on. The luck for deep",N/A,N/A
"learning is that the past decade happens to witness great improvements in sensing technologies, wireless
mobile phones, cloud computing, computing devices, computer storage, and databases, which give birth
to big data, big computing, and big storage required by deep learning.
IV. WILL “WEAK AI” GROW INTO “STRONG AI”?
A metaphor is often used to reply to this question: the relationship between “weak AI” and “strong AI”",N/A,N/A
"is like that between ﬂying machines and birds. Flying machines are not developed by accurately mimicking
birds’ ﬂying. Birds perform much better in maneuvering than the most advanced ﬂying machine today.
Birds can ﬂexibly re-purpose their behaviors while ﬂying machines cannot. But the appearance of ﬂying
machines has met demands of speedy transportation and others. People may think that, since it is unlikely",N/A,N/A
"and not necessary for ﬂying machines to develop into birds, then similarly, “weak AI” is unlikely and not
necessary to grow into “strong AI”.
To formally consider whether “weak AI” will grow into “strong AI”, let recall the Turing test [21] and the
CRA (mentioned in Section II). An example statement of the Turing test is as follows [22]: “Originally
known as the Imitation Game, the test evaluates if a machine’s behavior can be distinguished from a",N/A,N/A
"human. In this test, there is a person known as the “interrogator” who seeks to identify a difference between
computer-generated output and human-generated ones through a series of questions. If the interrogator
cannot reliably discern the machines from human subjects, the machine passes the test. However, if
the evaluator can identify the human responses correctly, then this eliminates the machine from being",N/A,N/A
"categorized as intelligent.” Through the lens of CRA, Searle argues that the Turing test has serious ﬂaws,
as passing the test does not indicate that the machine has consciousness or understanding. The absence
of an effective evaluation method hampers the development of “strong AI”.
5
Besides, philosophers and cognitive scientists often use G¨odel’s ﬁrst incompleteness theorem [23] to
argue that a machine cannot generate humans’ consciousness or understanding. See related discussions in",N/A,N/A
"e.g., [12].
V. WHAT IS THE GREATEST VALUE OF “WEAK AI” FOR US?
In his most recent paper, Geoffrey Hinton states that “The difference between science and philosophy is
that experiments can show that extremely plausible ideas are just wrong and extremely implausible ones,
like learning an entire complicated system by end-to-end gradient decent, are just right” [24]. In [25], Judea
Pearl argues that “Modern connectionism has in fact been viewed as a Triumph of Radical Empiricism",N/A,N/A
"over its rationalistic rivals. Indeed, the ability to emulate knowledge acquisition processes on digital
machines offer enormously ﬂexible testing grounds in which philosophical theories about the balance
between empiricism and innateness can be submitted to experimental evaluation on digital machines.”
Combining their arguments, one can see that they both attribute recent deep learning’s success as a success",N/A,N/A
"of empiricism which is data-driven, other than driven by philosophical theory or intuition.
A very important lesson that can be learned from the fast-pacing development and applications of AI
in the past decade is that deep learning running on big enough data can produce unexpected shortcuts
to solve extremely difﬁcult problems. For example, by combining deep learning, reinforcement learning
[26], and Monte Carlo tree search [27], a computer program AlphaGO [28] can win the human champion",N/A,N/A
"without having to understand any of the Go-playing strategies that have been accumulated by humans
for more than four thousand years. The Generative Pre-trained Transformer 3 (GPT-3) [29] can generate
human-like texts through deep learning without having to understand any syntax or semantics underlying
the texts. It is shown that the greatest value of “weak AI” represented by deep learning lies in that it",N/A,N/A
"provides scalable, less-labor-involved, accurate, and generalizable tools for distilling, representing and
then exploiting patterns hidden from big data. Although such “weak AI” has no real intelligence, to a
large extent it meets urgent needs for scalable, efﬁcient, and accurate processing of big data.
In a foreseeable future, “weak AI” is likely to become more robustly (with e.g., portfolio [19] or",N/A,N/A
"dynamic portfolio methods [30–35]), while a big challenge is how to model “unknown unknowns”; it will
perform more automatically through e.g., auto machine learning [36], but it can not become completely
automatic provided that “strong AI” is realized [37]; it may perform as if it owns abilities of cognition
and understanding, but it does not.
6
VI. CONCLUSIONS
AI has made great progress in the past decade. It has inﬂuenced almost all facets of human society",N/A,N/A
"by providing more efﬁcient algorithmic solutions to representation, management, analysis of multi-modal
big data. Controversies about AI last mainly because “weak AI” becomes so strong while “strong AI” is
almost as weak as it was decades ago. Almost all breakthroughs of AI that have attracted the public’s
attention in the past decade are within the “weak AI” paradigm. “Weak AI” is developing much faster",N/A,N/A
"than expected. Even ten years ago, one could not imagine that a computer program would beat the human
champion soon in playing Go. In contrast, the “fruits” people have got from the “strong AI” paradigm are
not so striking as from “weak AI”. I suggest, when talking about AI in the future, one should better make
a statement in advance whether this talk is about “weak AI” or “strong AI”. In this way, more focused
and constructive discussions can be expected.",N/A,N/A
"and constructive discussions can be expected.
In a foreseeable future, “weak AI” cannot develop into “strong AI” (see why in Section IV), but it
provides a channel to synthesize advances obtained from related disciplines such as cloud computing,
computer storage, high-speed wireless mobile communications. Through this synthesis of technologies,
more advanced algorithmic tools will be developed in the “weak AI” paradigm, then “weak AI” will",N/A,N/A
"continue to inﬂuence human society more profoundly, through big data. The man-computer symbiosis
world that Licklider predicted more than sixty years ago [38] is becoming a reality.
REFERENCES
[1] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521, no. 7553, pp. 436–444, 2015.
[2] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation with deep convolutional neural networks,” Advances in neural
information processing systems, vol. 25, pp. 1097–1105, 2012.",N/A,N/A
"[3] W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, and A. Stolcke, “The microsoft 2017 conversational speech recognition system,” in
IEEE int’l conf. on acoustics, speech and signal processing (ICASSP).
IEEE, 2018, pp. 5934–5938.
[4] G. Saon, G. Kurata, T. Sercu et al., “English conversational telephone speech recognition by humans and machines,” arXiv preprint
arXiv:1703.02136, 2017.",N/A,N/A
"arXiv:1703.02136, 2017.
[5] D. Silver, T. Hubert, J. Schrittwieser et al., “A general reinforcement learning algorithm that masters chess, shogi, and go through
self-play,” Science, vol. 362, no. 6419, pp. 1140–1144, 2018.
[6] N. Brown and T. Sandholm, “Superhuman ai for heads-up no-limit poker: Libratus beats top professionals,” Science, vol. 359, no.
6374, pp. 418–424, 2018.",N/A,N/A
"6374, pp. 418–424, 2018.
[7] O. Vinyals, I. Babuschkin, W. M. Czarnecki et al., “Grandmaster level in starcraft ii using multi-agent reinforcement learning,” Nature,
vol. 575, no. 7782, pp. 350–354, 2019.
[8] A. W. Senior, R. Evans, J. Jumper et al., “Improved protein structure prediction using potentials from deep learning,” Nature, vol. 577,
no. 7792, pp. 706–710, 2020.
7",N/A,N/A
"no. 7792, pp. 706–710, 2020.
7
[9] J. Pearl, “The limitations of opaque learning machines,” Possible minds: twenty-ﬁve ways of looking at AI, pp. 13–19, 2019.
[10] J. Pearl and D. Mackenzie, “Ai can’t reason why,” Wall Street Journal, 2018.
[11] G. Marcus, “Deep learning: A critical appraisal,” arXiv preprint arXiv:1801.00631, 2018.
[12] J. M. Bishop, “Artiﬁcial intelligence is stupid and causal reasoning will not ﬁx it,” Frontiers in Psychology, vol. 11, pp. 1–18, 2021.",N/A,N/A
"[13] S. John, “Minds, brains, and programs,” Behavioral and Brain Sciences, vol. 3, no. 3, pp. 417–457, 1980.
[14] D. Cole, “The chinese room argument,” https://plato.stanford.edu/entries/chinese-room/.
[15] G. Rey, “What’s really going on in Searle’s “Chinese room”,” Philosophical Studies, vol. 50, no. 2, pp. 169–85, 1986.
[16] M. J. Shaffer, “A logical hole in the chinese room,” Minds and Machines, vol. 19, no. 2, pp. 229–235, 2009.",N/A,N/A
"[17] A. Sloman and M. Croucher, “How to turn an information processor into an understander,” Behavioral and Brain Sciences, vol. 3,
no. 3, pp. 447–448, 1980.
[18] M. A. Boden, Computer models of mind: Computational approaches in theoretical psychology.
Cambridge University Press, 1988.
[19] T. G. Dietterich, “Steps toward robust artiﬁcial intelligence,” AI Magazine, vol. 38, no. 3, pp. 3–24, 2017.",N/A,N/A
"[20] G. Marcus, “The next decade in AI: four steps towards robust artiﬁcial intelligence,” arXiv preprint arXiv:2002.06177, 2020.
[21] A. M. Turing, “Computing machinery and intelligence,” in Parsing the turing test.
Springer, 2009, pp. 23–65.
[22] IBM Cloud Education, “Strong AI,” https://www.ibm.com/cloud/learn/strong-ai.
[23] P. Raatikainen, “G¨odel’s incompleteness theorems,” https://plato.stanford.edu/entries/goedel-incompleteness/.",N/A,N/A
"[24] G. Hinton, “How to represent part-whole hierarchies in a neural network,” arXiv preprint arXiv:2102.12627, 2021.
[25] J. Pearl, “Radical empiricism and machine learning research,” Causal Analysis in Theory and Practice (Blog), vol. 26, 2020.
[26] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction.
MIT press, 2018.
[27] S. Gelly and D. Silver, “Monte-carlo tree search and rapid action value estimation in computer go,” Artiﬁcial Intelligence, vol. 175,",N/A,N/A
"no. 11, pp. 1856–1875, 2011.
[28] D. Silver, A. Huang, C. J. Maddison et al., “Mastering the game of go with deep neural networks and tree search,” Nature, vol. 529,
no. 7587, pp. 484–489, 2016.
[29] T. B. Brown, B. Mann, N. Ryder et al., “Language models are few-shot learners,” arXiv preprint arXiv:2005.14165, 2020.
[30] B. Liu, Y. Qi, and K. Chen, “Sequential online prediction in the presence of outliers and change points: an instant temporal structure",N/A,N/A
"learning approach,” Neurocomputing, vol. 413, pp. 240–258, 2020.
[31] Y. Qi, B. Liu, Y. Wang, and G. Pan, “Dynamic ensemble modeling approach to nonstationary neural decoding in brain-computer
interfaces,” Advances in neural information processing systems, pp. 6087–6096, 2019.
[32] B. Liu, “Robust particle ﬁlter by dynamic averaging of multiple noise models,” in IEEE Int’l Conf. on Acoustics, Speech and Signal
Processing (ICASSP).
IEEE, 2017, pp. 4034–4038.",N/A,N/A
"Processing (ICASSP).
IEEE, 2017, pp. 4034–4038.
[33] Y. Dai and B. Liu, “Robust video object tracking via bayesian model averaging-based feature fusion,” Optical Engineering, vol. 55,
no. 8, pp. 1–11, 2016.
[34] B. Liu, “Data-driven model set design for model averaged particle ﬁlter,” in IEEE Int’l Conf. on Acoustics, Speech and Signal Processing
(ICASSP).
IEEE, 2020, pp. 5835–5839.",N/A,N/A
"(ICASSP).
IEEE, 2020, pp. 5835–5839.
[35] ——, “Instantaneous frequency tracking under model uncertainty via dynamic model averaging and particle ﬁltering,” IEEE Trans. on
Wireless Communications, vol. 10, no. 6, pp. 1810–1819, 2011.
[36] F. Hutter, L. Kotthoff, and J. Vanschoren, Automated machine learning: methods, systems, challenges.
Springer Nature, 2019.
[37] B. Liu, “A very brief and critical discussion on automl,” arXiv preprint arXiv:1811.03822, 2018.",N/A,N/A
"[38] J. Licklider, “Man-computer symbiosis,” IRE Transactions on human factors in electronics, no. 1, pp. 4–11, 1960.",N/A,N/A
"A bibliometric view of AI Ethics development 
 
 
Di Kevin Gao 
Management Department -  
California State University, East 
Bay  
Hayward, CA, USA 
kevin.gao@csueastbay.edu 
 
  
Andrew Haverly 
Computer Science and 
Engineering Dept 
Mississippi State University 
Mississippi State, MS 39762 
arh876@msstate.edu 
 
 
Dr. Sudip Mittal  
Computer Science and 
Engineering Dept 
Mississippi State University 
Mississippi State, MS 39762 
mittal@cse.msstate.edu 
 
 
Dr. Jingdao Chen",N/A,N/A
"mittal@cse.msstate.edu 
 
 
Dr. Jingdao Chen 
Computer Science and 
Engineering Dept 
Mississippi State University 
Mississippi State, MS 39762 
chenjingdao@cse.msstate.edu
 
 
 
Abstract— Artificial Intelligence (AI) Ethics is a nascent yet 
critical research field. Recent developments in generative AI and 
foundational models necessitate a renewed look at the problem 
of AI Ethics. In this study, we perform a bibliometric analysis of",N/A,N/A
"AI Ethics literature for the last 20 years based on keyword 
search. Our study reveals a three-phase development in AI 
Ethics, namely an incubation phase, making AI human-like 
machines phase, and making AI human-centric machines phase. 
We conjecture that the next phase of AI ethics is likely to focus 
on making AI more machine-like as AI matches or surpasses 
humans intellectually, a term we coin as “machine-like human”.  
Keywords— artificial intelligence ethics, AI ethics, machine",N/A,N/A
"ethics, algorithm ethics, Roboethics, human-like machine, 
machine-like human  
I. INTRODUCTION 
Artificial Intelligence (AI) Ethics is the study of the 
ethical and responsible development and deployment of AI 
technology. Our bibliometric analysis of AI Ethics literature 
published between 2004 and 2023 points us to a three-phase 
development: 1. Incubation; 2. Making AI human-like 
machines; 3. Making AI human-centric machines.  
This article contributes to AI Ethics discussions with",N/A,N/A
"unique insights based on keyword usage patterns. It also 
contrasts “human-like machine”, “human-centric machine”, and 
“machine-like human”, which represent the past, current, and 
potential future phases of AI Ethics development. 
II. DEFINITIONS AND HISTORICAL DEVELOPMENT  
AI was first coined in 1955 at the Dartmouth Workshop [1]. 
John McCarthy, one of the key contributors at the conference 
and an AI pioneer, defined AI as ""the science and engineering",N/A,N/A
"of making intelligent machines, especially intelligent computer 
programs. It is related to the similar task of using computers to 
understand human intelligence, but AI does not have to confine 
itself to methods that are biologically observable"" [2].  
AI has gone through multiple cycles of boom and bust. 
It was a rising star from its inception to 1973. Scientists were 
excited by its potential to solve algebra word problems, prove",N/A,N/A
"geometry theorems, and even learn to speak. However, it failed 
to deliver on the hyped expectations. That led to the Lighthill 
Report in 1974, which triggered a massive loss of confidence in 
AI [3]. In the United States, the Defense Advanced Research 
Projects Agency (DARPA) also drastically reduced its AI 
funding. AI sank into an “AI Winter"" until 1980. The relief in 
the 80s turned out to be short-lived. In 1987, AI was again placed",N/A,N/A
"in a freezer. By the early 2000s, AI was haunted by over-
promises and under-delivery. In 2005, John Markoff in the New 
York Times described that some computer scientists avoided the 
term artificial intelligence altogether “for fear of being viewed 
as wild-eyed dreamers"" [4]. In 2007, Alex Castro referred to 
artificial intelligence as a subject that has “too often failed to live 
up to their promises"" [5]. That has resulted in “once something",N/A,N/A
"becomes useful enough and common enough it’s not labeled AI 
anymore"" [6]. In the 1990s and 2000s, new computer science 
disciplines flourished. However, they were deliberately not 
categorized under Artificial Intelligence, for example, 
informatics, machine learning, machine perception, analytics, 
predictive analytics, decision support systems, knowledge-
based systems, business rules management, cognitive systems, 
intelligent systems, language models, intelligent agents, or",N/A,N/A
"computational intelligence. 
AI regained its popularity with Google Translate, 
Google Image Search, and IBM Watson’s winning the 
Jeopardy game in 2011 [7]. 2012 marked a turning point for AI 
due to breakthroughs in deep learning and GPU technology. 
AlexNet used GPU to train its Convolutional Neural Network 
(CNN) model to recognize and label images automatically and 
won the ImageNet 2012 Challenge by a large margin[8] [9]. 
AI’s resurgence became insurmountable. AI broadened its",N/A,N/A
"scope to absorb many downstream research fields. It became 
an aggregator and a destination.  
In November 2022, Open AI released ChatGPT which 
attracted intense interest from the general public. It triggered an 
all-out war between the Big Techs and stiffened competition 
between rival countries. Ethical AI development and 
deployment have become more important than ever.  
 
III. METHODS 
 
We selected SCOPUS1 as the main data source and",N/A,N/A
"We selected SCOPUS1 as the main data source and 
VOSviewer2 as the data aggregator. In the SCOPUS database, 
we searched for “AI ethics"" OR “artificial intelligence ethics"" 
OR “machine ethics"" OR “algorithm ethics"" OR “information 
ethics"" OR ""ethics of technology"" OR “Robotic Ethics"" OR 
“Robot Ethics"" OR “artificial moral agent"" OR “artificial moral 
agents"" from 2004 to 2023, a period of 20 years, for all 
languages, all countries, and territories. In total, 2,517 articles",N/A,N/A
"were selected. After removing 60 entries due to missing info, a 
total of 2,457 pieces of literature were included in this analysis. 
For keyword analysis, we used 2004-2023 co-occurrence author 
keywords from VOSviewer. We used “Full counting"", which 
means each keyword is counted as one regardless of how many 
keywords were listed in the literature. We then exported the 
results for time series and pattern analysis.  
IV. AI ETHICS DEVELOPMENT  
A. AI ethics and related ethics usage analysis",N/A,N/A
"A. AI ethics and related ethics usage analysis 
We calculated the keyword usage frequencies for AI 
Ethics and other related ethical fields based on SCOPUS data. 
Other related ethical fields included information ethics, machine 
ethics, roboethics, technology ethics, computer ethics, data 
ethics, engineering ethics, digital ethics, and computational 
ethics. The data is summarized in Figure 1.  
""AI Ethics"" or ""Artificial Intelligence ethics"" first",N/A,N/A
"appeared in keywords in 2008, followed by five 5 years of 
hibernation. In 2014, AI Ethics reemerged and has since enjoyed 
exponential growth. In 2014, there was only one occurrence of 
the keyword “AI Ethics” in our literature research. However, by 
2022, the keyword frequency had increased to 148. In the 2023 
partial year till July 28, the usage has also reached 114. The 
keyword “AI Ethics” completely outnumbered the rest of the",N/A,N/A
"terms such as “roboethics”, “data ethics”, or “machine ethics”.  
This finding is important because in the historical 
development section of AI, we know that 2012 marked the 
turning point for AI as a research field. We believe 2014 is the 
year that AI Ethics was formed. Before that, AI Ethics was 
dispersed across information ethics, machine ethics, roboethics, 
technology ethics, and computer ethics. Thus, we define the pre-
2014 period as the incubation period.",N/A,N/A
"2014 period as the incubation period.   
 
B. Ethics principles usage pattern analysis 
We leveraged VOSviewer to unpack keyword usages 
that are related to AI Ethics. Figure 2 is generated from the 
VOSviewer based on data since 2004 by using co-occurrence 
data and author keywords. We used full counting instead of 
partial counting, which means each author keyword is counted 
as one regardless of how many keywords were used in the",N/A,N/A
"literature. The size of the circle indicates the keywords’ relative 
frequency. Color represents the closeness of the topics. 
We sorted this information chronologically and further 
bifurcated the keywords based on product orientation and their 
associations with AI Ethics principles. The information is 
presented in Figure 3. The top rectangles are product-oriented 
 
1 www.scopus.com 
features, the middle ovals illustrate when keywords started to be 
consistently used.",N/A,N/A
"consistently used. 
The results revealed a significant shift in AI Ethics 
research principles from 2020. Between 2014 and 2019, AI 
Ethics keywords focused on principles to make AI ethical 
humans, e.g., trust, empathy, justice, care, and fairness. From 
2020, however, the AI Ethics keywords were increasingly 
focused on protecting the downside risks and making AI 
explainable, accountable, trustworthy, non-biased, non-
discriminatory, less opaque, and for-diversity.",N/A,N/A
"discriminatory, less opaque, and for-diversity. 
Based on this observation, we grouped AI Ethics 
development into the following three phases: 
 
• 
Phase I: Incubation (2004 to 2013) 
• 
Phase II: Making AI human-like machines (2014 to 2019)  
• 
Phase III: Making AI human-centric machines (2020 and 
on) 
 
C. AI Ethics Development Phases 
In the following section, we will go through each 
phase and highlight the major developments. 
1) Phase I: Incubation (2004-2013)",N/A,N/A
"1) Phase I: Incubation (2004-2013)  
AI Ethics trailed AI’s rapid development. In 1997, 
IBM’s Deep Blue defeated the world chess champion Garry 
Kasparov [10]. In 2005, the Stanford autonomous vehicle, 
Stanley, successfully crossed 212 kilometers of terrain in the 
Mojave Desert [11]. In 2011, IBM’s Watson won the Jeopardy! 
that conventional wisdom believed only humans could master 
[12]. AI technology’s fast development galvanized many",N/A,N/A
"exciting research fronts and, in a way, “pushed” AI Ethics to 
the forefront. It became apparent that other ethics would not be 
sufficient to cover the wide spectrum of fields that AI covers. 
AI Ethics as a research field was born.  
The popular keyword in 2004 was “privacy"". Privacy 
was not a new discipline; neither was it exclusive to AI. It 
became a hot topic with the explosive growth of data collection 
and data usage in the Internet age. In the next few years, 
“autonomy"",",N/A,N/A
"“autonomy"", 
“reliability"", 
“safety"", 
“security"", 
and 
“sustainability"" surfaced. The majority of the keywords were 
product-oriented. 
2) Phase II: Make AI Human-like Machines (2014-2019)  
In Phase II, AI has increasingly demonstrated its 
potential to function like a human. AI Ethicists and the general 
public welcomed the development. AI Ethics’ focus was on the 
ethical application of AI, the mini-human, in different fields. 
For this reason, we labeled this phase “Make AI Human-like",N/A,N/A
"Machines"".  
During this phase, AI continued its breakneck 
advancement and pushed deep into new frontiers. In 2014, 
generative adversarial networks (GAN) were developed to 
synthesize new and creative images from existing ones. In 
2015, AI enabled machines to ""see"" and label images better than 
humans [13]. In 2016, Deep Mind’s AlphaGo defeated  
 
 
2 Vosviewer.com",N/A,N/A
"2 Vosviewer.com 
 
 
 
Fig 1: Usage of different ethics in literature key words. AI Ethics first appeared in 2008. It consistently appeared after 2014 and have taken off since 2020.  
 
 
  
  
Fig 2: AI Ethics and related fields based on bibliographical data in VOSviewer by using Scopus data from 2004 to July 28, 2023. 
2
1
2
2
19 16
57
99
148
114
0
20
40
60
80
100
120
140
160
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015
2016
2017
2018
2019
2020
2021
2022
2023",N/A,N/A
"2014
2015
2016
2017
2018
2019
2020
2021
2022
2023
Usage of different ethics in literature keywords 
(Since 2004. 2023 partial year till 7/28)
ai ethics
information ethics
machine ethics
roboethics
technology ethics
computer ethics
data ethics
engineering ethics
digital ethics
computational ethics
  
 
Fig 3: AI Ethics Development Phases Based on Keyword Analysis 
 
world Go champion Lee Sedol [14]. In 2018, AI beat human 
dermatologists in accurately detecting skin cancer [15]. In",N/A,N/A
"2018, Google Waymo’s Robotaxi started roaming in Phoenix’s 
streets [16]. The general public viewed the development 
positively and was excited by AI’s boundless applications.  
However, AI Ethics development lagged behind AI 
technology development. As mentioned in the historical 
background section, AI regained popularity and broadened its 
scope to include any computer science disciplines that enabled 
human-like intelligence in 2012. Machine learning, machine",N/A,N/A
"perception, text analysis, natural language processing (NLP), 
logical reasoning, game-playing, decision support systems, data 
analytics, and predictive analytics became AI’s upstream or 
supporting disciplines. Robotics (including autonomous 
vehicles) was a fast-developing field that was enabled by AI. 
AI became an aggregator.  
AI Ethics keywords during this phase reflected many 
human-like features, for example, “accountability"", “care"", 
“compassion"", 
“empathy"", 
“fairness"",",N/A,N/A
"“compassion"", 
“empathy"", 
“fairness"", 
“justice"", 
“transparency"", “trust"", and Explainable AI (XAI). The AI 
Ethics community wanted to make this intelligent technology 
accountable, caring, compassionate, empathetic, fair, unbiased, 
transparent, and trustworthy, just like an ethical human.  
3) Phase III: Make AI Human-centric Machines (2020- 
present)  
In Phase III, while continuing its rapid ascension, AI 
had shown aspects that were far from angelic. The AI Ethics",N/A,N/A
"community focused on grounding AI into an explainable, 
responsible, and trustworthy machine that serves humans 
instead of being a runaway alien technology. That was the 
reason we titled this phase ""Make AI Human-centric 
Machines"".  
By 2020, AI had surpassed humans in handwriting 
recognition, speech recognition, image recognition, read 
comprehension, and language understanding [17]. In the 
meantime, Deep Fakes exacerbated online misinformation and",N/A,N/A
"undermined basic human trust. In May 2021, the United States 
National Security Commission urged the US to win the AI arms 
race against China, reminiscing the costly and dangerous Cold 
War [18]. In July 2022, Google fired an engineer who claimed 
that its LaMDA language model was sentient, exacerbating the 
general public’s suspicion of AI [19]. In November 2022, Open 
AI released Chat GPT 3.0 to the public and triggered an all-out 
AI race. It looked increasingly like the AI companies were",N/A,N/A
"racing to the bottom to win but put safety and security on the 
backburner [20]. In 2023, ChatGPT became the second Large 
Language Model to pass the Turing Test [21] [22]. In 2023, 
Goldman Sachs estimated that 300 million jobs could be 
displacement by AI [23]. Scientists, entrepreneurs, and public 
officers started to alarm the general public about the 
consequences of unconstrained AI development. Public distrust 
of AI surged.  
During this phase, precautionary keywords showed up",N/A,N/A
"very frequently in the literature, such as “algorithm bias"", “AI 
bias"", “gender bias"", and “discrimination"" in 2020, and 
“opacity"", “responsibility gap"", and “social justice"" in 2021. 
Meanwhile, 
keywords 
such 
as 
“explainability"" 
and 
“trustworthy AI’ popped up in 2020. “Human-centric"", 
“responsible AI"" showed up in 2021, and “interpretability"" and 
“sustainable AI"" showed up in 2022. The AI ethics community 
wanted to make AI responsible, explainable, and trustworthy to",N/A,N/A
"humans. AI Ethics entered a phase to make AI ""human-centric"". 
D. The future of AI Ethics   
AI technology is disruptive in nature. AI Ethics is 
pivotal in the benign and benevolent rollout of AI technology. 
With the current development pace, it is almost inevitable that 
AI and robotics will match or surpass humans both physically 
and intellectually. AI can become near-human. AI ethicists may 
need to explore how to make these intelligent AI embodiments",N/A,N/A
"“machine-like humans”: machines that are intelligent and 
capable, but never achieve the same status as full humans. 
Another challenge is the confluence of AI, robotics, 
and biotechnology. Machine-augmented humans and machine-
augmented non-human (animals or newly created species) 
could blur the definition of humans. AI ethicists may need to 
study the ethical ramifications of this development and draw 
redlines on socially acceptable creations of alien beings.",N/A,N/A
"Superintelligence, a form of AI that is superior to 
human intelligence, can be a concern. Even if the risks are 
extremely low, if indeed it happens, the consequences could be 
incredibly serious. AI Ethicists may need to develop a 
framework to prevent Superintelligence from remotely 
happening. 
V. LIMITATION 
Our bibliometric analysis has a few limitations:  
1. We rely heavily on SCOPUS for data sources. Literature 
unlisted on SCOPUS would be excluded.",N/A,N/A
"unlisted on SCOPUS would be excluded. 
2. We relied heavily on VOSviewer to generate keyword co-
occurrence data. Errors in VOSviewer could be carried 
into our final analysis.  
3. Literature search was based on literature titles and 
keywords. That could result in the addition of unwanted 
papers. Some legitimate AI ethics articles might be 
excluded.   
4. The majority of literature included in this study was in 
English (97%). It is highly probable that some non-",N/A,N/A
"English literature was missed.  
Despite these caveats, we believe that our bibliometric analysis 
remains highly valuable to the scientific and engineering 
community since most AI and AI Ethics research is published 
in English-language journals and conferences that are indexed 
by Scopus. 
VI. CONCLUSION 
The bibliometric analysis of AI Ethics literature has 
pointed to a 3-phase AI Ethics development, namely incubation, 
making AI human-like machines, and making AI human-centric",N/A,N/A
"machines. AI ethicists may need to get ahead of the AI 
technology development and research on making AI machine-
like humans, prohibit unethical development of machine-
augmented non-humans, and prevent the development of 
malicious or malevolent Superintelligence.  
VII. ACKNOWLEDGEMENT 
The work reported herein was supported by the National 
Science Foundation (NSF) (Award #2246920). Any opinions, 
findings, and conclusions or recommendations expressed in",N/A,N/A
"this material are those of the authors and do not necessarily 
reflect the views of the NSF. 
 
 
[1] 
Dartmouth University, “Dartmouth workshop,” 1956. 
https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-
dartmouth 
[2] 
John McCarthy, “What is ai?,” 2023. http://jmc.stanford.edu/artificial-
intelligence/what-is-ai/index.html 
[3] 
James Lighthill, “Lighthill report: Artificial intelligence: a paper 
symposium,” Science Research Council, London, 1973. 
[4]",N/A,N/A
"[4] 
John Markoff, “Behind artificial intelligence, a squadron of bright real 
people,” 2005. New York Times. 
[5] 
Patty Tascarella, “Are you talking to me?” 2005. 
https://www.economist.com/technology-quarterly/2007/06/09/are-you-
talking-to-me 
[6] 
CNN, “Ai set to exceed human brain power,” 2006. CNN.com.  
[7] 
Mike Hale, “Actors and their roles for $300, hal? hal!” 
New York Times, 2011 
[8] 
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, “Imagenet",N/A,N/A
"classification with deep convolutional neural networks,” 
Communications of the ACM, vol. 60, 2017. 
[9] 
Dave Gershgorn, “The inside story of how ai got good 
enough to dominate Silicon Valley,” Quartz, 2018. 
[10] Bruce Weber, “Swift and slashing, computer topples 
kasparov,” 1997. https://www.nytimes.com/1997/05/12/nyregion/swift-
and-slashing-computer-topples-kasparov.html 
[11] Steve Russell, “Darpa grand challenge winner: Stanley the robot!” 
2006.",N/A,N/A
"2006. 
https://www.popularmechanics.com/technology/robots/a393/2169012/ 
[12] John Markoff, “Computer wins on ‘Jeopardy!’: Trivial, 
it’s not!,” 2011. 
https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html 
[13] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei, 
“Imagenet: A large-scale hierarchical image database,” in 2009 IEEE 
Conference on Computer Vision and Pattern Recognition, 2009, pp. 
248–255.",N/A,N/A
"248–255. 
[14] Adrian Cho, “‘Huge leap forward’: Computer that mimics human brain 
beats professional at game of go,” Science, 2016. 
[15] Alexa Lardieri, “Ai beats doctors at cancer diagnoses,” 
2018. https://www.usnews.com/news/health-care-news/articles/2018-05-
28/artificial-intelligence-beats-dermatologists-at-diagnosing-skin-cancer 
[16] Jon Fingas, “Waymo launches its first commercial self-driving car 
service,” 2019. 
https://en.wikipedia.org/wiki/Waymo#:~:text=In%20December%20201",N/A,N/A
"8%2C%20Waymo%20launched,and%20request%20a%20pick%2Dup 
[17] Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus 
Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet 
Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, 
Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, 
Christopher Potts, and Adina Williams, “Dynabench: Rethinking 
benchmarking in nlp,” 2021. 
[18] National Security Commission on Artificial Intelligence, “National",N/A,N/A
"security commission on Artificial Intelligence - final report,” 2021. 
https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-
1.pdf 
[19] Miles Kruppa, “Google parts with engineer who claimed its ai system is 
sentient,” 2022. https://www.wsj.com/articles/google-parts-with -
engineer-who-claimed-its-ai-system-is-sentient-
11658538296?ns=prod/accounts-wsj 
[20] Samantha Lock, “What is ai chatbot phenomenon chat-gpt and could it 
replace humans?,” 2022, Accessed: 2022-12-05.",N/A,N/A
"replace humans?,” 2022, Accessed: 2022-12-05. 
https://www.theguardian.com/technology/2022/dec/05/what-is-ai-
chatbot-phenomenon-chatgpt-and-could-it-replace-humans 
[21] Celeste Biever, “Chatgpt broke the Turing test - the race 
is on for new ways to assess ai,” 2023. Nature, vol. 619, 2023 
[22] Will Oremus, “Google’s ai passed a famous test — and showed how the 
test is broken,” 2022. The Washington Post.  
[23] Beatrice Nolan, “AI systems like chatgpt could impact 300 million full-",N/A,N/A
"time jobs worldwide, with administrative and legal roles 
some of the most at risk, goldman sachs report says,” 
https://www.businessinsider.com/generative-ai-chatpgt-300-million-full-
time-jobs-goldman-sachs-2023-3.",N/A,N/A
"lecture notes:
Optimization for Machine Learning
version 0.57
All rights reserved.
Elad Hazan 1
1www.cs.princeton.edu/~ehazan
arXiv:1909.03550v1  [cs.LG]  8 Sep 2019
ii
Preface
This text was written to accompany a series of lectures given at the Machine
Learning Summer School Buenos Aires, following a lecture series at the
Simons Center for Theoretical Computer Science, Berkeley. It was extended
for the course COS 598D - Optimization for Machine Learning, Princeton
University, Spring 2019.",N/A,N/A
"University, Spring 2019.
I am grateful to Paula Gradu for proofreading parts of this manuscript.
I’m also thankful for the help of the following students and colleagues for
corrections and suggestions to this text: Udaya Ghai, John Hallman, No´e
Pion, Xinyi Chen.
iii
iv
Preface
Figure 1:
Professor Arkadi Nemirovski, Pioneer of mathematical optimiza-
tion
Contents
Preface
iii
1
Introduction
3
1.1
Examples of optimization problems in machine learning
. . .
4
1.1.1
Empirical Risk Minimization",N/A,N/A
". . .
4
1.1.1
Empirical Risk Minimization
. . . . . . . . . . . . . .
4
1.1.2
Matrix completion and recommender systems . . . . .
6
1.1.3
Learning in Linear Dynamical Systems
. . . . . . . .
7
1.2
Why is mathematical programming hard? . . . . . . . . . . .
8
1.2.1
The computational model . . . . . . . . . . . . . . . .
8
1.2.2
Hardness of constrained mathematical programming .
9
2
Basic concepts in optimization and analysis
11
2.1
Basic deﬁnitions and the notion of convexity . . . . . . . . . .",N/A,N/A
"11
2.1.1
Projections onto convex sets . . . . . . . . . . . . . . .
13
2.1.2
Introduction to optimality conditions . . . . . . . . . .
14
2.1.3
Solution concepts for non-convex optimization
. . . .
15
2.2
Potentials for distance to optimality
. . . . . . . . . . . . . .
16
2.3
Gradient descent and the Polyak stepsize
. . . . . . . . . . .
18
2.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.5
Bibliographic remarks
. . . . . . . . . . . . . . . . . . . . . .
23
3",N/A,N/A
". . . . . . . . . . . . . . . . . . . . . .
23
3
Stochastic Gradient Descent
25
3.1
Training feedforward neural networks
. . . . . . . . . . . . .
25
3.2
Gradient descent for smooth optimization . . . . . . . . . . .
27
3.3
Stochastic gradient descent
. . . . . . . . . . . . . . . . . . .
29
3.4
Bibliographic remarks
. . . . . . . . . . . . . . . . . . . . . .
31
4
Generalization and Non-Smooth Optimization
33
4.1
A note on non-smooth optimization
. . . . . . . . . . . . . .
34
4.2",N/A,N/A
". . . . . . . . . . . . . .
34
4.2
Minimizing Regret . . . . . . . . . . . . . . . . . . . . . . . .
35
v
vi
CONTENTS
4.3
Regret implies generalization
. . . . . . . . . . . . . . . . . .
35
4.4
Online gradient descent
. . . . . . . . . . . . . . . . . . . . .
36
4.5
Lower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
4.6
Online gradient descent for strongly convex functions . . . . .
39
4.7
Online Gradient Descent implies SGD . . . . . . . . . . . . .
41
4.8
Exercises",N/A,N/A
"41
4.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
4.9
Bibliographic remarks
. . . . . . . . . . . . . . . . . . . . . .
45
5
Regularization
47
5.1
Motivation: prediction from expert advice . . . . . . . . . . .
47
5.1.1
The weighted majority algorithm . . . . . . . . . . . .
49
5.1.2
Randomized weighted majority . . . . . . . . . . . . .
51
5.1.3
Hedge . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
5.2
The Regularization framework",N/A,N/A
"52
5.2
The Regularization framework
. . . . . . . . . . . . . . . . .
53
5.2.1
The RFTL algorithm
. . . . . . . . . . . . . . . . . .
54
5.2.2
Mirrored Descent . . . . . . . . . . . . . . . . . . . . .
55
5.2.3
Deriving online gradient descent
. . . . . . . . . . . .
56
5.2.4
Deriving multiplicative updates . . . . . . . . . . . . .
57
5.3
Technical background: regularization functions . . . . . . . .
57
5.4
Regret bounds for Mirrored Descent
. . . . . . . . . . . . . .
59
5.5
Exercises",N/A,N/A
". . . . . . . . . . . . . .
59
5.5
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
5.6
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . .
63
6
Adaptive Regularization
65
6.1
Adaptive Learning Rates: Intuition . . . . . . . . . . . . . . .
65
6.2
A Regularization Viewpoint
. . . . . . . . . . . . . . . . . .
66
6.3
Tools from Matrix Calculus . . . . . . . . . . . . . . . . . . .
66
6.4
The AdaGrad Algorithm and Its Analysis . . . . . . . . . . .
67
6.5",N/A,N/A
"67
6.5
Diagonal AdaGrad . . . . . . . . . . . . . . . . . . . . . . . .
71
6.6
State-of-the-art: from Adam to Shampoo and beyond
. . . .
72
6.7
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
6.8
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . .
74
7
Variance Reduction
75
7.1
Variance reduction: Intuition . . . . . . . . . . . . . . . . . .
75
7.2
Setting and deﬁnitions . . . . . . . . . . . . . . . . . . . . . .
76
7.3",N/A,N/A
"76
7.3
The variance reduction advantage . . . . . . . . . . . . . . . .
77
7.4
A simple variance-reduced algorithm . . . . . . . . . . . . . .
78
7.5
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . .
80
CONTENTS
vii
8
Nesterov Acceleration
81
8.1
Algorithm and implementation . . . . . . . . . . . . . . . . .
81
8.2
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
8.3
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . .
84
9",N/A,N/A
"84
9
The conditional gradient method
85
9.1
Review: relevant concepts from linear algebra . . . . . . . . .
85
9.2
Motivation: matrix completion and recommendation systems
86
9.3
The Frank-Wolfe method
. . . . . . . . . . . . . . . . . . . .
88
9.4
Projections vs. linear optimization . . . . . . . . . . . . . . .
90
9.5
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
9.6
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . .
94",N/A,N/A
"94
10 Second order methods for machine learning
95
10.1 Motivating example: linear regression
. . . . . . . . . . . . .
95
10.2 Self-Concordant Functions . . . . . . . . . . . . . . . . . . . .
96
10.3 Newton’s method for self-concordant functions
. . . . . . . .
97
10.4 Linear-time second-order methods
. . . . . . . . . . . . . . . 100
10.4.1 Estimators for the Hessian Inverse . . . . . . . . . . . 100
10.4.2 Incorporating the estimator . . . . . . . . . . . . . . . 101
10.5 Exercises",N/A,N/A
"10.5 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
10.6 Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . . 104
11 Hyperparameter Optimization
105
11.1 Formalizing the problem . . . . . . . . . . . . . . . . . . . . . 105
11.2 Hyperparameter optimization algorithms . . . . . . . . . . . . 106
11.3 A Spectral Method . . . . . . . . . . . . . . . . . . . . . . . . 107
11.3.1 Background: Compressed Sensing
. . . . . . . . . . . 108",N/A,N/A
". . . . . . . . . . . 108
11.3.2 The Spectral Algorithm . . . . . . . . . . . . . . . . . 110
11.4 Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . . 111
viii
CONTENTS
Notation
We use the following mathematical notation in this writeup:
• d-dimensional Euclidean space is denoted Rd.
• Vectors are denoted by boldface lower-case letters such as x ∈Rd. Co-
ordinates of vectors are denoted by underscore notation xi or regular
brackets x(i).",N/A,N/A
"brackets x(i).
• Matrices are denoted by boldface upper-case letters such as X ∈Rm×n.
Their coordinates by X(i, j), or Xij.
• Functions are denoted by lower case letters f : Rd 7→R.
• The k-th diﬀerential of function f is denoted by ∇kf ∈Rdk.
The
gradient is denoted without the superscript, as ∇f.
• We use the mathcal macro for sets, such as K ⊆Rd.
• We denote the gradient at point xt as ∇xt, or simply ∇t.
• We denote the global or local optima of functions by x⋆.",N/A,N/A
"• We denote distance to optimality for iterative algorithms by ht =
f(xt) −f(x⋆).
• Euclidean distance to optimality is denoted dt = ∥xt −x⋆∥.
1
2
CONTENTS
Chapter 1
Introduction
The topic of this lecture series is the mathematical optimization approach
to machine learning.
In standard algorithmic theory, the burden of designing an eﬃcient al-
gorithm for solving a problem at hand is on the algorithm designer. In the
decades since in the introduction of computer science, elegant algorithms",N/A,N/A
"have been designed for tasks ranging from ﬁnding the shortest path in a
graph, computing the optimal ﬂow in a network, compressing a computer
ﬁle containing an image captured by digital camera, and replacing a string
in a text document.
The design approach, while useful to many tasks, falls short of more
complicated problems, such as identifying a particular person in an image
in bitmap format, or translating text from English to Hebrew. There may",N/A,N/A
"very well be an elegant algorithm for the above tasks, but the algorithmic
design scheme does not scale.
As Turing promotes in his paper [83], it is potentially easier to teach a
computer to learn how to solve a task, rather than teaching it the solution
for the particular tasks. In eﬀect, that’s what we do at school, or in this
lecture series...
The machine learning approach to solving problems is to have an au-
tomated mechanism for learning an algorithm.
Consider the problem of",N/A,N/A
"Consider the problem of
classifying images into two categories: those containing cars and those con-
taining chairs (assuming there are only two types of images in the world).
In ML we train (teach) a machine to achieve the desired functionality. The
same machine can potentially solve any algorithmic task, and diﬀers from
task to task only by a set of parameters that determine the functionality of
the machine. This is much like the wires in a computer chip determine its
3
4",N/A,N/A
"3
4
CHAPTER 1. INTRODUCTION
functionality. Indeed, one of the most popular machines are artiﬁcial neural
networks.
The mathematical optimization approach to machine learning is to view
the process of machine training as an optimization problem. If we let w ∈Rd
be the parameters of our machine (a.k.a. model), that are constrained to
be in some set K ⊆Rd, and f the function measuring success in mapping
examples to their correct label, then the problem we are interested in is",N/A,N/A
"described by the mathematical optimization problem of
min
w∈K f(w)
(1.1)
This is the problem that the lecture series focuses on, with particular em-
phasis on functions that arise in machine learning and have special structure
that allows for eﬃcient algorithms.
1.1
Examples of optimization problems in machine
learning
1.1.1
Empirical Risk Minimization
Machine learning problems exhibit special structure. For example, one of",N/A,N/A
"the most basic optimization problems in supervised learning is that of ﬁtting
a model to data, or examples, also known as the optimization problem of
Empirical Risk Minimization (ERM). The special structure of the problems
arising in such formulations is separability across diﬀerent examples into
individual losses.
An example of such formulation is the supervised learning paradigm of
linear classiﬁcation. In this model, the learner is presented with positive and",N/A,N/A
"negative examples of a concept. Each example, denoted by ai, is represented
in Euclidean space by a d dimensional feature vector. For example, a com-
mon representation for emails in the spam-classiﬁcation problem are binary
vectors in Euclidean space, where the dimension of the space is the number of
words in the language. The i’th email is a vector ai whose entries are given
as ones for coordinates corresponding to words that appear in the email,",N/A,N/A
"and zero otherwise1. In addition, each example has a label bi ∈{−1, +1},
corresponding to whether the email has been labeled spam/not spam. The
1Such a representation may seem na¨ıve at ﬁrst as it completely ignores the words’ order
of appearance and their context. Extensions to capture these features are indeed studied
in the Natural Language Processing literature.
1.1. EXAMPLES OF OPTIMIZATION PROBLEMS IN MACHINE LEARNING5",N/A,N/A
"goal is to ﬁnd a hyperplane separating the two classes of vectors: those with
positive labels and those with negative labels. If such a hyperplane, which
completely separates the training set according to the labels, does not ex-
ist, then the goal is to ﬁnd a hyperplane that achieves a separation of the
training set with the smallest number of mistakes.
Mathematically speaking, given a set of m examples to train on, we seek",N/A,N/A
"x ∈Rd that minimizes the number of incorrectly classiﬁed examples, i.e.
min
x∈Rd
1
m
X
i∈[m]
δ(sign(x⊤ai) ̸= bi)
(1.2)
where sign(x) ∈{−1, +1} is the sign function, and δ(z) ∈{0, 1} is the
indicator function that takes the value 1 if the condition z is satisﬁed and
zero otherwise.
The mathematical formulation of the linear classiﬁcation above is a spe-
cial case of mathematical programming (1.1), in which
f(x) = 1
m
X
i∈[m]
δ(sign(x⊤ai) ̸= bi) =
E
i∼[m][ℓi(x)],",N/A,N/A
"m
X
i∈[m]
δ(sign(x⊤ai) ̸= bi) =
E
i∼[m][ℓi(x)],
where we make use of the expectation operator for simplicity, and denote
ℓi(x) = δ(sign(x⊤ai) ̸= bi) for brevity. Since the program above is non-
convex and non-smooth, it is common to take a convex relaxation and replace
ℓi with convex loss functions. Typical choices include the means square error
function and the hinge loss, given by
ℓai,bi(x) = max{0, 1 −bi · x⊤ai}.
This latter loss function in the context of binary classiﬁcation gives rise",N/A,N/A
"to the popular soft-margin SVM problem.
Another important optimization problem is that of training a deep neural
network for binary classiﬁcation. For example, consider a dataset of images,
represented in bitmap format and denoted by {ai ∈Rd|i ∈[m]}, i.e. m
images over n pixels. We would like to ﬁnd a mapping from images to the
two categories, {bi ∈{0, 1}} of cars and chairs. The mapping is given by a
set of parameters of a machine class, such as weights in a neural network,",N/A,N/A
"or values of a support vector machine.
We thus try to ﬁnd the optimal
parameters that match ai to b, i..e
min
w∈Rd f(w) = E
ai,bi [ℓ(fw(ai), bi)] .
6
CHAPTER 1. INTRODUCTION
1.1.2
Matrix completion and recommender systems
Media recommendations have changed signiﬁcantly with the advent of the
Internet and rise of online media stores. The large amounts of data collected
allow for eﬃcient clustering and accurate prediction of users’ preferences
for a variety of media.",N/A,N/A
"for a variety of media.
A well-known example is the so called “Netﬂix
challenge”—a competition of automated tools for recommendation from a
large dataset of users’ motion picture preferences.
One of the most successful approaches for automated recommendation
systems, as proven in the Netﬂix competition, is matrix completion. Perhaps
the simplest version of the problem can be described as follows.
The entire dataset of user-media preference pairs is thought of as a",N/A,N/A
"partially-observed matrix. Thus, every person is represented by a row in
the matrix, and every column represents a media item (movie). For sim-
plicity, let us think of the observations as binary—a person either likes or
dislikes a particular movie. Thus, we have a matrix M ∈{0, 1, ∗}n×m where
n is the number of persons considered, m is the number of movies at our
library, and 0/1 and ∗signify “dislike”, “like” and “unknown” respectively:
Mij =











0,
person i dislikes movie j",N/A,N/A
"









0,
person i dislikes movie j
1,
person i likes movie j
∗,
preference unknown
.
The natural goal is to complete the matrix, i.e. correctly assign 0 or 1 to
the unknown entries. As deﬁned so far, the problem is ill-posed, since any
completion would be equally good (or bad), and no restrictions have been
placed on the completions.
The common restriction on completions is that the “true” matrix has
low rank. Recall that if a matrix X ∈Rn×m has rank k ≤ρ = min{n, m}",N/A,N/A
"then it can be written as
X = UV , U ∈Rn×k, V ∈Rk×m.
The intuitive interpretation of this property is that each entry in M
can be explained by only k numbers.
In matrix completion this means,
intuitively, that there are only k factors that determine a persons preference
over movies, such as genre, director, actors and so on.
Now the simplistic matrix completion problem can be well-formulated
as in the following mathematical program. Denote by ∥· ∥OB the Euclidean",N/A,N/A
"1.1. EXAMPLES OF OPTIMIZATION PROBLEMS IN MACHINE LEARNING7
norm only on the observed (non starred) entries of M, i.e.,
∥X∥2
OB =
X
Mij̸=∗
X2
ij.
The mathematical program for matrix completion is given by
min
X∈Rn×m
1
2∥X −M∥2
OB
s.t.
rank(X) ≤k.
1.1.3
Learning in Linear Dynamical Systems
Many learning problems require memory, or the notion of state. This is
captured by the paradigm of reinforcement learning, as well of the special
case of control in Linear Dynamical Systems (LDS).",N/A,N/A
"LDS model a variety of control and robotics problems in continuous
variables. The setting is that of a time series, with following parameters:
1. Inputs to the system, also called controls, denoted by u1, ..., uT ∈Rn.
2. Outputs from the system, also called observations, denoted y1, ..., yT ∈
Rm.
3. The state of the system, which may either be observed or hidden,
denoted xt, ..., xT ∈Rd.
4. The system parameters, which are transformations matrices A, B, C, D
in appropriate dimensions.",N/A,N/A
"in appropriate dimensions.
In the online learning problem of LDS, the learner iteratively observes
ut, yt, and has to predict ˆyt+1. The actual yt is generated according to the
following dynamical equations:
xt+1 = Axt + But + εt
yt+1 = Cxt+1 + Dut + ζt,
where εt, ζt are noise which is distributed as a Normal random variable.
Consider an online sequence in which the states are visible. At time t,
all system states, inputs and outputs are visible up to this time step. The",N/A,N/A
"learner has to predict yt+1, and only afterwards observes ut+1.xt+1, yt+1.
8
CHAPTER 1. INTRODUCTION
One reasonable way to predict yt+1 based upon past observations is to
compute the system, and use the computed transformations to predict. This
amounts to solving the following mathematical program:
min
A,B, ˆC, ˆD
(X
τ<t
(xτ+1 −Axτ + Buτ)2 + (yτ+1 −ˆCxτ + ˆDuτ)2
)
,
and then predicting ˆyt+1 = ˆC ˆA(xt + But) + ˆDut.
1.2
Why is mathematical programming hard?",N/A,N/A
"1.2
Why is mathematical programming hard?
The general formulation (1.1) is NP hard. To be more precise, we have to
deﬁne the computational model we are working in as well as and the access
model to the function.
Before we give a formal proof, the intuition to what makes mathematical
optimization hard is simple to state. In one line: it is the fact that global
optimality cannot be veriﬁed on the basis of local properties.
Most, if not all, eﬃcient optimization algorithms are iterative and based",N/A,N/A
"on a local improvement step. By this nature, any optimization algorithm
will terminate when the local improvement is no longer possible, giving rise
to a proposed solution. However, the quality of this proposed solution may
diﬀer signiﬁcantly, in general, from that of the global optimum.
This intuition explains the need for a property of objectives for which
global optimality is locally veriﬁable.
Indeed, this is exactly the notion",N/A,N/A
"Indeed, this is exactly the notion
of convexity, and the reasoning above explains its utmost importance in
mathematical optimization.
We now to prove that mathematical programming is NP-hard.
This
requires discussion of the computational model as well as access model to
the input.
1.2.1
The computational model
The computational model we shall adopt throughout this manuscript is that
of a RAM machine equipped with oracle access to the objective function",N/A,N/A
"f : Rd 7→R and constraints set K ⊆Rd. The oracle model for the objective
function can be one of the following, depending on the speciﬁc scenario:
1. Value oracle:
given a point x ∈Rd, oracle returns f(x) ∈R.
2. Gradient (ﬁrst-order) oracle:
given a point x ∈Rd, oracle returns
the gradient ∇f(x) ∈Rd.
1.2. WHY IS MATHEMATICAL PROGRAMMING HARD?
9
3. k-th order diﬀerential oracle:
given a point x ∈Rd, oracle returns
the tensor ∇kf(x) ∈Rdk.",N/A,N/A
"the tensor ∇kf(x) ∈Rdk.
The oracle model for the constraints set is a bit more subtle. We distin-
guish between the following oracles:
1. Membership oracle:
given a point x ∈Rd, oracle returns one if
x ∈K and zero otherwise.
2. Separating hyperplane oracle:
given a point x ∈Rd, oracle either
returns ”Yes” if x ∈K, or otherwise returns a hyperplane h ∈Rd such
that h⊤x > 0 and ∀y ∈K , h⊤y ≤0.
3. Explicit sets:
the most common scenario in machine learning is one",N/A,N/A
"in which K is “natural”, such as the Euclidean ball or hypercube, or
the entire Euclidean space.
1.2.2
Hardness of constrained mathematical programming
Under this computational model, we can show:
Lemma 1.1. Mathematical programming is NP-hard, even for a convex
continuous constraint set K and quadratic objective functions.
Informal sketch. Consider the MAX-CUT problem:
given a graph G =
(V, E), ﬁnd a subset of the vertices that maximizes the number of edges",N/A,N/A
"cut. Let A be the negative adjacency matrix of the graph, i.e.
Aij =



−1,
(i, j) ∈E
0,
o/w
Also suppose that Aii = 0.
Next, consider the mathematical program:
min

fA(x) = 1
4(x⊤Ax −2|E|)

(1.3)
∥x∥∞= 1 .
Consider the cut deﬁned by the solution of this program, namely
Sx = {i ∈V |xi = 1},
for x = x⋆. Let C(S) denote the size of the cut speciﬁed by the subset of
edges S ⊆E. Observe that the expression 1
2x⊤Ax, is exactly equal to the
10
CHAPTER 1. INTRODUCTION",N/A,N/A
"10
CHAPTER 1. INTRODUCTION
number of edges that are cut by Sx minus the number of edges that are
uncut. Thus, we have
1
2xAx = C(Sx) −(E −C(Sx)) = 2C(Sx) −E,
and hence f(x) = C(Sx). Therefore, maximizing f(x) is equivalent to the
MAX-CUT problem, and is thus NP-hard. We proceed to make the con-
straint set convex and continuous. Consider the mathematical program
min {fA(x)}
(1.4)
∥x∥∞≤1 .
This is very similar to the previous program, but we relaxed the equality",N/A,N/A
"to be an inequality, consequently the constraint set is now the hypercube.
We now claim that the solution is w.l.o.g. a vertex. To see that, consider
y(x) ∈{±1}d a rounding of x to the corners deﬁned by:
yi = y(x)i =



1,
w.p.1+xi
2
−1,
w.p.1−xi
2
Notice that
E[y] = x , ∀i ̸= j . E[yiyj] = xixj,
and therefore E[y(x)⊤Ay(x)] = x⊤Ax. We conclude that the optimum of
mathematical program 1.4 is the same as that for 1.3, and both are NP-
hard.
Chapter 2
Basic concepts in
optimization and analysis",N/A,N/A
"Basic concepts in
optimization and analysis
2.1
Basic deﬁnitions and the notion of convexity
We consider minimization of a continuous function over a convex subset of
Euclidean space. We mostly consider objective functions that are convex. In
later chapters we relax this requirement and consider non-convex functions
as well.
Henceforth, let K ⊆Rd be a bounded convex and compact set in Eu-
clidean space. We denote by D an upper bound on the diameter of K:
∀x, y ∈K, ∥x −y∥≤D.",N/A,N/A
"∀x, y ∈K, ∥x −y∥≤D.
A set K is convex if for any x, y ∈K, all the points on the line segment
connecting x and y also belong to K, i.e.,
∀α ∈[0, 1], αx + (1 −α)y ∈K.
A function f : K 7→R is convex if for any x, y ∈K
∀α ∈[0, 1], f(αx + (1 −α)y) ≤αf(x) + (1 −α)f(y).
Gradients and subgradients.
The set of all subgradients of a function
f at x, denoted ∂f(x), is the set of all vectors u such that
f(y) ≥f(x) + u⊤(y −x).
It can be shown that the set of subgradients of a convex function is always",N/A,N/A
"non-empty.
11
12
CHAPTER 2. BASIC CONCEPTS
Suppose f is diﬀerentiable, let ∇f(x)[i] =
∂
∂xi f(x) be the vector of
partial derivatives according to the variables, called the gradient.
If the
gradient ∇f(x) exists, then ∇f(x) ∈∂f(x) and ∀y ∈K
f(y) ≥f(x) + ∇f(x)⊤(y −x).
Henceforth we shall denote by ∇f(x) the gradient, if it exists, or any member
of ∂f(x) otherwise.
We denote by G > 0 an upper bound on the norm of the subgradients of",N/A,N/A
"f over K, i.e., ∥∇f(x)∥≤G for all x ∈K. The existence of Such an upper
bound implies that the function f is Lipschitz continuous with parameter
G, that is, for all x, y ∈K
|f(x) −f(y)| ≤G∥x −y∥.
Smoothness and strong convexity.
The optimization and machine learn-
ing literature studies special types of convex functions that admit useful
properties, which in turn allow for more eﬃcient optimization. Notably, we
say that a function is α-strongly convex if
f(y) ≥f(x) + ∇f(x)⊤(y −x) + α
2 ∥y −x∥2.",N/A,N/A
"f(y) ≥f(x) + ∇f(x)⊤(y −x) + α
2 ∥y −x∥2.
A function is β-smooth if
f(y) ≤f(x) + ∇f(x)⊤(y −x) + β
2 ∥y −x∥2.
The latter condition is implied by a slightly stronger Lipschitz condition
over the gradients, which is sometimes used to deﬁned smoothness, i.e.,
∥∇f(x) −∇f(y)∥≤β∥x −y∥.
If the function is twice diﬀerentiable and admits a second derivative,
known as a Hessian for a function of several variables, the above conditions",N/A,N/A
"are equivalent to the following condition on the Hessian, denoted ∇2f(x):
Smoothness:
−βI ≼∇2f(x) ≼βI
Strong-convexity:
αI ≼∇2f(x),
where A ≼B if the matrix B −A is positive semideﬁnite.
When the function f is both α-strongly convex and β-smooth, we say
that it is γ-well-conditioned where γ is the ratio between strong convexity
and smoothness, also called the condition number of f
γ = α
β ≤1
2.1. BASICS
13
2.1.1
Projections onto convex sets",N/A,N/A
"2.1. BASICS
13
2.1.1
Projections onto convex sets
In the following algorithms we shall make use of a projection operation onto
a convex set, which is deﬁned as the closest point inside the convex set to a
given point. Formally,
Π
K(y) ≜arg min
x∈K
∥x −y∥.
When clear from the context, we shall remove the K subscript. It is left as
an exercise to the reader to prove that the projection of a given point over
a closed non-empty convex set exists and is unique.",N/A,N/A
"The computational complexity of projections is a subtle issue that de-
pends much on the characterization of K itself. Most generally, K can be
represented by a membership oracle—an eﬃcient procedure that is capable
of deciding whether a given x belongs to K or not. In this case, projections
can be computed in polynomial time. In certain special cases, projections
can be computed very eﬃciently in near-linear time.
A crucial property of projections that we shall make extensive use of is",N/A,N/A
"the Pythagorean theorem, which we state here for completeness:
Figure 2.1: Pythagorean theorem.
Theorem 2.1 (Pythagoras, circa 500 BC). Let K ⊆Rd be a convex set,
y ∈Rd and x = ΠK(y). Then for any z ∈K we have
∥y −z∥≥∥x −z∥.
14
CHAPTER 2. BASIC CONCEPTS
We note that there exists a more general version of the Pythagorean
theorem. The above theorem and the deﬁnition of projections are true and
valid not only for Euclidean norms, but for projections according to other",N/A,N/A
"distances that are not norms. In particular, an analogue of the Pythagorean
theorem remains valid with respect to Bregman divergences.
2.1.2
Introduction to optimality conditions
The standard curriculum of high school mathematics contains the basic facts
concerning when a function (usually in one dimension) attains a local opti-
mum or saddle point. The KKT (Karush-Kuhn-Tucker) conditions general-
ize these facts to more than one dimension, and the reader is referred to the",N/A,N/A
"bibliographic material at the end of this chapter for an in-depth rigorous
discussion of optimality conditions in general mathematical programming.
For our purposes, we describe only brieﬂy and intuitively the main facts
that we will require henceforth. We separate the discussion into convex and
non-convex programming.
Optimality for convex optimization
A local minimum of a convex function is also a global minimum (see exercises",N/A,N/A
"at the end of this chapter). We say that x⋆is an ε-approximate optimum if
the following holds:
∀x ∈K . f(x⋆) ≤f(x) + ε.
The generalization of the fact that a minimum of a convex diﬀerentiable
function on R is a point in which its derivative is equal to zero, is given by
the multi-dimensional analogue that its gradient is zero:
∇f(x) = 0
⇐⇒
x ∈arg min
x∈Rn
f(x).
We will require a slightly more general, but equally intuitive, fact for con-",N/A,N/A
"strained optimization: at a minimum point of a constrained convex function,
the inner product between the negative gradient and direction towards the
interior of K is non-positive. This is depicted in Figure 2.2, which shows that
−∇f(x⋆) deﬁnes a supporting hyperplane to K. The intuition is that if the
inner product were positive, one could improve the objective by moving in
the direction of the projected negative gradient. This fact is stated formally
in the following theorem.
2.1. BASICS
15",N/A,N/A
"in the following theorem.
2.1. BASICS
15
Theorem 2.2 (Karush-Kuhn-Tucker). Let K ⊆Rd be a convex set, x⋆∈
arg minx∈K f(x). Then for any y ∈K we have
∇f(x⋆)⊤(y −x⋆) ≥0.
Figure 2.2: Optimality conditions: negative (sub)gradient pointing out-
wards.
2.1.3
Solution concepts for non-convex optimization
We have seen in the previous chapter that mathematical optimization is NP-
hard. This implies that ﬁnding global solutions for non-convex optimization",N/A,N/A
"is NP-hard, even for smooth functions over very simple convex domains. We
thus consider other trackable concepts of solutions.
The most common solution concept is that of ﬁrst-order optimality, a.k.a.
saddle-points or stationary points. These are points that satisfy
∥∇f(x⋆)∥= 0.
Unfortunately, even ﬁnding such stationary points is NP-hard.
We thus
settle for approximate stationary points, which satisify
∥∇f(x⋆)∥≤ε.
16
CHAPTER 2. BASIC CONCEPTS
Figure 2.3: First and second-order local optima.",N/A,N/A
"Figure 2.3: First and second-order local optima.
A more stringent notion of optimality we may consider is obtained by
looking at the second derivatives. We can require they behave as for global
minimum, see ﬁgure 2.3. Formally, we say that a point x⋆is a second-order
local minimum if it satisﬁes the two conditions:
∥∇f(x⋆)∥≤ε , ∇2f(x⋆) ⪰−√εI.
The diﬀerences in approximation criteria for ﬁrst and second derivatives is
natural, as we shall explore in non-convex approximation algorithms hence-",N/A,N/A
"forth.
We note that it is possible to further deﬁne optimality conditions for
higher order derivatives, although this is less useful in the context of machine
learning.
2.2
Potentials for distance to optimality
When analyzing convergence of gradient methods, it is useful to use potential
functions in lieu of function distance to optimality, such as gradient norm
and/or Euclidean distance to optimality. The following relationships hold
between these quantities.",N/A,N/A
"between these quantities.
Lemma 2.3. The following properties hold for α-strongly-convex functions
and/or β-smooth functions over Euclidean space Rd.
1.
α
2 d2
t ≤ht
2. ht ≤β
2 d2
t
2.2. POTENTIALS FOR DISTANCE TO OPTIMALITY
17
3.
1
2β∥∇t∥2 ≤ht
4. ht ≤
1
2α∥∇t∥2
Proof.
1. ht ≥α
2 d2
t :
By strong convexity, we have
ht
= f(xt) −f(x⋆)
≥∇f(x⋆)⊤(xt −x⋆) + α
2 ∥xt −x⋆∥2
= α
2 ∥xt −x⋆∥2
where the last inequality follows since the gradient at the global opti-
mum is zero.
2. ht ≤β
2 d2
t :",N/A,N/A
"mum is zero.
2. ht ≤β
2 d2
t :
By smoothness,
ht
= f(xt) −f(x⋆)
≤∇f(x⋆)⊤(xt −x⋆) + β
2 ∥xt −x⋆∥2
= β
2 ∥xt −x⋆∥2
where the last inequality follows since the gradient at the global opti-
mum is zero.
3. ht ≥
1
2β∥∇t∥2: Using smoothness, and let xt+1 = xt −η∇t for η = 1
β,
ht =
f(xt) −f(x⋆)
≥f(xt) −f(xt+1)
≥∇f(xt)⊤(xt −xt+1) −β
2 ∥xt −xt+1∥2
= η∥∇t∥2 −β
2 η2∥∇t∥2
=
1
2β∥∇t∥2.
4. ht ≤
1
2α∥∇t∥2:
We have for any pair x, y ∈Rd:
f(y) ≥f(x) + ∇f(x)⊤(y −x) + α
2 ∥x −y∥2
≥min
z∈Rd
n",N/A,N/A
"2 ∥x −y∥2
≥min
z∈Rd
n
f(x) + ∇f(x)⊤(z −x) + α
2 ∥x −z∥2o
= f(x) −1
2α∥∇f(x)∥2.
by taking z = x −1
α∇f(x)
18
CHAPTER 2. BASIC CONCEPTS
In particular, taking x = xt , y = x⋆, we get
ht = f(xt) −f(x⋆) ≤1
2α∥∇t∥2.
(2.1)
2.3
Gradient descent and the Polyak stepsize
The simplest iterative optimization algorithm is gradient descent, as given
in Algorithm 1. We analyze GD with the Polyak stepsize, which has the
advantage of not depending on the strong convexity and/or smoothness",N/A,N/A
"parameters of the objective function.
Algorithm 1 GD with the Polyak stepsize
1: Input: time horizon T, x0
2: for t = 0, . . . , T −1 do
3:
Set ηt =
ht
∥∇t∥2
4:
xt+1 = xt −ηt∇t
5: end for
6: Return ¯x = arg minxt{f(xt)}
To prove convergence bounds, assume ∥∇t∥≤G, and deﬁne:
BT
=
min
(
Gd0
√
T
, 2βd2
0
T
, 3G2
αT , βd2
0

1 −α
4β
T )
Theorem 2.4. (GD with the Polyak Step Size) Algorithm 1 attains the
following regret bound after T steps:
h(¯x)
=
min
0≤t≤T{ht} ≤BT",N/A,N/A
"h(¯x)
=
min
0≤t≤T{ht} ≤BT
Theorem 2.4 directly follows from the following lemma. Let 0 ≤γ ≤1,
deﬁne RT,γ as follows:
RT,γ = min
(
Gd0
√γT , 2βd2
0
γT , 3G2
γαT , βd2
0

1 −γ α
4β
T )
.
Lemma 2.5. For 0 ≤γ ≤1, suppose that a sequence x0, . . . xt satisﬁes:
d2
t+1 ≤d2
t −γ
h2
t
∥∇t∥2
(2.2)
2.3. GRADIENT DESCENT AND THE POLYAK STEPSIZE
19
then for ¯x as deﬁned in the algorithm, we have:
h(¯x) ≤RT,γ .
Proof. The proof analyzes diﬀerent cases:
1. For convex functions with gradient bounded by G,
d2",N/A,N/A
"d2
t+1 −d2
t
≤−γh2
t
∥∇t∥2 ≤−γh2
t
G2
Summing up over T iterations, and using Cauchy-Schwartz, we have
1
T
X
t
ht
≤
1
√
T
sX
t
h2
t
≤
G
√γT
sX
t
(d2
t −d2
t+1) ≤Gd0
√γT .
2. For smooth functions whose gradient is bounded by G, Lemma 2.3
implies:
d2
t+1 −d2
t ≤−γh2
t
∥∇t∥2 ≤−γht
2β .
This implies
1
T
X
t
ht ≤2βd2
0
γT
.
3. For strongly convex functions, Lemma 2.3 implies:
d2
t+1 −d2
t ≤−γ
h2
t
∥∇t∥2 ≤−γ h2
t
G2 ≤−γ α2d4
t
4G2 .
In other words, d2
t+1 ≤d2
t (1 −γ α2d2
t",N/A,N/A
"t
4G2 .
In other words, d2
t+1 ≤d2
t (1 −γ α2d2
t
4G2 ) . Deﬁning at := γ α2d2
t
4G2 , we have:
at+1 ≤at(1 −at) .
20
CHAPTER 2. BASIC CONCEPTS
This implies that at ≤
1
t+1, which can be seen by induction1. The
proof is completed as follows2 :
1
T/2
T
X
t=T/2
h2
t
≤
2G2
γT
T
X
t=T/2
(d2
t −d2
t+1)
=
2G2
γT (d2
T/2 −d2
T )
=
8G4
γ2α2T (aT/2 −aT )
≤
9G4
γ2α2T 2 .
Thus, there exists a t for which h2
t ≤
9G4
γ2α2T 2 . Taking the square root
completes the claim.",N/A,N/A
"completes the claim.
4. For both strongly convex and smooth functions:
d2
t+1 −d2
t ≤−γ
h2
t
∥∇t∥2 ≤−γht
2β ≤−γ α
4β d2
t
Thus,
hT ≤βd2
T ≤βd2
0

1 −γ α
4β
T
.
This completes the proof of all cases.
1That a0 ≤1 follows from Lemma 2.3. For t = 1, a1 ≤1
2 since a1 ≤a0(1 −a0) and
0 ≤a0 ≤1. For the induction step, at ≤at−1(1 −at−1) ≤1
t (1 −1
t ) = t−1
t2 =
1
t+1( t2−1
t2 ) ≤
1
t+1.
2This assumes T is even. T odd leads to the same constants.
2.4. EXERCISES
21
2.4
Exercises",N/A,N/A
"2.4. EXERCISES
21
2.4
Exercises
1. Write an explicit expression for the gradient and projection operation
(if needed) for each of the example optimization problems in the ﬁrst
chapter.
2. Prove that a diﬀerentiable function f(x) : R →R is convex if and only
if for any x, y ∈R it holds that f(x) −f(y) ≤(x −y)f′(x).
3. Recall that we say that a function f : Rn →R has a condition number
γ = α/β over K ⊆Rd if the following two inequalities hold for all
x, y ∈K:
(a) f(y) ≥f(x) + (y −x)⊤∇f(x) + α",N/A,N/A
"x, y ∈K:
(a) f(y) ≥f(x) + (y −x)⊤∇f(x) + α
2 ∥x −y∥2
(b) f(y) ≤f(x) + (y −x)⊤∇f(x) + β
2 ∥x −y∥2
For matrices A, B ∈Rn×n we denote A ≽B if A −B is positive
semideﬁnite. Prove that if f is twice diﬀerentiable and it holds that
βI ≽∇2f(x) ≽αI for any x ∈K, then the condition number of f
over K is α/β.
4. Prove:
(a) The sum of convex functions is convex.
(b) Let f be α1-strongly convex and g be α2-strongly convex. Then
f + g is (α1 + α2)-strongly convex.",N/A,N/A
"f + g is (α1 + α2)-strongly convex.
(c) Let f be β1-smooth and g be β2-smooth. Then f +g is (β1 +β2)-
smooth.
5. Let K ⊆Rd be closed, compact, non-empty and bounded. Prove that
a necessary and suﬃcient condition for ΠK(x) to be a singleton, that
is for | ΠK(x)| = 1, is for K to be convex.
6. Prove that for convex functions, ∇f(x) ∈∂f(x), that is, the gradient
belongs to the subgradient set.
7. Let f(x) : Rn →R be a convex diﬀerentiable function and K ⊆Rn be",N/A,N/A
"a convex set. Prove that x⋆∈K is a minimizer of f over K if and only
if for any y ∈K it holds that (y −x⋆)⊤∇f(x⋆) ≥0.
8. Consider the n-dimensional simplex
∆n = {x ∈Rn |
n
X
i=1
xi = 1, xi ≥0 , ∀i ∈[n]}.
22
CHAPTER 2. BASIC CONCEPTS
Give an algorithm for computing the projection of a point x ∈Rn onto
the set ∆n (a near-linear time algorithm exists).
2.5. BIBLIOGRAPHIC REMARKS
23
2.5
Bibliographic remarks
The reader is referred to dedicated books on convex optimization for much",N/A,N/A
"more in-depth treatment of the topics surveyed in this background chapter.
For background in convex analysis see the texts [11, 68]. The classic text-
book [12] gives a broad introduction to convex optimization with numerous
applications. For an adaptive analysis of gradient descent with the Polyak
stepsize see [33].
24
CHAPTER 2. BASIC CONCEPTS
Chapter 3
Stochastic Gradient Descent
The most important optimization algorithm in the context of machine learn-",N/A,N/A
"ing is stochastic gradient descent (SGD), especially for non-convex optimiza-
tion and in the context of deep neural networks. In this chapter we spell
out the algorithm and analyze it up to tight ﬁnite-time convergence rates.
3.1
Training feedforward neural networks
Perhaps the most common optimization problem in machine learning is that
of training feedforward neural networks. In this problem, we are given a set
of labelled data points, such as labelled images or text. Let {xi, yi} be the",N/A,N/A
"set of labelled data points, also called the training data.
The goal is to ﬁt the weights of an artiﬁcial neural network in order to
minimize the loss over the data. Mathematically, the feedforward network
is a given weighted a-cyclic graph G = (V, E, W). Each node v is assigned
an activation function, which we assume is the same function for all nodes,
denoted σ : Rd 7→R. Using a biological analogy, an activation function σ",N/A,N/A
"is a function that determines how strongly a neuron (i.e. a node) ‘ﬁres’ for
a given input by mapping the result into the desired range, usually [0, 1] or
[−1, 1] . Some popular examples include:
• Sigmoid: σ(x) =
1
1+e−x
• Hyperbolic tangent: tanh(x) = ex−e−x
ex+e−x
• Rectiﬁed linear unit: ReLU(x) = max{0, x} (currently the most widely
used of the three)
25
26
CHAPTER 3. STOCHASTIC GRADIENT DESCENT
The inputs to the input layer nodes is a given data point, while the",N/A,N/A
"inputs to to all other nodes are the output of the nodes connected to it. We
denote by ρ(v) the set of input neighbors to node v. The top node output
is the input to the loss function, which takes its “prediction” and the true
label to form a loss.
For an input node v, its output as a function of the graph weights and
input example x (of dimension d), which we denote as
v(W, x) = σ
 X
i∈d
Wv,ixi
!
The output of an internal node v is a function of its inputs u ∈ρ(v) and a",N/A,N/A
"given example x, which we denote as
v(W, x) = σ

X
u∈ρ(v)
Wuvu(W, x)


If we denote the top node as v1, then the loss of the network over data point
(xi, yi) is given by
ℓ(v1(W, xi), yi).
The objective function becomes
f(W) = E
xi,yi

ℓ(v1(W, xi), yi)

For most commonly-used activation and loss functions, the above func-
tion is non-convex. However, it admits important computational properties.
The most signiﬁcant property is given in the following lemma.",N/A,N/A
"Lemma 3.1 (Backpropagation lemma). The gradient of f can be computed
in time O(|E|).
The proof of this lemma is left as an exercise, but we sketch the main
ideas. For every variable Wuv, we have by linearity of expectation that
∂
∂Wuv
f(W) = E
xi,yi

∂
∂Wuv
ℓ(v1(W, xi), yi)

.
Next, using the chain rule, we claim that it suﬃces to know the partial
derivatives of each node w.r.t. its immediate daughters. To see this, let us
3.2. GRADIENT DESCENT FOR SMOOTH OPTIMIZATION
27",N/A,N/A
"3.2. GRADIENT DESCENT FOR SMOOTH OPTIMIZATION
27
write the derivative w.r.t. Wuv using the chain rule:
∂
∂Wuv
ℓ(v1(W, xi), yi) = ∂ℓ
∂v1 · ∂v1
∂Wuv
= ∂ℓ
∂v1 ·
X
v2∈ρ(v1)
∂v1
∂v2 ·
∂vj
∂Wuv
= ...
= ∂ℓ
∂v1 ·
X
v2∈ρ(v1)
∂v1
∂v2 · ... ·
X
vk
j ∈ρ(vk−1)
· ∂vk
∂Wuv
We conclude that we only need to obtain the E partial derivatives along
the edges in order to compute all partial derivatives of the function. The
actual product at each node can be computed by a dynamic program in
linear time.
3.2",N/A,N/A
"linear time.
3.2
Gradient descent for smooth optimization
Before moving to stochastic gradient descent, we consider its determinis-
tic counterpart:
gradient descent, in the context of smooth non-convex
optimization.
Our notion of solution is a point with small gradient, i.e.
∥∇f(x)∥≤ε.
As we prove below, this requires O( 1
ε2 ) iterations, each requiring one gra-
dient computation. Recall that gradients can be computed eﬃciently, linear",N/A,N/A
"in the number of edges, in feed forward neural networks. Thus, the time to
obtain a ε-approximate solution becomes O(|E|m
ε2 ) for neural networks with
E edges and over m examples.
Algorithm 2 Gradient descent
1: Input: f, T, initial point x1 ∈K, sequence of step sizes {ηt}
2: for t = 1 to T do
3:
Let yt+1 = xt −ηt∇f(xt), xt+1 = ΠK (yt+1)
4: end for
5: return xT+1
Although the choice of ηt can make a diﬀerence in practice, in theory",N/A,N/A
"the convergence of the vanilla GD algorithm is well understood and given in
the following theorem. Below we assume that the function is bounded such
that |f(x)| ≤M.
28
CHAPTER 3. STOCHASTIC GRADIENT DESCENT
Theorem 3.2. For unconstrained minimization of β-smooth functions and
ηt = 1
β, GD Algorithm 2 converges as
1
T
X
t
∥∇t∥2 ≤4Mβ
T
.
Proof. Denote by ∇t the shorthand for ∇f(xt), and ht = f(xt) −f(x∗).
The Descent Lemma is given in the following simple equation,
ht+1 −ht = f(xt+1) −f(xt)
≤∇⊤",N/A,N/A
"ht+1 −ht = f(xt+1) −f(xt)
≤∇⊤
t (xt+1 −xt) + β
2 ∥xt+1 −xt∥2
β-smoothness
= −ηt∥∇t∥2 + β
2 η2
t ∥∇t∥2
algorithm defn.
= −1
2β ∥∇t∥2
choice of ηt = 1
β
Thus, summing up over T iterations, we have
1
2β
T
X
t=1
∥∇t∥2 ≤
X
t
(ht −ht+1) = h1 −hT+1 ≤2M
For convex functions, the above theorem implies convergence in function
value due to the following lemma,
Lemma 3.3. A convex function satisﬁes
ht ≤D∥∇t∥,
and an α-strongly convex function satisﬁes
ht ≤1
2α∥∇t∥2.",N/A,N/A
"ht ≤1
2α∥∇t∥2.
Proof. The gradient upper bound for convex functions gives
ht ≤∇t(x∗−xt) ≤D∥∇t∥
The strongly convex case appears in Lemma 2.3.
3.3. STOCHASTIC GRADIENT DESCENT
29
3.3
Stochastic gradient descent
In the context of training feed forward neural networks, the key idea of
Stochastic Gradient Descent is to modify the updates to be:
Wt+1 = Wt −η e∇t
(3.1)
where e∇t is a random variable with E[e∇t] = ∇f (Wt) and bounded second
moment E[∥e∇t∥2
2] ≤σ2.",N/A,N/A
"moment E[∥e∇t∥2
2] ≤σ2.
Luckily, getting the desired e∇t random variable is easy in the posed
problem since the objective function is already in expectation form so:
∇f(W) = ∇E
xi,yi[ℓ(v1(W, xi), yi)] = E
xi,yi[∇ℓ(v1(W, xi), yi)].
Therefore, at iteration t we can take e∇t = ∇ℓ(v1(W, xi), yi) where i ∈
{1, ..., m} is picked uniformly at random. Based on the observation above,
choosing e∇t this way preserves the desired expectation. So, for each iteration",N/A,N/A
"we only compute the gradient w.r.t. to one random example instead of the
entire dataset, thereby drastically improving performance for every step. It
remains to analyze how this impacts convergence.
Algorithm 3 Stochastic gradient descent
1: Input: f, T, initial point x1 ∈K, sequence of step sizes {ηt}
2: for t = 1 to T do
3:
Let yt+1 = xt −ηt∇f(xt), xt+1 = ΠK (yt+1)
4: end for
5: return xT+1
Theorem 3.4. For unconstrained minimization of β-smooth functions and
ηt = η =
q
M",N/A,N/A
"ηt = η =
q
M
βσ2T , SGD Algorithm 3 converges as
E
""
1
T
X
t
∥∇t∥2
#
≤2
r
Mβσ2
T
.
30
CHAPTER 3. STOCHASTIC GRADIENT DESCENT
Proof. Denote by ∇t the shorthand for ∇f(xt), and ht = f(xt) −f(x∗).
The stochastic descent lemma is given in the following equation,
E[ht+1 −ht] = E[f(xt+1) −f(xt)]
≤E[∇⊤
t (xt+1 −xt) + β
2 ∥xt+1 −xt∥2]
β-smoothness
= −E[η∇⊤
t ˜∇t] + β
2 η2 E ∥˜∇t∥2
algorithm defn.
= −η∥∇t∥2 + β
2 η2σ2
variance bound.
Thus, summing up over T iterations, we have for η =
q
M
βσ2T ,
E
""
1
T",N/A,N/A
"q
M
βσ2T ,
E
""
1
T
T
X
t=1
∥∇t∥2
#
≤
1
Tη
P
t E [ht −ht+1] + η β
2 σ2 ≤M
Tη + η β
2 σ2
=
q
Mβσ2
T
+ 1
2
q
Mβσ2
T
≤2
q
Mβσ2
T
.
We thus conclude that O( 1
ε4 ) iterations are needed to ﬁnd a point with
∥∇f(x)∥≤ε, as opposed to O( 1
ε2 ). However, each iteration takes O(|E|)
time, instead of O(|E|m) time for gradient descent.
This is why SGD is one of the most useful algorithms in machine learning.
3.4. BIBLIOGRAPHIC REMARKS
31
3.4
Bibliographic remarks",N/A,N/A
"31
3.4
Bibliographic remarks
For in depth treatment of backpropagation and the role of deep neural net-
works in machine learning the reader is referred to [25].
For detailed rigorous convergence proofs of ﬁrst order methods, see lec-
ture notes by Nesterov [57] and Nemirovskii [53, 54], as well as the recent
text [13].
32
CHAPTER 3. STOCHASTIC GRADIENT DESCENT
Chapter 4
Generalization and
Non-Smooth Optimization
In previous chapter we have introduced the framework of mathematical op-",N/A,N/A
"timization within the context of machine learning. We have described the
mathematical formulation of several machine learning problems, notably
training neural networks, as optimization problems. We then described as
well as analyzed the most useful optimization method to solve such formu-
lations: stochastic gradient descent.
However, several important questions arise:
1. SGD was analyzed for smooth functions. Can we minimize non-smooth
objectives?",N/A,N/A
"objectives?
2. Given an ERM problem (a.k.a. learning from examples, see ﬁrst chap-
ter), what can we say about generalization to unseen examples? How
does it aﬀect optimization?
3. Are there faster algorithms than SGD in the context of ML?
In this chapter we address the ﬁrst two, and devote the rest of this
manuscript/course to the last question.
How many examples are needed to learn a certain concept? This is a
fundamental question of statistical/computational learning theory that has",N/A,N/A
"been studied for decades (see end of chapter for bibliographic references).
The classical setting of learning from examples is statistical. It assumes
examples are drawn i.i.d from a ﬁxed, arbitrary and unknown distribution.
The mathematical optimization formulations that we have derived for the
ERM problem assume that we have suﬃciently many examples, such that
33
34
CHAPTER 4. GENERALIZATION
optimizing a certain predictor/neural-network/machine on them will result",N/A,N/A
"in a solution that is capable of generalizing to unseen examples. The number
of examples needed to generalize is called the sample complexity of the prob-
lem, and it depends on the concept we are learning as well as the hypothesis
class over which we are trying to optimize.
There are dimensionality notions in the literature, notably the VC-
dimension and related notions, that give precise bounds on the sample com-
plexity for various hypothesis classes. In this text we take an algorithmic",N/A,N/A
"approach, which is also deterministic. Instead of studying sample complex-
ity, which is non-algorithmic, we study algorithms for regret minimization.
We will show that they imply generalization for a broad class of machines.
4.1
A note on non-smooth optimization
Minimization of a function that is both non-convex and non-smooth is in
general hopeless, from an information theoretic perspective. The following
image explains why. The depicted function on the interval [0, 1] has a single",N/A,N/A
"local/global minimum, and if the crevasse is narrow enough, it cannot be
found by any method other than extensive brute-force search, which can
take arbitrarily long.
0
1
Figure 4.1: Intractability of nonsmooth optimization
Since non-convex and non-smooth optimization is hopeless, in the con-
text of non-smooth functions we only consider convex optimization.
4.2. MINIMIZING REGRET
35
4.2
Minimizing Regret
The setting we consider for the rest of this chapter is that of online (convex)",N/A,N/A
"optimization. In this setting a learner iteratively predicts a point xt ∈K in
a convex set K ⊆Rd, and then receives a cost according to an adversarially
chosen convex function ft ∈F from family F.
The goal of the algorithms introduced in this chapter is to minimize
worst-case regret, or diﬀerence between total cost and that of best point in
hindsight:
regret =
sup
f1,...,fT ∈F
( T
X
t=1
ft(xt) −min
x∈K
T
X
t=1
ft(x)
)
.
In order to compare regret to optimization error it is useful to consider",N/A,N/A
"the average regret, or regret/T. Let ¯xT = 1
T
PT
t=1 xt be the average decision.
If the functions ft are all equal to a single function f : K 7→R, then Jensen’s
inequality implies that f(¯xT ) converges to f(x⋆) if the average regret is
vanishing, since
f(¯xT ) −f(x⋆) ≤1
T
T
X
t=1
[f(xt) −f(x⋆)] = regret
T
4.3
Regret implies generalization
Statistical learning theory for learning from examples postulates that exam-
ples from a certain concept are sampled i.i.d. from a ﬁxed and unknown",N/A,N/A
"distribution. The learners’ goal is to choose a hypothesis from a certain
hypothesis class that can generalize to unseen examples.
More formally, let D be a distribution over labelled examples {ai ∈
Rd, bi ∈R} ∼D. Let H = {x} , x : Rd 7→R be a hypothsis class over which
we are trying to learn (such as linear separators, deep neural networks,
etc.). The generalization error of a hypothesis is the expected error of a
hypothesis over randomly chosen examples according to a given loss function",N/A,N/A
"ℓ: R × R 7→R, which is applied to the prediction of the hypothesis and the
true label, ℓ(x(ai), bi). Thus,
error(x) =
E
ai,bi∼D[ℓ(x(ai), bi)].
An algorithm that attains sublinear regret over the hypothesis class H,
w.r.t. loss functions given by ft(x) = fa,b(x) = ℓ(x(a), b), gives rise to a
generalizing hypothesis as follows.
36
CHAPTER 4. GENERALIZATION
Lemma 4.1. Let ¯x = xt for t ∈[T] be chose uniformly at random from",N/A,N/A
"{x1, ..., xT }.Then, with expectation taken over random choice of ¯x as well
as choices of ft ∼D,
E[error(¯x)] ≤E[error(x∗)] + regret
T
Proof. By random choice of ¯x, we have
E[f(¯x)] = E
""
1
T
X
t
f(xt)
#
Using the fact that ft ∼D, we have
E[error(¯x)]
= Ef∼D[f(¯x)]
= Eft[ 1
T
P
t ft(xt)]
≤Eft[ 1
T
P
t ft(x⋆)] + regret
T
= Ef[f(x⋆)] + regret
T
= Ef[error(x⋆)] + regret
T
4.4
Online gradient descent
Perhaps the simplest algorithm that applies to the most general setting of",N/A,N/A
"online convex optimization is online gradient descent. This algorithm is an
online version of standard gradient descent for oﬄine optimization we have
seen in the previous chapter.
Pseudo-code for the algorithm is given in
Algorithm 4, and a conceptual illustration is given in Figure 4.2.
In each iteration, the algorithm takes a step from the previous point in
the direction of the gradient of the previous cost. This step may result in",N/A,N/A
"a point outside of the underlying convex set. In such cases, the algorithm
projects the point back to the convex set, i.e. ﬁnds its closest point in the
convex set. Despite the fact that the next cost function may be completely
diﬀerent than the costs observed thus far, the regret attained by the algo-
rithm is sublinear. This is formalized in the following theorem (recall the
deﬁnition of G and D from the previous chapter).
Theorem 4.2. Online gradient descent with step sizes {ηt =
D
G
√",N/A,N/A
"D
G
√
t, t ∈[T]}
guarantees the following for all T ≥1:
regretT =
T
X
t=1
ft(xt) −min
x⋆∈K
T
X
t=1
ft(x⋆) ≤3GD
√
T
4.4. ONLINE GRADIENT DESCENT
37
Figure 4.2: Online gradient descent: the iterate xt+1 is derived by advancing
xt in the direction of the current gradient ∇t, and projecting back into K.
Algorithm 4 online gradient descent
1: Input: convex set K, T, x1 ∈K, step sizes {ηt}
2: for t = 1 to T do
3:
Play xt and observe cost ft(xt).
4:
Update and project:
yt+1 = xt −ηt∇ft(xt)
xt+1 = Π",N/A,N/A
"Update and project:
yt+1 = xt −ηt∇ft(xt)
xt+1 = Π
K(yt+1)
5: end for
Proof. Let x⋆∈arg minx∈K
PT
t=1 ft(x). Deﬁne ∇t ≜∇ft(xt). By convexity
ft(xt) −ft(x⋆) ≤∇⊤
t (xt −x⋆)
(4.1)
We ﬁrst upper-bound ∇⊤
t (xt −x⋆) using the update rule for xt+1 and The-
orem 2.1 (the Pythagorean theorem):
∥xt+1 −x⋆∥2 =
Π
K(xt −ηt∇t) −x⋆

2
≤∥xt −ηt∇t −x⋆∥2
(4.2)
38
CHAPTER 4. GENERALIZATION
Hence,
∥xt+1 −x⋆∥2
≤
∥xt −x⋆∥2 + η2
t ∥∇t∥2 −2ηt∇⊤
t (xt −x⋆)
2∇⊤
t (xt −x⋆)
≤
∥xt −x⋆∥2 −∥xt+1 −x⋆∥2
ηt
+ ηtG2
(4.3)",N/A,N/A
"≤
∥xt −x⋆∥2 −∥xt+1 −x⋆∥2
ηt
+ ηtG2
(4.3)
Summing (4.1) and (4.3) from t = 1 to T, and setting ηt =
D
G
√
t (with
1
η0 ≜0):
2
 T
X
t=1
ft(xt) −ft(x⋆)
!
≤2
T
X
t=1
∇⊤
t (xt −x⋆)
≤
T
X
t=1
∥xt −x⋆∥2 −∥xt+1 −x⋆∥2
ηt
+ G2
T
X
t=1
ηt
≤
T
X
t=1
∥xt −x⋆∥2
 1
ηt
−
1
ηt−1

+ G2
T
X
t=1
ηt
1
η0
≜0,
∥xT+1 −x∗∥2 ≥0
≤D2
T
X
t=1
 1
ηt
−
1
ηt−1

+ G2
T
X
t=1
ηt
≤D2 1
ηT
+ G2
T
X
t=1
ηt
telescoping series
≤3DG
√
T.
The last inequality follows since ηt =
D
G
√
t and PT
t=1
1
√
t ≤2
√
T.",N/A,N/A
"D
G
√
t and PT
t=1
1
√
t ≤2
√
T.
The online gradient descent algorithm is straightforward to implement,
and updates take linear time given the gradient. However, there is a projec-
tion step which may take signiﬁcantly longer.
4.5
Lower bounds
Theorem 4.3. Any algorithm for online convex optimization incurs Ω(DG
√
T)
regret in the worst case. This is true even if the cost functions are generated
from a ﬁxed stationary distribution.",N/A,N/A
"from a ﬁxed stationary distribution.
We give a sketch of the proof; ﬁlling in all details is left as an exercise
at the end of this chapter.
4.6. ONLINE GRADIENT DESCENT FOR STRONGLY CONVEX FUNCTIONS39
Consider an instance of OCO where the convex set K is the n-dimensional
hypercube, i.e.
K = {x ∈Rn , ∥x∥∞≤1}.
There are 2n linear cost functions, one for each vertex v ∈{±1}n, deﬁned
as
∀v ∈{±1}n , fv(x) = v⊤x.
Notice that both the diameter of K and the bound on the norm of the cost",N/A,N/A
"function gradients, denoted G, are bounded by
D ≤
v
u
u
t
n
X
i=1
22 = 2√n, G =
v
u
u
t
n
X
i=1
(±1)2 = √n
The cost functions in each iteration are chosen at random, with uniform
probability, from the set {fv, v ∈{±1}n}. Denote by vt ∈{±1}n the vertex
chosen in iteration t, and denote ft = fvt. By uniformity and independence,
for any t and xt chosen online, Evt[ft(xt)] = Evt[v⊤
t xt] = 0. However,
E
v1,...,vT
""
min
x∈K
T
X
t=1
ft(x)
#
= E

min
x∈K
X
i∈[n]
T
X
t=1
vt(i) · xi


= n E
""
−",N/A,N/A
"min
x∈K
X
i∈[n]
T
X
t=1
vt(i) · xi


= n E
""
−

T
X
t=1
vt(1)

#
i.i.d. coordinates
= −Ω(n
√
T).
The last equality is left as exercise 3.
The facts above nearly complete the proof of Theorem 4.3; see the exer-
cises at the end of this chapter.
4.6
Online gradient descent for strongly convex
functions
The ﬁrst algorithm that achieves regret logarithmic in the number of iter-
ations is a twist on the online gradient descent algorithm, changing only",N/A,N/A
"the step size. The following theorem establishes logarithmic bounds on the
regret if the cost functions are strongly convex.
40
CHAPTER 4. GENERALIZATION
Theorem 4.4. For α-strongly convex loss functions, online gradient descent
with step sizes ηt = 1
αt achieves the following guarantee for all T ≥1
regretT ≤
T
X
t=1
1
αt∥∇t∥2 ≤G2
2α (1 + log T).
Proof. Let x⋆∈arg minx∈K
PT
t=1 ft(x). Recall the deﬁnition of regret
regretT =
T
X
t=1
ft(xt) −
T
X
t=1
ft(x⋆).",N/A,N/A
"regretT =
T
X
t=1
ft(xt) −
T
X
t=1
ft(x⋆).
Deﬁne ∇t ≜∇ft(xt). Applying the deﬁnition of α-strong convexity to
the pair of points xt,x∗, we have
2(ft(xt) −ft(x⋆))
≤
2∇⊤
t (xt −x⋆) −α∥x⋆−xt∥2.
(4.4)
We proceed to upper-bound ∇⊤
t (xt −x⋆). Using the update rule for xt+1
and the Pythagorean theorem 2.1, we get
∥xt+1 −x⋆∥2 = ∥Π
K(xt −ηt∇t) −x⋆∥2 ≤∥xt −ηt∇t −x⋆∥2.
Hence,
∥xt+1 −x⋆∥2
≤
∥xt −x⋆∥2 + η2
t ∥∇t∥2 −2ηt∇⊤
t (xt −x⋆)
and
2∇⊤
t (xt −x⋆)
≤
∥xt −x⋆∥2 −∥xt+1 −x⋆∥2
ηt
+ ηt∥∇t∥2.
(4.5)",N/A,N/A
"≤
∥xt −x⋆∥2 −∥xt+1 −x⋆∥2
ηt
+ ηt∥∇t∥2.
(4.5)
4.7. ONLINE GRADIENT DESCENT IMPLIES SGD
41
Summing (4.5) from t = 1 to T, setting ηt =
1
αt (deﬁne
1
η0 ≜0), and
combining with (4.4), we have:
2
T
X
t=1
(ft(xt) −ft(x⋆))
≤
T
X
t=1
∥xt −x⋆∥2
 1
ηt
−
1
ηt−1
−α

+
T
X
t=1
ηt∥∇t∥2
since 1
η0
≜0, ∥xT+1 −x∗∥2 ≥0
=
0 +
T
X
t=1
1
αt∥∇t∥2
≤
G2
α (1 + log T)
4.7
Online Gradient Descent implies SGD
In this section we notice that OGD and its regret bounds imply the SGD",N/A,N/A
"bounds we have studied in the previous chapter. The main advantage are
the guarantees for non-smooth stochastic optimization, and constrained op-
timization.
Recall that in stochastic optimization, the optimizer attempts to mini-
mize a convex function over a convex domain as given by the mathematical
program:
min
x∈K f(x).
However, unlike standard oﬄine optimization, the optimizer is given access
to a noisy gradient oracle, deﬁned by
O(x) ≜˜∇x s.t.
E[ ˜∇x] = ∇f(x) , E[∥˜∇x∥2] ≤G2",N/A,N/A
"O(x) ≜˜∇x s.t.
E[ ˜∇x] = ∇f(x) , E[∥˜∇x∥2] ≤G2
That is, given a point in the decision set, a noisy gradient oracle returns
a random vector whose expectation is the gradient at the point and whose
second moment is bounded by G2.
We will show that regret bounds for OCO translate to convergence rates
for stochastic optimization. As a special case, consider the online gradient
42
CHAPTER 4. GENERALIZATION
descent algorithm whose regret is bounded by
regretT = O(DG
√
T)",N/A,N/A
"regretT = O(DG
√
T)
Applying the OGD algorithm over a sequence of linear functions that are
deﬁned by the noisy gradient oracle at consecutive points, and ﬁnally re-
turning the average of all points along the way, we obtain the stochastic
gradient descent algorithm, presented in Algorithm 5.
Algorithm 5 stochastic gradient descent
1: Input: f, K, T, x1 ∈K, step sizes {ηt}
2: for t = 1 to T do
3:
Let ˜∇t = O(xt) and deﬁne: ft(x) ≜⟨˜∇t, x⟩
4:
Update and project:
yt+1 = xt −ηt ˜∇t
xt+1 = Π",N/A,N/A
"4:
Update and project:
yt+1 = xt −ηt ˜∇t
xt+1 = Π
K(yt+1)
5: end for
6: return ¯xT ≜1
T
PT
t=1 xt
Theorem 4.5. Algorithm 5 with step sizes ηt =
D
G
√
t guarantees
E[f(¯xT )] ≤min
x⋆∈K f(x⋆) + 3GD
√
T
Proof. By the regret guarantee of OGD, we have
E[f(¯xT )] −f(x⋆)
≤E[ 1
T
X
t
f(xt)] −f(x⋆)
convexity of f (Jensen)
≤1
T E[
X
t
⟨∇f(xt), xt −x⋆⟩]
convexity again
= 1
T E[
X
t
⟨˜∇t, xt −x⋆⟩]
noisy gradient estimator
= 1
T E[
X
t
ft(xt) −ft(x⋆)]
Algorithm 5, line (3)
≤regretT
T
deﬁnition
≤3GD
√
T",N/A,N/A
"≤regretT
T
deﬁnition
≤3GD
√
T
theorem 4.2
4.7. ONLINE GRADIENT DESCENT IMPLIES SGD
43
It is important to note that in the proof above, we have used the fact
that the regret bounds of online gradient descent hold against an adaptive
adversary. This need arises since the cost functions ft deﬁned in Algorithm
5 depend on the choice of decision xt ∈K.
In addition, the careful reader may notice that by plugging in diﬀerent
step sizes (also called learning rates) and applying SGD to strongly convex",N/A,N/A
"functions, one can attain ˜O(1/T) convergence rates. Details of this deriva-
tion are left as exercise 1.
44
CHAPTER 4. GENERALIZATION
4.8
Exercises
1. Prove that SGD for a strongly convex function can, with appropriate
parameters ηt, converge as ˜O( 1
T ). You may assume that the gradient
estimators have Euclidean norms bounded by the constant G.
2. Design an OCO algorithm that attains the same asymptotic regret
bound as OGD, up to factors logarithmic in G and D, without knowing",N/A,N/A
"the parameters G and D ahead of time.
3. In this exercise we prove a tight lower bound on the regret of any
algorithm for online convex optimization.
(a) For any sequence of T fair coin tosses, let Nh be the number of
head outcomes and Nt be the number of tails. Give an asymp-
totically tight upper and lower bound on E[|Nh −Nt|] (i.e., order
of growth of this random variable as a function of T, up to mul-
tiplicative and additive constants).",N/A,N/A
"tiplicative and additive constants).
(b) Consider a 2-expert problem, in which the losses are inversely
correlated: either expert one incurs a loss of one and the second
expert zero, or vice versa. Use the fact above to design a set-
ting in which any experts algorithm incurs regret asymptotically
matching the upper bound.
(c) Consider the general OCO setting over a convex set K. Design
a setting in which the cost functions have gradients whose norm",N/A,N/A
"is bounded by G, and obtain a lower bound on the regret as
a function of G, the diameter of K, and the number of game
iterations.
4.9. BIBLIOGRAPHIC REMARKS
45
4.9
Bibliographic remarks
The OCO framework was introduced by Zinkevich in [87], where the OGD
algorithm was introduced and analyzed. Precursors to this algorithm, albeit
for less general settings, were introduced and analyzed in [47]. Logarithmic
regret algorithms for Online Convex Optimization were introduced and an-",N/A,N/A
"alyzed in [32]. For more detailed exposition on this prediction framework
and its applications see [31].
The SGD algorithm dates back to Robbins and Monro [67]. Application
of SGD to soft-margin SVM training was explored in [74]. Tight conver-
gence rates of SGD for strongly convex and non-smooth functions were only
recently obtained in [35],[62],[76].
46
CHAPTER 4. GENERALIZATION
Chapter 5
Regularization
In this chapter we consider a generalization of the gradient descent called",N/A,N/A
"by diﬀerent names in diﬀerent communities (such as mirrored-descent, or
regularized-follow-the-leader). The common theme of this generalization is
called Regularization, a concept that is founded in generalization theory.
Since this course focuses on optimization rather than generalization, we
shall refer the reader to the generalization aspect of regularization, and
focus hereby on optimization algorithms.
We start by motivating this general family of methods using the funda-",N/A,N/A
"mental problem of decision theory.
5.1
Motivation: prediction from expert advice
Consider the following fundamental iterative decision making problem:
At each time step t = 1, 2, . . . , T, the decision maker faces a choice
between two actions A or B (i.e., buy or sell a certain stock). The decision
maker has assistance in the form of N “experts” that oﬀer their advice. After
a choice between the two actions has been made, the decision maker receives",N/A,N/A
"feedback in the form of a loss associated with each decision. For simplicity
one of the actions receives a loss of zero (i.e., the “correct” decision) and
the other a loss of one.
We make the following elementary observations:
1. A decision maker that chooses an action uniformly at random each
iteration, trivially attains a loss of T
2 and is “correct” 50% of the time.
47
48
CHAPTER 5. REGULARIZATION
2. In terms of the number of mistakes, no algorithm can do better in the",N/A,N/A
"worst case! In a later exercise, we will devise a randomized setting in
which the expected number of mistakes of any algorithm is at least T
2 .
We are thus motivated to consider a relative performance metric: can
the decision maker make as few mistakes as the best expert in hindsight?
The next theorem shows that the answer in the worst case is negative for a
deterministic decision maker.
Theorem 5.1. Let L ≤T
2 denote the number of mistakes made by the best",N/A,N/A
"2 denote the number of mistakes made by the best
expert in hindsight. Then there does not exist a deterministic algorithm that
can guarantee less than 2L mistakes.
Proof. Assume that there are only two experts and one always chooses op-
tion A while the other always chooses option B. Consider the setting in
which an adversary always chooses the opposite of our prediction (she can
do so, since our algorithm is deterministic). Then, the total number of mis-",N/A,N/A
"takes the algorithm makes is T. However, the best expert makes no more
than T
2 mistakes (at every iteration exactly one of the two experts is mis-
taken). Therefore, there is no algorithm that can always guarantee less than
2L mistakes.
This observation motivates the design of random decision making algo-
rithms, and indeed, the OCO framework gracefully models decisions on a
continuous probability space. Henceforth we prove Lemmas 5.3 and 5.4 that
show the following:
Theorem 5.2. Let ε ∈(0, 1",N/A,N/A
"show the following:
Theorem 5.2. Let ε ∈(0, 1
2). Suppose the best expert makes L mistakes.
Then:
1. There is an eﬃcient deterministic algorithm that can guarantee less
than 2(1 + ε)L + 2 log N
ε
mistakes;
2. There is an eﬃcient randomized algorithm for which the expected num-
ber of mistakes is at most (1 + ε)L + log N
ε
.
5.1. MOTIVATION: PREDICTION FROM EXPERT ADVICE
49
5.1.1
The weighted majority algorithm
The weighted majority (WM) algorithm is intuitive to describe: each expert",N/A,N/A
"i is assigned a weight Wt(i) at every iteration t. Initially, we set W1(i) = 1
for all experts i ∈[N]. For all t ∈[T] let St(A), St(B) ⊆[N] be the set of
experts that choose A (and respectively B) at time t. Deﬁne,
Wt(A) =
X
i∈St(A)
Wt(i)
Wt(B) =
X
i∈St(B)
Wt(i)
and predict according to
at =
(
A
if Wt(A) ≥Wt(B)
B
otherwise.
Next, update the weights Wt(i) as follows:
Wt+1(i) =
(
Wt(i)
if expert i was correct
Wt(i)(1 −ε)
if expert i was wrong ,",N/A,N/A
"Wt(i)(1 −ε)
if expert i was wrong ,
where ε is a parameter of the algorithm that will aﬀect its performance.
This concludes the description of the WM algorithm. We proceed to bound
the number of mistakes it makes.
Lemma 5.3. Denote by Mt the number of mistakes the algorithm makes
until time t, and by Mt(i) the number of mistakes made by expert i until
time t. Then, for any expert i ∈[N] we have
MT ≤2(1 + ε)MT (i) + 2 log N
ε
.
We can optimize ε to minimize the above bound. The expression on the",N/A,N/A
"right hand side is of the form f(x) = ax + b/x, that reaches its minimum
at x =
p
b/a. Therefore the bound is minimized at ε⋆=
p
log N/MT (i).
Using this optimal value of ε, we get that for the best expert i⋆
MT ≤2MT (i⋆) + O
p
MT (i⋆) log N

.
Of course, this value of ε⋆cannot be used in advance since we do not know
which expert is the best one ahead of time (and therefore we do not know the
value of MT (i⋆)). However, we shall see later on that the same asymptotic",N/A,N/A
"bound can be obtained even without this prior knowledge.
Let us now prove Lemma 5.3.
50
CHAPTER 5. REGULARIZATION
Proof. Let Φt = PN
i=1 Wt(i) for all t ∈[T], and note that Φ1 = N.
Notice that Φt+1 ≤Φt. However, on iterations in which the WM algo-
rithm erred, we have
Φt+1 ≤Φt(1 −ε
2),
the reason being that experts with at least half of total weight were wrong
(else WM would not have erred), and therefore
Φt+1 ≤1
2Φt(1 −ε) + 1
2Φt = Φt(1 −ε
2).
From both observations,
Φt ≤Φ1(1 −ε
2)Mt = N(1 −ε",N/A,N/A
"From both observations,
Φt ≤Φ1(1 −ε
2)Mt = N(1 −ε
2)Mt.
On the other hand, by deﬁnition we have for any expert i that
WT (i) = (1 −ε)MT (i).
Since the value of WT (i) is always less than the sum of all weights ΦT , we
conclude that
(1 −ε)MT (i) = WT (i) ≤ΦT ≤N(1 −ε
2)MT .
Taking the logarithm of both sides we get
MT (i) log(1 −ε) ≤log N + MT log (1 −ε
2).
Next, we use the approximations
−x −x2 ≤log (1 −x) ≤−x
0 < x < 1
2,",N/A,N/A
"−x −x2 ≤log (1 −x) ≤−x
0 < x < 1
2,
which follow from the Taylor series of the logarithm function, to obtain that
−MT (i)(ε + ε2) ≤log N −MT
ε
2,
and the lemma follows.
5.1. MOTIVATION: PREDICTION FROM EXPERT ADVICE
51
5.1.2
Randomized weighted majority
In the randomized version of the WM algorithm, denoted RWM, we choose
expert i w.p. pt(i) = Wt(i)/ PN
j=1 Wt(j) at time t.
Lemma 5.4. Let Mt denote the number of mistakes made by RWM until
iteration t. Then, for any expert i ∈[N] we have",N/A,N/A
"iteration t. Then, for any expert i ∈[N] we have
E[MT ] ≤(1 + ε)MT (i) + log N
ε
.
The proof of this lemma is very similar to the previous one, where the factor
of two is saved by the use of randomness:
Proof. As before, let Φt = PN
i=1 Wt(i) for all t ∈[T], and note that Φ1 = N.
Let ˜mt = Mt −Mt−1 be the indicator variable that equals one if the RWM
algorithm makes a mistake on iteration t. Let mt(i) equal one if the i’th
expert makes a mistake on iteration t and zero otherwise. Inspecting the",N/A,N/A
"sum of the weights:
Φt+1 =
X
i
Wt(i)(1 −εmt(i))
= Φt(1 −ε
X
i
pt(i)mt(i))
pt(i) =
Wt(i)
P
j Wt(j)
= Φt(1 −ε E[ ˜mt])
≤Φte−εE[ ˜mt].
1 + x ≤ex
On the other hand, by deﬁnition we have for any expert i that
WT (i) = (1 −ε)MT (i)
Since the value of WT (i) is always less than the sum of all weights ΦT , we
conclude that
(1 −ε)MT (i) = WT (i) ≤ΦT ≤Ne−εE[MT ].
Taking the logarithm of both sides we get
MT (i) log(1 −ε) ≤log N −ε E[MT ]
Next, we use the approximation
−x −x2 ≤log (1 −x) ≤−x
,
0 < x < 1
2",N/A,N/A
"−x −x2 ≤log (1 −x) ≤−x
,
0 < x < 1
2
52
CHAPTER 5. REGULARIZATION
to obtain
−MT (i)(ε + ε2) ≤log N −ε E[MT ],
and the lemma follows.
5.1.3
Hedge
The RWM algorithm is in fact more general: instead of considering a dis-
crete number of mistakes, we can consider measuring the performance of an
expert by a non-negative real number ℓt(i), which we refer to as the loss
of the expert i at iteration t. The randomized weighted majority algorithm",N/A,N/A
"guarantees that a decision maker following its advice will incur an average
expected loss approaching that of the best expert in hindsight.
Historically, this was observed by a diﬀerent and closely related algorithm
called Hedge.
Algorithm 6 Hedge
1: Initialize: ∀i ∈[N], W1(i) = 1
2: for t = 1 to T do
3:
Pick it ∼R Wt, i.e., it = i with probability xt(i) =
Wt(i)
P
j Wt(j)
4:
Incur loss ℓt(it).
5:
Update weights Wt+1(i) = Wt(i)e−εℓt(i)
6: end for",N/A,N/A
"Update weights Wt+1(i) = Wt(i)e−εℓt(i)
6: end for
Henceforth, denote in vector notation the expected loss of the algorithm
by
E[ℓt(it)] =
N
X
i=1
xt(i)ℓt(i) = x⊤
t ℓt
Theorem 5.5. Let ℓ2
t denote the N-dimensional vector of square losses,
i.e., ℓ2
t (i) = ℓt(i)2, let ε > 0, and assume all losses to be non-negative. The
Hedge algorithm satisﬁes for any expert i⋆∈[N]:
T
X
t=1
x⊤
t ℓt ≤
T
X
t=1
ℓt(i⋆) + ε
T
X
t=1
x⊤
t ℓ2
t + log N
ε
5.2. THE REGULARIZATION FRAMEWORK
53",N/A,N/A
"t + log N
ε
5.2. THE REGULARIZATION FRAMEWORK
53
Proof. As before, let Φt = PN
i=1 Wt(i) for all t ∈[T], and note that Φ1 = N.
Inspecting the sum of weights:
Φt+1
= P
i Wt(i)e−εℓt(i)
= Φt
P
i xt(i)e−εℓt(i)
xt(i) =
Wt(i)
P
j Wt(j)
≤Φt
P
i xt(i)(1 −εℓt(i) + ε2ℓt(i)2))
for x ≥0,
e−x ≤1 −x + x2
= Φt(1 −εx⊤
t ℓt + ε2x⊤
t ℓ2
t )
≤Φte−εx⊤
t ℓt+ε2x⊤
t ℓ2
t .
1 + x ≤ex
On the other hand, by deﬁnition, for expert i⋆we have that
WT (i⋆) = e−ε PT
t=1 ℓt(i⋆)",N/A,N/A
"WT (i⋆) = e−ε PT
t=1 ℓt(i⋆)
Since the value of WT (i⋆) is always less than the sum of all weights Φt, we
conclude that
WT (i⋆) ≤ΦT ≤Ne−ε P
t x⊤
t ℓt+ε2 P
t x⊤
t ℓ2
t .
Taking the logarithm of both sides we get
−ε
T
X
t=1
ℓt(i⋆) ≤log N −ε
T
X
t=1
x⊤
t ℓt + ε2
T
X
t=1
x⊤
t ℓ2
t
and the theorem follows by simplifying.
5.2
The Regularization framework
In the previous section we studied the multiplicative weights update method
for decision making. A natural question is: couldn’t we have used online",N/A,N/A
"gradient descent for the same exact purpose?
Indeed, the setting of prediction from expert advice naturally follows
into the framework of online convex optimization. To see this, consider the
loss functions given by
ft(x) = ℓ⊤
t x = E
i∼x[ℓt(i)],
which capture the expected loss of choosing an expert from distribution
x ∈∆n as a linear function.
54
CHAPTER 5. REGULARIZATION
The regret guarantees we have studied for OGD imply a regret of
O(GD
√
T) = O(
√
nT).",N/A,N/A
"O(GD
√
T) = O(
√
nT).
Here we have used the fact that the Eucliean diameter of the simplex is two,
and that the losses are bounded by one, hence the Euclidean norm of the
gradient vector ℓt is bounded by √n.
In contrast, the Hedge algorithm attains regret of O(√T log n) for the
same problem. How can we explain this discrepancy?!
5.2.1
The RFTL algorithm
Both OGD and Hedge are, in fact, instantiations of a more general meta-
algorithm called RFTL (Regularized-Follow-The-Leader).",N/A,N/A
"In an OCO setting of regret minimization, the most straightforward
approach for the online player is to use at any time the optimal decision
(i.e., point in the convex set) in hindsight. Formally, let
xt+1 = arg min
x∈K
t
X
τ=1
fτ(x).
This ﬂavor of strategy is known as “ﬁctitious play” in economics, and has
been named “Follow the Leader” (FTL) in machine learning. It is not hard
to see that this simple strategy fails miserably in a worst-case sense. That",N/A,N/A
"is, this strategy’s regret can be linear in the number of iterations, as the
following example shows: Consider K = [−1, 1], let f1(x) = 1
2x, and let fτ
for τ = 2, . . . , T alternate between −x or x. Thus,
t
X
τ=1
fτ(x) =



1
2x,
t is odd
−1
2x,
otherwise
The FTL strategy will keep shifting between xt = −1 and xt = 1, always
making the wrong choice.
The intuitive FTL strategy fails in the example above because it is un-",N/A,N/A
"stable. Can we modify the FTL strategy such that it won’t change decisions
often, thereby causing it to attain low regret?
This question motivates the need for a general means of stabilizing the
FTL method. Such a means is referred to as “regularization”.
5.2. THE REGULARIZATION FRAMEWORK
55
Algorithm 7 Regularized Follow The Leader
1: Input: η > 0, regularization function R, and a convex compact set K.
2: Let x1 = arg minx∈K {R(x)}.
3: for t = 1 to T do
4:
Predict xt.
5:",N/A,N/A
"3: for t = 1 to T do
4:
Predict xt.
5:
Observe the payoﬀfunction ft and let ∇t = ∇ft(xt).
6:
Update
xt+1 = arg min
x∈K
(
η
t
X
s=1
∇⊤
s x + R(x)
)
7: end for
The generic RFTL meta-algorithm is deﬁned in Algorithm 7. The reg-
ularization function R is assumed to be strongly convex, smooth, and twice
diﬀerentiable.
5.2.2
Mirrored Descent
An alternative view of this algorithm is in terms of iterative updates, which
can be spelled out using the above deﬁnition directly. The resulting algo-",N/A,N/A
"rithm is called ”Mirrored Descent”.
OMD is an iterative algorithm that computes the current decision using a
simple gradient update rule and the previous decision, much like OGD. The
generality of the method stems from the update being carried out in a “dual”
space, where the duality notion is deﬁned by the choice of regularization:
the gradient of the regularization function deﬁnes a mapping from Rn onto
itself, which is a vector ﬁeld. The gradient updates are then carried out in",N/A,N/A
"this vector ﬁeld.
For the RFTL algorithm the intuition was straightforward—the regular-
ization was used to ensure stability of the decision. For OMD, regularization
has an additional purpose: regularization transforms the space in which gra-
dient updates are performed. This transformation enables better bounds in
terms of the geometry of the space.
The OMD algorithm comes in two ﬂavors: an agile and a lazy version.
The lazy version keeps track of a point in Euclidean space and projects onto",N/A,N/A
"the convex decision set K only at decision time. In contrast, the agile version
maintains a feasible point at all times, much like OGD.
56
CHAPTER 5. REGULARIZATION
Algorithm 8 Online Mirrored Descent
1: Input: parameter η > 0, regularization function R(x).
2: Let y1 be such that ∇R(y1) = 0 and x1 = arg minx∈K BR(x||y1).
3: for t = 1 to T do
4:
Play xt.
5:
Observe the payoﬀfunction ft and let ∇t = ∇ft(xt).
6:
Update yt according to the rule:
[Lazy version]
∇R(yt+1) = ∇R(yt) −η ∇t",N/A,N/A
"[Lazy version]
∇R(yt+1) = ∇R(yt) −η ∇t
[Agile version]
∇R(yt+1) = ∇R(xt) −η ∇t
Project according to BR:
xt+1 = arg min
x∈K
BR(x||yt+1)
7: end for
A myriad of questions arise, but ﬁrst, let us see how does this algorithm
give rise to both OGD.
We note that there are other important special cases of the RFTL meta-
algorithm: those are derived with matrix-norm regularization—namely, the
von Neumann entropy function, and the log-determinant function, as well",N/A,N/A
"as self-concordant barrier regularization. Perhaps most importantly for opti-
mization, also the AdaGrad algorithm is obtained via changing regularization—
which we shall explore in detail in the next chapter.
5.2.3
Deriving online gradient descent
To derive the online gradient descent algorithm, we take R(x) =
1
2∥x −
x0∥2
2 for an arbitrary x0 ∈K. Projection with respect to this divergence
is the standard Euclidean projection (left as an exercise), and in addition,",N/A,N/A
"∇R(x) = x−x0. Hence, the update rule for the OMD Algorithm 8 becomes:
xt = Π
K(yt), yt = yt−1 −η∇t−1
lazy version
xt = Π
K(yt), yt = xt−1 −η∇t−1
agile version
The latter algorithm is exactly online gradient descent, as described in
Algorithm 4 in Chapter 4. Furthermore, both variants are identical for the
case in which K is the unit ball.
5.3. TECHNICAL BACKGROUND: REGULARIZATION FUNCTIONS57
We later prove general regret bounds that will imply a O(GD
√
T) regret",N/A,N/A
"√
T) regret
for OGD as a special case of mirrored descent.
5.2.4
Deriving multiplicative updates
Let R(x) = x log x = P
i xi log xi be the negative entropy function, where
log x is to be interpreted elementwise. Then ∇R(x) = 1 + log x, and hence
the update rules for the OMD algorithm become:
xt = arg min
x∈K
BR(x||yt), log yt = log yt−1 −η∇t−1
lazy version
xt = arg min
x∈K
BR(x||yt), log yt = log xt−1 −η∇t−1
agile version
With this choice of regularizer, a notable special case is the experts",N/A,N/A
"problem we encountered in §5.1, for which the decision set K is the n-
dimensional simplex ∆n = {x ∈Rn
+ | P
i xi = 1}. In this special case, the
projection according to the negative entropy becomes scaling by the ℓ1 norm
(left as an exercise), which implies that both update rules amount to the
same algorithm:
xt+1(i) =
xt(i) · e−η∇t(i)
Pn
j=1 xt(j) · e−η∇t(j) ,
which is exactly the Hedge algorithm! The general theorem we shall prove",N/A,N/A
"henceforth recovers the O(√T log n) bound for prediction from expert advice
for this algorithm.
5.3
Technical background: regularization functions
In the rest of this chapter we analyze the mirrored descent algorithm. For
this purpose, consider regularization functions, denoted R : K 7→R, which
are strongly convex and smooth (recall deﬁnitions in §2.1).
Although it is not strictly necessary, we assume that the regularization",N/A,N/A
"functions in this chapter are twice diﬀerentiable over K and, for all points
x ∈int(K) in the interior of the decision set, have a Hessian ∇2R(x) that
is, by the strong convexity of R, positive deﬁnite.
We denote the diameter of the set K relative to the function R as
DR =
r
max
x,y∈K{R(x) −R(y)}
58
CHAPTER 5. REGULARIZATION
Henceforth we make use of general norms and their dual. The dual norm
to a norm ∥· ∥is given by the following deﬁnition:
∥y∥∗≜max
∥x∥≤1⟨x, y⟩",N/A,N/A
"∥y∥∗≜max
∥x∥≤1⟨x, y⟩
A positive deﬁnite matrix A gives rise to the matrix norm ∥x∥A =
√
x⊤Ax.
The dual norm of a matrix norm is ∥x∥∗
A = ∥x∥A−1.
The generalized Cauchy-Schwarz theorem asserts ⟨x, y⟩≤∥x∥∥y∥∗and
in particular for matrix norms, ⟨x, y⟩≤∥x∥A∥y∥∗
A.
In our derivations, we usually consider matrix norms with respect to
∇2R(x), the Hessian of the regularization function R(x). In such cases, we
use the notation
∥x∥y ≜∥x∥∇2R(y)
and similarly
∥x∥∗
y ≜∥x∥∇−2R(y)",N/A,N/A
"∥x∥y ≜∥x∥∇2R(y)
and similarly
∥x∥∗
y ≜∥x∥∇−2R(y)
A crucial quantity in the analysis with regularization is the remainder
term of the Taylor approximation of the regularization function, and es-
pecially the remainder term of the ﬁrst order Taylor approximation. The
diﬀerence between the value of the regularization function at x and the value
of the ﬁrst order Taylor approximation is known as the Bregman divergence,
given by
Deﬁnition 5.6. Denote by BR(x||y) the Bregman divergence with respect",N/A,N/A
"to the function R, deﬁned as
BR(x||y) = R(x) −R(y) −∇R(y)⊤(x −y)
For twice diﬀerentiable functions, Taylor expansion and the mean-value
theorem assert that the Bregman divergence is equal to the second derivative
at an intermediate point, i.e., (see exercises)
BR(x||y) = 1
2∥x −y∥2
z,
for some point z ∈[x, y], meaning there exists some α ∈[0, 1] such that
z = αx+(1−α)y. Therefore, the Bregman divergence deﬁnes a local norm,
which has a dual norm. We shall denote this dual norm by
∥· ∥∗",N/A,N/A
"∥· ∥∗
x,y ≜∥· ∥∗
z.
5.4. REGRET BOUNDS FOR MIRRORED DESCENT
59
With this notation we have
BR(x||y) = 1
2∥x −y∥2
x,y.
In online convex optimization, we commonly refer to the Bregman divergence
between two consecutive decision points xt and xt+1.
In such cases, we
shorthand notation for the norm deﬁned by the Bregman divergence with
respect to R on the intermediate point in [xt, xt+1] as ∥· ∥t ≜∥· ∥xt,xt+1.
The latter norm is called the local norm at iteration t. With this notation,",N/A,N/A
"we have BR(xt||xt+1) = 1
2∥xt −xt+1∥2
t .
Finally, we consider below generalized projections that use the Bregman
divergence as a distance instead of a norm. Formally, the projection of a
point y according to the Bregman divergence with respect to function R is
given by
arg min
x∈K
BR(x||y)
5.4
Regret bounds for Mirrored Descent
In this subsection we prove regret bounds for the agile version of the RFTL
algorithm. The analysis is quite diﬀerent than the one for the lazy version,",N/A,N/A
"and of independent interest.
Theorem 5.7. The RFTL Algorithm 8 attains for every u ∈K the following
bound on the regret:
regretT ≤2η
T
X
t=1
∥∇t∥∗2
t + R(u) −R(x1)
η
.
If an upper bound on the local norms is known, i.e. ∥∇t∥∗
t ≤GR for all
times t, then we can further optimize over the choice of η to obtain
regretT ≤2DRGR
√
2T.
Proof. Since the functions ft are convex, for any x∗∈K,
ft(xt) −ft(x∗) ≤∇ft(xt)⊤(xt −x∗).
60
CHAPTER 5. REGULARIZATION",N/A,N/A
"60
CHAPTER 5. REGULARIZATION
The following property of Bregman divergences follows easily from the def-
inition: for any vectors x, y, z,
(x −y)⊤(∇R(z) −∇R(y)) = BR(x, y) −BR(x, z) + BR(y, z).
Combining both observations,
2(ft(xt) −ft(x∗)) ≤2∇ft(xt)⊤(xt −x∗)
= 1
η(∇R(yt+1) −∇R(xt))⊤(x∗−xt)
= 1
η[BR(x∗, xt) −BR(x∗, yt+1) + BR(xt, yt+1)]
≤1
η[BR(x∗, xt) −BR(x∗, xt+1) + BR(xt, yt+1)]
where the last inequality follows from the generalized Pythagorean inequality",N/A,N/A
"(see [15] Lemma 11.3), as xt+1 is the projection w.r.t the Bregman divergence
of yt+1 and x∗∈K is in the convex set. Summing over all iterations,
2regret
≤
1
η[BR(x∗, x1) −BR(x∗, xT )] +
T
X
t=1
1
ηBR(xt, yt+1)
≤
1
ηD2 +
T
X
t=1
1
ηBR(xt, yt+1)
(5.1)
We proceed to bound BR(xt, yt+1). By deﬁnition of Bregman divergence,
and the generalized Cauchy-Schwartz inequality,
BR(xt, yt+1) + BR(yt+1, xt) = (∇R(xt) −∇R(yt+1))⊤(xt −yt+1)
= η∇ft(xt)⊤(xt −yt+1)
≤η∥∇ft(xt)∥∗∥xt −yt+1∥
≤1
2η2G2
∗+ 1",N/A,N/A
"≤η∥∇ft(xt)∥∗∥xt −yt+1∥
≤1
2η2G2
∗+ 1
2∥xt −yt+1∥2.
where in the last inequality follows from (a−b)2 ≥0. Thus, by our assump-
tion BR(x, y) ≥1
2∥x −y∥2, we have
BR(xt, yt+1) ≤1
2η2G2
∗+ 1
2∥xt −yt+1∥2 −BR(yt+1, xt) ≤1
2η2G2
∗.
Plugging back into Equation (5.1), and by non-negativity of the Bregman
divergence, we get
regret ≤1
2[1
ηD2 + 1
2ηTG2
∗] ≤DG∗
√
T ,
5.4. REGRET BOUNDS FOR MIRRORED DESCENT
61
by taking η =
D
2
√
TG∗
62
CHAPTER 5. REGULARIZATION
5.5
Exercises
1.",N/A,N/A
"TG∗
62
CHAPTER 5. REGULARIZATION
5.5
Exercises
1.
(a) Show that the dual norm to a matrix norm given by A ≻0
corresponds to the matrix norm of A−1.
(b) Prove the generalized Cauchy-Schwarz inequality for any norm,
i.e.,
⟨x, y⟩≤∥x∥∥y∥∗
2. Prove that the Bregman divergence is equal to the local norm at an
intermediate point, that is:
BR(x||y) = 1
2∥x −y∥2
z,
where z ∈[x, y] and the interval [x, y] is deﬁned as
[x, y] = {v = αx + (1 −α)y , α ∈[0, 1]}
3. Let R(x) = 1",N/A,N/A
"3. Let R(x) = 1
2∥x−x0∥2 be the (shifted) Euclidean regularization func-
tion.
Prove that the corresponding Bregman divergence is the Eu-
clidean metric. Conclude that projections with respect to this diver-
gence are standard Euclidean projections.
4. Prove that both agile and lazy versions of the OMD meta-algorithm
are equivalent in the case that the regularization is Euclidean and the
decision set is the Euclidean ball.
5. For this problem the decision set is the n-dimensional simplex. Let",N/A,N/A
"R(x) = x log x be the negative entropy regularization function. Prove
that the corresponding Bregman divergence is the relative entropy,
and prove that the diameter DR of the n-dimensional simplex with
respect to this function is bounded by log n. Show that projections
with respect to this divergence over the simplex amounts to scaling by
the ℓ1 norm.
6. ∗A set K ⊆Rd is symmetric if x ∈K implies −x ∈K. Symmetric
sets gives rise to a natural deﬁnition of a norm. Deﬁne the function",N/A,N/A
"∥· ∥K : Rd 7→R as
∥x∥K = arg min
α>0
 1
αx ∈K

Prove that ∥· ∥K is a norm if and only if K is convex.
5.6. BIBLIOGRAPHIC REMARKS
63
5.6
Bibliographic Remarks
Regularization in the context of online learning was ﬁrst studied in [26]
and [48]. The inﬂuential paper of Kalai and Vempala [45] coined the term
“follow-the-leader” and introduced many of the techniques that followed
in OCO. The latter paper studies random perturbation as a regularization",N/A,N/A
"and analyzes the follow-the-perturbed-leader algorithm, following an early
development by [29] that was overlooked in learning for many years.
In the context of OCO, the term follow-the-regularized-leader was coined
in [73, 71], and at roughly the same time an essentially identical algorithm
was called “RFTL” in [1]. The equivalence of RFTL and Online Mirrored
Descent was observed by [34].
64
CHAPTER 5. REGULARIZATION
Chapter 6
Adaptive Regularization",N/A,N/A
"Chapter 6
Adaptive Regularization
In the previous chapter we have studied a geometric extension of online /
stochastic / determinisitic gradient descent. The technique to achieve it is
called regularization, and we have seen how for the problem of prediction
from expert advice, it can potentially given exponential improvements in
the dependence on the dimension.
A natural question that arises is whether we can automatically learn the",N/A,N/A
"optimal regularization, i.e. best algorithm from the mirrored-descent class,
for the problem at hand?
The answer is positive in a strong sense: it is theoretically possible to
learn the optimal regularization online and in a data-speciﬁc way. Not only
that, the resulting algorithms exhibit the most signiﬁcant speedups in train-
ing deep neural networks from all accelerations studied thus far.
6.1
Adaptive Learning Rates: Intuition",N/A,N/A
"6.1
Adaptive Learning Rates: Intuition
The intuition for adaptive regularization is simple: consider an optimization
problem which is axis-aligned, in which each coordinate is independent of
the rest. It is reasonable to ﬁne tune the learning rate for each coordinate
separately - to achieve optimal convergence in that particular subspace of
the problem, independently of the rest.
Thus, it is reasonable to change the SGD update rule from xt+1 ←
xt −η∇t, to the more robust
xt+1 ←xt −Dt∇t,",N/A,N/A
"xt −η∇t, to the more robust
xt+1 ←xt −Dt∇t,
where Dt is a diagonal matrix that contains in coordinate (i, i) the learning
rate for coordinate i in the gradient.
Recall from the previous sections
65
66
CHAPTER 6. ADAPTIVE REGULARIZATION
that the optimal learning rate for stochastic non-convex optimization is of
the order O( 1
√
t). More precisely, in Theorem 3.4, we have seen that this
learning rate should be on the order of O(
1
√
tσ2 ), where σ2 is the variance of",N/A,N/A
"1
√
tσ2 ), where σ2 is the variance of
the stochastic gradients. The empirical estimator of the latter is P
i<t ∥∇i∥2.
Thus, the robust version of stochastic gradient descent for smooth non-
convex optimization should behave as the above equation, with
Dt(i, i) =
1
pP
i<t ∇t(i)2 .
This is exactly the diagonal version of the AdaGrad algorithm! We continue
to rigorously derive it and prove its performance guarantee.
6.2
A Regularization Viewpoint",N/A,N/A
"6.2
A Regularization Viewpoint
In the previous chapter we have introduced regularization as a general
methodology for deriving online convex optimization algorithms. Theorem
5.7 bounds the regret of the Mirrored Descent algorithm for any strongly
convex regularizer as
regretT ≤max
u∈K
s
2
X
t
∥∇t∥∗2
t BR(u||x1).
In addition, we have seen how to derive the online gradient descent and the
multiplicative weights algorithms as special cases of the RFTL methodology.",N/A,N/A
"We consider the following question: thus far we have thought of R as
a strongly convex function. But which strongly convex function should we
choose to minimize regret? This is a deep and diﬃcult question which has
been considered in the optimization literature since its early developments.
The ML approach is to learn the optimal regularization online. That is,
a regularizer that adapts to the sequence of cost functions and is in a sense",N/A,N/A
"the “optimal” regularization to use in hindsight. We formalize this in the
next section.
6.3
Tools from Matrix Calculus
Many of the inequalities that we are familiar with for positive real numbers
hold for positive semi-deﬁnite matrices as well.
We henceforth need the
following inequality, which is left as an exercise,
6.4. THE ADAGRAD ALGORITHM AND ITS ANALYSIS
67
Proposition 6.1. For positive deﬁnite matrices A ≽B ≻0:
2Tr((A −B)1/2) + Tr(A−1/2B) ≤2Tr(A1/2).",N/A,N/A
"2Tr((A −B)1/2) + Tr(A−1/2B) ≤2Tr(A1/2).
Next, we require a structural result which explicitly gives the optimal
regularization as a function of the gradients of the cost functions. For a
proof see the exercises.
Proposition 6.2. Let A ≽0. The minimizer of the following minimization
problem:
min
X
Tr(X−1A)
subject to X ≽0
Tr(X) ≤1,
is X = A1/2/Tr(A1/2), and the minimum objective value is Tr2(A1/2).
6.4
The AdaGrad Algorithm and Its Analysis",N/A,N/A
"6.4
The AdaGrad Algorithm and Its Analysis
To be more formal, let us consider the set of all strongly convex regulariza-
tion functions with a ﬁxed and bounded Hessian in the set
∀x ∈K . ∇2R(x) = ∇2 ∈H ≜{X ∈Rn×n ; Tr(X) ≤1 , X ≽0}
The set H is a restricted class of regularization functions (which does not
include the entropic regularization). However, it is a general enough class
to capture online gradient descent along with any rotation of the Euclidean
regularization.",N/A,N/A
"regularization.
Algorithm 9 AdaGrad (Full Matrix version)
1: Input: parameters η, x1 ∈K.
2: Initialize: S0 = G0 = 0,
3: for t = 1 to T do
4:
Predict xt, suﬀer loss ft(xt).
5:
Update:
St = St−1 + ∇t∇⊤
t , Gt = St1/2
yt+1 = xt −ηG−1
t ∇t
xt+1 = arg min
x∈K
∥yt+1 −x∥2
Gt
6: end for
68
CHAPTER 6. ADAPTIVE REGULARIZATION
The problem of learning the optimal regularization has given rise to Algo-
rithm 9, known as the AdaGrad (Adaptive subGradient method) algorithm.",N/A,N/A
"In the algorithm deﬁnition and throughout this chapter, the notation A−1
refers to the Moore-Penrose pseudoinverse of the matrix A. Perhaps sur-
prisingly, the regret of AdaGrad is at most a constant factor larger than the
minimum regret of all RFTL algorithm with regularization functions whose
Hessian is ﬁxed and belongs to the class H. The regret bound on AdaGrad
is formally stated in the following theorem.
Theorem 6.3. Let {xt} be deﬁned by Algorithm 9 with parameters η = D,
where
D = max",N/A,N/A
"where
D = max
u∈K ∥u −x1∥2.
Then for any x⋆∈K,
regretT (AdaGrad) ≤2D
s
min
H∈H
X
t
∥∇t∥∗2
H .
Before proving this theorem, notice that it delivers on one of the promised
accounts: comparing to the bound of Theorem 5.7 and ignoring the diameter
D and dimensionality, the regret bound is as good as the regret of RFTL
for the class of regularization functions.
We proceed to prove Theorem 6.3. First, a direct corollary of Proposition
6.2 is that
Corollary 6.4.
s
min
H∈H
X
t
∥∇t∥∗2
H
=
q",N/A,N/A
"Corollary 6.4.
s
min
H∈H
X
t
∥∇t∥∗2
H
=
q
minH∈H Tr(H−1 P
t ∇t∇⊤
t )
= Tr
qP
t ∇t∇⊤
t = Tr(GT )
Hence, to prove Theorem 6.3, it suﬃces to prove the following lemma.
Lemma 6.5.
regretT (AdaGrad) ≤2DTr(GT ) = 2D
s
min
H∈H
X
t
∥∇t∥∗2
H .
Proof. By the deﬁnition of yt+1:
yt+1 −x⋆= xt −x⋆−ηGt−1∇t,
(6.1)
6.4. THE ADAGRAD ALGORITHM AND ITS ANALYSIS
69
and
Gt(yt+1 −x⋆) = Gt(xt −x⋆) −η∇t.
(6.2)
Multiplying the transpose of (6.1) by (6.2) we get
(yt+1 −x⋆)⊤Gt(yt+1 −x⋆) =
(xt−x⋆)⊤Gt(xt−x⋆) −2η∇⊤",N/A,N/A
"(yt+1 −x⋆)⊤Gt(yt+1 −x⋆) =
(xt−x⋆)⊤Gt(xt−x⋆) −2η∇⊤
t (xt−x⋆) + η2∇⊤
t G−1
t ∇t.
(6.3)
Since xt+1 is the projection of yt+1 in the norm induced by Gt, we have (see
§2.1.1)
(yt+1 −x⋆)⊤Gt(yt+1 −x⋆) = ∥yt+1 −x⋆∥2
Gt ≥∥xt+1 −x⋆∥2
Gt.
This inequality is the reason for using generalized projections as opposed
to standard projections, which were used in the analysis of online gradient
descent (see §4.4 Equation (4.2)). This fact together with (6.3) gives
∇⊤
t (xt−x⋆) ≤η
2∇⊤
t G−1
t ∇t + 1
2η
 ∥xt −x⋆∥2",N/A,N/A
"∇⊤
t (xt−x⋆) ≤η
2∇⊤
t G−1
t ∇t + 1
2η
 ∥xt −x⋆∥2
Gt −∥xt+1 −x⋆∥2
Gt

.
Now, summing up over t = 1 to T we get that
T
X
t=1
∇⊤
t (xt −x⋆) ≤η
2
T
X
t=1
∇⊤
t G−1
t ∇t + 1
2η∥x1 −x⋆∥2
G0
(6.4)
+ 1
2η
T
X
t=1

∥xt −x⋆∥2
Gt −∥xt −x⋆∥2
Gt−1

−1
2η∥xT+1 −x⋆∥2
GT
≤η
2
T
X
t=1
∇⊤
t G−1
t ∇t + 1
2η
T
X
t=1
(xt−x⋆)⊤(Gt −Gt−1)(xt−x⋆).
In the last inequality we use the fact that G0 = 0. We proceed to bound
each of the terms above separately.
Lemma 6.6. With St, Gt as deﬁned in Algorithm 9,
T
X
t=1
∇⊤",N/A,N/A
"T
X
t=1
∇⊤
t G−1
t ∇t ≤2
T
X
t=1
∇⊤
t G−1
T ∇t ≤2Tr(GT ).
Proof. We prove the lemma by induction. The base case follows since
∇⊤
1 G−1
1 ∇1 = Tr(G−1
1 ∇1∇⊤
1 )
= Tr(G−1
1 G2
1)
= Tr(G1).
70
CHAPTER 6. ADAPTIVE REGULARIZATION
Assuming the lemma holds for T −1, we get by the inductive hypothesis
T
X
t=1
∇⊤
t G−1
t ∇t ≤2Tr(GT−1) + ∇⊤
T G−1
T ∇T
= 2Tr((G2
T −∇T ∇⊤
T )1/2) + Tr(G−1
T ∇T ∇⊤
T )
≤2Tr(GT ).
Here, the last inequality is due to the matrix inequality 6.1.
Lemma 6.7.
T
X
t=1",N/A,N/A
"Lemma 6.7.
T
X
t=1
(xt−x⋆)⊤(Gt −Gt−1)(xt−x⋆) ≤D2Tr(GT ).
Proof. By deﬁnition St ≽St−1, and hence Gt ≽Gt−1. Thus,
T
X
t=1
(xt−x⋆)⊤(Gt −Gt−1)(xt−x⋆)
≤
T
X
t=1
D2λmax(Gt −Gt−1)
≤D2
T
X
t=1
Tr(Gt −Gt−1)
A ≽0 ⇒λmax(A) ≤Tr(A)
= D2
T
X
t=1
(Tr(Gt) −Tr(Gt−1))
linearity of the trace
≤D2Tr(GT ).
Plugging both lemmas into Equation (6.4), we obtain
T
X
t=1
∇⊤
t (xt −x⋆) ≤ηTr(GT ) + 1
2ηD2Tr(GT ) ≤2DTr(GT ).
6.5. DIAGONAL ADAGRAD
71
6.5
Diagonal AdaGrad",N/A,N/A
"6.5. DIAGONAL ADAGRAD
71
6.5
Diagonal AdaGrad
The AdaGrad algorithm maintains potentially dense matrices, and requires
the computation of the square root of these matrices. This is usually pro-
hibitive in machine learning applications in which the dimension is very
large.
Fortunately, the same ideas can be applied with almost no com-
putational overhead on top of vanilla SGD, using the diagonal version of
AdaGrad given by:
Algorithm 10 AdaGrad (diagonal version)
1: Input: parameters η, x1 ∈K.",N/A,N/A
"1: Input: parameters η, x1 ∈K.
2: Initialize: S0 = G0 = 0,
3: for t = 1 to T do
4:
Predict xt, suﬀer loss ft(xt).
5:
Update:
St = St−1 + diag(∇t∇⊤
t ), Gt = St1/2
yt+1 = xt −ηG−1
t ∇t
xt+1 = arg min
x∈K
∥yt+1 −x∥2
Gt
6: end for
In contrast to the full-matrix version, this version can be implemented in
linear time and space, since diagonal matrices can be manipulated as vectors.
Thus, memory overhead is only a single d-dimensional vector, which is used",N/A,N/A
"to represent the diagonal preconditioning (regularization) matrix, and the
computational overhead is a few vector manipulations per iteration.
Very similar to the full matrix case, the diagonal AdaGrad algorithm
can be analyzed and the following performance bound obtained:
Theorem 6.8. Let {xt} be deﬁned by Algorithm 10 with parameters η =
D∞, where
D∞= max
u∈K ∥u −x1∥∞,
and let diag(H) be the set of all diagonal matrices in H.
Then for any
x⋆∈K,
regretT (D-AdaGrad) ≤2D∞
s
min
H∈diag(H)
X
t",N/A,N/A
"regretT (D-AdaGrad) ≤2D∞
s
min
H∈diag(H)
X
t
∥∇t∥∗2
H .
72
CHAPTER 6. ADAPTIVE REGULARIZATION
6.6
State-of-the-art: from Adam to Shampoo and
beyond
Since the introduction of the adaptive regularization technique in the con-
text of regret minimization, several improvements were introduced that now
compose state-of-the-art. A few notable advancements include:
AdaDelta: The algorithm keeps an exponential average of past gradients and uses
that in the update step.",N/A,N/A
"that in the update step.
Adam: Adds a sliding window to AdaGrad, as well as adding a form of mo-
mentum via estimating the second moments of past gradients and
adjusting the update accordingly.
Shampoo: Interpolates between full-matrix and diagonal adagrad in the context
of deep neural networks: use of the special layer structure to reduce
memory constraints.
AdaFactor: Suggests a Shampoo-like approach to reduce memory footprint even
further, to allow the training of huge models.",N/A,N/A
"further, to allow the training of huge models.
GGT: While full-matrix AdaGrad is computationally slow due to the cost
of manipulating matrices, this algorithm uses recent gradients (a thin
matrix G), and via linear algebraic manipulations reduces computa-
tion by never computing GG⊤, but rather only G⊤G, which is low
dimensional.
SM3 , ET: Diagonal AdaGrad requires an extra O(n) memory to store diag(Gt).
These algorithms, inspired by AdaFactor, approximate Gt as a low",N/A,N/A
"rank tensor to save memory and computation.
6.7. EXERCISES
73
6.7
Exercises
1. ∗Prove that for positive deﬁnite matrices A ≽B ≻0 it holds that
(a) A1/2 ≽B1/2
(b) 2Tr((A −B)1/2) + Tr(A−1/2B) ≤2Tr(A1/2).
2. ∗Consider the following minimization problem where A ≻0:
min
X
Tr(X−1A)
subject to
X ≻0
Tr(X) ≤1.
Prove that its minimizer is given by X = A1/2/Tr(A1/2), and the
minimum is obtained at Tr2(A1/2).
74
CHAPTER 6. ADAPTIVE REGULARIZATION
6.8
Bibliographic Remarks",N/A,N/A
"6.8
Bibliographic Remarks
The AdaGrad algorithm was introduced in [19, 18], its diagonal version
was also discovered in parallel in [52]. Adam [46] and RMSprop [39] are
widely used methods based on adaptive regularization. A cleaner analysis
was recently proposed in [27], see also [17].
Adaptive regularization has received much attention recently, see e.g.,
[60, 85]. Newer algorithmic developments on adaptive regularization include",N/A,N/A
"Shampoo [28], GGT [3], AdaFactor [77], Extreme Tensoring [16] and SM3
[6].
Chapter 7
Variance Reduction
In the previous chapter we have studied the ﬁrst of our three acceleration
techniques over SGD, adaptive regularization, which is a geometric tool for
acceleration. In this chapter we introduce the second ﬁrst-order accelera-
tion technique, called variance reduction. This technique is probabilistic in
nature, and applies to more restricted settings of mathematical optimiza-",N/A,N/A
"tion in which the objective function has a ﬁnite-sum structure. Namely, we
consider optimization problems of the form
min
x∈K f(x) , f(x) = 1
m
m
X
i=1
fi(x) .
(7.1)
Such optimization problems are canonical in training of ML models, con-
vex and non-convex. However, in the context of machine learning we should
remember that the ultimate goal is generalization rather than training.
7.1
Variance reduction: Intuition
The intuition for variance reduction is simple, and comes from trying to",N/A,N/A
"improve the naive convergence bounds for SGD that we have covered in the
ﬁrst lesson.
Recall the SGD update rule xt+1 ←xt−η ˆ∇t, in which ˆ∇t is an unbiased
estimator for the gradient such that
E[ ˆ∇t] = ∇t , E[∥ˆ∇t∥2
2] ≤σ2.
We have seen in Theorem 3.4, that for this update rule,
E
""
1
T
X
t
∥∇t∥2
#
≤2
r
Mβσ2
T
.
75
76
CHAPTER 7. VARIANCE REDUCTION
The convergence is proportional to the second moment of the gradient esti-
mator, and thus it makes sense to try to reduce this second moment. The",N/A,N/A
"variance reduction technique attempts to do so by using the average of all
previous gradients, as we show next.
7.2
Setting and deﬁnitions
We consider the ERM optimization problem over an average of loss func-
tions. Before we begin, we need a few preliminaries and assumptions:
1. We denote distance to optimality according to function value as
ht = f(xt) −f(x∗),
and in the k’th epoch of an algorithm, we denote hk
t = f(xk
t ) −f(x∗).
2. We denote ˜hk = max

4hk
0 , 8αD2
k
	
over an epoch.",N/A,N/A
"
4hk
0 , 8αD2
k
	
over an epoch.
3. Assume all stochastic gradients have bounded second moments
∥ˆ
∇t∥2
2 ≤σ2.
4. We will assume that the individual functions fi in formulation (7.1)
are also ˆβ-smooth and have ˆβ-Lipschitz gradient, namely
∥∇fi(x) −∇fi(y)∥≤ˆβ∥x −y∥.
5. We will use, proved in Lemma 2.3, that for β-smooth and α-strongly
convex f we have
ht ≥1
2β ∥∇t∥2
and
α
2 d2
t = α
2 ∥xt −x∗∥2 ≤ht ≤1
2α∥∇t∥2.
6. Recall that a function f is γ-well-conditioned if it is β-smooth, α-",N/A,N/A
"strongly convex and γ ≤α
β .
7.3. THE VARIANCE REDUCTION ADVANTAGE
77
7.3
The variance reduction advantage
Consider gradient descent for γ-well conditioned functions, and speciﬁcally
used for ML training as in formulation (7.1) . It is well known that GD
attains linear convergence rate as we now prove for completeness:
Theorem 7.1. For unconstrained minimization of γ-well-conditioned func-
tions and ηt = 1
β, the Gradient Descent Algorithm 2 converges as
ht+1 ≤h1e−γt.
Proof.",N/A,N/A
"ht+1 ≤h1e−γt.
Proof.
ht+1 −ht = f(xt+1) −f(xt)
≤∇⊤
t (xt+1 −xt) + β
2 ∥xt+1 −xt∥2
β-smoothness
= −ηt∥∇t∥2 + β
2 η2
t ∥∇t∥2
algorithm defn.
= −1
2β ∥∇t∥2
choice of ηt = 1
β
≤−α
β ht.
by (2.1)
Thus,
ht+1 ≤ht(1 −α
β ) ≤· · · ≤h1(1 −γ)t ≤h1e−γt
where the last inequality follows from 1 −x ≤e−x for all x ∈R.
However, what is the overall computational cost? Assuming that we can
compute the gradient of each loss function corresponding to the individual",N/A,N/A
"training examples in O(d) time, the overall running time to compute the
gradient is O(md).
In order to attain approximation ε to the objective, the algorithm re-
quires O( 1
γ log 1
ε) iterations, as per the Theorem above. Thus, the overall
running time becomes O(md
γ log 1
ε). As we show below, variance reduction
can reduce this running time to be O((m+ 1
˜γ2 )d log 1
ε), where ˜γ is a diﬀerent
condition number for the same problem, that is in general smaller than the",N/A,N/A
"original. Thus, in one line, the variance reduction advantage can be sum-
marized as:
md
γ log 1
ε 7→(m + 1
˜γ2 )d log 1
ε .
78
CHAPTER 7. VARIANCE REDUCTION
7.4
A simple variance-reduced algorithm
The following simple variance-reduced algorithm illustrates the main ideas
of the technique.
The algorithm is a stochastic gradient descent variant
which proceeds in epochs. Strong convexity implies that the distance to the
optimum shrinks with function value, so it is safe to decrease the distance",N/A,N/A
"upper bound every epoch.
The main innovation is in line 7, which constructs the gradient estimator.
Instead of the usual trick - which is to sample one example at random - here
the estimator uses the entire gradient computed at the beginning of the
current epoch.
Algorithm 11 Epoch GD
1: Input: f, T, x1
0 ∈K, upper bound D1 ≥∥x1
0 −x∗∥, step sizes {ηt}
2: for k = 1 to log 1
ε do
3:
Let BDk(xk
0) be the ball of radius Dk around xk
0.
4:
compute full gradient ∇k
0 = ∇f(xk
0)
5:
for t = 1 to T do",N/A,N/A
"0 = ∇f(xk
0)
5:
for t = 1 to T do
6:
Sample it ∈[m] uniformly at random, let ft = fit.
7:
construct stochastic gradient ˆ∇k
t = ∇ft(xk
t ) −∇ft(xk
0) + ∇k
0
8:
Let yk
t+1 = xk
t −ηt ˆ∇k
t , xt+1 = ΠBDk(xk
0) (yt+1)
9:
end for
10:
Set xk+1
0
= 1
T
PT
t=1 xk
t . Dk+1 ←Dk/2.
11: end for
12: return x0
T+1
The main guarantee for this algorithm is the following theorem, which
delivers upon the aforementioned improvement,
Theorem 7.2. Algorithm 11 returns an ε-approximate solution to optimiza-",N/A,N/A
"tion problem (7.1) in total time
O

m + 1
˜γ2

d log 1
ε

.
Let ˜γ = α
ˆβ < γ. Then the proof of this theorem follows from the following
lemma.
Lemma 7.3. For T = ˜O

1
˜γ2

, we have
E[˜hk+1] ≤1
2
˜hk.
7.4. A SIMPLE VARIANCE-REDUCED ALGORITHM
79
Proof. As a ﬁrst step, we bound the variance of the gradients. Due to the
fact that xk
t ∈BDk(xk
0), we have that for k′ > k, ∥xk
t −xk′
t ∥2 ≤4D2
k. Thus,
∥ˆ∇k
t ∥2
= ∥∇ft(xk
t ) −∇ft(xk
0) + ∇f(xk
0)∥2
deﬁnition
≤2∥∇ft(xk
t ) −∇ft(xk",N/A,N/A
"0) + ∇f(xk
0)∥2
deﬁnition
≤2∥∇ft(xk
t ) −∇ft(xk
0)∥2 + 2∥∇f(xk
0)∥2
(a + b)2 ≤2a2 + 2b2
≤2ˆβ2∥xk
t −xk
0∥2 + 4βhk
0
smoothness
≤8ˆβ2D2
k + 4βhk
0
projection step
≤ˆβ2 1
α˜hk + 4βhk
0 ≤˜hk(
ˆβ2
α + β)
Next, using the regret bound for strongly convex functions, we have
E[hk+1
0
]
≤E[ 1
T
P
t hk
t ]
Jensen
≤
1
αT E[P
t
1
t ∥ˆ∇k
t ∥2]
Theorem 4.4
≤
1
αT
P
t
1
t ˜hk(
ˆβ2
α + β)
above
≤log T
T ˜hk( 1
˜γ2 + 1
γ )
˜γ = α
ˆβ
Which implies the Lemma by choice of T, deﬁnition of ˜hk = max

4hk
0 , 8αD2
k",N/A,N/A
"
4hk
0 , 8αD2
k
	
,
and exponential decrease of Dk.
The expectation is over the stochastic gradient deﬁnition, and is required
for using Theorem 4.4.
To obtain the theorem from the lemma above, we need to strengthen
it to a high probability statement using a martingale argument.
This is
possible since the randomness in construction of the stochastic gradients is
i.i.d.
The lemma now implies the theorem by noting that O(log 1
ε) epochs",N/A,N/A
"ε) epochs
suﬃces to get ε-approximation. Each epoch requires the computation of one
full gradient, in time O(md), and ˜O( 1
˜γ2 ) iterations that require stochastic
gradient computation, in time O(d).
80
CHAPTER 7. VARIANCE REDUCTION
7.5
Bibliographic Remarks
The variance reduction technique was ﬁrst introduced as part of the SAG
algorithm [70]. Since then a host of algorithms were developed using the
technique. The simplest exposition of the technique was given in [44]. The",N/A,N/A
"exposition in this chapter is developed from the Epoch GD algorithm [37],
which uses a related technique for stochastic strongly convex optimization,
as developed in [86].
Chapter 8
Nesterov Acceleration
In previous chapters we have studied our bread and butter technique, SGD,
as well as two acceleration techniques of adaptive regularization and variance
reduction.
In this chapter we study the historically earliest acceleration",N/A,N/A
"technique, known as Nesterov acceleration, or simply “acceleration”.
For smooth and convex functions, Nesterov acceleration improves the
convergence rate to optimality to O( 1
T 2 ), a quadratic improvement over
vanilla gradient descent. Similar accelerations are possible when the func-
tion is also strongly convex: an accelerated rate of e−√γT , where γ is the
condition number, vs. e−γT of vanilla gradient descent. This improvement
is theoretically very signiﬁcant.",N/A,N/A
"is theoretically very signiﬁcant.
However, in terms of applicability, Nesterov acceleration is theoretically
the most restricted in the context of machine learning: it requires a smooth
and convex objective. More importantly, the learning rates of this method
are very brittle, and the method is not robust to noise. Since noise is pre-
dominant in machine learning, the theoretical guarantees in stochastic op-
timization environments are very restricted.",N/A,N/A
"timization environments are very restricted.
However, the heuristic of momentum, which historically inspired acceler-
ation, is extremely useful for non-convex stochastic optimization (although
not known to yield signiﬁcant improvements in theory).
8.1
Algorithm and implementation
Nesterov acceleration applies to the general setting of constrained smooth
convex optimization:
min
x∈Rd f(x).
(8.1)
81
82
CHAPTER 8. NESTEROV ACCELERATION",N/A,N/A
"(8.1)
81
82
CHAPTER 8. NESTEROV ACCELERATION
For simplicity of presentation, we restrict ourselves to the unconstrained
convex and smooth case.
Nevertheless, the method can be extended to
constrained smooth convex, and potentially strongly convex, settings.
The simple method presented in Algorithm 12 below is computationally
equivalent to gradient descent.
The only overhead is saving three state
vectors (that can be reduced to two) instead of one for gradient descent.",N/A,N/A
"The following simple accelerated algorithm illustrates the main ideas of the
technique.
Algorithm 12 Simpliﬁed Nesterov Acceleration
1: Input: f, T, initial point x0, parameters η, β, τ.
2: for t = 1 to T do
3:
Set xt+1 = τzt + (1 −τ)yt, and denote ∇t+1 = ∇f(xt+1).
4:
Let yt+1 = xt+1 −1
β∇t+1
5:
Let zt+1 = zt −η∇t+1
6: end for
7: return ¯x = 1
T
P
t xt
8.2
Analysis
The main guarantee for this algorithm is the following theorem.",N/A,N/A
"Theorem 8.1. Algorithm 12 converges to an ε-approximate solution to op-
timization problem (8.1) in O( 1
√ε) iterations.
The proof starts with the following lemma which follows from our earlier
standard derivations.
Lemma 8.2.
η∇⊤
t+1(zt −x∗) ≤2η2β(f(xt+1) −f(yt+1)) +

∥zt −x∗∥2 −∥zt+1 −x∗∥2
.
Proof. The proof is very similar to that of Theorem 4.2. By deﬁnition of zt,
1
∥zt+1 −x∗∥2
= ∥zt −η∇t+1 −x∗∥2
= ∥zt −x∗∥2 −η∇⊤
t+1(zt −x∗) + η2∥∇t+1∥2
≤∥zt −x∗∥2 −η∇⊤",N/A,N/A
"t+1(zt −x∗) + η2∥∇t+1∥2
≤∥zt −x∗∥2 −η∇⊤
t+1(zt −x∗) + 2η2β(f(xt+1) −f(yt+1))
Lemma 2.3 part 3
1Henceforth we use Lemma 2.3 part 3.
This proof of this Lemma shows that for
y = x −1
β ∇f(x), it holds that f(x) −f(y) ≥
1
2β ∥∇f(x)∥2.
8.2. ANALYSIS
83
Lemma 8.3. For 2ηβ = 1−τ
τ , we have that
η∇⊤
t+1(xt+1 −x∗) ≤2η2β(f(yt) −f(yt+1)) +

∥zt −x∗∥2 −∥zt+1 −x∗∥2
.
Proof.
η∇⊤
t+1(xt+1 −x∗) −η∇⊤
t+1(zt −x∗)
= η∇⊤
t+1(xt+1 −zt)
= (1−τ)η
τ
∇⊤
t+1(yt −xt+1)
τ(xt+1 −zt) = (1 −τ)(yt −xt+1)
≤(1−τ)η
τ",N/A,N/A
"τ(xt+1 −zt) = (1 −τ)(yt −xt+1)
≤(1−τ)η
τ
(f(yt) −f(xt+1)).
convexity
Thus, in combination with Lemma 8.2, and the condition of the Lemma, we
get the inequality.
We can now sketch the proof of the main theorem.
Proof. Telescope Lemma 8.3 for all iterations to obtain:
ThT
= T(f(¯x) −f(x∗))
≤P
t ∇⊤
t (xt −x∗)
≤2ηβ P
t(f(yt) −f(yt+1)) + 1
η
P
t

∥zt −x∗∥2 −∥zt+1 −x∗∥2
≤2ηβ(f(y1) −f(yT+1)) + 1
η

∥z1 −x∗∥2 −∥zT+1 −x∗∥2
≤√2βh1D,
optimizing η",N/A,N/A
"η

∥z1 −x∗∥2 −∥zT+1 −x∗∥2
≤√2βh1D,
optimizing η
where h1 is an upper bound on the distance f(y1) −f(x∗), and D bounds
the Euclidean distance of zt to the optimum. Thus, we get a recurrence of
the form
hT ≤
√h1
T
.
Restarting Algorithm 12 and adapting the learning rate according to hT
gives a rate of convergence of O( 1
T 2 ) to optimality.
84
CHAPTER 8. NESTEROV ACCELERATION
8.3
Bibliographic Remarks
Accelerated rates of order O( 1
T 2 ) were obtained by Nemirovski as early as",N/A,N/A
"T 2 ) were obtained by Nemirovski as early as
the late seventies. The ﬁrst practically eﬃcient accelerated algorithm is due
to Nesterov [56] , see also [57]. The simpliﬁed proof presented hereby is due
to [5].
Chapter 9
The conditional gradient
method
In many computational and learning scenarios the main bottleneck of opti-
mization, both online and oﬄine, is the computation of projections onto the
underlying decision set (see §2.1.1). In this chapter we discuss projection-free",N/A,N/A
"methods in convex optimization, and some of their applications in machine
learning.
The motivating example throughout this chapter is the problem of ma-
trix completion, which is a widely used and accepted model in the con-
struction of recommendation systems. For matrix completion and related
problems, projections amount to expensive linear algebraic operations and
avoiding them is crucial in big data applications.
Henceforth we describe the conditional gradient algorithm, also known as",N/A,N/A
"the Frank-Wolfe algorithm. Afterwards, we describe problems for which lin-
ear optimization can be carried out much more eﬃciently than projections.
We conclude with an application to exploration in reinforcement learning.
9.1
Review: relevant concepts from linear algebra
This chapter addresses rectangular matrices, which model applications such
as recommendation systems naturally. Consider a matrix X ∈Rn×m. A
non-negative number σ ∈R+ is said to be a singular value for X if there are",N/A,N/A
"two vectors u ∈Rn, v ∈Rm such that
X⊤u = σv,
Xv = σu.
85
86
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD
The vectors u, v are called the left and right singular vectors respectively.
The non-zero singular values are the square roots of the eigenvalues of the
matrix XX⊤(and X⊤X). The matrix X can be written as
X = UΣV ⊤, U ∈Rn×ρ , V ⊤∈Rρ×m,
where ρ = min{n, m}, the matrix U is an orthogonal basis of the left singular
vectors of X, the matrix V is an orthogonal basis of right singular vectors,",N/A,N/A
"and Σ is a diagonal matrix of singular values. This form is called the singular
value decomposition for X.
The number of non-zero singular values for X is called its rank, which
we denote by k ≤ρ. The nuclear norm of X is deﬁned as the ℓ1 norm of its
singular values, and denoted by
∥X∥∗=
ρ
X
i=1
σi
It can be shown (see exercises) that the nuclear norm is equal to the trace
of the square root of the matrix times its transpose, i.e.,
∥X∥∗= Tr(
√
X⊤X)",N/A,N/A
"∥X∥∗= Tr(
√
X⊤X)
We denote by A • B the inner product of two matrices as vectors in Rn×m,
that is
A • B =
n
X
i=1
m
X
j=1
AijBij = Tr(AB⊤)
9.2
Motivation: matrix completion and recommen-
dation systems
Media recommendations have changed signiﬁcantly with the advent of the
Internet and rise of online media stores. The large amounts of data collected
allow for eﬃcient clustering and accurate prediction of users’ preferences
for a variety of media.
A well-known example is the so called “Netﬂix",N/A,N/A
"A well-known example is the so called “Netﬂix
challenge”—a competition of automated tools for recommendation from a
large dataset of users’ motion picture preferences.
One of the most successful approaches for automated recommendation
systems, as proven in the Netﬂix competition, is matrix completion. Perhaps
the simplest version of the problem can be described as follows.
The entire dataset of user-media preference pairs is thought of as a",N/A,N/A
"partially-observed matrix. Thus, every person is represented by a row in
9.2. MOTIVATION
87
the matrix, and every column represents a media item (movie). For sim-
plicity, let us think of the observations as binary—a person either likes or
dislikes a particular movie. Thus, we have a matrix M ∈{0, 1, ∗}n×m where
n is the number of persons considered, m is the number of movies at our
library, and 0/1 and ∗signify “dislike”, “like” and “unknown” respectively:
Mij =











0,",N/A,N/A
"Mij =











0,
person i dislikes movie j
1,
person i likes movie j
∗,
preference unknown
.
The natural goal is to complete the matrix, i.e. correctly assign 0 or 1 to
the unknown entries. As deﬁned so far, the problem is ill-posed, since any
completion would be equally good (or bad), and no restrictions have been
placed on the completions.
The common restriction on completions is that the “true” matrix has
low rank. Recall that a matrix X ∈Rn×m has rank k < ρ = min{n, m} if",N/A,N/A
"and only if it can be written as
X = UV , U ∈Rn×k, V ∈Rk×m.
The intuitive interpretation of this property is that each entry in M
can be explained by only k numbers.
In matrix completion this means,
intuitively, that there are only k factors that determine a persons preference
over movies, such as genre, director, actors and so on.
Now the simplistic matrix completion problem can be well-formulated
as in the following mathematical program. Denote by ∥· ∥OB the Euclidean",N/A,N/A
"norm only on the observed (non starred) entries of M, i.e.,
∥X∥2
OB =
X
Mij̸=∗
X2
ij.
The mathematical program for matrix completion is given by
min
X∈Rn×m
1
2∥X −M∥2
OB
s.t.
rank(X) ≤k.
Since the constraint over the rank of a matrix is non-convex, it is stan-
dard to consider a relaxation that replaces the rank constraint by the nuclear
norm. It is known that the nuclear norm is a lower bound on the matrix
88
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD",N/A,N/A
"88
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD
rank if the singular values are bounded by one (see exercises). Thus, we
arrive at the following convex program for matrix completion:
min
X∈Rn×m
1
2∥X −M∥2
OB
(9.1)
s.t.
∥X∥∗≤k.
We consider algorithms to solve this convex optimization problem next.
9.3
The Frank-Wolfe method
In this section we consider minimization of a convex function over a convex
domain.
The conditional gradient (CG) method, or Frank-Wolfe algorithm, is a",N/A,N/A
"simple algorithm for minimizing a smooth convex function f over a convex
set K ⊆Rn. The appeal of the method is that it is a ﬁrst order interior point
method - the iterates always lie inside the convex set, and thus no projections
are needed, and the update step on each iteration simply requires minimizing
a linear objective over the set. The basic method is given in Algorithm 13.
Algorithm 13 Conditional gradient
1: Input: step sizes {ηt ∈(0, 1], t ∈[T]}, initial point x1 ∈K.",N/A,N/A
"2: for t = 1 to T do
3:
vt ←arg minx∈K

x⊤∇f(xt)
	
.
4:
xt+1 ←xt + ηt(vt −xt).
5: end for
Note that in the CG method, the update to the iterate xt may be not be
in the direction of the gradient, as vt is the result of a linear optimization
procedure in the direction of the negative gradient.
This is depicted in
Figure 9.1.
The following theorem gives an essentially tight performance guarantee
of this algorithm over smooth functions. Recall our notation from Chapter",N/A,N/A
"2: x⋆denotes the global minimizer of f over K, D denotes the diameter of
the set K, and ht = f(xt)−f(x⋆) denotes the suboptimality of the objective
value in iteration t.
Theorem 9.1. The CG algorithm applied to β-smooth functions with step
sizes ηt = min{2H
t , 1}, for H ≥max{1, h1}, attains the following conver-
gence guarantee:
ht ≤2βHD2
t
9.3. THE FRANK-WOLFE METHOD
89
Figure 9.1: Direction of progression of the conditional gradient algorithm.",N/A,N/A
"Proof. As done before in this manuscript, we denote ∇t = ∇f(xt), and also
denote H ≥max{h1, 1}, such that ηt = min{2H
t , 1}. For any set of step
sizes, we have
f(xt+1) −f(x⋆) = f(xt + ηt(vt −xt)) −f(x⋆)
≤f(xt) −f(x⋆) + ηt(vt −xt)⊤∇t + η2
t
β
2 ∥vt −xt∥2
β-smoothness
≤f(xt) −f(x⋆) + ηt(x⋆−xt)⊤∇t + η2
t
β
2 ∥vt −xt∥2
vt optimality
≤f(xt) −f(x⋆) + ηt(f(x⋆) −f(xt)) + η2
t
β
2 ∥vt −xt∥2
convexity of f
≤(1 −ηt)(f(xt) −f(x⋆)) + η2
t β
2 D2.
(9.2)
90
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD",N/A,N/A
"90
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD
We reached the recursion ht+1 ≤(1 −ηt)ht + η2
t
βD2
2 , and by induction,
ht+1 ≤(1 −ηt)ht + η2
t
βD2
2
≤(1 −ηt)2βHD2
t
+ η2
t
βD2
2
induction hypothesis
≤(1 −2H
t )2βHD2
t
+ 4H2
t2
βD2
2
value of ηt
= 2βHD2
t
−2H2βD2
t2
≤2βHD2
t
(1 −1
t )
since H ≥1
≤2βHD2
t + 1 .
t−1
t
≤
t
t+1
9.4
Projections vs. linear optimization
The conditional gradient (Frank-Wolfe) algorithm described before does not",N/A,N/A
"resort to projections, but rather computes a linear optimization problem of
the form
arg min
x∈K
n
x⊤u
o
.
(9.3)
When is the CG method computationally preferable? The overall compu-
tational complexity of an iterative optimization algorithm is the product
of the number of iterations and the computational cost per iteration. The
CG method does not converge as well as the most eﬃcient gradient descent
algorithms, meaning it requires more iterations to produce a solution of a",N/A,N/A
"comparable level of accuracy. However, for many interesting scenarios the
computational cost of a linear optimization step (9.3) is signiﬁcantly lower
than that of a projection step.
Let us point out several examples of problems for which we have very eﬃ-
cient linear optimization algorithms, whereas our state-of-the-art algorithms
for computing projections are signiﬁcantly slower.
Recommendation systems and matrix prediction.
In the example",N/A,N/A
"In the example
pointed out in the preceding section of matrix completion, known methods
9.4. PROJECTIONS VS. LINEAR OPTIMIZATION
91
for projection onto the spectahedron, or more generally the bounded nuclear-
norm ball, require singular value decompositions, which take superlinear
time via our best known methods. In contrast, the CG method requires
maximal eigenvector computations which can be carried out in linear time
via the power method (or the more sophisticated Lanczos algorithm).",N/A,N/A
"Network routing and convex graph problems.
Various routing and
graph problems can be modeled as convex optimization problems over a
convex set called the ﬂow polytope.
Consider a directed acyclic graph with m edges, a source node marked
s and a target node marked t. Every path from s to t in the graph can be
represented by its identifying vector, that is a vector in {0, 1}m in which the
entries that are set to 1 correspond to edges of the path. The ﬂow polytope",N/A,N/A
"of the graph is the convex hull of all such identifying vectors of the simple
paths from s to t. This polytope is also exactly the set of all unit s–t ﬂows
in the graph if we assume that each edge has a unit ﬂow capacity (a ﬂow
is represented here as a vector in Rm in which each entry is the amount of
ﬂow through the corresponding edge).
Since the ﬂow polytope is just the convex hull of s–t paths in the graph,
minimizing a linear objective over it amounts to ﬁnding a minimum weight",N/A,N/A
"path given weights for the edges. For the shortest path problem we have
very eﬃcient combinatorial optimization algorithms, namely Dijkstra’s al-
gorithm.
Thus, applying the CG algorithm to solve any convex optimization prob-
lem over the ﬂow polytope will only require iterative shortest path compu-
tations.
Ranking and permutations.
A common way to represent a permutation
or ordering is by a permutation matrix.
Such are square matrices over",N/A,N/A
"Such are square matrices over
{0, 1}n×n that contain exactly one 1 entry in each row and column.
Doubly-stochastic matrices are square, real-valued matrices with non-
negative entries, in which the sum of entries of each row and each column
amounts to 1.
The polytope that deﬁnes all doubly-stochastic matrices
is called the Birkhoﬀ-von Neumann polytope. The Birkhoﬀ-von Neumann
theorem states that this polytope is the convex hull of exactly all n × n
permutation matrices.",N/A,N/A
"permutation matrices.
Since a permutation matrix corresponds to a perfect matching in a fully
connected bipartite graph, linear minimization over this polytope corre-
sponds to ﬁnding a minimum weight perfect matching in a bipartite graph.
92
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD
Consider a convex optimization problem over the Birkhoﬀ-von Neumann
polytope.
The CG algorithm will iteratively solve a linear optimization
problem over the BVN polytope, thus iteratively solving a minimum weight",N/A,N/A
"perfect matching in a bipartite graph problem, which is a well-studied com-
binatorial optimization problem for which we know of eﬃcient algorithms.
In contrast, other gradient based methods will require projections, which
are quadratic optimization problems over the BVN polytope.
Matroid polytopes.
A matroid is pair (E, I) where E is a set of elements
and I is a set of subsets of E called the independent sets which satisfy vari-",N/A,N/A
"ous interesting proprieties that resemble the concept of linear independence
in vector spaces. Matroids have been studied extensively in combinatorial
optimization and a key example of a matroid is the graphical matroid in
which the set E is the set of edges of a given graph and the set I is the set of
all subsets of E which are cycle-free. In this case, I contains all the spanning
trees of the graph. A subset S ∈I could be represented by its identifying",N/A,N/A
"vector which lies in {0, 1}|E| which also gives rise to the matroid polytope
which is just the convex hull of all identifying vectors of sets in I. It can
be shown that some matroid polytopes are deﬁned by exponentially many
linear inequalities (exponential in |E|), which makes optimization over them
diﬃcult.
On the other hand, linear optimization over matroid polytopes is easy
using a simple greedy procedure which runs in nearly linear time. Thus, the",N/A,N/A
"CG method serves as an eﬃcient algorithm to solve any convex optimization
problem over matroids iteratively using only a simple greedy procedure.
9.5. EXERCISES
93
9.5
Exercises
1. Prove that if the singular values are smaller than or equal to one, then
the nuclear norm is a lower bound on the rank, i.e., show
rank(X) ≥∥X∥∗.
2. Prove that the trace is related to the nuclear norm via
∥X∥∗= Tr(
√
XX⊤) = Tr(
√
X⊤X).
3. Show that maximizing a linear function over the spectahedron is equiv-",N/A,N/A
"alent to a maximal eigenvector computation. That is, show that the
following mathematical program:
min X • C
X ∈Sd = {X ∈Rd×d , X ≽0 , Tr(X) ≤1},
is equivalent to the following:
min
x∈Rd x⊤Cx
s.t. ∥x∥2 ≤1.
4. Download the MovieLens dataset from the web. Implement an online
recommendation system based on the matrix completion model: im-
plement the OCG and OGD algorithms for matrix completion. Bench-
mark your results.
94
CHAPTER 9. THE CONDITIONAL GRADIENT METHOD
9.6
Bibliographic Remarks",N/A,N/A
"9.6
Bibliographic Remarks
The matrix completion model has been extremely popular since its inception
in the context of recommendation systems [80, 66, 69, 50, 14, 75].
The conditional gradient algorithm was devised in the seminal paper
by Frank and Wolfe [21]. Due to the applicability of the FW algorithm to
large-scale constrained problems, it has been a method of choice in recent
machine learning applications, to name a few: [42, 49, 41, 20, 30, 36, 72, 7,
82, 22, 23, 8].",N/A,N/A
"82, 22, 23, 8].
The online conditional gradient algorithm is due to [36]. An optimal
regret algorithm, attaining the O(
√
T) bound, for the special case of poly-
hedral sets was devised in [23].
Chapter 10
Second order methods for
machine learning
At this point in our course, we have exhausted the main techniques in
ﬁrst-order (or gradient-based) optimization.
We have studied the main
workhorse - stochastic gradient descent, the three acceleration techniques,",N/A,N/A
"and projection-free gradient methods. Have we exhausted optimization for
ML?
In this section we discuss using higher derivatives of the objective func-
tion to accelerate optimization. The canonical method is Newton’s method,
which involves the second derivative or Hessian in high dimensions. The
vanilla approach is computationally expensive since it involves matrix inver-
sion in high dimensions that machine learning problems usually require.",N/A,N/A
"However, recent progress in random estimators gives rise to linear-time
second order methods, for which each iteration is as computationally cheap
as gradient descent.
10.1
Motivating example: linear regression
In the problem of linear regression we are given a set of measurements {ai ∈
Rd, bi ∈R}, and the goal is to ﬁnd a set of weights that explains them best
in the mean squared error sense. As a mathematical program, the goal is to
optimize:
min
x∈Rd



1
2
X
i∈[m]

a⊤
i x −bi
2


,",N/A,N/A
"min
x∈Rd



1
2
X
i∈[m]

a⊤
i x −bi
2


,
95
96
CHAPTER 10. SECOND ORDER METHODS
or in matrix form,
min
x f(x) =
1
2∥Ax −b∥2

.
Here A ∈Rm×d, b ∈Rm. Notice that the objective function f is smooth,
but not necessarily strongly convex. Therefore, all algorithms that we have
studied so far without exception, which are all ﬁrst order methods, attain
rates which are poly(1
ε).
However, the linear regression problem has a closed form solution that",N/A,N/A
"can be computed by taking the gradient to be zero, i.e. (Ax −b)⊤A = 0,
which gives
x = (A⊤A)−1A⊤b.
The Newton direction is given by the inverse Hessian multiplied by the
gradient, ∇−2f(x)∇f(x). Observe that a single Newton step, i.e. moving in
the Newton direction with step size one, from any direction gets us directly
to the optimal solution in one iteration! (see exercises)
More generally, Newton’s method yields O(log 1
ε) convergence rates for",N/A,N/A
"ε) convergence rates for
a large class of functions without dependence on the condition number of
the function! We study this property next.
10.2
Self-Concordant Functions
In this section we deﬁne and collect some of the properties of a special class
of functions, called self-concordant functions. These functions allow New-
ton’s method to run in time which is independent of the condition number.
The class of self-concordant functions is expressive and includes quadratic",N/A,N/A
"functions, logarithms of inner products, a variety of barriers such as the log
determinant, and many more.
An excellent reference for this material is the lecture notes on this subject
by Nemirovski [55]. We begin by deﬁning self-concordant functions.
Deﬁnition 10.1 (Self-Concordant Functions). Let K ⊆Rn be a non-empty
open convex set, and and let f : K 7→R be a C3 convex function. Then, f
is said to be self-concordant if
|∇3f(x)[h, h, h]| ≤2(h⊤∇2f(x)h)3/2,
where we have",N/A,N/A
"|∇3f(x)[h, h, h]| ≤2(h⊤∇2f(x)h)3/2,
where we have
∇kf(x)[h1, . . . , hk] ≜
∂k
∂t1 . . . ∂tk
|t1=···=tkf(x + t1h1 + · · · + tkhk).
10.2. NEWTON’S METHOD
97
Another key object in the analysis of self concordant functions is the
notion of a Dikin Ellipsoid, which is the unit ball around a point in the
norm given by the Hessian ∥· ∥∇2f at the point. We will refer to this norm
as the local norm around a point and denote it as ∥· ∥x. Formally,",N/A,N/A
"Deﬁnition 10.2 (Dikin ellipsoid). The Dikin ellipsoid of radius r centered
at a point x is deﬁned as
Er(x) ≜{y | ∥y −x∥∇2f(x) ≤r}
One of the key properties of self-concordant functions that we use is that
inside the Dikin ellipsoid, the function is well conditioned with respect to
the local norm at the center. The next lemma makes this formal. The proof
of this lemma can be found in [55].
Lemma 10.3 (See [55]). For all h such that ∥h∥x < 1 we have that
(1 −∥h∥x)2∇2f(x) ⪯∇2f(x + h) ⪯
1",N/A,N/A
"(1 −∥h∥x)2∇2f(x) ⪯∇2f(x + h) ⪯
1
(1 −∥h∥x)2 ∇2f(x)
Another key quantity, which is used both as a potential function as well
as a dampening for the step size in the analysis of Newton’s method, is the
Newton Decrement:
λx ≜∥∇f(x)∥∗
x =
q
∇f(x)⊤∇−2f(x)∇f(x).
The following lemma quantiﬁes how λx behaves as a potential by showing
that once it drops below 1, it ensures that the minimum of the function lies
in the current Dikin ellipsoid. This is the property which we use crucially",N/A,N/A
"in our analysis. The proof can be found in [55].
Lemma 10.4 (See [55]). If λx < 1 then
∥x −x∗∥x ≤
λx
1 −λx
10.3
Newton’s method for self-concordant func-
tions
Before introducing the linear time second order methods, we start by intro-
ducing a robust Newton’s method and its properties. The pseudo-code is
given in Algorithm 14.
98
CHAPTER 10. SECOND ORDER METHODS
The usual analysis of Newton’s method allows for quadratic convergence,
i.e. error ε in O(log log 1",N/A,N/A
"i.e. error ε in O(log log 1
ε) iterations for convex objectives. However, we
prefer to present a version of Newton’s method which is robust to certain
random estimators of the Newton direction. This yields a slower rate of
O(log 1
ε).
The faster running time per iteration, which does not require
matrix manipulations, more than makes up for this.
Algorithm 14 Robust Newton’s method
Input: T, x1
for t = 1 to T do
Set c = 1
8, η = min{c,
c
8λxt }. Let 1
2∇−2f(xt) ⪯˜∇−2
t
⪯2∇−2f(xt).",N/A,N/A
"c
8λxt }. Let 1
2∇−2f(xt) ⪯˜∇−2
t
⪯2∇−2f(xt).
xt+1 = xt −η ˜∇−2
t ∇f(xt)
end for
return xT+1
It is important to notice that every two consecutive points are within
the same Dikin ellipsoid of radius 1
2. Denote ∇t = ∇xt, and similarly for
the Hessian. Then we have:
∥xt −xt+1∥2
xt = η2∇⊤
t ˜∇−2
t ∇2
t ˜∇−2
t ∇t ≤4η2λ2
t ≤1
2.
The advantage of Newton’s method as applied to self-concordant func-
tions is its linear convergence rate, as given in the following theorem.",N/A,N/A
"Theorem 10.5. Let f be self-concordant, and f(x1) ≤M, then
ht = f(xt) −f(x∗) ≤O(M + log 1
ε)
The proof of this theorem is composed of two steps, according to the
magnitude of the Newton decrement.
Phase 1: damped Newton
Lemma 10.6. As long as λx ≥1
8, we have that
ht ≤−1
4c
10.3. NEWTON’S METHOD FOR SELF-CONCORDANT FUNCTIONS99
Proof. Using similar analysis to the descent lemma we have that
f(xt+1) −f(xt)
≤∇⊤
t (xt+1 −xt) + 1
2(xt −xt+1)⊤∇2(ζ)(xt −xt+1)
Taylor
≤∇⊤
t (xt+1 −xt) + 1",N/A,N/A
"Taylor
≤∇⊤
t (xt+1 −xt) + 1
4(xt −xt+1)⊤∇2(xt)(xt −xt+1)
xt+1 ∈E1/2(xt)
= −η∇⊤
t ˜∇−2
t ∇t + 1
4η2∇⊤
t ˜∇−2
t ∇2
t ˜∇−2
t ∇t
= −ηλ2
t + 1
4η2λ2
t ≤−1
16c
The conclusion from this step is that after O(M) steps, Algorithm 14
reaches a point for which λx ≤1
8. According to Lemma 10.4, we also have
that ∥x −x∗∥x ≤1
4, that is, the optimum is in the same Dikin ellipsoid as
the current point.
Phase 2: pure Newton
In the second phase our step size is changed to",N/A,N/A
"In the second phase our step size is changed to
be larger. In this case, we are guaranteed that the Newton decrement is less
than one, and thus we know that the global optimum is in the same Dikin
ellipsoid as the current point. In this ellipsoid, all Hessians are equivalent
up to a factor of two, and thus Mirrored-Descent with the inverse Hessian
as preconditioner becomes gradient descent. We make this formal below.
Algorithm 15 Preconditioned Gradient Descent
Input: P, T
for t = 1 to T do",N/A,N/A
"Input: P, T
for t = 1 to T do
xt+1 = xt −ηP −1∇f(xt)
end for
return xT+1
Lemma 10.7. Suppose that 1
2P ⪯∇2f(x) ⪯2P, and ∥x1 −x∗∥P ≤1
2, then
Algorithm 15 converges as
ht+1 ≤h1e−1
8 t.
This theorem follows from noticing that the function g(z) = f(P −1/2x)
is 1
2-strongly convex and 2-smooth, and using Theorem 3.2. It can be shown
that gradient descent on g is equivalent to Newton’s method in f. Details
are left as an exercise.
An immediate corollary is that Newton’s method converges at a rate of",N/A,N/A
"O(log 1
ε) in this phase.
100
CHAPTER 10. SECOND ORDER METHODS
10.4
Linear-time second-order methods
Newton’s algorithm is of foundational importance in the study of mathemat-
ical programming in general. A major application are interior point methods
for convex optimization, which are the most important polynomial-time al-
gorithms for general constrained convex optimization.
However, the main downside of this method is the need to maintain and",N/A,N/A
"manipulate matrices - namely the Hessians. This is completely impractical
for machine learning applications in which the dimension is huge.
Another signiﬁcant downside is the non-robust nature of the algorithm,
which makes applying it in stochastic environments challenging.
In this section we show how to apply Newton’s method to machine
learning problems.
This involves relatively new developments that allow
for linear-time per-iteration complexity, similar to SGD, and theoretically",N/A,N/A
"superior running times.
At the time of writing, however, these methods
are practical only for convex optimization, and have not shown superior
performance on optimization tasks involving deep neural networks.
The ﬁrst step to developing a linear time Newton’s method is an eﬃcient
stochastic estimator for the Newton direction, and the Hessian inverse.
10.4.1
Estimators for the Hessian Inverse
The key idea underlying the construction is the following well known fact",N/A,N/A
"about the Taylor series expansion of the matrix inverse.
Lemma 10.8. For a matrix A ∈Rd×d such that A ⪰0 and ∥A∥≤1, we
have that
A−1 =
∞
X
i=0
(I −A)i
We propose two unbiased estimators based on the above series. To deﬁne
the ﬁrst estimator pick a probability distribution over non-negative integers
{pi} and sample ˆi from the above distribution. Let X1, . . . Xˆi be independent
samples of the Hessian ∇2f and deﬁne the estimator as
Deﬁnition 10.9 (Estimator 1).
˜∇−2f = 1
pˆi
ˆiY
j=1
(I −Xj)",N/A,N/A
"˜∇−2f = 1
pˆi
ˆiY
j=1
(I −Xj)
10.4. LINEAR-TIME SECOND-ORDER METHODS
101
Observe that our estimator of the Hessian inverse is unbiased, i.e. E[ ˆX] =
∇−2f at any point. Estimator 1 has the disadvantage that in a single sample
it incorporates only one term of the Taylor series.
The second estimator below is based on the observation that the above
series has the following succinct recursive deﬁnition, and is more eﬃcient.
For a matrix A deﬁne
A−1
j
=
j
X
i=0
(I −A)i",N/A,N/A
"For a matrix A deﬁne
A−1
j
=
j
X
i=0
(I −A)i
i.e. the ﬁrst j terms of the above Taylor expansion. It is easy to see that
the following recursion holds for A−1
j
A−1
j
= I + (I −A)A−1
j−1
Using the above recursive formulation, we now describe an unbiased
estimator of ∇−2f by deriving an unbiased estimator ˜∇−2fj for ∇−2fj.
Deﬁnition 10.10 (Estimator 2). Given j independent and unbiased samples
{X1 . . . Xj} of the hessian ∇2f. Deﬁne { ˜∇−2f0 . . . ˜∇−2fj} recursively as
follows
˜∇−2f0 = I",N/A,N/A
"follows
˜∇−2f0 = I
˜∇−2ft = I + (I −Xj) ˜∇−2ft−1
It can be readily seen that E[ ˜∇−2fj] = ∇−2fj and therefore E[ ˜∇−2fj] →
∇−2f as j →∞giving us an unbiased estimator in the limit.
10.4.2
Incorporating the estimator
Both of the above estimators can be computed using only Hessian-vector
products, rather than matrix manipulations. For many machine learning
problems, Hessian-vector products can be computed in linear time. Exam-
ples include:",N/A,N/A
"ples include:
1. Convex regression and SVM objectives over training data have the
form
min
w f(w) = E
i [ℓ(w⊤xi)],
where ℓis a convex function. The Hessian can thus be written as
∇2f(w) = E
i [ℓ′′(w⊤xi)xix⊤
i ]
102
CHAPTER 10. SECOND ORDER METHODS
Thus, the ﬁrst Newton direction estimator can now be written as
˜∇2f(w)∇w = E
j∼D[
jY
i=1
(I −ℓ′′(w⊤xi)xix⊤
i )]∇w.
Notice that this estimator can be computed using j vector-vector prod-
ucts if the ordinal j was randomly chosen.",N/A,N/A
"ucts if the ordinal j was randomly chosen.
2. Non-convex optimization over neural networks: a similar derivation as
above shows that the estimator can be computed only using Hessian-
vector products. The special structure of neural networks allow this
computation in a constant number of backpropagation steps, i.e. linear
time in the network size, this is called the “Pearlmutter trick”, see [61].
We note that non-convex optimization presents special challenges for",N/A,N/A
"second order methods, since the Hessian need not be positive semi-
deﬁnite.
Nevertheless, the techniques presented hereby can still be
used to provide theoretical speedups for second order methods over
ﬁrst order methods in terms of convergence to local minima.
The
details are beyond our scope, and can be found in [2].
Putting everything together.
These estimators we have studied can
be used to create unbiased estimators to the Newton direction of the form
˜∇−2
x ∇x for ˜∇−2
x
which satisﬁes
1",N/A,N/A
"˜∇−2
x ∇x for ˜∇−2
x
which satisﬁes
1
2∇−2f(xt) ⪯˜∇−2
t
⪯2∇−2f(xt).
These can be incorporated into Algorithm 14, which we proved is capable
of obtaining fast convergence with approximate Newton directions of this
form.
10.5. EXERCISES
103
10.5
Exercises
1. Prove that a single Newton step for linear regression yields the optimal
solution.
2. Let f : Rd 7→R, and consider the aﬃne transformation y = Ax, for
A ∈Rd×d being a symmetric matrix. Prove that
yt+1 ←yt −η∇f(yt)
is equivalent to",N/A,N/A
"yt+1 ←yt −η∇f(yt)
is equivalent to
xt+1 ←xt −ηA−2∇f(xt).
3. Prove that the function g(z) deﬁned in phase 2 of the robust Newton
algorithm is 1
2-strongly convex and 2-smooth. Conclude with a proof
of Theorem 10.7.
104
CHAPTER 10. SECOND ORDER METHODS
10.6
Bibliographic Remarks
The modern application of Newton’s method to convex optimization was
put forth in the seminal work of Nesterov and Nemirovski [58] on interior
point methods. A wonderful exposition is Nemirovski’s lecture notes [55].",N/A,N/A
"The fact that Hessian-vector products can be computed in linear time
for feed forward neural networks was described in [61]. Linear time second
order methods for machine learning and the Hessian-vector product model
in machine learning was introduced in [4]. This was extended to non-convex
optimization for deep learning in [2].
Chapter 11
Hyperparameter
Optimization
Thus far in this class, we have been talking about continuous mathematical",N/A,N/A
"optimization, where the search space of our optimization problem is continu-
ous and mostly convex. For example, we have learned about how to optimize
the weights of a deep neural network, which take continuous real values, via
various optimization algorithms (SGD, AdaGrad, Newton’s method, etc.).
However, in the process of training a neural network, there are some meta
parameters, which we call hyperparameters, that have a profound eﬀect on",N/A,N/A
"the ﬁnal outcome. These are global, mostly discrete, parameters that are
treated diﬀerently by algorithm designers as well as by engineers. Examples
include the architecture of the neural network (number of layers, width of
each layer, type of activation function, ...), the optimization scheme for up-
dating weights (SGD/AdaGrad, initial learning rate, decay rate of learning
rate, momentum parameter, ...), and many more. Roughly speaking, these",N/A,N/A
"hyperparameters are chosen before the training starts.
The purpose of this chapter is to formalize this problem as an optimiza-
tion problem in machine learning, which requires a diﬀerent methodology
than we have treated in the rest of this course. We remark that hyperpa-
rameter optimization is still an active area of research and its theoretical
properties are not well understood as of this time.
11.1
Formalizing the problem
What makes hyperparameters diﬀerent from “regular” parameters?
105",N/A,N/A
"105
106
CHAPTER 11. HYPERPARAMETER OPTIMIZATION
1. The search space is often discrete (for example, number of layers). As
such, there is no natural notion of gradient or diﬀerentials and it is
not clear how to apply the iterative methods we have studied thus far.
2. Even evaluating the objective function is extremely expensive (think
of evaluating the test error of the trained neural network). Thus it is
crucial to minimize the number of function evaluations, whereas other",N/A,N/A
"computations are signiﬁcantly less expensive.
3. Evaluating the function can be done in parallel. As an example, train-
ing feedforward deep neural networks over diﬀerent architectures can
be done in parallel.
More formally, we consider the following optimization problem
min
xi∈GF(qi)
f(x),
where x is the representation of discrete hyperparameters, each taking value
from qi ≥2 possible discrete values and thus in GF(q), the Galois ﬁeld of",N/A,N/A
"order q. The example to keep in mind is that the objective f(x) is the test
error of the neural network trained with hyperparameters x. Note that x
has a search space of size Q
i qi ≥2n, exponentially large in the number of
diﬀerent hyperparameters.
11.2
Hyperparameter optimization algorithms
The properties of the problem mentioned before prohibits the use of the
algorithms we have studied thus far, which are all suitable for continuous",N/A,N/A
"optimization. A naive method is to perform a grid search over all hyperpa-
rameters, but this quickly becomes infeasible. An emerging ﬁeld of research
in recent years, called AutoML, aims to choose hyperparameters automati-
cally. The following techniques are in common use:
• Grid search, try all possible assignments of hyperparameters and
return the best. This becomes infeasible very quickly with n - the
number of hyperparameters.",N/A,N/A
"number of hyperparameters.
• Random search, where one randomly picks some choices of hyper-
parameters, evaluates their function objective, and chooses the one
choice of hyperparameters giving best performance. An advantage of
this method is that it is easy to implement in parallel.
11.3. A SPECTRAL METHOD
107
• Successive Halving and Hyperband, random search combined
with early stopping using multi-armed bandit techniques. These gain
a small constant factor improvement over random search.",N/A,N/A
"• Bayesian optimization, a statistical approach which has a prior over
the objective and tries to iteratively pick an evaluation point which
reduces the variance in objective value.
Finally it picks the point
that attains the lowest objective objective with highest conﬁdence.
This approach is sequential in nature and thus diﬃcult to parallelize.
Another important question is how to choose a good prior.
The hyperparameter optimization problem is essentially a combinato-",N/A,N/A
"rial optimization problem with exponentially large search space. Without
further assumptions, this optimization problem is information-theoretically
hard. Such assumptions are explored in the next section with an accompa-
nying algorithm.
Finally, we note that a simple but hard-to-beat benchmark is random
search with double budget. That is, compare the performance of a method
to that of random search, but allow random search double the query budget
of your own method.
11.3
A Spectral Method",N/A,N/A
"of your own method.
11.3
A Spectral Method
For simplicity, in this section we consider the case in which hyperparam-
eters are binary. This retains the diﬃculty of the setting, but makes the
mathematical derivation simpler. The optimization problem now becomes
min
x∈{−1,1}n
f(x).
(11.1)
The method we describe in this section is inspired by the following key
observation: although the whole search space of hyperparameters is exponen-",N/A,N/A
"tially large, it is often the case in practice that only a few hyperparameters
together play a signiﬁcant role in the performance of a deep neural network.
To make this intuition more precise, we need some deﬁnitions and facts
from Fourier analysis of Boolean functions.
Fact 11.1. Any function f : {−1, 1}n →[−1, 1] can be uniquely represented
in the Fourier basis
f(x) =
X
S⊆[n]
αs ˆχS(x),
108
CHAPTER 11. HYPERPARAMETER OPTIMIZATION
where each Fourier basis function
ˆχS(x) =
Y
i∈S
xi.",N/A,N/A
"ˆχS(x) =
Y
i∈S
xi.
is a monomial, and thus f(x) has a polynomial representation.
Now we are ready to formalize our key observation in the following as-
sumption:
Assumption 11.2. The objective function f in the hyperparameter opti-
mization problem (11.1) is low degree and sparse in the Fourier basis, i.e.
f(x) ≈
X
|S|≤d
αS ˆχS(x),
∥α∥1 ≤k,
(11.2)
where d is the upper bound of polynomial degree, and k is the sparsity of",N/A,N/A
"Fourier coeﬃcient α (indexed by S) in ℓ1 sense (which is a convex relaxation
of ∥α∥0, the true sparsity).
Remark 11.3. Clearly this assumption does not always hold. For example,
many deep reinforcement learning algorithms nowadays rely heavily on the
choice of the random seed, which can also be seen as a hyperparameter. If
x ∈{−1, 1}32 is the bit representation of a int32 random seed, then there is
no reason to assume that a few of these bits should play a more signiﬁcant
role than the others.",N/A,N/A
"role than the others.
Under this assumption, all we need to do now is to ﬁnd out the few im-
portant sets of variables S’s, as well as their coeﬃcients αS’s, in the approx-
imation (11.2). Fortunately, there is already a whole area of research, called
compressed sensing, that aims to recover a high-dimensional but sparse vec-
tor, using only a few linear measurements. Next, we will brieﬂy introduce
the problem of compressed sensing, and one useful result from the litera-",N/A,N/A
"ture. After that, we will introduce the Harmonica algorithm, which applies
compressed sensing techniques to solve the hyperparameter optimization
problem (11.1).
11.3.1
Background: Compressed Sensing
The problem of compressed sensing is as follows. Suppose there is a hidden
signal x ∈Rn that we cannot observe. In order to recover x, we design a
measurement matrix A ∈Rm×n, and obtain noisy linear measurements y =
Ax + η ∈Rm, where η is some random noise. The diﬃculty arises when we",N/A,N/A
"11.3. A SPECTRAL METHOD
109
have a limited budget for measurements, i.e. m ≪n. Note that even without
noise, recovering x is non-trivial since y = Ax is an underdetermined linear
system, therefore if there is one solution x that solves this linear system,
there will be inﬁnitely many solutions. The key to this problem is to assume
that x is k-sparse, that is, ∥x∥0 ≤k. This assumption has been justiﬁed
in various real-world applications; for example, natural images tend to be",N/A,N/A
"sparse in the Fourier/wavelet domain, a property which forms the bases of
many image compression algorithms.
Under the assumption of sparsity, the natural way to recover x is to
solve a least squares problem, subject to some sparsity constraint ∥x∥0 ≤k.
However, ℓ0 norm is diﬃcult to handle, and it is often replaced by ℓ1 norm,
its convex relaxation. One useful result from the literature of compressed
sensing is the following.
Proposition 11.4 (Informal statement of Theorem 4.4 in [63]). Assume",N/A,N/A
"the ground-truth signal x ∈Rn is k-sparse.
Then, with high probability,
using a randomly designed A ∈Rm×n that is “near-orthogonal” (random
Gaussian matrix, subsampled Fourier basis, etc.), with m = O(k log(n)/ε)
and ∥η∥2 = O(√m), x can be recovered by a convex program
min
z∈Rn ∥y −Az∥2
2
s.t.
∥z∥1 ≤k,
(11.3)
with accuracy ∥x −z∥2 ≤ε.
This result is remarkable; in particular, it says that the number of mea-
surements needed to recover a sparse signal is independent of the dimension",N/A,N/A
"n (up to a logarithm term), but only depends on the sparsity k and the
desired accuracy ε. 1
Remark 11.5. The convex program (11.3) is equivalent to the following
LASSO problem
min
z∈Rn ∥y −Az∥2
2 + λ∥z∥1,
with a proper choice of regularization parameter λ. The LASSO problem
is an unconstrained convex program, and has eﬃcient solvers, as per the
algorithms we have studied in this course.
1It also depends on the desired high-probability bound, which is omitted in this informal
statement.
110",N/A,N/A
"statement.
110
CHAPTER 11. HYPERPARAMETER OPTIMIZATION
11.3.2
The Spectral Algorithm
The main idea is that, under Assumption 11.2, we can view the problem
of hyperparameter optimization as recovering the sparse signal α from lin-
ear measurements. More speciﬁcally, we need to query T random samples,
f(x1), . . . , f(xT ), and then solve the LASSO problem
min
α
T
X
t=1
(
X
|S|≤d
αS ˆχS(xt) −f(xt))2 + λ∥α∥1,
(11.4)
where the regularization term λ∥α∥1 controls the sparsity of α. Also note",N/A,N/A
"that the constraint |S| ≤d not only implies that the solution is a low-degree
polynomial, but also helps to reduce the “eﬀective” dimension of α from 2n
to O(nd), which makes it feasible to solve this LASSO problem.
Denote by S1, . . . , Ss the indices of the s largest coeﬃcients of the LASSO
solution, and deﬁne
g(x) =
X
i∈[s]
αSi ˆχSi(x),
which involves only a few dimensions of x since the LASSO solution is sparse
and low-degree.
The next step is to set the variables outside ∪i∈[s]Si to",N/A,N/A
"arbitrary values, and compute a minimizer x∗∈arg min g(x).
In other
words, we have reduced the original problem of optimizing f(x) over n
variables, to the problem of optimizing g(x) (an approximation of f(x))
over only a few variables (which is now feasible to solve). One remarkable
feature of this algorithm is that the returned solution x∗may not belong to
the samples {x1, . . . , xT }, which is not the case for other existing methods
(such as random search).",N/A,N/A
"(such as random search).
Using theoretical results from compressed sensing (e.g.
Proposition
11.4), we can derive the following guarantee for the sparse recovery of α
via LASSO.
Theorem 11.6 (Informal statement of Lemma 7 in [38]). Assume f is k-
sparse in the Fourier expansion. Then, with T = O(k2 log(n)/ε) samples,
the solution of the LASSO problem (11.4) achieves ε accuracy.
Finally, the above derivation can be considered as only one stage in a",N/A,N/A
"multi-stage process, each iteratively setting the value of a few more variables
that are the most signiﬁcant.
11.4. BIBLIOGRAPHIC REMARKS
111
11.4
Bibliographic Remarks
For a nice exposition on hyperparameter optimization see [64, 65], in which
the the benchmark of comparing to Random Search with double queries was
proposed.
Perhaps the simplest approach to HPO is random sampling of diﬀerent
choices of parameters and picking the best amongst the chosen evaluations
[9].",N/A,N/A
"[9].
Successive Halving (SH) algorithm was introduced [43].
Hyperband
further improves SH by automatically tuning the hyperparameters in SH
[51].
The Bayesian optimization (BO) methodology is currently the most stud-
ied in HPO. For recent studies and algorithms of this ﬂavor see [10, 78, 81,
79, 24, 84, 40].
The spectral approach for hyperparameter optimization was introduced
in [38]. For an in-depth treatment of compressed sensing see the survey of",N/A,N/A
"[63], and for Fourier analysis of Boolean functions see [59].
112
CHAPTER 11. HYPERPARAMETER OPTIMIZATION
Bibliography
[1] Jacob Abernethy, Elad Hazan, and Alexander Rakhlin.
Competing
in the dark: An eﬃcient algorithm for bandit linear optimization. In
Proceedings of the 21st Annual Conference on Learning Theory, pages
263–274, 2008.
[2] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and
Tengyu Ma. Finding approximate local minima faster than gradient",N/A,N/A
"descent. In Proceedings of the 49th Annual ACM SIGACT Symposium
on Theory of Computing, pages 1195–1199. ACM, 2017.
[3] Naman Agarwal, Brian Bullins, Xinyi Chen, Elad Hazan, Karan Singh,
Cyril Zhang, and Yi Zhang. The case for full-matrix adaptive regular-
ization. arXiv preprint arXiv:1806.02958, 2018.
[4] Naman Agarwal, Brian Bullins, and Elad Hazan. Second-order stochas-
tic optimization for machine learning in linear time. The Journal of
Machine Learning Research, 18(1):4148–4187, 2017.",N/A,N/A
"Machine Learning Research, 18(1):4148–4187, 2017.
[5] Zeyuan Allen-Zhu and Lorenzo Orecchia.
Linear coupling:
An ul-
timate uniﬁcation of gradient and mirror descent.
arXiv preprint
arXiv:1407.1537, 2014.
[6] Rohan Anil, Vineet Gupta, Tomer Koren, and Yoram Singer. Memory-
eﬃcient adaptive optimization for large-scale learning. arXiv preprint
arXiv:1901.11150, 2019.
[7] Francis Bach, Simon Lacoste-Julien, and Guillaume Obozinski.
On",N/A,N/A
"On
the equivalence between herding and conditional gradient algorithms.
In John Langford and Joelle Pineau, editors, Proceedings of the 29th
International Conference on Machine Learning (ICML-12), ICML ’12,
pages 1359–1366, New York, NY, USA, July 2012. Omnipress.
113
114
BIBLIOGRAPHY
[8] Aur´elien Bellet, Yingyu Liang, Alireza Bagheri Garakani, Maria-
Florina Balcan, and Fei Sha.
Distributed frank-wolfe algorithm: A
uniﬁed framework for communication-eﬃcient sparse learning. CoRR,",N/A,N/A
"abs/1404.2644, 2014.
[9] James Bergstra and Yoshua Bengio.
Random search for hyper-
parameter optimization. J. Mach. Learn. Res., 13:281–305, February
2012.
[10] James S. Bergstra, R´emi Bardenet, Yoshua Bengio, and Bal´azs K´egl.
Algorithms for hyper-parameter optimization. In J. Shawe-Taylor, R. S.
Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems 24, pages 2546–2554.
Curran Associates, Inc., 2011.",N/A,N/A
"Curran Associates, Inc., 2011.
[11] J.M. Borwein and A.S. Lewis. Convex Analysis and Nonlinear Opti-
mization: Theory and Examples. CMS Books in Mathematics. Springer,
2006.
[12] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge Uni-
versity Press, March 2004.
[13] S´ebastien Bubeck. Convex optimization: Algorithms and complexity.
Foundations and Trends in Machine Learning, 8(3–4):231–357, 2015.
[14] E. Candes and B. Recht. Exact matrix completion via convex optimiza-",N/A,N/A
"tion. Foundations of Computational Mathematics, 9:717–772, 2009.
[15] Nicol`o Cesa-Bianchi and G´abor Lugosi.
Prediction, Learning, and
Games. Cambridge University Press, 2006.
[16] Xinyi Chen, Naman Agarwal, Elad Hazan, Cyril Zhang, and Yi Zhang.
Extreme tensoring for low-memory preconditioning.
arXiv preprint
arXiv:1902.04620, 2019.
[17] Qi Deng, Yi Cheng, and Guanghui Lan. Optimal adaptive and accel-
erated stochastic gradient descent. arXiv preprint arXiv:1810.00553,
2018.",N/A,N/A
"2018.
[18] John Duchi, Elad Hazan, and Yoram Singer.
Adaptive subgradient
methods for online learning and stochastic optimization. The Journal
of Machine Learning Research, 12:2121–2159, 2011.
BIBLIOGRAPHY
115
[19] John C. Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient
methods for online learning and stochastic optimization. In COLT 2010
- The 23rd Conference on Learning Theory, Haifa, Israel, June 27-29,
2010, pages 257–269, 2010.",N/A,N/A
"2010, pages 257–269, 2010.
[20] Miroslav Dud´ık, Za¨ıd Harchaoui, and J´erˆome Malick. Lifted coordinate
descent for learning with trace-norm regularization. Journal of Machine
Learning Research - Proceedings Track, 22:327–336, 2012.
[21] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval
Research Logistics Quarterly, 3:149–154, 1956.
[22] Dan Garber and Elad Hazan. Approximating semideﬁnite programs in
sublinear time. In NIPS, pages 1080–1088, 2011.",N/A,N/A
"sublinear time. In NIPS, pages 1080–1088, 2011.
[23] Dan Garber and Elad Hazan.
Playing non-linear games with linear
oracles. In FOCS, pages 420–428, 2013.
[24] Jacob R. Gardner, Matt J. Kusner, Zhixiang Eddie Xu, Kilian Q. Wein-
berger, and John P. Cunningham. Bayesian optimization with inequal-
ity constraints.
In Proceedings of the 31th International Conference
on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014,
pages 937–945, 2014.",N/A,N/A
"pages 937–945, 2014.
[25] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning.
MIT Press, 2016. http://www.deeplearningbook.org.
[26] A .J. Grove, N. Littlestone, and D. Schuurmans. General convergence
results for linear discriminant updates. Machine Learning, 43(3):173–
210, 2001.
[27] Vineet Gupta, Tomer Koren, and Yoram Singer. A uniﬁed approach
to adaptive regularization in online and stochastic optimization. arXiv
preprint arXiv:1706.06569, 2017.",N/A,N/A
"preprint arXiv:1706.06569, 2017.
[28] Vineet Gupta, Tomer Koren, and Yoram Singer. Shampoo: Precondi-
tioned stochastic tensor optimization. arXiv preprint arXiv:1802.09568,
2018.
[29] James Hannan. Approximation to bayes risk in repeated play. In M.
Dresher, A. W. Tucker, and P. Wolfe, editors, Contributions to the
Theory of Games, volume 3, pages 97–139, 1957.
116
BIBLIOGRAPHY
[30] Za¨ıd Harchaoui, Matthijs Douze, Mattis Paulin, Miroslav Dud´ık, and",N/A,N/A
"J´erˆome Malick. Large-scale image classiﬁcation with trace-norm regu-
larization. In CVPR, pages 3386–3393, 2012.
[31] Elad Hazan. Introduction to online convex optimization. Foundations
and Trends ˆA R⃝in Optimization, 2(3-4):157–325, 2016.
[32] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret al-
gorithms for online convex optimization. In Machine Learning, volume
69(2–3), pages 169–192, 2007.
[33] Elad Hazan and Sham Kakade. Revisiting the polyak step size. arXiv",N/A,N/A
"preprint arXiv:1905.00313, 2019.
[34] Elad Hazan and Satyen Kale. Extracting certainty from uncertainty:
Regret bounded by variation in costs. In The 21st Annual Conference
on Learning Theory (COLT), pages 57–68, 2008.
[35] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier:
an optimal algorithm for stochastic strongly-convex optimization. Jour-
nal of Machine Learning Research - Proceedings Track, pages 421–436,
2011.",N/A,N/A
"2011.
[36] Elad Hazan and Satyen Kale. Projection-free online learning. In ICML,
2012.
[37] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier:
optimal algorithms for stochastic strongly-convex optimization.
The
Journal of Machine Learning Research, 15(1):2489–2512, 2014.
[38] Elad Hazan, Adam Klivans, and Yang Yuan. Hyperparameter opti-
mization: A spectral approach. ICLR, 2018.
[39] Geoﬀrey Hinton, Nitish Srivastava, and Kevin Swersky. Neural net-",N/A,N/A
"works for machine learning lecture 6a overview of mini-batch gradient
descent. Cited on, 14, 2012.
[40] Ilija Ilievski, Taimoor Akhtar, Jiashi Feng, and Christine Annette Shoe-
maker.
Eﬃcient hyperparameter optimization for deep learning al-
gorithms using deterministic RBF surrogates.
In Proceedings of the
Thirty-First AAAI Conference on Artiﬁcial Intelligence, February 4-9,
2017, San Francisco, California, USA., pages 822–829, 2017.
BIBLIOGRAPHY
117
[41] Martin Jaggi.",N/A,N/A
"BIBLIOGRAPHY
117
[41] Martin Jaggi.
Revisiting frank-wolfe: Projection-free sparse convex
optimization. In ICML, 2013.
[42] Martin Jaggi and Marek Sulovsk´y. A simple algorithm for nuclear norm
regularized problems. In ICML, pages 471–478, 2010.
[43] Kevin G. Jamieson and Ameet Talwalkar.
Non-stochastic best arm
identiﬁcation and hyperparameter optimization. In Proceedings of the
19th International Conference on Artiﬁcial Intelligence and Statistics,",N/A,N/A
"AISTATS 2016, Cadiz, Spain, May 9-11, 2016, pages 240–248, 2016.
[44] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent
using predictive variance reduction. In Advances in neural information
processing systems, pages 315–323, 2013.
[45] Adam Kalai and Santosh Vempala. Eﬃcient algorithms for online de-
cision problems. Journal of Computer and System Sciences, 71(3):291–
307, 2005.
[46] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic",N/A,N/A
"optimization. arXiv preprint arXiv:1412.6980, 2014.
[47] Jyrki Kivinen and Manfred K. Warmuth. Exponentiated gradient ver-
sus gradient descent for linear predictors. Inf. Comput., 132(1):1–63,
1997.
[48] Jyrki Kivinen and Manfred K. Warmuth.
Relative loss bounds for
multidimensional regression problems. Machine Learning, 45(3):301–
329, 2001.
[49] Simon Lacoste-Julien, Martin Jaggi, Mark W. Schmidt, and Patrick
Pletscher.
Block-coordinate frank-wolfe optimization for structural",N/A,N/A
"svms. In Proceedings of the 30th International Conference on Machine
Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 53–
61, 2013.
[50] J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. A. Tropp. Prac-
tical large-scale optimization for max-norm regularization. In NIPS,
pages 1297–1305, 2010.
[51] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar.
Hyperband: A Novel Bandit-Based Approach to Hyperparameter Op-
timization. ArXiv e-prints, March 2016.
118",N/A,N/A
"timization. ArXiv e-prints, March 2016.
118
BIBLIOGRAPHY
[52] H. Brendan McMahan and Matthew J. Streeter. Adaptive bound op-
timization for online convex optimization. In COLT 2010 - The 23rd
Conference on Learning Theory, Haifa, Israel, June 27-29, 2010, pages
244–256, 2010.
[53] Arkadi S. Nemirovski and David B. Yudin. Problem Complexity and
Method Eﬃciency in Optimization. John Wiley UK/USA, 1983.
[54] A.S. Nemirovskii. Interior point polynomial time methods in convex",N/A,N/A
"programming, 2004. Lecture Notes.
[55] AS Nemirovskii.
Interior point polynomial time methods in convex
programming. Lecture Notes, 2004.
[56] Y. Nesterov. A method of solving a convex programming problem with
convergence rate O(1/k2). Soviet Mathematics Doklady, 27(2):372–376,
1983.
[57] Y. Nesterov. Introductory Lectures on Convex Optimization: A Basic
Course. Applied Optimization. Springer, 2004.
[58] Y. E. Nesterov and A. S. Nemirovskii. Interior Point Polynomial Al-",N/A,N/A
"gorithms in Convex Programming. SIAM, Philadelphia, 1994.
[59] Ryan O’Donnell. Analysis of Boolean Functions. Cambridge University
Press, New York, NY, USA, 2014.
[60] Francesco Orabona and Koby Crammer. New adaptive algorithms for
online classiﬁcation. In Proceedings of the 24th Annual Conference on
Neural Information Processing Systems 2010., pages 1840–1848, 2010.
[61] Barak A Pearlmutter. Fast exact multiplication by the hessian. Neural
computation, 6(1):147–160, 1994.",N/A,N/A
"computation, 6(1):147–160, 1994.
[62] Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan.
Making
gradient descent optimal for strongly convex stochastic optimization.
In ICML, 2012.
[63] Holger Rauhut. Compressive sensing and structured random matrices.
Theoretical foundations and numerical methods for sparse recovery, 9:1–
92, 2010.
[64] Benjamin Recht. Embracing the random. http://www.argmin.net/
2016/06/23/hyperband/, 2016.
BIBLIOGRAPHY
119",N/A,N/A
"2016/06/23/hyperband/, 2016.
BIBLIOGRAPHY
119
[65] Benjamin Recht. The news on auto-tuning. http://www.argmin.net/
2016/06/20/hypertuning/, 2016.
[66] Jasson D. M. Rennie and Nathan Srebro. Fast maximum margin matrix
factorization for collaborative prediction. In Proceedings of the 22Nd
International Conference on Machine Learning, ICML ’05, pages 713–
719, New York, NY, USA, 2005. ACM.
[67] Herbert Robbins and Sutton Monro.
A stochastic approximation",N/A,N/A
"A stochastic approximation
method. The Annals of Mathematical Statistics, 22(3):400–407, 09 1951.
[68] R.T. Rockafellar. Convex Analysis. Convex Analysis. Princeton Uni-
versity Press, 1997.
[69] R. Salakhutdinov and N. Srebro.
Collaborative ﬁltering in a non-
uniform world: Learning with the weighted trace norm. In NIPS, pages
2056–2064, 2010.
[70] Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing ﬁnite
sums with the stochastic average gradient. Mathematical Programming,",N/A,N/A
"162(1-2):83–112, 2017.
[71] Shai Shalev-Shwartz. Online Learning: Theory, Algorithms, and Ap-
plications. PhD thesis, The Hebrew University of Jerusalem, 2007.
[72] Shai Shalev-Shwartz, Alon Gonen, and Ohad Shamir. Large-scale con-
vex minimization with a low-rank constraint. In ICML, pages 329–336,
2011.
[73] Shai Shalev-Shwartz and Yoram Singer. A primal-dual perspective of
online learning algorithms. Machine Learning, 69(2-3):115–142, 2007.",N/A,N/A
"[74] Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cot-
ter.
Pegasos: primal estimated sub-gradient solver for svm.
Math.
Program., 127(1):3–30, 2011.
[75] O. Shamir and S. Shalev-Shwartz.
Collaborative ﬁltering with the
trace norm: Learning, bounding, and transducing. JMLR - Proceedings
Track, 19:661–678, 2011.
[76] Ohad Shamir and Tong Zhang.
Stochastic gradient descent for
non-smooth optimization: Convergence results and optimal averaging
schemes. In ICML, 2013.
120",N/A,N/A
"schemes. In ICML, 2013.
120
BIBLIOGRAPHY
[77] Noam Shazeer and Mitchell Stern. Adafactor: Adaptive learning rates
with sublinear memory cost. arXiv preprint arXiv:1804.04235, 2018.
[78] Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian
optimization of machine learning algorithms. In Advances in Neural
Information Processing Systems 25: 26th Annual Conference on Neural
Information Processing Systems 2012. Proceedings of a meeting held",N/A,N/A
"December 3-6, 2012, Lake Tahoe, Nevada, United States., pages 2960–
2968, 2012.
[79] Jasper Snoek, Kevin Swersky, Richard S. Zemel, and Ryan P. Adams.
Input warping for bayesian optimization of non-stationary functions. In
Proceedings of the 31th International Conference on Machine Learning,
ICML 2014, Beijing, China, 21-26 June 2014, pages 1674–1682, 2014.
[80] Nathan Srebro. Learning with Matrix Factorizations. PhD thesis, Mas-
sachusetts Institute of Technology, 2004.",N/A,N/A
"sachusetts Institute of Technology, 2004.
[81] Kevin Swersky, Jasper Snoek, and Ryan Prescott Adams. Multi-task
bayesian optimization. In Advances in Neural Information Processing
Systems 26: 27th Annual Conference on Neural Information Processing
Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake
Tahoe, Nevada, United States., pages 2004–2012, 2013.
[82] Ambuj Tewari, Pradeep D. Ravikumar, and Inderjit S. Dhillon. Greedy",N/A,N/A
"algorithms for structurally constrained high dimensional problems. In
NIPS, pages 882–890, 2011.
[83] A. M. Turing.
Computing machinery and intelligence.
Mind,
59(236):433–460, 1950.
[84] Ziyu Wang, Masrour Zoghi, Frank Hutter, David Matheson, and Nando
de Freitas. Bayesian optimization in high dimensions via random em-
beddings. In IJCAI 2013, Proceedings of the 23rd International Joint
Conference on Artiﬁcial Intelligence, Beijing, China, August 3-9, 2013,
pages 1778–1784, 2013.",N/A,N/A
"pages 1778–1784, 2013.
[85] Rachel Ward, Xiaoxia Wu, and Leon Bottou. Adagrad stepsizes: Sharp
convergence over nonconvex landscapes, from any initialization. arXiv
preprint arXiv:1806.01811, 2018.
[86] Lijun Zhang, Mehrdad Mahdavi, and Rong Jin. Linear convergence
with condition number independent access of full gradients. In Advances
in Neural Information Processing Systems, pages 980–988, 2013.
BIBLIOGRAPHY
121
[87] Martin Zinkevich.
Online convex programming and generalized in-",N/A,N/A
"Online convex programming and generalized in-
ﬁnitesimal gradient ascent.
In Proceedings of the 20th International
Conference on Machine Learning, pages 928–936, 2003.",N/A,N/A
"arXiv:1811.04422v1  [cs.LG]  11 Nov 2018
An Optimal Control View of Adversarial Machine Learning
Xiaojin Zhu
Department of Computer Sciences, University of Wisconsin-Madison
Abstract
I describe an optimal control view of adversarial machine learning, where the dynamical system is the
machine learner, the input are adversarial actions, and the control costs are deﬁned by the adversary’s
goals to do harm and be hard to detect. This view encompasses many types of adversarial machine",N/A,N/A
"learning, including test-item attacks, training-data poisoning, and adversarial reward shaping. The view
encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement
learning.
1
Adversarial Machine Learning is not Machine Learning
Machine learning has its mathematical foundation in concentration inequalities. This is a consequence of
the independent and identically-distributed (i.i.d.) data assumption. In contrast, I suggest that adversarial",N/A,N/A
"machine learning may adopt optimal control as its mathematical foundation [3,25]. There are telltale signs:
adversarial attacks tend to be subtle and have peculiar non-i.i.d. structures – as control input might be.
2
Optimal Control
I will focus on deterministic discrete-time optimal control because it matches many existing adversarial
attacks. Extensions to stochastic and continuous control are relevant to adversarial machine learning, too.",N/A,N/A
"The system to be controlled is called the plant, which is deﬁned by the system dynamics:
xt+1 = f(xt, ut)
(1)
where xt ∈Xt is the state of the system, ut ∈Ut is the control input, and Ut is the control constraint
set. The function f deﬁnes the evolution of state under external control. The time index t ranges from 0
to T −1, and the time horizon T can be ﬁnite or inﬁnite. The quality of control is speciﬁed by the running
cost:
gt(xt, ut)
(2)",N/A,N/A
"cost:
gt(xt, ut)
(2)
which deﬁnes the step-by-step control cost, and the terminal cost for ﬁnite horizon:
gT (xT )
(3)
which deﬁnes the quality of the ﬁnal state. The optimal control problem is to ﬁnd control inputs u0 . . . uT −1
in order to minimize the objective:
min
u0...uT −1
gT (xT ) +
T −1
X
t=0
gt(xt, ut)
(4)
s.t.
xt+1 = f(xt, ut), ut ∈Ut, ∀t
x0 given
1
More generally, the controller aims to ﬁnd control policies φt(xt) = ut, namely functions that map observed",N/A,N/A
"states to inputs. In optimal control the dynamics f is known to the controller. There are two styles of
solutions: dynamic programming and Pontryagin minimum principle [2,10,17]. When f is not fully known,
the problem becomes either robust control where control is carried out in a minimax fashion to accommodate
the worst case dynamics [28], or reinforcement learning where the controller probes the dynamics [23].
3
Adversarial Machine Learning as Control",N/A,N/A
"3
Adversarial Machine Learning as Control
Now let us translate adversarial machine learning into a control formulation. Adversarial machine learning
studies vulnerability throughout the learning pipeline [4, 13, 20, 26]. As examples, I present training-data
poisoning, test-time attacks, and adversarial reward shaping below. In all cases, the adversary attempts to
control the machine learning system, and the control costs reﬂect the adversary’s desire to do harm and be
hard to detect.",N/A,N/A
"hard to detect.
Unfortunately, the notations from the control community and the machine learning community clash.
For example, x denotes the state in control but the feature vector in machine learning. I will use the machine
learning convention below.
3.1
Training-Data Poisoning
In training-data poisoning the adversary can modify the training data. The machine learner then trains a
“wrong” model from the poisoned data. The adversary’s goal is for the “wrong” model to be useful for some",N/A,N/A
"nefarious purpose. I use supervised learning for illustration.
3.1.1
Batch Learner
At this point, it becomes useful to distinguish batch learning and sequential (online) learning. If the machine
learner performs batch learning, then the adversary has a degenerate one-step control problem. One-step
control has not been the focus of the control community and there may not be ample algorithmic solutions to",N/A,N/A
"borrow from. Still, it is illustrative to pose batch training set poisoning as a control problem. I use Support
Vector Machine (SVM) with a batch training set as an example below:
• The state is the learner’s model h : X 7→Y. For instance, for SVM h is the classiﬁer parametrized by
a weight vector w. I will use h and w interchangeably.
• The control u0 is a whole training set, for instance u0 = {(xi, yi)}1:n.",N/A,N/A
"• The control constraint set U0 consists of training sets available to the adversary; if the adversary
can arbitrary modify a training set for supervised learning (including changing features and labels,
inserting and deleting items), this could be U0 = ∪∞
n=0(X × Y)n, namely all training sets of all sizes.
This is a large control space.
• The system dynamics (1) is deﬁned by the learner’s learning algorithm. For the SVM learner, this",N/A,N/A
"would be empirical risk minimization with hinge loss ℓ() and a regularizer:
w1 = f(u0) ∈argminw
n
X
i=1
ℓ(w, xi, yi) + λ∥w∥2.
(5)
The batch SVM does not need an initial weight w0. The adversary has full knowledge of the dynamics
f() if it knows the form (5), ℓ(), and the value of λ.
• The time horizon T = 1.
2
• The adversary’s running cost g0(u0) measures the poisoning eﬀort in preparing the training set u0.",N/A,N/A
"This is typically deﬁned with respect to a given “clean” data set ˜u before poisoning in the form of
g0(u0) = distance(u0, ˜u).
(6)
The running cost is domain dependent. For example, the distance function may count the number of
modiﬁed training items; or sum up the Euclidean distance of changes in feature vectors.
• The adversary’s terminal cost g1(w1) measures the lack of intended harm. The terminal cost is also
domain dependent. For example:",N/A,N/A
"domain dependent. For example:
– If the adversary must force the learner into exactly arriving at some target model w∗, then
g1(w1) = I∞[w1 ̸= w∗].
Here Iy[z] = y if z is true and 0 otherwise, which acts as a hard
constraint.
– If the adversary only needs the learner to get near w∗then g1(w1) = ∥w1 −w∗∥for some norm.
– If the adversary wants to ensure that a speciﬁc future item x∗is classiﬁed ǫ-conﬁdently as positive,",N/A,N/A
"it can use g1(w1) = I∞[w1 /∈W∗] with the target set W∗= {w : w⊤x∗≥ǫ}. More generally,
W∗can be a polytope deﬁned by multiple future classiﬁcation constraints.
With these deﬁnitions, the adversary’s one-step control problem (4) specializes to
min
u0
g1(w1) + g0(w0, u0)
(7)
s.t.
w1 = f(w0, u0)
Unsurprisingly, the adversary’s one-step control problem is equivalent to a Stackelberg game and bi-level",N/A,N/A
"optimization (the lower level optimization is hidden in f), a well-known formulation for training-data poi-
soning [12,21].
3.1.2
Sequential Learner
The adversary performs classic discrete-time control if the learner is sequential:
• The learner starts from an initial model w0, which is the initial state.
• The control input at time t is ut = (xt, yt), namely the tth training item for t = 0, 1, . . .",N/A,N/A
"• The dynamics is the sequential update algorithm of the learner. For example, the learner may perform
one step of gradient descent:
wt+1 = f(wt, ut) = wt −ηt∇ℓ(wt, xt, yt).
(8)
• The adversary’s running cost gt(wt, ut) typically measures the eﬀort of preparing ut. For example, it
could measure the magnitude of change ∥ut −˜ut∥with respect to a “clean” reference training sequence
˜u. Or it could be the constant 1 which reﬂects the desire to have a short control sequence.",N/A,N/A
"• The adversary’s terminal cost gT (wT ) is the same as in the batch case.
The problem (4) then produces the optimal training sequence poisoning. Earlier attempts on sequential
teaching can be found in [1,18,19].
3
3.2
Test-Time Attack
Test-time attack diﬀers from training-data poisoning in that a machine learning model h : X 7→Y is already-
trained and given. Also given is a “test item” x. There are several variants of test-time attacks, I use the",N/A,N/A
"following one for illustration: The adversary seeks to minimally perturb x into x′ such that the machine
learning model classiﬁes x and x′ diﬀerently. That is,
min
x′
distance(x, x′)
(9)
s.t.
h(x) ̸= h(y).
The distance function is domain-dependent, though in practice the adversary often uses a mathematically
convenient surrogate such as some p-norm ∥x −x′∥p.
One way to formulate test-time attack as optimal control is to treat the test-item itself as the state, and",N/A,N/A
"the adversarial actions as control input. Let us ﬁrst look at the popular example of test-time attack against
image classiﬁcation:
• Let the initial state x0 = x be the clean image.
• The adversary’s control input u0 is the vector of pixel value changes.
• The control constraint set is U0 = {u : x0 + u ∈[0, 1]d} to ensure that the modiﬁed image has valid
pixel values (assumed to be normalized in [0, 1]).
• The dynamical system is trivially vector addition: x1 = f(x0, u0) = x0 + u0.",N/A,N/A
"• The adversary’s running cost is g0(x0, u0) = distance(x0, x1).
• The adversary’s terminal cost is g1(x1) = I∞[h(x1) = h(x0)]. Note the machine learning model h is
only used to deﬁne the hard constraint terminal cost; h itself is not modiﬁed.
With these deﬁnitions this is a one-step control problem (4) that is equivalent to the test-time attack
problem (9).
This control view on test-time attack is more interesting when the adversary’s actions are sequential",N/A,N/A
"U0, U1, . . ., and the system dynamics render the action sequence non-commutative. The adversary’s running
cost gt then measures the eﬀort in performing the action at step t. One limitation of the optimal control
view is that the action cost is assumed to be additive over the steps.
3.3
Defense Against Test-Time Attack by Adversarial Training
Some defense strategies can be viewed as optimal control, too. One defense against test-time attack is to",N/A,N/A
"require the learned model h to have the large-margin property with respect to a training set. Let (x, y)
be any training item, and ǫ a margin parameter. Then the large-margin property states that the decision
boundary induced by h should not pass ǫ-close to (x, y):
∀x′ : (∥x′ −x∥p ≤ǫ) ⇒h(x′) = y.
(10)
This is an uncountable number of constraints. It is relatively easy to enforce for linear learners such as
SVMs, but impractical otherwise.",N/A,N/A
"SVMs, but impractical otherwise.
Adversarial training can be viewed as a heuristic to approximate the uncountable constraint (10) with
a ﬁnite number of active constraints: one performs test-time attack against the current h from x to ﬁnd
an adversarial item x(1), such that ∥x(1) −x∥p ≤ǫ but h(x(1)) ̸= y. Instead of adding a single constraint
h(x(1)) = y, an additional training item (x(1), y) is then added to the training set. The machine learning",N/A,N/A
"algorithm learns a diﬀerent h, with the hope (but not constraining) that h(x(1)) = y. This process repeats
for k iteration, resulting in k additional training items (x(i), y) for i = 1 . . . k.
It should be clear that such defense is similar to training-data poisoning, in that the defender uses data
to modify the learned model. This is especially interesting when the learner performs sequential updates.
One way to formulate adversarial training defense as control is the following:
4",N/A,N/A
"4
• The state is the model ht. Initially h0 can be the model trained on the original training data.
• The control input ut = (xt, yt) is an additional training item with the trivial constraint set Ut = X×y.
• The dynamics ht+1 = f(ht, ut) is one-step update of the model, e.g. by back-propagation.
• The defender’s running cost gt(ht, ut) can simply be 1 to reﬂect the desire for less eﬀort (the running
cost sums up to k).",N/A,N/A
"cost sums up to k).
• The defender’s terminal cost gT (hT ) penalizes small margin of the ﬁnal model hT with respect to the
original training data.
Of course, the resulting control problem (4) does not directly utilize adversarial examples. One way to
incorporate them is to restrict Ut to a set of adversarial examples found by invoking test-time attackers on
ht, similar to the heuristic in [7]. These adversarial examples do not even need to be successful attacks.
3.4
Adversarial Reward Shaping",N/A,N/A
"3.4
Adversarial Reward Shaping
When adversarial attacks are applied to sequential decision makers such as multi-armed bandits or reinforce-
ment learning agents, a typical attack goal is to force the latter to learn a wrong policy useful to the adversary.
The adversary may do so by manipulating the rewards and the states experienced by the learner [11,14].
To simplify the exposition, I focus on adversarial reward shaping against stochastic multi-armed bandit,",N/A,N/A
"because this does not involve deception through perceived states. To review, in stochastic multi-armed bandit
the learner at iteration t chooses one of k arms, denoted by It ∈[k], to pull according to some strategy [6].
For example, the (α, ψ)-Upper Conﬁdence Bound (UCB) strategy chooses the arm
It ∈argmaxi∈[k]ˆµi,Ti(t−1) + ψ∗−1
 α log t
Ti(t −1)

(11)
where Ti(t −1) is the number of times arm i has been pulled up to time t −1, ˆµi,Ti(t−1) is the empirical",N/A,N/A
"mean of arm i so far, and ψ∗is the dual of a convex function ψ. The environment generates a stochastic
reward rIt ∼νIt. The learner updates its estimate of the pulled arm:
ˆµIt,TIt(t) =
ˆµIt,TIt(t−1)TIt(t −1) + rIt
TIt(t −1) + 1
(12)
which in turn aﬀects which arm it will pull in the next iteration. The learner’s goal is to minimize the
pseudo-regret T µmax −E PT
t=1 µIt where µi = Eνi and µmax = maxi∈[k] µi. Stochastic multi-armed bandit
strategies oﬀer upper bounds on the pseudo-regret.",N/A,N/A
"With adversarial reward shaping, an adversary fully observes the bandit. The adversary intercepts the
environmental reward rIt in each iteration, and may choose to modify (“shape”) the reward into
rIt + ut
with some ut ∈R before sending the modiﬁed reward to the learner. The adversary’s goal is to use minimal
reward shaping to force the learner into performing speciﬁc wrong actions. For example, the adversary may",N/A,N/A
"want the learner to frequently pull a particular target arm i∗∈[k]. It should be noted that the adversary’s
goal may not be the exact opposite of the learner’s goal: the target arm i∗is not necessarily the one with
the worst mean reward, and the adversary may not seek pseudo-regret maximization.
Adversarial reward shaping can be formulated as stochastic optimal control:
• The state st, now called control state to avoid confusion with the Markov Decision Process states",N/A,N/A
"experienced by an reinforcement learning agent, consists of the suﬃcient statistic tuple at time t:
st = (T1(t −1), ˆµ1,T1(t−1), . . . , Tk(t −1), ˆµk,Tk(t−1), It).
5
• The control input is ut ∈Ut with Ut = R in the unconstrained shaping case, or the appropriate Ut if
the rewards must be binary, for example.
• The dynamics st+1 = f(st, ut) is straightforward via empirical mean update (12), TIt increment, and
new arm choice (11).",N/A,N/A
"new arm choice (11).
• The adversary’s running cost gt(st, ut) reﬂects shaping eﬀort and target arm achievement in iteration
t. For instance,
gt(st, ut) = u2
t + Iλ[It ̸= i∗].
(13)
where λ > 0 is a trade oﬀparameter.
• There is not necessarily a time horizon T or a terminal cost gT (sT ).
The control state is stochastic due to the stochastic reward rIt entering through (12).
4
Advantages of the Optimal Control View
There are a number of potential beneﬁts in taking the optimal control view:",N/A,N/A
"• It oﬀers a uniﬁed conceptual framework for adversarial machine learning;
• The optimal control literature provides eﬃcient solutions when the dynamics f is known and one can
take the continuous limit to solve the diﬀerential equations [15];
• Reinforcement learning, either model-based with coarse system identiﬁcation or model-free policy it-
eration, allows approximate optimal control when f is unknown, as long as the adversary can probe
the dynamics [8,9];",N/A,N/A
"the dynamics [8,9];
• A generic defense strategy may be to limit the controllability the adversary has over the learner.
• I mention in passing that the optimal control view applies equally to machine teaching [27, 29], and
thus extends to the application of personalized education [22,24].
I need to point out some limitations:
• Having a uniﬁed optimal control view does not automatically produce eﬃcient solutions to the control",N/A,N/A
"problem (4). For adversarial machine learning applications the dynamics f is usually highly nonlinear
and complex.
Furthermore, in graybox and blackbox attack settings f is not fully known to the
attacker. They aﬀect the complexity in ﬁnding an optimal control.
• The adversarial learning setting is largely non-game theoretic, though there are exceptions [5,16].
These problems call for future research from both machine learning and control communities.",N/A,N/A
"Acknowledgments. I acknowledge funding NSF 1837132, 1545481, 1704117, 1623605, 1561512, and
the MADLab AF Center of Excellence FA9550-18-1-0166.
References
[1] Scott Alfeld, Xiaojin Zhu, and Paul Barford. Data poisoning attacks against autoregressive models. In
The Thirtieth AAAI Conference on Artiﬁcial Intelligence (AAAI-16), 2016.
[2] Michael Athans and Peter L Falb. Optimal control: An introduction to the theory and its applications.
Courier Corporation, 2013.",N/A,N/A
"Courier Corporation, 2013.
[3] Dimitri P. Bertsekas. Dynamic Programming and Optimal Control. Athena Scientiﬁc, 4th edition, 2017.
6
[4] Battista Biggio and Fabio Roli. Wild patterns: Ten years after the rise of adversarial machine learning.
CoRR, abs/1712.03141, 2017.
[5] Michael Br¨uckner and Tobias Scheﬀer. Stackelberg games for adversarial prediction problems. In Pro-
ceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,
pages 547–555. ACM, 2011.",N/A,N/A
"pages 547–555. ACM, 2011.
[6] S´ebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundations and Trends in Machine Learning, 5(1):1–122, 2012.
[7] Qi-Zhi Cai, Min Du, Chang Liu, and Dawn Song.
Curriculum adversarial training.
In The 27th
International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2018.
[8] Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on",N/A,N/A
"graph structured data. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 1115–
1124, Stockholmsmssan, Stockholm Sweden, 10–15 Jul 2018. PMLR.
[9] Yang Fan, Fei Tian, Tao Qin, and Tie-Yan Liu. Learning to teach. In ICLR, 2018.
[10] Terry L Friesz. Dynamic optimization and diﬀerential games, volume 135. Springer Science & Business
Media, 2010.",N/A,N/A
"Media, 2010.
[11] Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel. Adversarial attacks on
neural network policies. arXiv, 2017.
[12] Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, and Bo Li. Ma-
nipulating machine learning: Poisoning attacks and countermeasures for regression learning. The 39th
IEEE Symposium on Security and Privacy, 2018.",N/A,N/A
"IEEE Symposium on Security and Privacy, 2018.
[13] Anthony D. Joseph, Blaine Nelson, Benjamin I. P. Rubinstein, and J. D. Tygar. Adversarial Machine
Learning. Cambridge University Press, 2018. in press.
[14] Kwang-Sung Jun, Lihong Li, Yuzhe Ma, and Xiaojin Zhu. Adversarial attacks on stochastic bandits.
In Advances in Neural Information Processing Systems (NIPS), 2018.
[15] L. Lessard, X. Zhang, and X. Zhu. An Optimal Control Approach to Sequential Machine Teaching.",N/A,N/A
"ArXiv e-prints, October 2018.
[16] Bo Li and Yevgeniy Vorobeychik. Scalable Optimization of Randomized Operational Decisions in Ad-
versarial Classiﬁcation Settings. In Guy Lebanon and S. V. N. Vishwanathan, editors, Proceedings of the
Eighteenth International Conference on Artiﬁcial Intelligence and Statistics, volume 38 of Proceedings
of Machine Learning Research, pages 599–607, San Diego, California, USA, 09–12 May 2015. PMLR.",N/A,N/A
"[17] Daniel Liberzon. Calculus of variations and optimal control theory: A concise introduction. Princeton
University Press, 2011.
[18] Weiyang Liu, Bo Dai, Ahmad Humayun, Charlene Tay, Chen Yu, Linda B Smith, James M Rehg,
and Le Song. Iterative machine teaching. In International Conference on Machine Learning, pages
2149–2158, 2017.
[19] Weiyang Liu, Bo Dai, Xingguo Li, Zhen Liu, James M. Rehg, and Le Song. Towards black-box iterative",N/A,N/A
"machine teaching. In ICML, volume 80 of JMLR Workshop and Conference Proceedings, pages 3147–
3155. JMLR.org, 2018.
[20] Daniel Lowd and Christopher Meek. Adversarial learning. In Proceedings of the eleventh ACM SIGKDD
international conference on Knowledge discovery in data mining, pages 641–647. ACM, 2005.
7
[21] Shike Mei and Xiaojin Zhu. Using machine teaching to identify optimal training-set attacks on machine
learners. In The Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence, 2015.",N/A,N/A
"[22] Kaustubh Patil, Xiaojin Zhu, Lukasz Kopec, and Bradley Love. Optimal teaching for limited-capacity
human learners. In Advances in Neural Information Processing Systems (NIPS), 2014.
[23] B. Recht. A Tour of Reinforcement Learning: The View from Continuous Control. ArXiv e-prints, June
2018.
[24] Ayon Sen, Purav Patel, Martina A. Rau, Blake Mason, Robert Nowak, Timothy T. Rogers, and Xiaojin
Zhu. Machine beats human at sequencing visuals for perceptual-ﬂuency practice. In Educational Data",N/A,N/A
"Mining, 2018.
[25] Emanuel Todorov. Optimal control theory. Bayesian brain: probabilistic approaches to neural coding,
pages 269–298, 2006.
[26] Yevgeniy Vorobeychik and Murat Kantarcioglu. Adversarial machine learning. Synthesis Lectures on
Artiﬁcial Intelligence and Machine Learning, 12(3):1–169, 2018.
[27] Xiaojin Zhu. Machine teaching: an inverse problem to machine learning and an approach toward optimal",N/A,N/A
"education. In The Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence (AAAI “Blue Sky” Senior
Member Presentation Track), 2015.
[28] Xiaojin Zhu, Ji Liu, and Manuel Lopes. No learner left behind: On the complexity of teaching multiple
learners simultaneously. In The 26th International Joint Conference on Artiﬁcial Intelligence (IJCAI),
2017.
[29] Xiaojin Zhu, Adish Singla, Sandra Zilles, and Anna N. Raﬀerty. An Overview of Machine Teaching.",N/A,N/A
"ArXiv e-prints, January 2018. https://arxiv.org/abs/1801.05927.
8",N/A,N/A
"arXiv:1707.04849v1  [cs.LG]  16 Jul 2017
Minimax deviation strategies for machine
learning and recognition with short learning
samples
Schlesinger M.I. and Vodolazskiy E.V.
August 31, 2018
Abstract
The article is devoted to the problem of small learning samples in
machine learning. The ﬂaws of maximum likelihood learning and min-
imax learning are looked into and the concept of minimax deviation
learning is introduced that is free of those ﬂaws.
1
Introduction",N/A,N/A
"1
Introduction
The small learning sample problem has been around in machine learning
under diﬀerent names during its whole life. The learning sample is used to
compensate for the lack of knowledge about the recognized object when its
statistical model is not completely known. Naturally, the longer the learning
sample is, the better is the subsequent recognition. However, when the learn-
ing sample becomes too small (2, 3, 5 elements) an eﬀect of small samples",N/A,N/A
"becomes evident. In spite of the fact that any learning sample (even a very
small one) provides some additional information about the object, it may be
better to ignore the learning sample than to utilize it with the commonly
used methods.
Example 1. Let us consider an object that can be in one of two random
states y = 1 and y = 2 with equal probabilities. In each state the object
generates two independent Gaussian random signals x1 and x2 with variances",N/A,N/A
"equal 1. Mean values of signals depend on the state as it is shown on Fig.
1
1. In the ﬁrst state the mean value is (2, 0). In the second state the mean
value depends on an unknown parameter θ and is (0, θ). Even if no learning
sample is given a minimax strategy can be used to make a decision about the
state y. The minimax strategy ignores the second signal and makes decision
y∗= 1 when x1 > 1 and decision y∗= 2 when x1 ≤1.
x2
x1
b
b
θ
b
2
0
y∗= 1
y∗= 2
p(x1, x2|y = 1)
p(x1, x2|y = 2)",N/A,N/A
"b
2
0
y∗= 1
y∗= 2
p(x1, x2|y = 1)
p(x1, x2|y = 2)
Figure 1: Example 1. (x1, x2) ∈R2 – signal, y ∈{1, 2} – state.
Now let us assume that there is a sample of signals generated by an
object in the second state but with higher variance 16. A maximum likelihood
strategy estimates the unknown parameter θ and then makes a decision about
y as if the estimated value of the parameter is its true value. Fig. 2 shows how
the probability of a wrong decision (called the risk) depends on parameter θ",N/A,N/A
"for diﬀerent sizes of the learning sample. If the learning sample is suﬃciently
long, the risk of maximum likelihood strategy may become arbitrarily close
to the minimum possible risk.
Naturally, when the length of the sample
decreases the risk becomes worse and worse. Furthermore, when it becomes
as small as 3 or 2 elements the risk of the maximum likelihood strategy
becomes worse than the risk of the minimax strategy that uses neither the",N/A,N/A
"learning sample nor the signal x2 at all. Hence, it is better to ignore available
additional data about the recognized object than to try to make use of it in
a conventional way. It demonstrates a serious theoretical ﬂaw of commonly
used methods, and deﬁnitely not that short samples are useless. Any learning
sample, no mater how long or short it is, provides some, may be not a lot
information about the recognized object and a reasonable method has to use
it.
2
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)",N/A,N/A
"it.
2
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
n = 1
n = 2
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
n = 3
n = 10
Figure 2: Example 1. Probability of a wrong decision (risk) for diﬀerent
sizes n of the learning sample. The curve R(qML, θ) is the risk of a maximum",N/A,N/A
"likelihood strategy. The curve R(qminmax, θ) is the risk of a minimax strategy.
The curve min
q
R(q, θ) is the minimum possible risk for each model.
Example 2. This is a simple example that has been used by H.Robbins in
his seminal article [5] where he initiated empirical Bayessian approach and
explaned its main idea. An object can be in one of two possible states y = 1
and y = 2. In each state the object generates a univariate Gaussian signal",N/A,N/A
"x with variance 1. The mean value of the generated signal depends on the
state y so that
p(x|y = 1) =
1
√
2πe−(x+1)2
2
,
p(x|y = 2) =
1
√
2πe−(x−1)2
2
.
Only a priori probabilities of states are unknown and θ is the probability
of the ﬁrst state so that p(y = 1) = θ and p(y = 2) = 1 −θ. A minimax
strategy for such incomplete statistical model makes decision y∗based on
the sign of the observed signal and ensures probability of correct recognition",N/A,N/A
"0.84 independently of a priori probabilities of states.
Let not only a single object, but a collection of mutually independant
objects be available for recognition. Each object is in its own hidden state and
is presented with its own signal. Let us also assume that the decision about
3
x
y∗= 2
y∗= 1
p(x|y = 1)
p(x|y = 2)
b
1
b
−1
b
Figure 3: Example 2. x ∈R – signal, y ∈{1, 2} – state.
each object’s state does not have to be made immediately when the object",N/A,N/A
"is observed and can be postponed until the whole collection is observed. In
this case maximum likelihood estimations of a priori probabilities of states
can be computed and then each object of the collection is recognized as if the
estimated values of probabilities were the true values. When the presented
collection is suﬃciently long the probability of a wrong decision can be made
as close to the minimum as possible (Fig.4). However, when the collection is",N/A,N/A
"too short, the probability of a wrong decision can be much worse than that
of the minimax strategy.
The considered examples lead to a diﬃcult and up to now an unanswered
question. What should be done when a ﬁxed sample of 2-3 elements is given
and no additional elements can be obtained? Is it really the best way to
ignore these data or is it possible to make use of them? We want to ﬁll up
this gap between maximum likelihood and minimax strategies and develop",N/A,N/A
"a strategy that covers teh whole range of learning samples lengths including
zero length. However, this gap, and it is infact a gap, shows a theoretical
imperfection of the commonly used learning procedures, namely, of maximum
likelihood learning. The short sample problem in whole follows from the fact
that maximum likelihood learning as well as many other learning procedures
have not been deduced from any explicit risk-oriented requirement to the
quality of post-learning recognition.",N/A,N/A
"quality of post-learning recognition.
We will formulate such risk-oriented
requirements a priori and will see what type of learning procedures follow.
2
Basic deﬁnitions
Deﬁnition 1. An object is represented with a tuple",N/A,N/A
"X, Y, Θ, pXY : X × Y × Θ →R

4
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
n = 1
n = 2
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
n = 5
n = 10
Figure 4: Example 2. Probability of a wrong decision (risk) for diﬀerent
sizes n of the learning sample.
The curve R(qML, θ) shows the risk of a",N/A,N/A
"The curve R(qML, θ) shows the risk of a
maximum likelihood strategy, R(qminmax, θ) is the risk of a minimax strategy,
min
q
R(q, θ) is the minimal possible risk.
where
X is a ﬁnite set of signal values x ∈X;
Y is a ﬁnite set of states y ∈Y ;
Θ is a ﬁnite set of models θ ∈Θ;
pXY (x, y; θ) is a probability of a pair (x ∈X, y ∈Y ) for a model θ ∈Θ.
A signal x is an observable parameter of recognized object whereas a
state y is its hidden parameter. A pair (x, y) is random and for each pair",N/A,N/A
"(x ∈X, y ∈Y ) its probability pXY (x, y; θ) exists. However, this probability
is not known because it depends on an unknown model θ. As for the model
θ it is not random, it takes a ﬁxed but unknown value. Only the set Θ is
known that the value θ belongs to.
Let z be some random data that depend on a model θ and take values
from a ﬁnite set Z. The data is speciﬁed with a tuple",N/A,N/A
"Z, pZ : Z × Θ →R

where pZ(z; θ) is a probability of data z ∈Z for model θ ∈Θ.
5
Deﬁnition 2. A random data

Z, pZ : Z ×Θ →R

that depends on a model
is called a learning data for an object",N/A,N/A
"X, Y, Θ, pXY : X × Y × Θ →R

if
pXY Z(x, y, z; θ) = pXY (x, y; θ) · pZ(z; θ) for all x ∈X, y ∈Y, z ∈Z, θ ∈Θ.
A learning sample ((xi, yi)|i = 1, 2, . . . , n) used for supervised learning is
a special cases of learning data when
Z = (X × Y )n and pZ(z; θ) =
n
Y
i=1
pXY (xi, yi; θ).
A learning sample (xi|i = 1, 2, . . . , n) for unsupervised learning is another
special case of learning data when
Z = Xn and pZ(z; θ) =
n
Y
i=1
X
y∈Y
pXY (xi, y; θ).",N/A,N/A
"n
Y
i=1
X
y∈Y
pXY (xi, y; θ).
Any expert knowledge about the true model is also learning data. One can
even consider the case when |Z| = 1 and therefore pZ(z; θ) = 1, which is
equivalent to the absence of any learning data at all. We do not restrict the
learning data in any way except that for any ﬁxed model the learning data
z depend neither on the current signal x nor on the current state y so that
pXY Z(x, y, z; θ) = pXY (x, y; θ) · pZ(z; θ) for all x ∈X, y ∈Y, z ∈Z, θ ∈Θ.",N/A,N/A
"Deﬁnition 3. A non-negative function q : X×Y ×Z →R is called a strategy
if P
y∈Y q(y|x, z) = 1 for all x ∈X, z ∈Z.
Value q(y|x, z) of a strategy q : X × Y × Z →R is a probability of a
randomized decision that the current state of an object is y, given the current
observed signal x and the available learning data z. The set of all strategies
q : X × Y × Z →R is denoted Q.
Let ω : Y × Y be a loss function whose value ω(y, y′) is the loss of a
decision y′ when the true state is y.",N/A,N/A
"decision y′ when the true state is y.
Deﬁnition 4. Risk R(q, θ) of a strategy q on a model θ is expected loss
R(q, θ) =
X
z∈Z
X
x∈X
X
y∈Y
pXY (x, y; θ)pZ(z; θ)
X
y′∈Y
q(y′|x, z)ω(y, y′).
6
Let us be reminded that throughout the paper the sets X, Y , Z and Θ
are assumed to be ﬁnite. This allows a much more transparent formulation
of main results. Allowing some of the sets to be inﬁnite would require ﬁner
mathematical tools and the results might be obscured by unnecessary tech-
nical details.
3",N/A,N/A
"nical details.
3
Improper and Bayesian strategies.
One can see that the risk of a strategy depends not only on the strategy itself
but also on the model that the strategy is applied to. Therefore, in a general
case it is not possible to prefer some strategy q1 to another strategy q2. The
risk of q1 may be better than the risk of q2 on some models and worse on the
others. However, it is possible to prefer strategy q2 to strategy q1 if the risk",N/A,N/A
"of q1 is greater than the risk of q2 on all models. In this case we will say that
q2 dominates q1 and q1 is dominated by q2.
Deﬁnition 5. A strategy q0 is called improper if a strategy q∗exists such
that R(q0, θ) > R(q∗, θ)
for all θ ∈Θ.
We want to exclude all improper from consideration strategies and derive
a common form of all the rest.
Let T denote the set of all non-negative
functions τ : Θ →R such that P
θ∈Θ
τ(θ) = 1. Functions of such type will be
reﬀerred to as weight functions.",N/A,N/A
"reﬀerred to as weight functions.
Deﬁnition 6. A strategy q∗is called Bayesian if there exists a weight func-
tion τ ∈T such that
q∗= arg min
q∈Q
X
θ∈Θ
τ(θ)R(q, θ).
Theorem 1. Each strategy q0 ∈Q is either Bayesian or improper, but never
both.
Proof. For a given strategy q0 let us deﬁne a function F: T × Q →R,
F(τ, q) =
X
θ∈Θ
τ(θ)

R(q, θ) −R(q0, θ)

.
7
According to Deﬁnition 4, for any ﬁxed θ the risk R(q, θ) is a linear function",N/A,N/A
"of probabilities q(y|x, z). Consequently, for any ﬁxed τ the function F is also
a linear function of probabilities q(y|x, z). Similarly, function F is a linear
function of weights τ(θ) for any ﬁxed strategy q. The set Q of strategies
and the set T of weight functions are both closed convex sets. Consequently,
due to the known duality theorem [1, 2, 4] function F has a saddle point
(τ ∗∈T, q∗∈Q) such that
max
τ∈T min
q∈Q F(τ, q) = F(τ ∗, q∗) = min
q∈Q max
τ∈T F(τ, q),
where
q∗= argmin
q∈Q
max",N/A,N/A
"q∈Q max
τ∈T F(τ, q),
where
q∗= argmin
q∈Q
max
τ∈T F(τ, q),
τ ∗= argmax
τ∈T
min
q∈Q F(τ, q).
It is obvious that F(τ, q0) = 0 for any τ ∈T. Therefore, the inequality
min
q∈Q F(τ, q) ≤0 holds for every τ ∈T and, consequently,
max
τ∈T min
q∈Q F(τ, q) = F(τ ∗, q∗) ≤0.
Therefore, there are two mutually exclusive cases: either F(τ ∗, q∗) < 0 or
F(τ ∗, q∗) = 0. In such way the proof of the theorem is reduced to proving
the following four propositions:",N/A,N/A
"the following four propositions:
Proposition 1. If the strategy q0 is Bayessian then F(τ ∗, q∗) = 0.
Proposition 2. If F(τ ∗, q∗) = 0 then the strategy q0 is Bayessian.
Proposition 3. If the strategy q0 is improper then F(τ ∗, q∗) < 0.
Proposition 4. If F(τ ∗, q∗) < 0 then the strategy q0 is improper.
Proof of Proposition 1. If the strategy q0 is Bayessian then according to
Deﬁnition 6 a weight function τ 0 exists such that inequality
X
θ∈Θ
τ 0(θ)R(q, θ) ≥
X
θ∈Θ
τ 0(θ)R(q0, θ)",N/A,N/A
"X
θ∈Θ
τ 0(θ)R(q, θ) ≥
X
θ∈Θ
τ 0(θ)R(q0, θ)
is valid for all q ∈Q. Consequently, for all q ∈Q the chain
0 ≤
X
θ∈Θ
τ 0(θ)[R(q, θ) −R(q0, θ)] = F(τ 0, q) ≤max
τ∈T F(τ, q)
8
is also valid. Since all numbers maxτ∈T F(τ, q), q ∈Q, are not negative the
least of them is also not negative and
min
q∈Q max
τ∈T F(τ, q) = F(τ ∗, q∗) ≥0
From this inequality it follows that F(τ ∗, q∗) = 0 because a case F(τ ∗, q∗) > 0
is impossible.
Proof of Proposition 2. Let F(τ ∗, q∗) = 0 then
0 = F(τ ∗, q∗) = max
τ∈T min",N/A,N/A
"0 = F(τ ∗, q∗) = max
τ∈T min
q∈Q F(τ, q) = min
q∈Q F(τ ∗, q) =
= min
q∈Q
X
θ∈Θ
τ ∗(θ)

R(q, θ) −R(q0, θ)

=
= min
q∈Q
 X
θ∈Θ
τ ∗(θ)R(q, θ)

−
X
θ∈Θ
τ ∗(θ)R(q0, θ).
It implies the equality
min
q∈Q
X
θ∈Θ
τ ∗(θ)R(q, θ) =
X
θ∈Θ
τ ∗(θ)R(q0, θ)
and therefore,
q0 = arg min
q∈Q
X
θ∈Θ
τ ∗(θ)R(q, θ),
which means that q0 is Bayesian according to Deﬁnition 6.
Proof of Proposition 3.
If the strategy q0 is improper then according to",N/A,N/A
"If the strategy q0 is improper then according to
Deﬁnition 5 a strategy q1 exists such that inequality R(q1, θ) < R(q0, θ)
holds for all θ. The set of models is ﬁnite and therefore, a value ε < 0 exists
such that for any θ inequality R(q1, θ) −R(q0, θ) ≤ε holds and a chain
0 > ε ≥
X
θ∈Θ
τ(θ)[R(q1, θ) −R(q0, θ)] = F(τ, q1) ≥min
q∈Q F(τ, q)
is valid for any τ ∈T. Since all numbers minq∈Q F(τ, q), τ ∈T, are not
greater then ε the greatest of them is also not greater then ε and
max
τ∈T min",N/A,N/A
"max
τ∈T min
q∈Q F(τ, q) = F(τ ∗, q∗) ≤ε < 0.
9
Proof of Proposition 4. Let F(τ ∗, q∗) < 0 then
F(τ ∗, q∗) = min
q∈Q max
τ∈T F(τ, q) = max
τ∈T F(τ, q∗) =
= max
τ∈T
X
θ∈Θ
τ(θ)

R(q∗, θ) −R(q0, θ)

= max
θ∈Θ

R(q∗, θ) −R(q0, θ)

and therefore
max
θ∈Θ

R(q∗, θ) −R(q0, θ)

< 0.
Consequently, the inequality R(q∗, θ) < R(q0, θ) holds for all models θ ∈Θ
and q0 is improper according to Deﬁnition 5.
The theorem gives good reasons to reappraise lot of well-known methods",N/A,N/A
"that are commonly used as something self-evident.
Let us illustrate this
criticism with two simple examples. The ﬁrst example considers a certain
method of recognition without learning and the second relates to maximum
likelihood learning. In both examples the loss function is
ω(y, y′) =
(
0,
if y = y′,
1,
if y ̸= y′.
Example 3. Let x be an image of a letter, y be its name and θ be a position
of the letter in a ﬁeld of vision. Let the function pXY : X × Y × Θ →R be",N/A,N/A
"constructively deﬁned so that probability pXY (x, y; θ) can be calculated for
each triple x, y, θ. In this case when an image x with an unknown position
θ is observed the decision y∗(x) about the name of the letter has to be of the
form
y∗(x) = argmax
y∈Y
X
θ∈Θ
τ(θ)pXY (x, y; θ).
(1)
Theorem 1 reveals a certain weakness of the commonly used form
argmax
y∈Y
max
θ∈Θ pXY (x, y; θ).
(2)
The strategy (2) could be represented in the form (1) if the weights τ(θ) in",N/A,N/A
"(1) could be chosen individually for each observation x ∈X. However, each
10
Bayessian strategy is speciﬁed with its own weight function τ : Θ →R so
that weights are assigned to elements of the set Θ, not of the set Θ × X.
As a rule, the strategy (2) cannot be represented in the form (1) with ﬁxed
weights τ(θ) that do not depend on x. It means that the strategy (2) is not
Bayessian and is dominated by some other strategy that for each position of",N/A,N/A
"the letter recognizes its name better then strategy (2).
Example 4. Let the sets X, Y and Θ be speciﬁed for the recognized object
as well as a function pXY : X × Y × Θ →R. Let the learning information
be a random learning sample z = ((xi, yi)|i = 1, 2, . . . , n) such that
pZ(z; θ) =
n
Y
i=1
pXY (xi, yi; θ).
Then the decision y∗about the current state y0 based on the current signal
x0 and available learning sample z has to be of the form
y∗= arg max
y0∈Y
X
θ∈Θ
τ(θ)
n
Y
i=0
p(xi, yi; θ)
(3)",N/A,N/A
"y0∈Y
X
θ∈Θ
τ(θ)
n
Y
i=0
p(xi, yi; θ)
(3)
for some ﬁxed τ that does not depend on z. One can see that the commonly
used maximum likelihood strategy
y∗= arg max
y0 p(x0, y0; θML(z)),
(4)
θML(z) = arg max
θ∈Θ
n
Y
i=1
p(xi, yi; θ)
can almost never be represented in the form (3) with constant weights and
therefore is not Bayessian. It means that some other strategy exists that
makes a decision about the current state based both on current signal and",N/A,N/A
"learning information and for each model makes it better than strategy (4).
4
A gap between maximum likelihood and
minimax strategies.
We consider maximum likelihood and minimax strategies and specify a gap
between them.
11
Let us deﬁne for each θ ∈Θ a strategy qopt(θ) = argminq∈Q R(q, θ) that
assigns a probability qopt(y|x, z; θ) for each triple (x, y, z).
The strategy
qopt(θ) is the best possible strategy that should be used if a true model were",N/A,N/A
"known. Since the model is known no learning data are needed. For any ﬁxed
model θ a strategy q(θ) : X × Y × Z →R can be replaced with a strategy
qX(θ) : X × Y →R with the same risk. Probabilities q(y|x, z; θ) have to be
transformed into probabilities qX(y|x; θ) according to expression
qX(y|x; θ) =
X
z∈Z
pZ(z; θ)q(y|x, z; θ)
and so the chain
R(q, θ) =
X
z∈Z
X
x∈X
X
y∈Y
pXY (x, y; θ)pZ(z; θ)
X
y′∈Y
q(y′|x, z; θ)ω(y, y′) =
=
X
x∈X
X
y∈Y
pXY (x, y; θ)
X
y′∈Y
ω(y, y′)
X
z∈Z
pZ(z; θ)q(y′|x, z; θ) =
=",N/A,N/A
"X
y′∈Y
ω(y, y′)
X
z∈Z
pZ(z; θ)q(y′|x, z; θ) =
=
X
x∈X
X
y∈Y
pXY (x, y; θ)
X
y′∈Y
qX(y′|x; θ)ω(y, y′) = R(qX, θ).
is valid for each model θ. Consequently, for each θ the equality
min
q∈Q R(q, θ) = min
qX∈QX R(qX, θ)
(5)
is valid. The symbol QX in (5) designates a set of all strategies of the form
qX : X × Y →R that do not use the learning data.
Deﬁnition 7. A strategy qML : X × Y × Z →R is called a maximum
likelihood strategy if for each triple (x, y, z) it speciﬁes a probability",N/A,N/A
"qML(y|x, z) = qopt
X (x|y; θML(z)),
where qopt
X (θ) = argmin
qX∈QX
R(qX, θ) and θML(z) = argmax
θ∈Θ
pZ(z; θ).
In other words, maximum likelihood strategies use the learning data z to
estimate a model θ and make a decision that minimizes the expected loss
with an assumption that the estimated model is the true model.
12
As it has been quoted for Examples 3 and 4, as a rule, maximum likelihood
strategies cannot be represented in a form of a Bayessian strategy
qB = argmin
q∈Q
X
θ∈Θ
τ(θ)R(q, θ)",N/A,N/A
"qB = argmin
q∈Q
X
θ∈Θ
τ(θ)R(q, θ)
with ﬁxed weights τ(θ) that do not depend on the learning data. In such
cases the maximum likelihood strategy qML may be dominated with another
strategy of the form X × Y × Z →R. Minimax strategies are free of this
ﬂaw.
Deﬁnition 8. Strategy argmin
q∈Q
max
θ∈Θ R(q, θ) is called a minimax strategy.
Theorem 2. No minimax strategy is improper.
Proof. Let us prove an equivalent statement that any improper strategy q0 is",N/A,N/A
"not minimax. Indeed, as far as q0 is improper another strategy q1 exists such
that R(q1, θ) < R(q0, θ) for all θ. Therefore, maxθ R(q1, θ) < maxθ R(q0, θ)
and minq maxθ R(q, θ) < maxθ R(q0, θ) and q0 is not argminq maxθ R(q0, θ).
Though maximum likelihood strategy may be improper whereas minimax
strategy is never improper the ﬁrst one has an essential advantage over the
second. There is a rather wide class of learning data such that the maximum",N/A,N/A
"likelihood strategy is in a sense consistent for any recognized object whereas
there is a rather wide class of recognized objects such that the minimax strat-
egy is not consistent for any learning data. Let us exactly formulate these
statements and prove them.
Let z ∈Z be a random variable that depends on model θ and let for each
z ∈Z and θ ∈Θ a probabillity pZ(z; θ) be given. We will say that this
dependence is essential if for each two diﬀerent models θ1 ̸= θ2 a value z∗",N/A,N/A
"exists such that pZ(z∗; θ1) ̸= pZ(z∗; θ2). Let zn = (zi|i = 1, 2, . . . , n) ∈Zn be
a learning sample, pZn(zn; θ∗) = Qn
i=1 pZ(zi; θ∗) be a probability of a sample
and θML(zn) = argmaxθ pZn(zn; θ) be a maximum likelihood estimation of
the model.
Consistency is a generally known property of maximum likelihood esti-
mate. In the considered case this property may be formulated in a simple
13
way that the probability of inequality θML(zn) ̸= θ∗converges to zero when
n increases or, formally,
lim",N/A,N/A
"n increases or, formally,
lim
n→∞
X
zn∈Zn
err
n
Y
i=1
pZ(zi; θ∗) = 0
(6)
where
Zn
err = {zn ∈Zn|θML(zn) ̸= θ∗}.
(7)
The consistency of a maximum likelihood estimations is a base for a proof of
the following theorem about consistency of maximum likelihood strategy.
Theorem 3. Let z be random variable that takes values from a set Z ac-
cording to probability distribution pZ(z; θ) that essentially depends on θ;
let n be a positive integer and zn = (zi|i = 1, 2, . . . , n) ∈Zn be a random",N/A,N/A
"learning sample with probability distribution pZn(zn; θ) = Qn
i=1 pZ(zi; θ);
let qML
n
: X × Y × Zn →R be a maximum likelihood strategy for an object
⟨X, Y, Θ, pXY : X × Y × Θ →R⟩and learning data ⟨Zn, pZn : Zn × Θ →R⟩.
Then
lim
n→∞max
θ∈Θ

R(qML
n
, θ) −min
q∈Q R(q, θ)

= 0.
Proof. As far as a set Θ is ﬁnite the proof of the theorem is reduced to proof
of the equality
lim
n→∞

R(qML
n
, θ) −min
q∈Q R(q, θ)

= 0
(8)
for any θ. The subsequent proof is based on equality (5), on equalities (6)",N/A,N/A
"and (7) that express consistency of maximum likelihood estimates and on
equality
R(qML
n
, θ) =
X
zn∈Zn
pZn(zn; θ) min
qX∈QX R(qX, θML(zn)),
where θML(zn) = argmax
θ∈Θ
pZn(zn; θ),
14
that follows from Deﬁnition 7. The following chain is valid:
lim
n→∞[R(qML
n
, θ) −min
q∈Q R(q, θ)] = lim
n→∞[R(qML
n
, θ) −min
qX∈QX R(qX, θ)] =
= lim
n→∞[
X
zn∈Zn
pZn(zn; θ) min
qX∈QX R(qX, θML(zn)) −min
qX∈QX R(qX, θ)]
= lim
n→∞
X
zn∈Zn
pZn(zn; θ)[ min
qX∈QX R(qX, θML(zn)) −min
qX∈QX R(qX, θ)]
= lim
n→∞
X
zn∈Zn",N/A,N/A
"qX∈QX R(qX, θ)]
= lim
n→∞
X
zn∈Zn
err
pZn(zn; θ)[ min
qX∈QX R(qX, θML(zn)) −min
qX∈QX RX(qX, θ)]
≤lim
n→∞
X
zn∈Zn
err
pZn(zn; θ)[max
y∈Y max
y′∈Y w(y, y′) −min
y∈Y min
y′∈Y w(y, y′)]
= lim
n→∞{[max
y∈Y max
y′∈Y w(y, y′) −min
y∈Y min
y′∈Y w(y, y′)]
X
zn∈Zn
err
pZn(zn; θ)}
= [max
y∈Y max
y′∈Y w(y, y′) −min
y∈Y min
y′∈Y w(y, y′)] lim
n→∞
X
zn∈Zn
err
pZn(zn; θ) = 0.
It follows from a chain that for any θ an inequality
lim
n→∞

R(qML
n
, θ) −min
q∈Q R(q, θ)

≤0
holds. The diﬀerence R(qML
n",N/A,N/A
"q∈Q R(q, θ)

≤0
holds. The diﬀerence R(qML
n
, θ)−minq∈Q R(q, θ) is never negative and so (8)
is proved.
So, with the increasing length of learning sample the risk function of max-
imum likelihood strategy becomes arbitrarily close to the minimum possible
risk function. Minimax strategy has not this property. Moreover, for certain
class of objects minimax strategies simply ignore the learning sample, no
matter how long it is.",N/A,N/A
"matter how long it is.
Theorem 4. Let for an object ⟨X, Y, Θ, pXY : X × Y × Θ →R⟩a pair (θ∗, q∗
X)
exists such that
q∗
X = argmin
qX∈QX
R(qX, θ∗),
θ∗= argmax
θ∈Θ
R(q∗
X, θ).
Then the inequality
max
θ∈Θ R(q, θ) ≥max
θ∈Θ R(q∗
X, θ)
(9)
is valid for any learning data ⟨Z, pZ : Z × Θ →R⟩and any strategy q : X ×
Y × Z →R.
15
Proof. For any strategy q ∈Q we have the chain
max
θ∈Θ R(q, θ) ≥R(q, θ∗) ≥min
q∈Q R(q, θ∗) =
= min
qX∈QX R(qX, θ∗) = R(q∗
X, θ∗) = max
θ∈Θ R(q∗
X, θ).",N/A,N/A
"X, θ∗) = max
θ∈Θ R(q∗
X, θ).
The theorem shows that for some objects the minimax approach is partic-
ularly inappropriate because it enforces to ignore any learning data. There
is nothing unusual in conditions of the Theorem 4. Examples 1 and 2 in
Introduction show just the cases when these conditions are satisﬁed.
So, there is a following gap between maximum likelihood and minimax strate-
gies. Maximum likelihood strategy may be dominated with other strategy.",N/A,N/A
"In this case it can be improved and, consequently, it is not optimal from any
point of view. However, for wide class of learning data maximum likelihood
strategies are consistent and so their chortage does not become apparent
when learning sample of an arbitrary size may be obtained. Cases of learn-
ing samples of ﬁxed sizes, especially, short samples form an area of improper
application of maximum likelihood strategies. This area is not covered with",N/A,N/A
"minimax strategies. Though minimax strategies are dominated with no strat-
egy, for rather wide class of objects minimax requirement enforces to ignore
any learning sample, no matter how long it is.
5
Minimax deviation strategies.
This section is aimed at developing a Bayesian consistent strategy that has
to ﬁll a gap between maximum likelihood and minimax strategies.
Deﬁnition 9. A strategy argmin
q∈Q
max
θ∈Θ

R(q, θ) −min
q′∈Q R(q′, θ)

is called mini-
max deviation strategy.",N/A,N/A
"
is called mini-
max deviation strategy.
Minimax deviation strategies do not have the drawback of the minimax
strategies. A theorem that is similar to Theorem 3 for maximum likelihood
strategies is also valid for minimax deviation strategies.
16
Theorem 5. Let z be random variable that takes values from a set Z ac-
cording to probability distribution pZ(z; θ) that essentially depends on θ;
let n be a positive integer and zn = (zi|i = 1, 2, . . . , n) ∈Zn is a random",N/A,N/A
"learning sample with probability distribution pZn(zn; θ) = Qn
i=1 pZ(zi; θ);
let q∗
n : X × Y × Zn →R be a minimax deviation strategy for an object
⟨X, Y, Θ, pXY : X × Y × Θ →R⟩and learning data ⟨Zn, pZn : Zn × Θ →R⟩.
Then
lim
n→∞max
θ∈Θ

R(q∗
n, θ) −min
q∈Q R(q, θ)

= 0.
(10)
Proof. The Theorem is a straighforward consequence of Deﬁnition 9 and
the Theorem 3. Let qML
n
be a maximum likelihood strategy for an object
⟨X, Y, Θ, pXY : X × Y × Θ →R⟩and learning data ⟨Zn, pZn : Zn × Θ →R⟩.",N/A,N/A
"It follows from Deﬁnition 9 that
max
θ∈Θ

R(q∗
n, θ) −min
q∈Q R(q, θ)

≤max
θ∈Θ

R(qML
n
, θ) −min
q∈Q R(q, θ)

for any n. It follows from Theorem 3 that
lim
n→∞max
θ∈Θ

R(q∗
n, θ) −min
q∈Q R(q, θ)

≤
≤lim
n→∞max
θ∈Θ

R(qML
n
, θ) −min
q∈Q R(q, θ)

= 0.
As far as the diﬀerence [R(q∗
n, θ) −minq∈Q R(q, θ)

is negative for no model
the equality (10) is proved.
Let us note that the proof of the Theorem 10 shows not only a consistency",N/A,N/A
"of minimax deviation strategy. It shows also that minimax deviation strat-
egy converges to desired result not slower than maximum likelihood strategy.
Similarly, one can show that this advantage of minimax deviation strategy
holds as compared with any consistent strategy and from this point of view
it is the best of all consistent strategies.
Following theorem states that minimax deviation strategies are also inap-
propriate for recognition of certain type of objects.
17",N/A,N/A
"17
Theorem 6. Let for an object ⟨X, Y, Θ, p : X × Y × Θ →R⟩a model θ∗and
a strategy q∗
X exist such that
q∗
X = argmin
qX∈QX
[RX(qX, θ∗) −min
q′
X∈QX RX(q′
X, θ∗)],
(11)
θ∗= argmax
θ∈Θ
[RX(q∗
X, θ) −min
q′
X∈QX RX(q′
X, θ)].
(12)
Then the inequality
max
θ∈Θ [R(q, θ) −min
qX∈QX R(qX, θ)] ≥max
θ∈Θ [R(q∗
X, θ) −min
qX∈QX R(qX, θ)]
holds for any learning data ⟨Z, pZ : Z × Θ →R⟩and any strategy q ∈Q.
Proof. In fact, proof of the theorem does not diﬀer from the proof of the
Theorem 4.",N/A,N/A
"Theorem 4.
However, the consequences of this theorem for minimax deviation strate-
gies are not so destructive as those of Theorem 4 for minimax strategies. In
fact, conditions (11) and (12) imply that a strategy q∗
X ∈QX exists that
does not use learning information and assures minimal possible risk for each
model,
R(q∗
X, θ) = min
qX∈QX R(qX, θ) for all θ ∈Θ.
In this case, any learning data are needless and has to be omitted by any
strategy.",N/A,N/A
"strategy.
Evidently, minimax deviation strategy is not improper and, consequently,
is Bayessian. The following theorem shows how the corresponding weight
function has to be obtained.
Theorem 7. Minimax deviation strategy
q∗= argmin
q∈Q
max
θ∈Θ

R(q, θ) −min
qX∈QX R(qX, θ)

is a Bayesian strategy argmin
q∈Q
P
θ∈Θ
τ ∗(θ)R(q, θ) with respect to weight function
τ ∗= arg max
τ∈T
""
min
q∈Q
X
θ∈Θ
τ(θ)R(q, θ) −
X
θ∈Θ
τ(θ) min
qX∈QX R(qX, θ)
#
.
(13)
18
Proof. Let us deﬁne a function F : T × Q →R,",N/A,N/A
"18
Proof. Let us deﬁne a function F : T × Q →R,
F(τ, q) =
X
θ∈Θ
τ(θ)R(q, θ) −
X
θ∈Θ
τ(θ) min
qX∈QX R(qX, θ)
and express q∗and τ ∗in terms of F,
q∗= argmin
q∈Q
max
θ∈Θ

R(q, θ) −min
qX∈QX R(qX, θ)

= argmin
q∈Q
max
τ∈T
X
θ∈Θ
τ(θ)

R(q, θ) −min
qX∈QX R(qX, θ)

= argmin
q∈Q
max
τ∈T F(τ, q),
τ ∗= arg max
τ∈T min
q∈Q F(τ, q).
The function F is a linear function of q for ﬁxed τ and a linear function of
τ for ﬁxed q and is deﬁned on a Cartesian product of two closed convex sets",N/A,N/A
"T and Q. In such case a pair (τ ∗, q∗) is a saddle point [1, 2, 4],
min
q∈Q max
τ∈T F(τ, q) = F(τ ∗, q∗) = max
τ∈T min
q∈Q F(τ, q),
that implies F(τ ∗, q∗) = min
q∈Q F(τ ∗, q) and
q∗= arg min
q∈Q F(τ ∗, q) =
= arg min
q∈Q
""X
θ∈Θ
τ ∗(θ)R(q, θ) −
X
θ∈Θ
τ ∗(θ) min
qX∈QX R(qX, θ)
#
=
= arg min
q∈Q
X
θ∈Θ
τ ∗(θ)R(q, θ).
In such way developing minimax deviation strategy is reduced to calculat-
ing weights τ(θ) of models that maximize concave function (13). In described",N/A,N/A
"below experiments general purpose methods of non-smooth optimization [6]
were used.
19
6
Experiments
Minimax deviation strategies have been built for objects considered in In-
troduction in Examples 1 and 2. Minimax deviation strategies have been
compared with maximum likelihood and minimax strategies.
Results are
presented on Figures 5 and 6 that show risk R(q, θ) of the strategies as a
function of a model for several learning sample sizes. Figure 5 relates to",N/A,N/A
"Example 1 and Figure 6 to Example 2.
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
n = 1
n = 2
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
θ
b
−6
−3
−0
3
6
b
b
b
b
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
n = 3
n = 10
Figure 5: Example 1. Probability of making a wrong decision for diﬀerent
sizes n of the learning sample. The dashed line shows the risk of a minimax",N/A,N/A
"deviation strategy. The curve R(qML, θ) is the risk of a maximum likelihood
strategy. The curve R(qminmax, θ) is the risk of a minimax strategy. The
curve min
q
R(q, θ) is the minimum possible risk for each model.
7
Conclusion
The paper analyzes the problem when for given object",N/A,N/A
"X, Y, Θ, pXY : X × Y × Θ →R

,
loss function w : Y × Y →R, learning data source",N/A,N/A
"Z, pZ : Z × Θ →R

,
observed current signal x and available learning data z a decision y∗about
20
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
n = 1
n = 2
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
θ
R(q, θ)
min
q
R(q, θ)
R(qmin max, θ)
R(qML, θ)
b0
b0.5
b1
n = 5
n = 10
Figure 6: Example 2. Probability of making a wrong decision for diﬀerent",N/A,N/A
"sizes n of the learning sample. The dashed line shows the risk of a minimax
deviation strategy. The curve R(qML, θ) is the risk of a maximum likelihood
strategy. The curve R(qminmax, θ) is the risk of a minimax strategy. The
curve min
q
R(q, θ) is the minimum possible risk for each model.
current hidden state y has to be made. The wide class of commonly used
strategies make the decision of a form
y∗= argmin
y′∈Y
X
y∈Y
pXY (x, y; θest(z))w(y, y′)
(14)",N/A,N/A
"y′∈Y
X
y∈Y
pXY (x, y; θest(z))w(y, y′)
(14)
where θest : Z →Θ is a reasonable estimating a model θ based on learning
data z. It means that the learning data are used to choose a single best model
and the objects are recognized as if this best model equals the true model.
The approach is acceptable if learning data are arbitrarily long learning sam-
ples and estimator θest : Z →Θ is consistent. If the learning information has",N/A,N/A
"a ﬁxed format, for example, is a learning sample of limited size then the ap-
proach gives no guarantee for subsequent recognition. Indeed, the approach
is not deduced from any risk-oriented requirement. Reasonable requirement
21
to the quality of post-learning recognition implies the decision of the form
y∗= argmin
y′∈Y
X
θ∈Θ
τ(θ)pZ(z; θ)
X
y∈Y
pXY (x, y; θ)w(y, y′)
(15)
that diﬀers from (14). Moreover, any decision that diﬀers from (15) can be",N/A,N/A
"replaced with a decision of the form (15) with the better recognition quality.
There is nothing in decision (15) that could be treated as a selecting some best
model of the model set and so no question stands what estimator θest : Z →Θ
has to be used. No model has to be selected, on the contrary, all models have
to take part in decision with their weights. It is essential that the weights do
not depend on learning data, they are determined by requirement to searched",N/A,N/A
"strategy for concrete applied situation. The paper shows a way for computing
these weights for minimax deviation strategy that is appropriate for learning
samples of any length and in such way ﬁlls a gap between maximum likeli-
hood and minimax startegies.
Minimax deviation strategy is not at all a single strategy that is reason-
able in such or other application. Many other strategies are appropriate too,
for example, a strategies of the form
argmin
q∈Q
max
θ∈Θ
R(q, θ) −α(θ)
β(θ)
(16)",N/A,N/A
"argmin
q∈Q
max
θ∈Θ
R(q, θ) −α(θ)
β(θ)
(16)
with predeﬁned numbers α(θ) and β(θ) > 0. Minimax strategy is a special
case of (16) when α(θ) = 0, β(θ) = 1, minimax deviation strategy is a case
when α(θ) = minq∈Q R(q, θ), β(θ) = 1. A reasonable modiﬁcation of mini-
max deviation strategy is a case when α(θ) = 0, β(θ) = minq∈Q R(q, θ). The
numbers α(θ) may be risks of some already developed strategy and this is a
case when the developer wants to check whether the better strategy is possi-",N/A,N/A
"ble. At last, numbers α(θ) may be simply desired values of risks in concrete
applied situation.
Requirements of the form (16) together with various loss functions deter-
mine various applied situations and obtained results show the way to cope
with all them. It has become quite clear now that each strategy of the form
(16) may be represented in the form (15) because, obviously, no of them is
improper. Obtained results imply unexpected conclusion that learning data
22",N/A,N/A
"22
take part in a decision (15) in a uniﬁed form that depends neither on applied
situation nor on recognized object. So, no question stands more how the
learning data have to inﬂuence the decision about current state when the
current signal is observed. Learning data inﬂuence the decision via and only
via probabilities pZ; (z; θ), not via choise of some best model of the model
set.
References
[1] J.M. Borwein and A.S. Lewis. Convex Analysis and Nonlinear Optimiza-
tion. Springer Verlag, 2000.",N/A,N/A
"tion. Springer Verlag, 2000.
[2] S. Boyd and L. Vandenberghe. Convex Optimization. Cambrige Univer-
sity Press, 2004.
[3] Richard O. Duda, Peter E. Hart, and David G. Stork. Pattern Classiﬁ-
cation. Wiley, 2000.
[4] J.-B. Hiriart-Urruty and C. Lemarechal. Fundamentals of Convex Anal-
ysis. Springer Verlag, 2002.
[5] Herbert Robbins. Asymptotically Subminimax Solutions of Compound
Statistical Decision Problems. In Jerzy Neyman, editor, Proceedings of the",N/A,N/A
"Second Berkeley Symposium on Mathematical Statistics and Probability,
pages 131–148. University of California Press, 1951.
[6] N.Z. Shor.
Nondiﬀerentiable Optimization and Polynomial Problems.
Nonconvex Optimization and Its Applications. Springer, 1998.
[7] Andrew R. Webb. Statistical Pattern Recognition. Wiley, 2002.
23",N/A,N/A
"Opening the black box of deep learning
Dian Lei , Xiaoxiao Chen , Jianfei Zhao
School of Mechatronics Engineering and Automation,
Shanghai University, Shanghai 200072, China
Abstract
The great success of deep learning shows that its technology contains profound
truth, and understanding its internal mechanism not only has important impli-
cations for the development of its technology and effective application in various",N/A,N/A
"ﬁelds, but also provides meaningful insights into the understanding of human brain
mechanism. At present, most of the theoretical research on deep learning is based
on mathematics. This dissertation proposes that the neural network of deep learn-
ing is a physical system, examines deep learning from three different perspectives:
microscopic, macroscopic, and physical world views, answers multiple theoretical
puzzles in deep learning by using physics principles. For example, from the per-",N/A,N/A
"spective of quantum mechanics and statistical physics, this dissertation presents
the calculation methods for convolution calculation, pooling, normalization, and
Restricted Boltzmann Machine, as well as the selection of cost functions, explains
why deep learning must be deep, what characteristics are learned in deep learn-
ing, why Convolutional Neural Networks do not have to be trained layer by layer,
and the limitations of deep learning, etc., and proposes the theoretical direction",N/A,N/A
"and basis for the further development of deep learning now and in the future. The
brilliance of physics ﬂashes in deep learning, we try to establish the deep learning
technology based on the scientiﬁc theory of physics.
1
Introduction
Deep learning is the main representative of the breakthrough in artiﬁcial intelligence today, it has
reached nearly human level in image classiﬁcation [1], speech recognition [2], natural language",N/A,N/A
"processing [3] and so on. The method of deep learning is developing rapidly, which almost subverts
all branches of computer vision ﬁeld. However, the fundamental problem of deep learning at present
is the lack of theoretical research on its internal principles, and there is no accepted theoretical
explanation, namely, the so-called black box problem: Why use such a deep model in deep learning?
Why is deep learning successful? What’s the key inside? The lack of theoretical basis has led to",N/A,N/A
"the academic community being unable to explain the fundamental reason for the success of deep
learning. The theoretical basis is not clear, and we simply do not know from what angle to look at
it. The black box model is purely based on data without considering the physical laws of the model,
it lacks the ability to adhere to mechanistic understandings of the underlying physical processes.
Hence, even if the model achieves high accuracy but it lacks of theoretical support, it cannot be",N/A,N/A
"used as a basis for subsequent scientiﬁc developments [4]. We must not rely solely on intuition
designed algorithmic structures and several empirically tried examples to prove the general validity
of an algorithm. This research method has the potential to learn false modes from non-generic
representations of data, the explanatory nature of the model is very low, and the resulting research
results are difﬁcult to pass on in the long term. As people’s new ideas have been replaced by more",N/A,N/A
"and more complex model architectures, which are almost invisible under the weight of layers of
models, calls for attention to the explanatory nature of machine learning are also getting higher.
Therefore, we need to thoroughly understand the entire system operation of deep learning. We
need to explain what the most fundamental problems are in the ﬁeld of deep learning and whether
1
arXiv:1805.08355v1  [cs.LG]  22 May 2018",N/A,N/A
"1
arXiv:1805.08355v1  [cs.LG]  22 May 2018
these fundamental issues are mature enough to be accurately described in mathematical and physical
languages.
The great success of deep learning shows that its technology contains profound truth, but the most
widely understood way is mathematical analysis, so far, very little attention has been paid to its sci-
entiﬁc issues. However, purely mathematical explanations may lead to misdirection. For example,",N/A,N/A
"the neural network is mathematically trying to approximate any function. In mathematics, it has
been proved that a single-layer neural network can approximate any function if it is long enough,
this viewpoint has greatly hindered the development of neural networks, this is why most people in
the past neglected multi-layer networks for a long time and without studying in depth. Only a small
number of people such as Yann LeCun, Geoffrey Hinton, and Yoshua Bengio still insist on research",N/A,N/A
"in multi-layer neural networks [5]. Therefore, from the great successes achieved in deep learning,
it is far from enough to explain deep learning in mathematics, and the technology of deep learning
needs to be based on scientiﬁc theory.
As deep learning has made breakthroughs in many aspects such as images, phonetics, and text,
methods based on deep learning are increasingly being applied in various other ﬁelds, for example,",N/A,N/A
"recently effective in solving many-body quantum physics problems has also been proved. Therefore,
the theory of deep learning methods must reﬂect some objective laws of the real world. obviously the
most basic and universal theory is quantum physics and statistical physics. What is science? Physics
is the most perfect science that has been developed so far. Just as most engineering disciplines
are based on physics, the engineering foundation for deep learning now and in the future will be",N/A,N/A
"physics. We need to describe the deep learning concept model in the language of physics, so that
we can scientiﬁcally guide the development and design of deep learning. From this we say that the
key to the current and future success of artiﬁcial intelligence depends not only on the mathematical
calculation, but also on the laws of physics. The theory of deep learning requires physics.
The data in the information world is divided into two different types of data: one is symbolic data,",N/A,N/A
"which is designated by our humans; the other is physical data, which objectively reﬂects the data
of the real world, any actual data set we care about (whether it is a natural image or a voice signal,
etc.) is physical data. Reference [6] shows that the reason why neural networks can perform clas-
siﬁcation tasks well is that these physical data x follow some simple physical laws and models can
be generated with relatively few free parameters: for example, they may exhibit symmetry, locality,",N/A,N/A
"or a simple form as an exponent of a low-order polynomial; and symbolic data, such as ”variable
y=cat” is speciﬁed by humans, in this case the symmetry or polynomial is meaningless, and they are
not related to physics. However, the probability distribution of non-physical data y can be obtained
by Bayes’ theorem using the physical characteristics of x. In the reference [4], a Physics-guided
Neural Networks (PGNN) is proposed, which combines the scientiﬁc knowledge of physics-based",N/A,N/A
"models with the deep learning. The PGNN leverages the output of physics-based model simulations
along with observational features to generate predictions using a neural network architecture. Ref-
erence [7] shows that deep learning is intimately related to one of the most important and successful
techniques in theoretical physics, the renormalization group (RG). Reference [8] using DBM and
RBM to represent quantum many-body states illustrates why the depth of neural networks in the",N/A,N/A
"quantum world is so important, revealing the close relationship between deep neural networks and
quantum many-body problems. Reference [9] establishes a mapping of tensor network (TN) based
on quantum mechanics and neural network in deep learning. Reference [10] mentions that people
have found more and more connections between basic physics and artiﬁcial intelligence, such as
Restricted Boltzmann Machine and spin systems, deep neural networks and renormalization groups;",N/A,N/A
"the effectiveness of machine learning allows people to think about the deeper connection between
physics and machine learning, and perhaps it can help us gain insights into intelligence and the
nature of the universe.
The research of the above reference mainly takes the neural network as a computational tool, or as a
method to solve the quantum many-body problem. This dissertation studies the artiﬁcial deep neural",N/A,N/A
"network as a real physical system, considers that the neural network model is a real physical model.
The goal of deep learning training is to obtain the neural network system model which accords with
the physical laws by the interaction or response between the neural network system and the input
physical information. Because the deep neural network is a physical system, its trained model and
its evolution in training must meet the laws of physics.
2",N/A,N/A
"2
This dissertation analyzes the principles of physics embodied in deep learning from three different
perspectives: microscopic, macroscopic, and world view, and describes deep learning with physics
language, aiming to provide theoretical guidance and basis for further study and future development
direction, and tries to establish the technology of deep learning based on the scientiﬁc theory of
physics.
2
A microscopic view of deep learning",N/A,N/A
"physics.
2
A microscopic view of deep learning
The biggest rule of the universe is that the world is made up of microscopic particles such as atoms,
electrons and photons, which obey quantum mechanics. Quantum mechanics is the science of study-
ing the motion law of the microscopic particles in the material world, so the neural network model of
deep learning as a physical system requires that the model must be governed by quantum mechanics.",N/A,N/A
"The following explains deep learning from the basic principles of quantum mechanics.
The human brain neural network is composed of atoms, the number of billions of neurons is the
same, and the computational methods of the human brain should be similar. The neural network,
as an interactive quantum many-body system, determines the deep learning system to be described
by the wave function. The coordinate operator, momentum operator (corresponding translation",N/A,N/A
"operator), angular momentum operator (corresponding rotation operator), energy operator, and spin
operator in the neural network are the most basic and important physical quantity or mechanical
quantity operator.
2.1
The physical meaning of neurons
Information has both physical and symbolic meanings, so neurons also have two meanings: 1)
physical, 2) symbolic mappings. Now discuss the meaning of its physics. In this dissertation, the ﬁrst",N/A,N/A
"hypothesis is that the neuron is the scattering source of the quasi-particle wave and the superposition
of receiving the quasi-particle wave. First look at a classic physics experiment—Young’s double slit
experiment.
Figure 1: Young’s double slit experiment.
As shown in Figure 1, the electrons are diffracted through the aperture a, and then diffracted and
interfered by b and c. The bright diffraction fringes and patches at F indicate that there is a greater",N/A,N/A
"probability of electrons appearing there, and the dark part is there is little or no chance of the appear-
ance of electrons. This dissertation holds that neurons act as electron diffraction interference. When
we look at a neuron as a physical unit, the neuron is a scattering potential well that causes scattering
of quasiparticles (perhaps this scattering originates from the quantum effect in the microtubules of",N/A,N/A
"the neurons, perhaps the electron-phonon coherence coupling in the biological system, perhaps some
other kind of elementary excitation). Therefore, the output after the input of the neuron calculation
is like the scattering output of the electrons through the circular hole, and the law is determined by
the quantum physics theorem. The physical meaning of neurons indicates that, as white light can be",N/A,N/A
"scattered as red, orange, yellow, green, cyan, blue, violet, it is a natural classiﬁer, calculator.
3
In the Young’s double slit experiment, whatever the input is light, or electrons, polarized electrons,
neutrons, and any particle including atomic and subatomic levels will cause diffraction and interfer-
ence effects. In the same way, the physical meaning of neurons indicates that neurons are inherently",N/A,N/A
"capable of discriminating characterizations and are inherently capable of excellent generalization.
The structure of Young’s double slit experiment provides the foundation for a universal quantum
neural network. The physical model of neurons assumed in this dissertation is:
The input of neurons is a multichannel wave function, for example, the input image is a wave
function of multiple pixel points, and the photon (quasi-particle) wave function is superimposed to",N/A,N/A
"become the new scattering source output. The state value of the neuron is the number of quasi-
particles (probability) of excitation after superposition, if you visualize multiple or large numbers
of neurons, you see images of the same nature as the interference diffraction experimentłstreaks and
patches.
Figure 2: Neuron physical model diagram.
The fundamental of this model is that the neuron is a physical model, which reﬂects the probabil-",N/A,N/A
"ity of its state value, and the related theories and deep learning techniques discussed later in this
dissertation can conﬁrm the correctness of its hypothesis.
2.2
Quantum physical model of CNN
In this section, we ﬁrst establish the quantum physics model of the Convolutional Neural Network,
and then make a scientiﬁc analysis of the CNN based on this model, give a physical explanation of
the success of the convolutional neural network, and explore the prospects for further development.",N/A,N/A
"The structure of Young’s double slit experiment provides the foundation for a universal quantum
neural network, as shown in Figure 3:
Figure 3: Universal quantum neural network.Figure courtesy: [11]
4
Similar to the quantum neural network in reference [11], this dissertation considers that the neural
network model of deep learning is the physical model of the interference diffraction of photon or
quasiparticle. The difference is that the input of the network is changed from the photon gun to",N/A,N/A
"the image of the input layer. The detection screen is made up of many neurons. Some neurons
superimpose the input photon or quasi-particle states on each path to obtain intensity (probability of
photons or quasiparticles) and re-scattering output, the intensity values of all neurons constitute an
interference diffraction pattern. In addition to the input, the interference diffraction pattern is also",N/A,N/A
"closely related to the structure of the neural network; the connecting line between neurons is related
to the excitation mode or interaction potential of the neuron and the structure of the neural network,
and has nothing to do with the input, which is consistent with the usual concept of artiﬁcial neural
network.
Is this model correct? Let’s look at two ﬁgures:
Figure 4: A real interference pattern",N/A,N/A
"Figure 4: A real interference pattern
Figure 5: The ﬁrst convolution layer of a typical convolution neural network after training.Figure
courtesy:http://cs231n.github.io/understanding-cnn/
Figure 4 is a diffraction interference fringe obtained from a real double-slit experiment, which con-
tains the total intensity distribution information of double-slit interference and single-slit diffrac-
tion. Figure 5 shows the ﬁrst convolution layer after a typical CNN training, it also sees stripes and",N/A,N/A
"patches. Comparing the two graphs, we can see that the two are very similar, and all of them are
stripes and patches, which fully shows that our neural network model is the quasi-particle diffrac-
tion interference model in physics. The neuron receives multiple signals from the previous layer,
performs quantum superposition, if the interference superposition elimination, then the neuron re-
mains silent; if the interference superposition intensity is extremely high (the stripe or patches in the",N/A,N/A
"ﬁgure), then the neuron activates the impulse, emits the superposition intensity output signal. This
also explains why physiological neurons may remain silent even if they have strong signal input.
From the ﬁrst layer of the convolutional layer in Figure 5, we can see that most people think that
the ﬁrst layer of convolution is to learn the edge of the image, and what the later convolution layer
5
learned is no one can understand. In this theoretical model, the ﬁrst and the back layers are in-",N/A,N/A
"terference diffraction fringes! Interferometric diffraction or scattering experiments in physics can
analyze and discover elements, and deep learning neural networks can be used for a wide range of
applications such as image recognition because its mechanism is also the mechanism of interference
diffraction or scattering experiments. Each fringe or patch reﬂects the momentum and angular mo-
mentum characteristics of the system, and the momentum or wave vector mechanics respectively",N/A,N/A
"represent the translation and rotation invariance of the space.
Let us ﬁrst look at the relationship between translation operation and convolutional neural networks.
2.2.1
CNN and translation operation
According to quantum mechanics, the space translation operator is:
ˆD(a) = eia.ˆp/hor ˆD(a) = eiˆk.a
(1)
Where a is the translational magnitude, the wave vector operator ˆk = −i∇, the momentum op-
erator ˆp = −ih∇, ˆp ≡hˆk, h is the Planck constant, the wave vector k and the momentum p are",N/A,N/A
"independent of a, and are mechanical quantities only related to the system.
The physical quantities that describe the spatial invariance or spatial symmetry of the arbitrary func-
tion f(x + a) = f(x) are the momentum or wave vector, i.e. the physical conservation quantities
corresponding to the spatial symmetry are the wave vector k or the momentum p. For example,
the free particle or plane wave function ψ(x) = Ceikx−iωt , where k is the wave vector, equal to",N/A,N/A
"the reciprocal of the wavelength, it describes its spatial properties. The edge boundary, texture, and
color change of the image must destroy the translation symmetry. The mechanical quantity wave
vectors can be used to express whether the edge, texture, color of the image is equal or unequal in
space. The wave vector is the basic physical quantity quantifying these attributes.
The translation in a one-dimensional case is easy to prove:
ea d
dx f(x) = f(x) +
∞
X
n=1
an
n!
dn
dxn f(x) = f(x + a)",N/A,N/A
"∞
X
n=1
an
n!
dn
dxn f(x) = f(x + a)
(2)
which is:
ˆD(a)f(x) = f(x + a)
(3)
The convolution calculation in the CNN actually reﬂect the translation operation, and the one-
dimensional convolution in book [12] for image I(x) and kernel function K(a) is as follows:
S(x) =
X
a K(a)I(x −a)
=
X
a K(a)e−a d
dx +a d
dy I(x)
=
X
a K(a)e−ˆk.aI(x)
=
X
a K(a) ˆD(a)I(x)
(4)
The two-dimensional form is as follows:
S(i, j) =
X
m
X
n K(m, n)I(i −m, j −n)
(5)",N/A,N/A
"S(i, j) =
X
m
X
n K(m, n)I(i −m, j −n)
(5)
The entire feature map layer image is obtained by translation. To understand the image, consider the
one-dimensional case, the minimum unit of translation is a pixel, if K(a) =

1, (a < r)
0, (a ≥r)
is set.
For the input layer is the image, only two points are taken within the |r| range, the range is small,
and the output of the convolutional layer is:
S(x) =
X
a K(a) ˆD(a)I(x) = ( ˆD(0)+ ˆD(1))I(x) ≈(2 + d
dx)I(x)
(6)
6",N/A,N/A
"dx)I(x)
(6)
6
So the ﬁrst convolution layer sees the edge of the image element in the background, but it is not
equal to the edge of the image element because of the convolution kernel.
If the image I(x) has spatial symmetry with wavelength λ, or if the wave vector has spatial symmetry
of k = 2π/λ , i.e. I(x) = sin(kx) , then the output of the convolutional layer is:
S(x) =
Z r
0
ˆD(a)I(x)da =
Z r
0
sin k(x + a)da = 2
k sin kr
2 sin(kx + kr
2 )
(7)",N/A,N/A
"sin k(x + a)da = 2
k sin kr
2 sin(kx + kr
2 )
(7)
After convolution, the value still has the same wave vector k volatility, but the intensity is
4
k2 sin2 kr
2 ,
the interference diffraction envelope appears, the maximum and the minimum intensity values ap-
pear in:
kr = nπ

n = 1, 3, 5, · · · the intensity is extremely high
n = 2, 4, 6, · · · the intensity is zero
The above results show that an interferometric diffraction image is obtained by spatial convolution.",N/A,N/A
"When the input wavelength is longer, the intensity at the maximum by the convolution is ampliﬁed
to 4/k2 times the original input wave intensity. When the convolution kernel structure is certain,
only the wave vectors satisfying certain conditions will appear extremely large. Assuming that only
the brightest point is taken, then only the input wave vector satisﬁes k = π/λ sine wave through the",N/A,N/A
"convolution after the ”bright spot.” That is to say, in the case of a convolutional kernel structure, the
”brightest” reﬂects the wave vector k of the sine wave. The actual wave is the superposition of sine
wave, and the ”brightest” point of the interferometric diffraction image will not have only one point.
The interference diffraction image reﬂects the spatial symmetry of the input wave.
The next section explains what the physical meaning of the convolution formula (Equation 4) is,",N/A,N/A
"explains the nature of the convolution kernel and explains why the convolution calculation is not
summed over the entire image range, but instead use a ﬁnite window convolution calculation such
as 3*3? Why do these moving convolution windows use the same convolution kernel, the so-called
shared weight? Why does a convolutional layer use multiple feature mapping layers? Why does
each feature mapping layer convolutional kernels differently? Why pooling? Why use Relu acti-",N/A,N/A
"vate functions, etc. In our model, the neuron is a unit that receives multiple inputs and quantum
superimposes and then scatters, so a perfect answer can be obtained by using the scattering theory
of quantum mechanics.
2.2.2
Physical meaning of convolution calculations and convolution kernels
A general CNN interprets a convolution kernel as a ﬁlter, but what does it ﬁlter? What does it
keep? It is not clear, so this argument is difﬁcult to convince, and the ﬁlter’s opinion is not clear.",N/A,N/A
"Convolutional neural networks have achieved great success in the ﬁeld of computer vision, one of the
most important components is the convolution kernel, which is primarily responsible for capturing
most of the abstraction of the network. In contrast, this component is the least understood processing
block because it requires the maximum computational learning [13].
This section builds the convolutional calculations on the quantum physics model described in Sec-",N/A,N/A
"tion 2.1. The physical basis of the interference diffraction experiment is quantum mechanical scat-
tering theory. According to the scattering theory, the system Hamiltonian does not contain time, and
the incident wave is directed at the target. The wave function ψ at the position r is: [14].
ψk(r) = eik·r −
Z
G(r −r′)U(r′)ψ(r′)dr′
(8)
Equation 8 is the integral equation, the integral is performed in the entire space, the ﬁrst is the input",N/A,N/A
"wave, and the second is the scattering wave. The physical meaning of the second item is very clear,
U is the interaction potential function. The input wave scatters in the dr′ range near r′ point to
form a scattering point source with intensity U(r′)ψ(r′)dr′ . This point source propagates to the
observation screen r point according to the outgoing Green function, and the scattering of the points
is superimposed as the scattering probability amplitude ψsc .
The Green function is:
G(r, r′) = −",N/A,N/A
"The Green function is:
G(r, r′) = −
eikr
4π |r −r′|
(9)
7
The incident wave requirement in Equation 8 is monochromatic and planar wave, and does not do
any other approximation. The equation is applicable both to elastic scattering and inelastic scattering
or collision scattering. So the total intensity of a neuron scattering from a quasi particle of a certain
wavelength is
S =
Z
|ψ(r)|2dr
(10)",N/A,N/A
"wavelength is
S =
Z
|ψ(r)|2dr
(10)
The integral r is in the range of neuron size. According to this model, the total intensity of a neuron
is deﬁned as the probability density ψ2 of the excited particle, so
S ≈|ψ(0)|2
(11)
Let S be the square of the convolution s , that is S = s2 , then the convolution s is:
s =

Z
G(r′)U(r′)ψ(r′)dr + b

(12)
Note that the left side of Equation 8 is a wave function, and there are also wave functions in the",N/A,N/A
"integral term, so it is difﬁcult to solve. As an approximate calculation, let the ψ in integral as input
image wave, converted to discrete expression. The volume element dxdydz = 1 , so the convolution
for a wave vector k is sk :
sk =

X
r′ G(r′; k)U(r′)ψ(r′) + b

(13)
Where the sum range of r′ is within the neuron volume range. The convolution kernel is:
K = G(r′; k)U(r′)
(14)
ψ(r′) is the input image wave, it is only related to x′, y′ , and has nothing to do with other coordi-
nates:",N/A,N/A
"nates:
sk =

X
x′y′z′ G(x′, y′, z′; k)U(x′, y′, z′)ψ(x′, y′) + b

=

X
x′y′
X
z′ G(x′, y′, z′; k)U(x′, y′, z′)ψ(x′, y′) + b

(15)
The square s2
k of sk represents the quasi-particle probability density that is excited when the incident
wave (or quasi-particle) has a wave vector k (size, direction, and polarization direction). So the
convolution kernel:
Kx′y′(k) =
X
z′ G(x′, y′, z′; k)U(x′, y′, z′)
(16)",N/A,N/A
"X
z′ G(x′, y′, z′; k)U(x′, y′, z′)
(16)
x′, y′ is a two-dimensional image coordinate, sk represents the convolution of the feature mapping
layer, and different wave vectors have different sk (if the quasi-particles are electrons also have a
direction: spin)
sk =
X
x′y′ Kx′y′(k)ψx′y′ + b
(17)
The convolution of all k is a set S = {sk}.
The following is a discussion of its physical meaning and its implications for the calculation of
convolutional neural networks.
2.2.3",N/A,N/A
"convolutional neural networks.
2.2.3
Quantum mechanics interpretation of CNN
There are various interpretations of convolutional neural networks, but according to the above quan-
tum physics model, CNN can be perfectly interpreted. The interpretation is fundamental and deter-
ministic, it will inspire the architectural design of deep convolutional networks.
(1) When the inner product of the convolution is represented by the norm and the angle:",N/A,N/A
"∥ω∥∥x∥cos(θ(ω,x)) , the trained inner product of the convolutional neural network can
be decoupled to ﬁnd the relationship between norm and angle in the feature map [15].
8
Figure 6: CNN learned features are naturally decoupled.Figure courtesy: [15]
If the convolution of spherical coordinates is used, the relationship between the norm and
angle in the feature map is more obvious:
Figure 7: 2D feature visualization on MNIST dataset with natural training.Figure courtesy: [15]",N/A,N/A
"The ﬁgure shows that the angles represent semantic/label differences, and the feature norm
represents within-class differences. This result can be explained in our model. It can be
seen from (Equation 14) that the general action potential U(r) is only related to r , i.e.
U(r) = U(r) . So the convolution kernel is related to the norm and has nothing to do with
the angle, the CNN feature image is related to the angle. The above experiments verify the",N/A,N/A
"correctness of the physical model of the convolutional neural network.
(2) The number of convolution kernels is related to the color of the image. The input re-
quirement in the scattering equation(Equation 8) is a monochromatic wave, that is, the
convolution kernel(Equation 16) is related to the wavelength of the input wave, and differ-
ent wavelength should have different convolution kernel Kmn. Applied to the color image,",N/A,N/A
"convolution neural network should have different convolution kernel for different colors
image. For example, they can be composed of three kinds of convolution kernels: red,
green, and blue. Of course, they can also be composed of multiple kernels such as red,
orange, yellow, green, blue, and purple.
(3) The number of convolution kernels is also related to the polarization direction of the inci-
dent wave. It can be seen from(Equation 16, 17) that even if the image is monochromatic,",N/A,N/A
"the convolution kernels of different z are different. So even if the input is a black-and-
white image, multiple feature mapping layers (multiple convolution kernels) are needed,
just as white light contains light of all colors, and random monochromatic light also con-
tains polarized light of all polarization directions. If the input is an electron, the number
of convolution cores is related to the spin direction. In a comparable size, the number of",N/A,N/A
"feature map layers is much larger than the convolutional window size.
9
(4) The reason of partial receptive ﬁelds is not because the pixels are usually highly corre-
lated in neighboring regions. The convolution kernel sharing of feature layer is not due to
translation invariance, they are due to the limited scope of the action potential U(r′) of the
neuron, that is, the coordinate x′, y′ in the convolution kernel (Equation 16) is 0 outside the",N/A,N/A
"range of action potential. Therefore, the summation of the x′, y′ in (Equation 17) does not
require full space, i.e.the CNN should not be fully connected but partial connection. For
the same feature mapping layer, all the neuron potentials U(r′) are the same, so the convo-
lution kernels of all the sliding window convolutions of the same feature mapping layer are
the same or share one, which explains from the scientiﬁc theory that the fundamental rea-",N/A,N/A
"son for the success of CNN is the important characteristic of CNN: partial receptive ﬁelds
+ weight sharing. In the actual application of CNN, the convolution kernel size (that is, the
convolution window size) is often 3x3, 5x5, 9x9 and so on, scattering is mainly concen-
trated in the incident direction, so the window size is too large to be meaningful. However,
if the 1*1 size of the convolution kernel is used, the interference effect will also be poor. In",N/A,N/A
"addition, considering the symmetry of K, convolution kernel size is generally used odd.
(5) The purpose of pooling operations is not only to reduce the size of the output eigenvectors.
(Equation 15) is the intensity of a neuron, and the image formed by all the neurons of a
convolutional feature layer is an interference diffraction pattern. Because the coherence of
the wave is strong in some places and weak in some places and not even in some places,",N/A,N/A
"and those ”bright” neurons will be the scattering sources of the subsequent convolutions,
so each convolutional layer must be pooling. That is, in the convolution window area,
the ”bright” neurons must be selected according to the intensity values of the neurons in
each convolution layer feature layer, which is also the physical reason why the biological
neuron can either output or not output even if it has a signal input. Obviously, pooling",N/A,N/A
"is an important computing component. In the early years, many of the studies based on
convolution architecture used average pooling, now they are replaced by Max Pooling.
From our model we can see that in practical application, because the window size is not
large, it is reasonable to select one of the most bright neurons, that is, to adopt the max
pooling method. It is also seen from here that the pooling is of decisive importance to the",N/A,N/A
"initial convolution layer, but as the number of layers increases, the interferogram sharpens
and bright points become less, so the effect of pooling is weakened, which is the same as
the result of the reference [16]. Pooling can also be explained by the renormalization group
in Section3.4.
(6) The convolution kernel of different layer is not same, because each of the ”brightest” neu-
ron positions represents the coherence of the corresponding convolution window image,",N/A,N/A
"which is related to the symmetry of the image and the structure of neural network. After
pooling, the spacing as a new scattering source is different, so subsequent convolution ker-
nels will also be different. That is, except for the same feature mapping layer, convolution
kernels of each feature map layer of the convolution layer are different.
(7) Coherence is the most important condition for multilayer CNN. In our model, the purpose",N/A,N/A
"of convolution is to create the entanglement of each pixel in the image under the action
of neurons, thus forming the interference diffraction fringes or patches according to the
spatial translation structure. According to the quantum mechanics, this is a coherence
phenomenon caused by the superposition principle of waves. The total intensity after inter-
ference superposition is not necessarily equal to the sum of the intensity of the sub-beams,",N/A,N/A
"may be more strong or may be equal to 0 under the interference. The important condition
of coherence is the coherent wave. There are two ways to produce coherent wave, the ﬁrst
one is to ensure that the monochrome of the wave and the phase of each wave of the ﬁxed,
so need multi-layer convolution; the second is the interference of oneself and oneself, so
need multi-layer convolution, generally need at least 3 or more.
10",N/A,N/A
"10
Figure 8: Interfering with oneself causes CNN to require multiple layers of convolutional layers.
If we understand from the biological neural network, the wavelength of the natural color
of the physicist’s world changes monotonously from red to purple, but the system of hu-
man perception of color is closed-loop, such as the combination of red light and purple
light is understood as the monochromatic magenta color. However, does not physically",N/A,N/A
"exist with a single physical wavelength of light corresponding to the color, but the human
perception system fusion understands as a single color. Therefore, the convolution neural
network must be fused or transformed after the input scattering (decomposition) must be
multilayered.
(8) Convolution is not the extraction of human knowledge such as image edges or colors, the
convolution is the physical law and does not require human prior knowledge. From (Equa-",N/A,N/A
"tion 2) to know the image gradient is obtained after the translation operation, so for the ﬁrst
feature layer of the image we can see that it reﬂects the edge of the image. But as the subse-
quent continuous pooling and convolution, feature layer image will become more and more
difﬁcult to understand and abstract compared to the original layer. However, in our model,
the convolution image is a diffraction stripe or patch image after destructive interference",N/A,N/A
"or constructive interference, which is the superposition of the same or coherent wave. That
is, the images are decomposed and classiﬁed by the same coherent attribute. The wave
of the same phase has a destructive interference and the opposite phase has a constructive
interference, and the interference diffraction patterns will effectively deconstruct the entire
information of the incident image. And this coherent property is the symmetry of the im-",N/A,N/A
"age, according to quantum mechanics, the physical quantity described by the symmetry is
the wave vector. It can also be said that CNN is to measure the wave vector of the image,
because it is the XY plane convolution of the image, i.e. the measurement of the momen-
tum px, py in the x, y direction. According to quantum mechanics, the z directional angular
momentum operator is deﬁned as: ˆlz = xˆpy −yˆpx , so it also detects angular momentum",N/A,N/A
"or rotational symmetry around the z direction. That’s to say, a trained CNN measures the
translational symmetry of the x, y direction of the image or the rotational symmetry of the
z direction through the translational operation and interaction of the image, is classiﬁed
as the interference diffraction fringes or patch image that we see. The feature map layer
is effectively classiﬁed according to the symmetry, and then the whole connection layer is",N/A,N/A
"mapped, which can effectively recognize the image.
In summary, the above research shows that LeCun’s most famous contribution, the convolutional
neural network, is entirely based on prior knowledge and that the idea of not requiring human struc-
tured knowledge is completely correct. CNN is based on the scientiﬁc theory, so it is the best method
in image recognition. CNN is a physical model, so it is very successful in the processing of physical",N/A,N/A
"data such as images, videos, sounds, condensed matter physics, etc., but the performance is worse
than other models when processing the strong subjectivity of symbolic modeling. For example, no
matter how much data is input, it is impossible to train a model that can read product descriptions
and generate an appropriate code base [17].
11
2.2.4
Signiﬁcance of classiﬁcation layers in CNN
The convolutional layer is followed by a classiﬁcation layer whose meaning maps the mechanical",N/A,N/A
"characteristics learned in the convolution layer to human symbols (marks). The signiﬁcance of the
classiﬁcation layer is expressed in:
• On the signiﬁcance of the classiﬁcation layer, the ﬁrst is mathematics. In order to effec-
tively apply the ability of neural network that can approximate arbitrary functions mathe-
matically, the classiﬁcation layer must be fully connected.
• The classifying layer in neural network is also physical. In our model, the neuron is a",N/A,N/A
"probability wave. The output of the last layer’s activation function must be guaranteed
to meet the normalized requirement, generally, the softmax function with a clear physical
meaning is used. The activation function is shown in Section 2.5.
• The classiﬁcation must have generalization and must obey the laws of statistical physics
and must cooperate with entropy. The content of entropy is shown in Section 3.2.
2.2.5
Development prospects of CNN",N/A,N/A
"2.2.5
Development prospects of CNN
(1) According to the neuron scattering theory, strictly speaking, the convolutional neural net-
work should be extended to the complex number ﬁeld so that it can use the wave function
with phase information. Thus, the input image is the intensity, and it should be squared
root when used as a wave function, which is equivalent to the fact part:
ψ(x, y) =
p
I(x, y)
However, in the actual calculation of CNN, the calculation on the complex number ﬁeld",N/A,N/A
"may not be signiﬁcant. In Equation 10, when we compute S, we need to square ψ , and
|ψ|2 is proportional to the intensity of the image. The calculation of S in the real ﬁeld
will appear negative, but subsequent Relu rectiﬁcation guarantees that the output is posi-
tive. It still conforms to the model where the value of the neuron is the intensity value, the
signiﬁcance of max pooling is to ﬁnd the brightest neurons. In short, if the convolution",N/A,N/A
"is calculated in the complex number ﬁeld, the square root is computed ﬁrst, and then the
square is computed, which is equivalent to repeating computation. And if the convolu-
tion is calculated in the real ﬁeld, input do not square root, output also do not square, the
Relu rectiﬁcation function guarantees that no negative number will appear. By reducing
the repetition calculation and saving the calculation amount, the calculation error can be",N/A,N/A
"reduced. There is no big difference between the calculated effect on the real ﬁeld and the
strict complex number ﬁeld.
(2) Choosing the appropriate convolution kernel is crucial for obtaining the most signiﬁcant
and important information contained in the input signal. This allows the model to make
better inferences about the content of the signal. The goal of this transformation is to
change the data in a way that is more easily separated by the classiﬁer. According to",N/A,N/A
"Equation 16, a better model is designed using the convolutional features, such as better
coordinates: cylinder coordinates or spherical coordinates of CNN [15].
(3) The training of CNN based on quantum scattering theory obtains a large amount of input
information, but the ﬁnal classiﬁcation only occupies a small part of the information. These
are correct and objective reﬂections of the input information, it is easy to drown in the",N/A,N/A
"training process. This is undoubtedly a waste of valuable prior probabilities that can be used
to migrate large-scale network knowledge into small-scale networks. Therefore, making
full use of this information or data migration learning in other ﬁelds is also a topic worthy
of study.
(4) Multilayer CNN can not only perceive the translational symmetry and rotational symme-
try of input, but also transform and perceive the fusion of various combinations of col-",N/A,N/A
"ors. In addition, it should also can transform and perceive the polarization direction of
light. That is, CNN can perceive very rich three-dimensional scenes and behavioral in-
formation from static two-dimensional images. The geometry school will laugh : how
can an image calculate three-dimensional, which is mathematically impossible. It doesn’t
make any sense mathematically, but it makes sense physically! Human beings can perceive
12",N/A,N/A
"12
three-dimensions from two-dimensional images, and deep convolution neural networks can
extract 2.5-dimensional information from two-dimensional images. This is the quantum
effect: White light can be decomposed into red, orange, yellow, green, cyan, blue and vio-
let through neuronal interaction or coupling or entanglement, and random monochromatic
light can be decomposed into various polarized light. According to the physical model",N/A,N/A
"above, a lot of new information can be found from the polarization information, such as
stereo information, like the principle of stereoscopic ﬁlm. This is an important prediction
of the deep convolution neural network in this dissertation.
(5) The CNN discussed above is to classify the spatial symmetry of the image by spatially
translating and interacting with neurons. After the above measurement, the state after the",N/A,N/A
"collapse is measured as the new environment of Hamiltonian to state a new round of evo-
lution. If the incident wave changes, such as the time dependent dispersion of the packet,
the visual retention, or the Hamiltonian contains time, then it will be a Schr¨odinger equa-
tion that contained time. At this time Equation 17 is time-containing, the green function
is divided into the delayed Green function and the advanced Green function, which can",N/A,N/A
"be computed to predict the short future by or to recall a brief past. For time translation
operations, according to quantum mechanics, the conserved quantity of time translation
invariance is energy. Through the convolution of time translation, it is also possible to clas-
sify the energy properties of the input information. And the scattering of neurons contains
time, so it will be an important research direction and may explain the important functions",N/A,N/A
"of visual retention, visual prediction and memory.
(6) The convolution neural network based on quantum scattering theory is expected to compute
the internal properties of the biological neurons and to gain more understanding of the
functions of the biological neurons and the human brain.
(7) CNN is supervised training, according to the above theory, it can be used in unsupervised
pre-training and training.",N/A,N/A
"pre-training and training.
(8) In our neural network model, all the neuron cells of CNN form an image of a grid cell and
a location cell, which is very similar to the image of the biological grid cell and position
cell. It will be an important research direction to combine CNN with LSTM to achieve
navigation like the brain grid cells.
2.3
Deep learning based on energy model
Energy is one of the most important concepts in physics and even in the entire natural sciences.",N/A,N/A
"All forms of physical movement have the concept of energy, such as mechanical, electromagnetic,
thermal, light, chemical movement, and biology, etc. The analysis of energy can greatly simplify the
analysis of material motion. Energy is the measure of movement transformation, and it is an additive
amount, following the law of conservation of energy. Energy in quantum mechanics is represented
by the Hamiltonian operator.",N/A,N/A
"by the Hamiltonian operator.
In our model, the strength of neurons is described by the square of the wave function. The typical
model of the neural network composed of interacting neurons in deep learning is the Boltzmann
machine.
According to quantum mechanics, the wave function of the system is Ψ, and the statistical average
of the mechanical quantity O is:
⟨Ψ | O |Ψ⟩
⟨Ψ | Ψ⟩
=
P
x |Ψ(x)|2O(x)
P
x |Ψ(x)|2
(18)",N/A,N/A
"⟨Ψ | Ψ⟩
=
P
x |Ψ(x)|2O(x)
P
x |Ψ(x)|2
(18)
There is an important conclusion between the quantum mechanics measurement and the statistical
sampling of wave functions: if Ψ is the eigenstate of the system energy, then:",N/A,N/A
"H2
=
D
H⟩2 = E2
0
(19)
That is, the variance of the Hamiltonian energy H is 0, which means that if the system is in the
ground state E0 , the statistical ﬂuctuation completely disappears. This feature is very important
because it means that the closer we are to the ground state, the less ﬂuctuations we have in the amount
13
we want to minimize, and the less energy we have. According to quantum statistical physics, if the",N/A,N/A
"system is a closed system, there is energy ﬂuctuations, but the total number of particles is constant,
the multi-body probability density ρ(x) satisﬁes the Boltzmann distribution:
ρ(XN) =
1
cNzN(T, V )e−βH(XN)
(20)
Partition function is: Z =
1
cN
R
dXNe−βH(XN) , probability density is the normalized |Ψ|2 . For a
neural network composed of interacting multi-body quantum systems, the general form of Hamilto-
nian is:
H = −ℏ2
2m
N
X
i
∇2
⃗ri +
X
i
V1(⃗ri) +
X
i<j
V2(⃗ri,⃗rj)
(21)",N/A,N/A
"X
i
∇2
⃗ri +
X
i
V1(⃗ri) +
X
i<j
V2(⃗ri,⃗rj)
(21)
The potential energy between two particles in physics is chosen as a function of the distance between
particles in the form of:
V12 = V (⃗r1,⃗r2) = V (|⃗r1 −⃗r2|) = V (r12)
(22)
Without regard to kinetic energy, only the interaction is considered, the interactions always interact
in pairs, that is, the interaction energy (potential energy) takes only quadratic term, so the energy
model is obtained:
E(v, h) = −bT v −cT h −vT Wh
(23)",N/A,N/A
"E(v, h) = −bT v −cT h −vT Wh
(23)
Where b,c and W are all unconstrained, real-valued learning parameters. The model is divided into
visible layer v and hidden layer h, and the interaction between them is described by matrix W [18].
This is the most basic component of deep learningłthe Restricted Boltzmann Machine energy model.
It is consistent with the view put forward in this dissertation that neural network in deep learning is",N/A,N/A
"a physical system and conforms to the laws of physics. For Boltzmann distribution sampling, the
method of random gradient descent that minimize the energy can determine network parameters b,
c and W.
2.4
Relationship between energy model and convolution model
From the above analysis, CNN is based on accurate quantum physics, and RBM is based on statisti-
cal physics which will be described later, the difference is pure ensemble and hybrid ensemble.",N/A,N/A
"The traditional RBM can only express the probability distribution function with a positive value.
In order to make it suitable for describing the wave function with phase information, Carleo and
others extend the parameters of RBM to the complex ﬁeld. In addition, in the actual calculation, the
function form used by Carleo is the product of multiple RBM that share weights. This structure is
equivalent to a single hidden-layer convolutional neural network, thus ensuring the spatial translation",N/A,N/A
"invariance of the physical system in the structure [19].
In addition, the RBM ignores the effect of the kinetic energy of the neuron, that is, the centroid
motion, or ignores the quantum effect of the neuron itself, so the effect of the model is obviously
worse than that of the CNN.
2.5
Normalization of neural networks
It has been explained that the wave function of the neural network system is ψ . According to",N/A,N/A
"quantum mechanics, the meaning of the neuron is that each neuron represents the probability |cn|2
that eigenvalue Fn can be measured by a group of mechanical quantities F , and the wave function
satisﬁes the normalized condition, so P
n
c2
n = 1.
Once the wave function of the system is determined, the average value of the mechanical quantity
and the probability distribution of the measurement result can be obtained through the mechanical",N/A,N/A
"quantity measurement. The results obtained by the physical system are obtained by measurement,
14
whereas in quantum mechanics, measurements differ from those in classical mechanics. The quan-
tum measurements affect the measured subsystems, such as changing the state of the measured
subsystem, which called the wave function collapse, and the measured result accords with a certain
probability distribution. In other words, when the mechanical quantity is measured, the state is col-",N/A,N/A
"lapsed to the eigenstate of this mechanical quantity, then the mechanical quantity is its eigenvalue.
But it may also be other eigenvalues, that is, it may also be collapsed to other momentum eigenstate,
which is a probability, so it must have:
X
ihl
i = 1
That is to meet the normalization conditions. Quantum measurement is the core issue of the quantum
mechanics interpretation system.
In deep learning, considering the concept of mechanical quantity measurement, the result output of",N/A,N/A
"each layer neural network characteristic (eigenvalue) learning should be a quantum measurement,
so the activation function is needed to determine its probability distribution. If there is no activation
function, then the network can only express the linear mapping. Even if there are more hidden layers,
the entire network and the single-layer neural network are equivalent. The meaning of the activation",N/A,N/A
"function is the output of the quantum measurement, which determines its probability distribution
and is normalized. The most important activation functions are:
• softmax(hi) =
exp(hi)
P
j exp(hj).
• sigmoid(hi) =
1
1 + exp(−hi)
• Relu(hi) =

hi, (hi > 0)
0, (hi ≤0)
The ﬁrst activation function guarantees that the sum of all output neurons is 1.0, which guarantees
the normalization of its probability distribution. So the last layer basically apply this activation",N/A,N/A
"function. The softmax function has a clear physical meaning, which is the Boltzmann probability
distribution of the ideal gas or quasi particle.
The sigmoid activation function is more commonly used in traditional neural networks, but it is not
suitable for deep neural networks. A major breakthrough in deep learning technology is the use of
a third activation function. The Relu function directly outputs a probability or probability density",N/A,N/A
"distribution which is a quasi-particle number in our physical image, and it must be greater than or
equal to 0.
3
A macroscopic view of deep learning
The deep neural network is an interacting quantum multibody system, according to quantum me-
chanics, by determining the wave function p of the quantum multi-body system, the whole in-
formation of the quantum system is grasped. The core goal is still to ﬁnd the solution ψ of the",N/A,N/A
"Schr¨odinger equation, this is generally very difﬁcult. However, because we are mainly concerned
with the macroscopic properties such as statistical mean of system observations, macroscopic per-
formance is subject to statistical physics. Statistical physics is a bridge between microscopic and
macroscopic, which determines the condition of macroscopic equilibrium state and stable state, and
the change direction of macroscopic state. Quantum statistical physics is described in two different",N/A,N/A
"ways, pure ensemble and hybrid ensemble, so there also are two different kinds of neural networks.
Ensemble is an abstract concept, which is divided into pure ensemble and mixed ensemble. If
the N subsystems in the ensemble are all in the same state |ψ⟩, then the ensemble is called pure
ensemble and they are described in pure state |ψ⟩. If N systems have N1 systems in state |ψ1⟩, N2
systems are in state |ψ2⟩, ... Ni are in state |ψi⟩,..., the probability of each measurement system",N/A,N/A
"being in |ψ1⟩, |ψ2⟩, · · · , |ψi⟩, · · · state is P1 =
N1
N , P2 =
N2
N , · · · , Pi =
Ni
N , · · · , and the set
of N systems(N →∞)is called a hybrid ensemble, which is described by a set of all |ψi⟩and
Pi(i = 1, 2, · · · ) .
15
3.1
Purely ensemble and hybrid ensemble neural networks
The theory of quantum statistical physics is used to design the neural network architecture, which
has two kinds of neural networks, pure ensemble and mixed ensemble. The practical applications of",N/A,N/A
"deep learning generally have both pure ensemble and mixed ensemble neural network structures.
Pure ensemble is described by the pure state wave function, so the pure ensemble neural network
architecture goal is to ﬁnd the connection weights of the neural network through training so that the
pure state can be constructed together with the input, and each layer can obtain the probability of
each value (characteristic quantity) of the observed amount. What it pursues is a numerical solution",N/A,N/A
"of the wave function.
The neural network structure of hybrid ensemble is suitable for using unsupervised training to ﬁnd
the set—mixed state, which does not correspond to an observation. and is designed to reconstruct
input. It is not from the Schr?dinger equation of quantum mechanics to ﬁnd the wave function of
the system. Instead, it believes that under certain macroscopic conditions, at certain moments the",N/A,N/A
"system will be in a quantum state with a certain probability. The hybrid ensemble requires secondary
statistics, which cant be solved in quantum mechanics, so wo need to introduce additional basic
assumptions of statistical physics—when the isolated system reaches equilibrium, the probability
of appearance of various microscopic states is equal. The macroscopic quantity of the system is
the statistical average of the various quantum states that the system may be in according to the",N/A,N/A
"corresponding microscopic quantity.
One important technical difference between these two neural network structures is:
Pure Ensemble only needs to ﬁnd out the probability distribution |cn|2 of each layer’s observable
amount through supervised training, it can satisfy the requirement of human application, do not have
to perform layer-by-layer pre-training, and each individual layer is entirely determined by quantum",N/A,N/A
"mechanics. From Equation 13 we know that the process is a physical calculation and the result is
a possible microscopic state, whether this microscopic state is a macroscopic state that satisﬁes the
requirements will be determined by supervised training at all levels. The deep learning of hybrid
ensemble, because there is no computational formula of quantum mechanics like Equation 13, it
must be pre-trained layer by layer to ﬁnd the probability distribution |ψi(x)|2 of the various states of",N/A,N/A
"the ensemble, then all layers should have supervised training to ﬁnd the probability distribution P of
the systems state ψi(x) , so there must be a second statistical calculation. The size of P cant be solved
by quantum mechanics, it requires statistical mechanics principles or assumptions. This answers
Yoshua Bengio’s perplexity in the paper [20]: training depth-supervised neural networks is usually",N/A,N/A
"very difﬁcult without pre-training with unsupervised learning, but the exception is CNNs. So we are
very curious about what special point in the structure of CNN make it has very good generalization
performance in tasks such as image processing? The answer is that CNN is the purely ensemble
of neural network structures, as explained earlier, its individual layers are completely described by
quantum mechanics. The hybrid ensemble of neural networks that must be used for unsupervised",N/A,N/A
"learning layer-by-layer pre-training, such as the RBM described previously.
3.1.1
Pure ensemble neural network
The pure ensemble neural network are similar to instrumentation, belongs to the category of physical
measurement, so its learning performance can be checked because of its clear physical meaning.
The pure ensemble neural network has a prominent advantage. The model it trains is likely to be",N/A,N/A
"a general model, sometimes it is not only useful in this ﬁeld, but also can be used across ﬁelds.
For example, the CNN trained on ImageNet can also be used for image recognition in furniture
projects, as well as for a wide range of computer vision applications, and can effectively serve as a
general model for our visual world. However, as the network deepens, the versatility of the neural
network away from the input layer will be signiﬁcantly reduced, and it is generally not reusable. The",N/A,N/A
"reusability depends on the depth of the model, because measurement is essentially the interaction of
the input signal and the neural network. As the layer increases, the more damage to the system, the
stronger the speciﬁcity of the measurement results and the less versatility. For example, in a speciﬁc
CNN, layers appearing earlier in the model will extract locally highly generalized feature maps,",N/A,N/A
"while higher levels will abstract more abstract concepts (such as cat ears or dog eyes). Therefore, if
your new dataset differs signiﬁcantly from the dataset trained by the original model, it is better to use
16
only the ﬁrst few layers of the model for feature extraction instead of using the entire convolution
model.
The pure ensemble neural networks are completely determined by quantum mechanics, so it is bound",N/A,N/A
"to have a good effect once applied. For example, using CNN to recognize the image is the best, and
can be widely applied to the front end of various types of neural networks, and can be widely used
in the front-end of various types of neural networks.
3.1.2
Hybrid ensemble neural network
The hybrid ensemble neural networks are neural networks such as classiﬁer, generator, automatic
encoder decoder, and the like. The hybrid ensemble neural networks and pure ensemble neural",N/A,N/A
"networks are often opposite in their characteristics, and the well-trained hybrid ensemble neural net-
works are generally not reusable; the performance of learning is not checkable, and it is essentially
a black box, because the view of the wave function does not have any macro meaning. For example,
the information that the classiﬁer in image recognition learns about the probability of existence of a",N/A,N/A
"class in the entire graph, completely frees from the concept of space. For issues where the location
of the object is important, densely connected characteristic will be essentially useless.
In hybrid ensemble, the observations of mechanical quantities are the results of two statistics. The
ﬁrst is quantum mechanics, which is caused by the probability property of the state vector; and the
second is due to the mixture of states, which is caused by the statistical nature of the state at which the",N/A,N/A
"system may be. So the hybrid ensemble of neural networks must be pre-trained with unsupervised
learning to meet the probability distribution of the state vector of quantum mechanics, and then use
supervised learning to ﬁne tune the entire network (second statistic) to determine macroeconomic
equilibrium or stable state.
3.2
Understanding deep learning from the concept of entropy
3.2.1
The role of entropy in deep learning",N/A,N/A
"3.2.1
The role of entropy in deep learning
Information is not a simple mathematical concept, but a basic physical concept like matter and
energy. Therefore, all the processing of information (such as computing) is subject to the basic laws
of physics, and a key concept in information theory is entropy. Thermodynamic entropy, which is
well known to physicists, is homologous to the information entropy that Shannon uses to measure",N/A,N/A
"information. The physical metric that describes the number of system states is the entropy. For
example, Brownian motion is the irregular motion exhibited by tiny particles, and the higher the
temperature, the more violent the irregular motion of the molecules. From the microscopic point of
view, Brownian motion is disorganized, but from a macroscopic point of view, it is a macroscopic
law with irreversible (increased entropy). Therefore, the entropy points out the direction of the",N/A,N/A
"evolution of the system and describes the conditions under which the system is in equilibrium. In
deep learning, a large amount of data is needed to train the discovery system model. Different
models have different entropy, the number of all microscopic states corresponding to the correct
model is extremely large (namely, the entropy is maximum). The cost function of correlated entropy
in deep learning applications is deﬁned based on the entropy of the physical principle.",N/A,N/A
"The deﬁnition of entropy in physics is: H = k ln Ω, where Ωis the number of microscopic state.
Entropy is additive, the entropy of system is the sum of the entropies of each subsystem, and entropy
is a homogeneous function. Let X be a discrete random variable whose probability distribution is
P(X = xk) = pk, k = 1, 2, 3, · · · , n , the probability of occurrence of xk is pk , then the number
of microscopic state is 1/pk , so the cumulative sum of all the entropy of the random variable X is:
H =",N/A,N/A
"H =
X
pi ln 1/pi =
X
pi ln pi
(24)
The probability distribution is P(x) , and the random variable is the number of microscopic states
of X, i.e. the entropy is:
H(X) = −
N
X
k=1
P(X = k) log P(X = k)
(25)
17
Cross entropy is an extended concept of entropy, it introduces a second probability distribution.
Then the number of microstates (entropy) for a random variable X is:
H(p(x), q(x)) = −
X
x∈X
p(x) logq(x)
(26)",N/A,N/A
"H(p(x), q(x)) = −
X
x∈X
p(x) logq(x)
(26)
Cross entropy measures the number of microstates of a random variable X under these two proba-
bility distributions using physical quantity entropy. Cross entropy contains the difference between
two probability distributions, and when the two distributions are the same, the entropy is Equation
25. It is used in deep learning applications to measure the degree to which the model distribution
approximates the unknown distribution.",N/A,N/A
"approximates the unknown distribution.
Therefore, entropy plays an important role in deep learning, it has become the objective function of
the selection and adjustment of the parameters of the deep learning model:
• How the neural network adjusts parameters, in which direction the parameters are adjusted,
the basis is the entropy of the random variables.
• How to determine the conditions for the physical balance and stability of the neural net-",N/A,N/A
"work, the basis is the entropy of the system. For example, the entropy of an isolated equi-
librium system must be maximum.
• Entropy allows us to precisely deﬁne ” correlation ” and extract features from massive data.
3.2.2
Application of entropy in cost function
According to statistical physics, a macroscopic state with a steady state and balance is a state where
the number of microscopic states is maximum (i.e. the entropy is maximum). This is the physical",N/A,N/A
"basis for the selection of the cost function.
The deep learning neural network discussed above are divided into two parts. The former is the neu-
ral networks that conforms to the laws of physics, such as each convolution layers of CNN, not only
the characteristics of the trained convolution layer have physical signiﬁcance, each of the conditions
in the training also has physical signiﬁcance. Because it is calculated according to the physical",N/A,N/A
"equations, except that this microscopic state does not correspond to the ﬁnal trained macroscopic
state, or the number of microscopic states that the ﬁnal trained macroscopic state has is very small
(entropy is small). The latter part is the classiﬁcation of neural networks, such as a convolution
layer that then maps human symbols (labels) to their physical characteristics. This is a distribution
of two completely different concepts, so the cross-entropy of the model’s output (physical) and the",N/A,N/A
"training target (labeled) should be used as a cost function to approach the real physical model. The
magic of the wonderful combination of classiﬁcation problems and cross-entropy is that even if the
cross-entropy on the test set is over-ﬁtted, the classiﬁcation error will not be overﬁt [21].
For the regression problem, it is the same kind of problem, so the mean square error is often used
as the objective function or the cost function, which is equivalent to the general entropy maximum.",N/A,N/A
"KL divergence is closely related to cross entropy, but it does not include the entropy of the model,
it reﬂects the difference between the two distributions. Unlike the use of cross entropy, the KL
divergence is used when there is no more physical distribution. These analyses show the powerful
power of statistical physics in understanding deep learning.
3.3
Understanding deep learning from the concept of master equations",N/A,N/A
"The evolution equation of the Markov process probability distribution is the master equation, which
is one of the most important equations in statistical physics because it is almost universally applica-
ble. The Markov process is a process in which most of the memory effects can be omitted during
the evolution process. When the system evolution of a random variable occurs, the transfer process
will occur between different values of the random variables, by transferring the probability of the",N/A,N/A
"system changes in a given state until the system reaches a ﬁnal equilibrium state.
In deep learning, one of the simplest examples of the Markov process is the Markov chain. The
Markov chain is deﬁned by a random state Xt and a transition distribution T(Xt+1|Xt) . The
transition distribution T is a probability distribution showing the probability of a random transfer to
18
Xt+1 in the case of a given state Xt . Running a Markov chain is the process of constantly updating",N/A,N/A
"the state Xt based on the value Xt+1 of the transition distribution T. Among them, the probability
distribution of the system state at time t + 1 is only related to the state at time t, and has nothing to
do with the state before t.
3.4
Understanding deep learning from the concept of renormalization group
David Schwab and Pankaj Mehta found that the Deep Belief Network (DBN) invented by Hinton
resembled the renormalization in physics in a speciﬁc case, which means that the details of the phys-",N/A,N/A
"ical system are obtained in a coarse-graining manner to calculate its overall state. When Schwab and
Mehta applied DBN to a magnetic model at the critical point (when the system is fractal and self-
similar at any scale), they found that the network automatically uses a reorganization-like process
to discover the state of the model. This discovery is shocking, as the biophysicist Ilya Nemenman",N/A,N/A
"commented, it shows that extracting related features in the context of statistical physics and extract-
ing related features in the context of deep learning are not just similar, but they are completely the
same.” [22].
The renormalization group is a mathematical tool for examining changes in the physical system
at different length scales. The details of the physical system are physically obtained in a coarse-",N/A,N/A
"grained manner to calculate its overall state. The important feature of this method is that it is
independent of the system type. Each key step in the renormalization group method is based on the
main characteristics of the system, rather than putting the system into the framework we are familiar
with, and then adjusting the parameters [23]. The standard renormalization process in statistical
physics is equivalent to the feature extraction process of supervised learning in depth learning. The",N/A,N/A
"information is transmitted layer by layer and eventually converges to the theoretical boundary (ﬁxed
points). The purpose of the renormalization group method is to obtain new features, and to ensure
that the Hamiltonian function forms are unchanged under the new scale of renormalization.
Figure 9: The pooling operation in convolution neural network.
For example, the pooling operation (pooling layer) in CNN is based on the main characteristics of",N/A,N/A
"the system and uses the max pooling method to integrate the feature points in the small neighborhood
according to self-similarity to obtain new features. As shown in Figure 9, the pooling layer uses the
max pooling (where the size of the ﬁltering core is 2*2 and the step size is 2) to fuse a feature with
an input size of 4*4 and retains only the largest feature point in the area, then the characteristic size",N/A,N/A
"after the pooling operation is 2*2, and the pooling layer plays a role of dimensionality reduction.
It has been proved that there is a one-to-one mapping relationship between RBM-based deep neural
networks and variational renormalization groups. The paper [7] illustrates the mapping relation-
ship by analyzing the DNN and numerical two-dimensional Ising model of a one-dimensional Ising
model, and it ﬁnds that these DNNs self-realize a coarse graining process, i.e. Kadanoff block renor-",N/A,N/A
"malization. The results show that deep learning may adopt a generalized renormalization group class
19
scheme to learn relevant features from the data. The paper proved that deep learning is closely related
to the renormalization group, one of the most important and successful technologies in theoretical
physics.
4
A physical world view of deep learning
4.1
The interpretability of deep learning
The interpretability of deep learning models can be divided into the following categories:",N/A,N/A
"(1) Feature attribution VS Internal logic:
The former maps the behavior of the model back to the original set of input features (or
artiﬁcially creates optional input features). In the complex decision-making process of the
model, the larger the inﬂuence of the characteristics will be assigned to the larger weight,
the structure of human knowledge plays a decisive role in this model; The latter argues
that: In the process of obtaining the ﬁnal answer of the model, it is the abstract role of",N/A,N/A
"the physical meaning of the model itself and the internal working logic, rather than human
structural knowledge. Obviously, the interpretation of deep learning in this dissertation
belongs to the latter. This paper analyzes deep learning from the internal logic according
to the principle of physics, while most of the papers use the former method to explain deep
learning.
(2) Simulation acquires knowledge VS Introspection acquires knowledge:",N/A,N/A
"Knowledge based on simulation means that we obtain an understanding of our own model
by generating some form of simulation data, capture how the model represents these data
points for understanding; Introspection acquires knowledge comes from the ﬁxed orienta-
tion of the model and use them to gain knowledge without having to simulate the former.
Obviously, the interpretation of deep learning in this dissertation belongs to the latter, while",N/A,N/A
"most papers belong to the former, the focus of their interpretation is to visualize the char-
acteristics of deep learning. However, this dissertation holds that the deep neural network
data has high dimensional data characteristics, and human beings cannot understand the
visual characteristics of high-dimensional data.
According to quantum statistical physics, a system with s classical degrees of freedom, the dynamic
state of the system is determined by the wave function:",N/A,N/A
"ψσ1σ1,···(q1, q2, · · · qs, t)
Where q is the classical coordinate and σ is the non-classical degree of freedom. People think that
deep learning is incomprehensible. It is precisely because it uses the ψ to characterize the macro-
scopic nature, which cannot be understood through visualization, nor can it be understood through
mathematics. Deep learning is the interpretation of observed data using the dynamic characteristics",N/A,N/A
"of microscopic layers that are not observed by humans or that are not intuitively understood.
4.2
Locality
One of the deepest principles of physics is locality, that is, things directly affect their surroundings.
Locality is a relative concept, usually referring to the scope and degree of inﬂuence of a physical
quantity. Locality has two effects:
(1) Short-range effect:
The interaction is only a nearby function, ignoring the effect of the remote, that is, the",N/A,N/A
"effect of the remote is averaged or canceled. For example, it has been explained before
that during the operation of the Markov chain, the system state at the current moment is
only related to the state at the previous moment, has nothing to do with the state before the
previous moment, that is, the short-range effect.
(2) Local coupling:
The local roles of each regions are coupled and then coupled as localization. Scale changes,",N/A,N/A
"renormalization, long procedures, strong correlation, and coarse-graining. For example,
20
pooling in CNN has already been described in the previous section. By using max pool-
ing, similar features of neighboring regions are merged (that is, processes that are locally
coupled), thereby achieving the effect of dimensionality reduction.
4.3
Symmetry
Symmetry and conservation law are the basic laws of nature. Symmetry can not only reduce the",N/A,N/A
"number of parameters, but also reduce the computational complexity. See the convolutional neu-
ral network under the symmetry (translation invariance) we introduced in Section 2.2. Whenever
Hamiltonian obeys a certain symmetry, that is, invariable under some transformation, the number
of independent parameters required to describe it decreases further. The most important mechanical
quantities of atoms are momentum and angular momentum, so the corresponding translation and ro-",N/A,N/A
"tation transformations are the most important and basic operations. For example, many probability
distributions are constant in the case of translation and rotation.
If the system has translational symmetry, then the state after the translation operation differs from
the original state by a maximum of one phase factor, that is, the difference between the input state
and the output state mainly appears as a phase shift. The input wave function can be labeled by the",N/A,N/A
"wave vector, and the physical meaning of the wave vector is momentum, which reﬂects the spatial
symmetry of the system. The state with translational symmetry is the eigenstate of the momentum
operator, and the momentum represented by the wave vector is the corresponding eigenvalue. There-
fore, the process of learning the eigenvalue and the eigenvalue is the process of obtaining the wave
vector.
4.4
Conjugacy and Duality",N/A,N/A
"vector.
4.4
Conjugacy and Duality
Conjugacy is the amount of pairing. For example, in physics: pressure and volume, temperature
and entropy, intensity and extension are conjugate quantities, in mathematics: real and imaginary
numbers, transposed conjugates of matrix, and so on. Duality is the correspondence between the
different physical theories that lead to the same physical results, such as, there is a reaction force",N/A,N/A
"with acting force, there are holes with electrons. These are the important organizations of physics,
and they are related to each other and to each other in physical relations. This worldview is also
used in deep learning. Here are two examples:
(1) Stochastic gradient descent algorithm using momentum
Although random gradient descent is a very popular optimization method in the training process, the",N/A,N/A
"learning process is sometimes very slow, and even cannot found the best point. The basic physical
idea to solve this problem is to introduce conjugates and use duality to solve this problem.
The cost function has a gradient g, there is ﬂow (or velocity or momentum), so the introduction of
the momentum variable v. The gradient of the cost function is seen as a force that pushes the cost
function to accelerate downhill and the momentum increases; if there is only this kind of force, the",N/A,N/A
"optimization process can never stop, so we need to add another force or gradient (called the viscous
resistance) to make the cost function converge to a minimum; but the minimum may not be the
smallest, so wo need to increase a momentum, let him out of the local minimum, so as to achieve
the overall optimal. Update the algorithm as follows:
v ←αν −εg
θ ←θ + ν
As shown in Figure 10, the contour depicts a quadratic loss function (Hessian matrix with ill-",N/A,N/A
"conditioned conditions). The red path across the proﬁle represents the path followed by the mo-
mentum learning rule, which minimizes the function. We draw an arrow at each step of the path,
indicating the step the gradient will take at that point. We can see that the quadratic objective func-
tion of a pathological condition looks like a long and narrow valley or a canyon with a steep edge.
The momentum passes right through the gorge, while ordinary gradient steps waste time moving",N/A,N/A
"around the narrow axis of the canyon [12].
21
Figure 10: Stochastic gradient descent algorithm using momentum. Figure courtesy: [12]
(2) Annealing and tempering
Temperature and entropy are conjugate quantities, when the temperature equals 0, the entropy equals
0(minimum); the temperature inﬁnity is the most chaotic, the model becomes uniform distribution.
Using the temperature in the Boltzmann distribution, tempering: The Markov chain temporarily",N/A,N/A
"samples from a high temperature distribution and returns to sampling at unit temperature. Annealing:
The Markov chain temporarily samples from a low temperature distribution and returns to sampling
at unit temperature to ﬁnd the best among the different peaks. However, it is necessary to pay
attention to the existence of a critical temperature.
Most of the models used for prediction in deep learning generally use the softmax activation function",N/A,N/A
"to assign probability distributions to tags. The reference [24] mentions that, in the image classiﬁ-
cation problem, we divide the pictures into cats, dogs, and tigers three kinds. In a training, the
probability of the three types is [0.0010, 0.0001, 0.9989], and the one-hot code of [0, 0, 1] is ob-
tained as the classiﬁcation result (hard-target). However, the intrinsic link between cats and tigers",N/A,N/A
"can easily be overwhelmed during training. This is undoubtedly a waste of valuable a priori prob-
abilities that can be used to transfer large-scale network knowledge into small-scale networks. In
order to make full use of the correlation between such class categories, we need to change the prob-
ability distribution in some way to make it more smooth. In the reference, Hinton further modiﬁed
the softmax function:
qi =
exp(zi/T)
P
j exp(zj/T)",N/A,N/A
"qi =
exp(zi/T)
P
j exp(zj/T)
When the temperature T = 1 in the equation, it degenerates into the traditional softmax function;
when T is inﬁnite, the result approaches 1/C, that is, the probabilities on all classes approach to
equal; when T > 1, we can obtain the soft target label. By increasing the temperature T, the
mapping curve of the softmax layer will be smoother, so the probability mapping of the instances",N/A,N/A
"will be more concentrate and the goal will be ”soft”. Therefore, in order to make full use of the
correlation between such class categories, the method of changing the probability distribution is to
increase T.
4.5
Hierarchy
One of the most striking features of the physical world is its hierarchy. Spatially, it is an object
hierarchy: elementary particles form atoms, then form molecules, cells, organisms, planets, the solar",N/A,N/A
"system, galaxies, and so on. Complex structures are usually layered and created through a series of
simple steps. The observables of world are inherently hierarchical and cannot be commutative.
The main reason for the success of deep learning is the hierarchical nature of neural networks (deep
neural networks). In order to extract uncomplicated features, a multi-layer neural network is required
to stack simple networks and then effectively implement the generation process through layering and",N/A,N/A
"combination. Multilayer networks provide layer-by-layer abstract channels from low to high levels.
22
4.6
Model Reusability
As a physical model, especially the convolution neural network, the deep neural network can be used
as a universal method because of its physics, so it is reusable in any ﬁeld. The important basis for
judging whether a model can be reused or reused is its physical properties. The following analyzes
the problem of model reusability of convolutional neural networks.",N/A,N/A
"(1) The convolutional network used for image classiﬁcation consists of two parts: they start
with a series of pooling and convolution layers and end up with densely connected clas-
siﬁers. The ﬁrst part is called the ”convolution base” of the model, it learns completely
from the physical characteristics, so its model can be used in various ﬁelds, but the dense
connection layer behind is the mapping between annotation and physics, and its model is",N/A,N/A
"not reusable. So in practice, ”feature extraction” simply use the convolved basis of the
previously trained network, run new data through it, and train a new classiﬁer over the
output.
(2) There are two conditions for the reusable base to be reused. First, the input and output are
the probability waves in the physical sense. Second, it internally measures the wave vector
of the input physical quantity. According to the uncertainty principle of quantum mechan-",N/A,N/A
"ics, the coordinate and wave vector cannot be measured at the same time. Therefore, its
output does not contain the input position information, it is impossible to obtain accurate
position information of the original input image. And the position is very important for the
object position, the dense connection is more completely useless.
(3) Feature characterization extracted using multi-layer architecture will evolve from simple",N/A,N/A
"and local to abstract and global in structure, but because of the process, the further away
from the input layer the convolutional base is, the lower the reusability is. On the one hand,
because in the continuous pooling, the speciﬁcity of features is getting stronger, and more
and more physical information is lost. On the other hand, equation 8 is calculated using the
input as the wave function, the error is getting bigger and bigger, it deviates more and more",N/A,N/A
"from the real physical model, so the reusability is getting lower and lower. So ﬁne-tuning is
another widely used model reuse technique. Fine-tuning freezes convolutional groups near
the input layer without training, thaws convolutions away from the input layer, and train
with the new classiﬁer to make them more relevant to the problem at hand.
4.7
Model vulnerability
Although deep learning has achieved great success in many applications, there are still many limi-",N/A,N/A
"tations: for example, it needs a lot of data, the vulnerability of the algorithm etc. Why is the neural
network easily disturbed by the input of small disturbances? From the physical model of deep neural
network in this paper, we can see that on the one hand this is a physical problem, behind which we
have not found new physical phenomena or new physical modes; On the other hand, labeling does
not match the actual physical characteristics, such as cross-entropy, the two distributions cannot be",N/A,N/A
"approximated, or they are approached in a group of training data, it does not mean that the test data
can match nonexistent labels, especially the deception problem. Therefore, the key to the vulnera-
bility of the model is the limitation of human understanding. According to the physical world view
of solving problems, providing anti-classiﬁcation is a direction worthy of study.
4.8
Causality and Correlation",N/A,N/A
"4.8
Causality and Correlation
At present, deep learning pays attention to relevance instead of causality, and uses joint probability
distribution to replace traditional theorems and laws. The theoretical foundation of deep learning
methods lies in the representation and transformation of statistical probability distributions. It is
consistent with the physical model of the deep neural network in this paper. That is, the state of the",N/A,N/A
"microscopic particle is completely described by the wave function ψ . After the wave function is
determined, all the characteristics of the system can be obtained, the average value of any mechanical
quantity and its measurement possible value and the corresponding probability distribution are also
completely determined.
However, in practice, a mathematical model of causality derived from statistical data will be com-",N/A,N/A
"prehensively used. For example, these models can be used to establish a causal relationship between
23
smoking and cancer, or to analyze the risks of a construction project, and so on. Can these mathe-
matical models be extended to the microscopic world dominated by quantum mechanics? Can it be
incorporated into the deep learning quantum physics model? Since quantum mechanics itself has
many strange features, for example, if two or more quantum systems are entangled with each other,",N/A,N/A
"it is difﬁcult to deduce whether the statistical correlation between them is causal.
The concept of causal information actually exceeds statistical relevance. For example, we can com-
pare these two sentences: ”The number of cars is related to the amount of air pollution” and ”The
car causes air pollution.” The ﬁrst sentence is a statistical statement, and the latter sentence is a
causal statement. Causality differs from relevance because it tells us how the system will change",N/A,N/A
"under intervention. In statistics, causal models can be used to extract causality from the empirical
data of complex systems. However, there is only one component in a system of quantum physicsłthe
wave function ψ , so mathematical models that use causality derived from statistical data cannot be
applied, including Bayesian inference. John-Mark Allen of Oxford University in the United King-
dom proposed a generalized quantum causal model based on Reichenbach’s principle of common",N/A,N/A
"reason [25], successfully combining causal intervention and Bayesian inference into a model.
5
Conclusions
At present, the research on the internal theory of deep learning is very scarce, and the successful
application of deep learning and the limitations of its existing technology further illustrate the im-
portance of studying its internal technical mechanism from a scientiﬁc perspective. Only knowing",N/A,N/A
"why to do it can transform existing methods or means from a deeper level. This is the scientiﬁc way
of thinking. Based on the principles of physics, this paper interprets the deep learning techniques
from three different perspectives: microscopic, macroscopic, and physical world perspectives. In-
spired by the biological neural network, a new neuron physics model was proposed. Based on this,
it explains the success of deep learning well, and fully reveals the internal mechanism of deep learn-",N/A,N/A
"ing by scientiﬁc methods. A good theory can not only explain existing experiments, but also predict
new phenomena and technologies. Therefore, this dissertation also proposes the direction of further
research in deep learning. Some of the main conclusions of this paper are as follows:
(1) The deep neural network is a physical system, and its architecture and algorithm should
conform to the principles of physics. The technical foundation for deep learning is physics,",N/A,N/A
"especially quantum physics and quantum statistical physics.
(2) In this dissertation, the physical meaning of neurons in deep neural network is proposed:
its output value is the distribution of quasi-particles.
(3) Two physical models of deep neural networks are proposed in this paper, one is pure ensem-
ble deep neural network and the other is hybrid ensemble deep neural network. The former
learning model corresponds to a quantum measurement of a microscopic state, such as",N/A,N/A
"CNN; the latter corresponds to a microscopically statistically averaged macroscopic state,
such as RBM.
(4) The physical model of neurons in CNN is a quantum superposition of a quasi-particle
incident wave (Figure 1) and is excited by the output. This excitation may be the elastic
scattering caused by the incident wave (exit only includes the incident wave), or inelastic
scattering (exit also includes internal new excited states), or various possible actions such",N/A,N/A
"as chemical reactions (exit only includes new quasiparticles). It obeys quantum mechanics.
According to the superposition principle of quantum mechanics, the excitation output of a
neuron is related not only to the intensity of incident quasi-particles in other neurons, but
also to their coherence, and to their polarization direction or spin.
(5) The input of the deep learning network is treated as a wave function, and the image is also a",N/A,N/A
"wave. The state of the neuron is also expressed by a wave function. If the measured neuron
is the number or probability of excited quasi-particles, the value of a layer of neurons
in the neural network is a probability distribution. The deep learning operator should be
performed on the complex number ﬁeld, but because the activation function is ReLU, the
computational difference in the real number domain may not be large.",N/A,N/A
"(6) Under such a physical model, the convolutional neural network algorithm is exactly the
same as the quantum calculation method for measuring the number of quasi-particles ex-
24
cited by neurons, so that it can perfectly explain the technology of each important com-
ponents of a convolutional neural network algorithm (convolution, rectiﬁcation, activation,
pooling, etc.) The purpose of convolution is to measure the number or probability of quasi-",N/A,N/A
"particles excited by each neuron. The convolution kernel is related to the Hamiltonian
interaction potential of neurons. All neurons present an interference diffraction pattern -
stripes and patches. That is, the deep convolutional neural network can measure the in-
put wave vector or momentum, and its computational model can decompose white light
into monochromatic light and decompose random-direction vibration into single-direction",N/A,N/A
"polarization. Therefore, the physical model of this paper can explain deep learning tech-
nology and success. This physical model shows that the deep convolutional neural network
has natural learning ability and cognitive ability, and the model learns the ability to char-
acterize the input micromechanical quantities, so it is reusable and can be applied across
ﬁelds.
(7) The basis for parameter adjustment and optimization in the deep learning classiﬁcation",N/A,N/A
"training process is the entropy in statistical physics, which is the number of microscopic
states corresponding to the corresponding macroscopic state. Different types of training
models should choose different cost functions according to the meaning of entropy, for
example, the convolutional neural network model should use cross entropy as the objective
function (cost function).
(8) A large number of operators, techniques, and methods in deep learning are related to the",N/A,N/A
"principles of physics such as energy, entropy, renormalization techniques, and translation
operations; they are also related to physical world views such as symmetry, conjugacy,
locality, hierarchy, etc.
The research in this paper shows that there are physics glimmers everywhere in deep learning. Deep
learning techniques can be based on scientiﬁc theories. From the principles of physics, this dis-",N/A,N/A
"sertation presents the calculation methods for convolution calculation, pooling, normalization, and
RBM, as well as the selection of cost functions, explains why deep learning must be deep, what
characteristics are learned in deep learning, why convolutional neural networks do not have to be
trained layer by layer, and the limitations of deep learning, etc. The physical model proposed in
this paper can not only explain the successful technology of existing deep learning, but also predict",N/A,N/A
"many researchable directions and topics, such as positional neurons (these are in the research stage,
and still need to be experimentally veriﬁed).
There is a striking homogeneity in the appearance and structure of the human cerebral cortex. In
other words, the cerebral cortex uses the same calculations to accomplish all its functions. All the
intelligence that humans exhibit (vision, auditory, physical movement...) are based on a uniﬁed set",N/A,N/A
"of algorithms. The deep learning technology is also based on a uniﬁed algorithm and is supported
by physical theories. It will have a broad prospect for development.
References
[1] Yi Sun, Xiaogang Wang, and Xiaoou Tang. Deep learning face representation from predict-
ing 10,000 classes. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 1891–1898, 2014.
[2] David Imseng, Petr Motlicek, Philip N. Garner, and Herve Bourlard. Impact of deep mlp",N/A,N/A
"architecture on different acoustic modeling techniques for under-resourced speech recognition.
In Automatic Speech Recognition and Understanding, pages 332–337, 2013.
[3] Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria. Recent trends in deep
learning based natural language processing. arXiv preprint arXiv:1708.02709, 2017.
[4] Anuj Karpatne, William Watkins, Jordan Read, and Vipin Kumar. Physics-guided neural net-",N/A,N/A
"works (pgnn): An application in lake temperature modeling. arXiv preprint arXiv:1710.11431,
2017.
[5] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436,
2015.
[6] Henry W Lin, Max Tegmark, and David Rolnick. Why does deep and cheap learning work so
well? Journal of Statistical Physics, 168(6):1223–1247, 2017.
25
[7] Pankaj Mehta and David J Schwab. An exact mapping between the variational renormalization",N/A,N/A
"group and deep learning. arXiv preprint arXiv:1410.3831, 2014.
[8] Xun Gao and Lu-Ming Duan. Efﬁcient representation of quantum many-body states with deep
neural networks. Nature communications, 8(1):662, 2017.
[9] Yoav Levine, Or Sharir, Nadav Cohen, and Amnon Shashua. Bridging many-body quantum
physics and deep learning via tensor networks. arXiv preprint arXiv:1803.09780, 2018.
[10] Giuseppe Carleo and Matthias Troyer. Solving the quantum many-body problem with artiﬁcial",N/A,N/A
"neural networks. Science, 355(6325):602–606, 2017.
[11] Ajit Narayanan and Tammy Menneer. Quantum artiﬁcial neural network architectures and
components. Information Sciences, 128(3-4):231–255, 2000.
[12] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, vol-
ume 1. MIT press Cambridge, 2016.
[13] Isma Hadji and Richard P Wildes. What do we understand about convolutional networks?
arXiv preprint arXiv:1803.08834, 2018.",N/A,N/A
"arXiv preprint arXiv:1803.08834, 2018.
[14] Ramamurti Shankar. Principles of quantum mechanics. Springer Science & Business Media,
2012.
[15] Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang, James M Rehg, and
Le Song. Decoupled networks. arXiv preprint arXiv:1804.08071, 2018.
[16] Avraham Ruderman, Neil Rabinowitz, Ari S Morcos, and Daniel Zoran. Learned deformation
stability in convolutional neural networks. arXiv preprint arXiv:1804.04438, 2018.",N/A,N/A
"[17] Francois Chollet. Deep learning with Python. Manning Publications Co., 2017.
[18] Jing Chen, Song Cheng, Haidong Xie, Lei Wang, and Tao Xiang. Equivalence of restricted
boltzmann machines and tensor network states. Physical Review B, 97(8):085104, 2018.
[19] Song Cheng, Jing Chen, and Lei Wang. Quantum entanglement: from quantum states of matter
to deep learning. Physics, 2017.
[20] Yoshua Bengio et al. Learning deep architectures for ai. Foundations and trends R⃝in Machine",N/A,N/A
"Learning, 2(1):1–127, 2009.
[21] T Poggio, K Kawaguchi, Q Liao, B Miranda, L Rosasco, X Boix, J Hidary, and HN Mhaskar.
Theory of deep learning iii: the non-overﬁtting puzzle. Technical report, CBMM memo 073,
2018.
[22] Shuo-Hui Li and Lei Wang.
Neural network renormalization group.
arXiv preprint
arXiv:1802.02840, 2018.
[23] Maciej Koch-Janusz and Zohar Ringel. Mutual information, neural networks and the renor-
malization group. Nature Physics, page 1, 2018.",N/A,N/A
"malization group. Nature Physics, page 1, 2018.
[24] Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George E Dahl, and Ge-
offrey E Hinton. Large scale distributed neural network training through online distillation.
arXiv preprint arXiv:1804.03235, 2018.
[25] John-Mark A Allen, Jonathan Barrett, Dominic C Horsman, Ciar´an M Lee, and Robert W
Spekkens.
Quantum common causes and quantum causal models.
Physical Review X,
7(3):031021, 2017.",N/A,N/A
"Physical Review X,
7(3):031021, 2017.
[26] Yoav Levine, David Yakira, Nadav Cohen, and Amnon Shashua. Deep learning and quantum
physics: A fundamental bridge. arXiv preprint arXiv:1704.01552, 2017.
[27] W Kinzel. Physics of neural networks. Europhysics News, 21(6):108–110, 1990.
[28] Gary Marcus. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018.
[29] Yoav Levine, David Yakira, Nadav Cohen, and Amnon Shashua. Deep learning and quan-",N/A,N/A
"tum entanglement: Fundamental connections with implications to network design. CoRR,
abs/1704.01552, 2017.
[30] Yoshua Bengio et al. Learning deep architectures for ai. Foundations and trends R⃝in Machine
Learning, 2(1):1–127, 2009.
[31] IE Lagaris, A Likas, and DI Fotiadis. Artiﬁcial neural network methods in quantum mechanics.
Computer Physics Communications, 104(1-3):1–14, 1997.
26
[32] Alaa Sagheer and Mohammed Zidan. Autonomous quantum perceptron neural network. arXiv",N/A,N/A
"preprint arXiv:1312.4149, 2013.
[33] Max Tegmark. Why the brain is probably not a quantum computer. Information Sciences,
128(3-4):155–179, 2000.
[34] G Perry, ET Rolls, and SM Stringer. Continuous transformation learning of translation invari-
ant representations. Experimental brain research, 204(2):255–270, 2010.
[35] Giuseppe Carleo, Matthias Troyer, Giacomo Torlai, Roger Melko, Juan Carrasquilla, and
Guglielmo Mazzola. Neural-network quantum states. Bulletin of the American Physical Soci-",N/A,N/A
"ety, 2018.
[36] Rongxin Xia and Sabre Kais. Quantum machine learning for electronic structure calculations.
arXiv preprint arXiv:1803.10296, 2018.
[37] Rene Vidal, Joan Bruna, Raja Giryes, and Stefano Soatto. Mathematics of deep learning. arXiv
preprint arXiv:1712.04741, 2017.
[38] IE Lagaris, A Likas, and DI Fotiadis. Artiﬁcial neural network methods in quantum mechanics.
Computer Physics Communications, 104(1-3):1–14, 1997.",N/A,N/A
"[39] Giacomo Torlai, Guglielmo Mazzola, Juan Carrasquilla, Matthias Troyer, Roger Melko, and
Giuseppe Carleo. Neural-network quantum state tomography. Nature Physics, page 1, 2018.
[40] MV Altaisky. Quantum neural network. arXiv preprint quant-ph/0107012, 2001.
[41] Judea Pearl. Theoretical impediments to machine learning with seven sparks from the causal
revolution. arXiv preprint arXiv:1801.04016, 2018.",N/A,N/A
"[42] Daniel J Buehrer. A mathematical framework for superintelligent machines. arXiv preprint
arXiv:1804.03301, 2018.
27",N/A,N/A
"Concept-Oriented Deep Learning 
 
Daniel T. Chang (张遵) 
 
IBM (Retired) dtchang43@gmail.com 
Abstract:  Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We 
propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and 
conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability,",N/A,N/A
"transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of 
CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems 
supporting incremental and continual learning.   
1 Introduction 
1.1 Human Deep Learning 
In human learning, deep learning [1] is an approach that involves the critical analysis of new topics and facts, linking",N/A,N/A
"them to already known concepts or forming new concepts, and leads to long term retention of concepts so that they can be 
used for problem solving in new situations. Deep learning promotes understanding and application for life. This is in contrast 
to surface learning which is the rote acceptance of facts and memorization as isolated and unlinked facts. It leads to 
superficial retention of facts and does not promote understanding or long term retention of knowledge.",N/A,N/A
"The major characteristics of deep learning are: aiming for understanding, focusing on concepts, and relating new and 
previous knowledge. According to the Bloom’s taxonomy [2], there are four types of knowledge: factual, conceptual, 
procedural and metacognitive, and six levels of cognitive processes: remember, understand, apply, analyze, evaluate and 
create. Factual knowledge, such as topics and facts, is locked in time, place, and/or situation. Factual knowledge does not",N/A,N/A
"promote understanding. Concepts [3] (e.g., dog) are general ideas derived or inferred from facts. They are abstract and broad, 
represented by different instances that share common attributes, universal in application, and timeless. Conceptual knowledge 
is required for  understanding and provides the framework for relating new and previous knowledge. 
The ultimate goal of learning is knowledge transfer [2]. Factual knowledge doesn't transfer, but conceptual",N/A,N/A
"understanding does. Conceptual understanding is built by abstracting “up” from factual knowledge or examples to understand 
concepts and the relationships among concepts. Whenever we try to apply our insights from one situation to another we are 
always abstracting to the conceptual level before our knowledge helps us unlock the new situation. When tasks remain 
similar to one another, this is known as low-road transfer. To transfer knowledge to dissimilar tasks requires high-road 
2",N/A,N/A
"2 
 
transfer which involves highly generalized concepts. A deep foundation of facts or surface learning is key for deep learning 
and knowledge transfer. Synergistic thinking, which involves the interaction between the factual and conceptual levels of 
thinking, is essential for deep learning. 
1.2 Machine Deep Learning 
In machine learning, deep learning has more than one definition. A useful, though narrow, definition [4] is: deep learning",N/A,N/A
"is neural networks with a large number of layers and parameters in one of four fundamental network architectures: 
unsupervised pretrained networks, convolutional neural networks, recurrent neural networks, and recursive neural networks 
Automatic feature extraction is one of the major facets, and great advantages, that deep learning has.  
Deep learning is more broadly defined as feature representation learning in [5, 6]. It uses machine learning to discover",N/A,N/A
"not only the mapping from feature representations to output but also the feature representations themselves. To learn features 
that best represent data, the goal is to separate the factors of variation that explain the data. Deep learning does this by 
learning successive layers of increasingly meaningful feature representations. The ‘deep’ in deep learning stands for this idea",N/A,N/A
"of deep layers of feature representations. Deep learning is therefore layered feature representation learning. These layered 
feature representations are generally learned via neural networks. 
Deep learning has achieved near-human accuracy levels in various types of classification and prediction tasks including 
images, text, speech, and video data. However, the current technology of deep learning is largely at the level of surface",N/A,N/A
"learning, not deep learning, in human learning, focusing on rote memorization of factual knowledge in the form of feature 
representations. A deep-learning model [6, 7] is just a chain of simple, continuous geometric transformations mapping one 
data manifold into another. Anything that needs reasoning is out of reach for deep-learning models. There are other major 
limitations as well. Firstly, the knowledge learned using deep-learning models cannot be transferred because, as discussed",N/A,N/A
"earlier, factual knowledge (feature representations) doesn't transfer, but conceptual understanding does. Secondly, deep-
learning models are difficult to understand or interpret [8]. This is to be expected since, as discussed earlier, factual 
knowledge (feature representations) does not promote understanding. Conceptual knowledge is required for understanding. 
As a result of the first two limitations, deep-learning models cannot leverage contextual knowledge. They are developed in",N/A,N/A
"isolation, within the narrow confine of the specific training data used, and do not support contextual adaptation [7]. Lastly, 
but not the least, deep-learning models require lots of labeled data for training, which can be hard to come by. This is not 
3 
 
surprising since deep learning relies on rote memorization of feature representations to perform classification and prediction 
tasks. It has no conceptual understanding of the data. 
1.3 Goal and Outline",N/A,N/A
"1.3 Goal and Outline 
From the above discussions it should be apparent that conceptual knowledge learning and conceptual understanding are 
needed to elevate machine deep learning toward the level of human deep learning. We propose Concept-Oriented Deep 
Learning (CODL) as a general approach to achieve that goal. CODL is an extension of (machine) deep learning. It extends",N/A,N/A
"feature representation learning with concept representation learning and it adds the conceptual understanding capability to 
deep learning. The major aspects of CODL include: concept graph, concept representations, concept exemplars, and concept 
representation learning systems. These are discussed in the following sections. The last section provides the summary and 
conclusion.  
2 Concept Graph",N/A,N/A
"conclusion.  
2 Concept Graph 
The Big Book of Concepts [9] states that “Concepts are the glue that holds our mental world together.” Without 
concepts, there would be no mental world. As discussed earlier, concepts [3] (e.g., dog) are general ideas derived or inferred 
from facts. They are abstract and broad, represented by different instances that share common attributes. A concept may",N/A,N/A
"contain a set of attributes that describe the concept and a set of sub-concepts that are components of the concept. Concepts 
may also be related by relationships. The most common relationships include isA relationships.  
Concepts and categories go together [9]. That is, whatever the concept is, there is a category of things that would be 
described by it. For material things (objects), ‘category’ is usually referred to as ‘class’; for abstract things (entities),",N/A,N/A
"‘category’ is commonly referred to as ‘type’. Thus, concepts denote categories, classes or types, and instances denote things, 
objects or entities. 
Microsoft Concept Graph [10, 11] aims to give machines ""common-sense computing capabilities"" and an awareness of a 
human's mental world, which is underpinned by concepts. Microsoft Concept Graph is built upon Probase, which uses the",N/A,N/A
"world as its model. The concept graph in Probase is automatically learned from billions of web pages and years' worth of 
search logs. The core taxonomy of Microsoft Concept Graph contains over 5.4 million concepts. Microsoft Concept Graph 
also has a large data space (each concept contains a set of instances or sub-concepts), a large attribute space (each concept is 
described by a set of attributes), and a large relationship space (e.g., ""isA"", ""locatedIn""). 
4",N/A,N/A
"4 
 
The Microsoft Concept Tagging Model [11 – 16], a part of Microsoft Concept Graph, maps text entities into concepts 
with some probabilities, which may depend on the context texts of the entities. Given an input text entity, it returns a ranked 
list of concepts. Each concept on the list has a probability denoting the possibility of the text entity belonging to this concept. 
Besides, some common measures for conceptualization (e.g., Typicality) are provided simultaneously.",N/A,N/A
"CODL uses Microsoft Concept Graph as the common / background conceptual knowledge base and the framework for 
conceptual understanding, due to its probabilistic nature and extensive scope. Microsoft Concept Graph plays an important 
role in CODL. Its usage in CODL is discussed in the following sections. However, CODL is not limited to using Microsoft 
Concept Graph as the common / background conceptual knowledge base. Other comparable system can be used as such. 
3 Concept Representations",N/A,N/A
"3 Concept Representations 
In deep learning, feature representations are generally learned as a blob of ungrouped features. However, an increasing 
number of visual applications nourish from inferring knowledge from imagery which requires scene understanding. Semantic 
segmentation is a task that paves the way towards scene understanding. Deep semantic segmentation [17] uses deep learning 
for semantic segmentation.",N/A,N/A
"for semantic segmentation.  
Deep semantic segmentation makes dense predictions inferring labels for every pixel. It can be carried out at three 
different levels: 
 
Class segmentation: each pixel is labeled with the class of its enclosing object or region 
 
Instance segmentation: separate labels for different instances of the same class 
 
Part segmentation: decomposition of already segmented classes into their component sub-classes",N/A,N/A
"CODL extends and generalizes deep semantic segmentation. In CODL, feature representations are always learned 
semantically segmented in a concept-oriented manner. Concept orientation means that each feature representation is 
associated with a concept, an instance or an attribute. These concepts, instances and attributes form a concept graph. In 
addition, the concept graph are generally linked to Microsoft Concept Graph, thus leveraging and integrating with the",N/A,N/A
"common conceptual knowledge and conceptual understanding capability provided by Microsoft Concept Graph. 
A concept representation consists of a concept, its instances and attributes, and all the feature representations associated 
with the concept and its instances and attributes. If a concept has sub-concepts, its concept representation also consists of the 
5 
 
concept representations of its sub-concepts. Concept representations, therefore, are the same as concept-oriented feature",N/A,N/A
"representations, but provide a different view. The latter is data driven and provides a bottom-up view starting from feature 
representations; the former is concept driven and provides a top-down view starting from concepts. Due to the focus on 
concepts instead of low-level feature representations, concept representations provide the proper view to work with in CODL.  
3.1 Supervised Concept Representation Learning",N/A,N/A
"3.1 Supervised Concept Representation Learning 
Concept representations can be learned using supervised learning. Similar to deep semantic segmentation [17], discussed 
above, it can be carried out at different levels: 
 
Concept level: each feature representation is labeled with the concept that owns the feature 
 
Instance level: separate labels for different instances of the same concept 
 
Attribute level: separate labels for different attributes of the same concept 
",N/A,N/A
" 
Component level: decomposition of already learned concept representations into their sub-concept 
representations 
The concept, instance and attribute names used for labeling should be taken from Microsoft Concept Graph, if available. 
This provides direct link to Microsoft Concept Graph to leverage its common conceptual knowledge and conceptual 
understanding capability. 
4 Concept Exemplars",N/A,N/A
"understanding capability. 
4 Concept Exemplars 
As is the case for deep semantic segmentation, it can be difficult to gather and create labeled concept representation 
datasets to use for training in supervised learning. Due to the semantically-segmented nature of concepts, a good alternative is 
to use concept exemplars.  
A concept exemplar set is a set of one or more typical instances of a concept, possibly augmented with instances",N/A,N/A
"generated from the typical instances using identity-preserving transformations. As an example, for image objects the identity-
preserving transformations [18] typically include: scaling, translation, rotation, contrast and color. Each concept is associated 
with at most one concept exemplar set. 
6 
 
With concept exemplars one can use supervised concept representation learning, as discussed earlier, or unsupervised",N/A,N/A
"concept representation learning, as discussed below. Concept exemplars can facilitate incremental and continual learning, to 
be discussed later. 
4.1 Unsupervised Concept Representation Learning 
Exemplar-CNN [18] is an approach for training a convolutional network using only unlabeled data. It trains the network 
to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a set of transformations to a",N/A,N/A
"randomly sampled ’seed’ image patch. The resulting feature representations are not task specific. They are generic and 
provide robustness to the transformations that have been applied during training. The applied transformations thus define the 
invariance properties that are to be learned by the network. 
Unsupervised concept representation learning uses the same approach as Exemplar-CNN. In CODL, concept exemplars",N/A,N/A
"play the role of surrogate classes, and identity-preserving transformations that of applied transformations, in Exemplar-CNN. 
Whereas surrogate classes are based on randomly sampled ’seed’ image patches, concept exemplars are based on 
semantically distinct, typical instances of concepts. Therefore, we expect unsupervised concept representation learning based 
on concept exemplars to result in generic, transferable concept representations. 
5 Concept Representation Learning Systems",N/A,N/A
"5 Concept Representation Learning Systems 
Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised 
concept representation learning as well as unsupervised concept representation learning based on concept exemplars. They 
also provide access to the common / background conceptual knowledge base, such as Microsoft Concept Graph. The",N/A,N/A
"following are major aspects of concept representation learning systems which are important for the success of CODL and its 
application. 
5.1 Incremental and Continual Learning 
In real-world scenarios, concepts and their associated data are almost always collected in an incremental manner. As 
such, incremental and continual learning [19] is a critical aspect of CODL. A good concept representation learning system",N/A,N/A
"must accommodate new concepts and their associated data that it is exposed to and gradually expands its capacity to predict 
increasing number of new concepts. 
7 
 
Doing incremental learning using deep neural network faces inherent technical challenges. Neural networks embed 
feature extraction and classification within the same model. This gives rise to the so-called “catastrophic forgetting /",N/A,N/A
"interference"" problem [20] which refers to the destruction / modification of existing feature representations learned from 
earlier data, when the model is exclusively trained with data of new concepts.  
Therefore, the challenge is to be able to incrementally and continually learn over time by accommodating new concepts 
and their data while retaining previously learned concept representations. There are various approaches [19] for incremental",N/A,N/A
"and continual learning that mitigate, to different extents, catastrophic interference.  The regularization approaches alleviate 
catastrophic interference by imposing constraints on the update of the neural weights. The dynamic architecture approaches 
change architectural properties in response to new concepts and their data, either by dynamically accommodating novel 
neural resources or by re-training with an increased number of neurons or network layers.",N/A,N/A
"A good approach to use in CODL is that of iCaRL [21] (incremental classifier and representation learning), which is a 
dynamic architecture approach. The approach allows learning in a concept-incremental way: only the training data for a small 
number of concepts has to be present at the same time and new concepts can be added progressively. Concept-incremental 
learning has the following properties:  
",N/A,N/A
"learning has the following properties:  
 
it is trainable from a data stream in which examples of different concepts appear at intermittent times, 
 
at any time it provides a competitive multi-concept classifier for all the concepts learned so far, and 
 
it does not require storing all training data or retraining already-learned concepts whenever new data becomes 
available.",N/A,N/A
"available. 
The main components [21] that enable simultaneous learning of concept representations and concept classifiers in the 
concept-incremental manner are: 
 
concept representation learning using knowledge distillation and prototype rehearsal, 
 
concept exemplar selection / learning based on herding, and 
 
concept classification by the nearest mean of concept exemplars. 
These are discussed below. 
8",N/A,N/A
"These are discussed below. 
8 
 
Prior to that we note that the deep learning network is used only for concept representation learning and concept 
exemplar selection, not for classifying new data, which is done using concept classifiers based on concept exemplars. The 
concept representation learning scheme, using knowledge distillation, addresses the “catastrophic forgetting / interference”",N/A,N/A
"problem of incremental and continual learning. The use of concept exemplars, for concept classifiers, avoids the other 
problem: storing of all training data. 
Concept Representation Learning 
Whenever data for new concepts arrive, the concept representations and concept exemplar sets are updated. Firstly, the 
network outputs for the existing concepts are stored. Secondly, an augmented training set is constructed, consisting of the",N/A,N/A
"(newly available) training examples for the new concepts together with the concepts exemplar sets for the existing concepts. 
Finally, the deep learning network is trained / updated by minimizing a loss function to output the correct concept indicators 
for new concepts (classification loss), and for old concepts, to reproduce the scores stored in the first step (distillation loss).",N/A,N/A
"The classification loss enables improvements of the concept representations that allow classifying the new concepts well; the 
distillation loss ensures that the discriminative information learned for existing concepts is not lost while training for the new 
concepts. 
Concept Exemplars Selection / Learning 
Concept exemplars selection is required for each concept only once, when it is first learned and its training data is",N/A,N/A
"available. For each concept, concept exemplars are selected and stored iteratively until the target number is met. In each step 
of the iteration, one more example of the training set is added to the concept exemplar set, namely the one that causes the 
average feature vector over all concept exemplars to best approximate the average feature vector over all training examples.",N/A,N/A
"Thus, the concept exemplar set is a prioritized list, with concept exemplars earlier in the list being more important. The 
concept exemplar set may be augmented using identity-preserving transformations, as discussed earlier. 
Concept Classification Based on Concept Exemplars 
For concept classification, a nearest-mean-of-concept-exemplars classification strategy is used. To predict a concept",N/A,N/A
"label for a new sample, it first computes a prototype vector for each concept by computing the average feature vector of all 
concept exemplars for the concept. It then computes the feature vector of the sample that should be classified and assigns the 
concept label with the most similar prototype. The concept prototypes automatically change whenever the concept 
9 
 
representations change, making the classifier robust against changes of the concept representations (as new concepts are",N/A,N/A
"learned) 
5.2 Concept Taxonomy and Basic-Level Concepts 
Concept taxonomy [9] is one particular kind of concept organization: the hierarchical structure of concepts with each 
branch being a sequence of progressively larger concepts in which each concept includes all the previous ones. Different 
levels of concepts reflect different levels of abstraction, which associate with different attributes. These taxonomic concepts 
are important for thought and communication.",N/A,N/A
"are important for thought and communication. 
In a concept taxonomy, the concepts that are higher in the hierarchy are superordinate to the lower-level concepts; the 
lower-level concepts are subordinate to the higher-level ones. The only relationship allowed between concepts in the 
hierarchy is the set inclusion relationship: the set of instances of  a superordinate concept (e.g., dog) includes the set of",N/A,N/A
"instances of its subordinate concept (e.g., bull dog). The set inclusion relationship is called the ‘‘isA’’ relationship, which is 
asymmetric and transitive. The transitivity of concept relationship in the hierarchy leads to a similar transitivity of attribute 
ascription, called attribute inheritance. Every attribute of a concept is also an attribute of the concept’s subordinates.",N/A,N/A
"By being able to locate a concept in its proper place in the concept taxonomy, one can learn a considerable amount about 
the concept, e.g., its superordinates and inherited attributes. In CODL, this is achieved by accessing Microsoft Concept 
Graph, as discussed near the beginning. Clearly, this is an important ability, since it allows one to immediately access 
knowledge (concepts) about new objects or entities without the need to directly learn. 
Basic-Level Concepts",N/A,N/A
"Basic-Level Concepts 
The objects and entities that we encounter every day do not each fit into a single concept, but can be classified with a 
large number of different concepts. It is important to know the preferred concept by which people think about any one object 
or entity.  
Any object or entity can be thought of as being in a set of hierarchically organized concepts, i.e., a concept taxonomy,",N/A,N/A
"ranging from extremely general (e.g., animal) to extremely specific (e.g., bull dog). Classification at the most general level 
maximizes accuracy of classification. Most specific concepts, on the other hand, allow for greater accuracy in prediction. Of 
all the possible concepts in a concept taxonomy to which a concept belongs, a middle level of specificity, the basic level [9], 
10",N/A,N/A
"10 
 
is the most natural, preferred level at which to conceptually carve up the world. The basic level (e.g., dog) can be seen as a 
compromise between the accuracy of classification at a most general level and the predictive power of a most specific level.  
Superordinate concepts (e.g., animal) are distinctive but not informative. Subordinate concepts (e.g., bull dog) are",N/A,N/A
"informative but not distinctive. It is only basic-level concepts (e.g., dog) that are both informative and distinctive. Basic-level 
concept is important because it provides rich information with little cognitive efforts. When a person obtains the basic-level 
concept of an unfamiliar object or entity, she will associate the object or entity with the known attributes of the basic-level 
concept.",N/A,N/A
"concept. 
Therefore, to be effective, in CODL one should focus on learning and using concept representations for basic-level 
concepts [11]. Superordinate concepts are automatically “learned” by accessing Microsoft Concept Graph, as discussed 
earlier. When needed, this can be supplemented by learning and using concept representations for selective subordinate 
concepts. 
6 Summary and Conclusion",N/A,N/A
"concepts. 
6 Summary and Conclusion 
 
Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. The current 
technology of machine deep learning is largely at the level of surface learning in human learning, focusing on rote 
memorization of factual knowledge in the form of feature representations. To elevate machine deep learning toward the level",N/A,N/A
"of human deep learning, we proposed concept-oriented deep learning (CODL) which extends (machine) deep learning with 
concept representations and conceptual understanding capability. 
CODL leverages Microsoft Concept Graph, or something comparable, as the common / background conceptual 
knowledge base and the framework for conceptual understanding. In particular, concept names and concept taxonomies (isA",N/A,N/A
"relationships) originate from Microsoft Concept Graph. In CODL, feature representations are always learned semantically 
segmented in a concept-oriented manner. Concept representations are the same as concept-oriented feature representations, 
but from a top-down, concept-driven perspective which is the focus of CODL. It can be difficult to gather and create labeled 
concept representation datasets to use for training. Due to the semantically-segmented nature of concepts, a good alternative",N/A,N/A
"is to use concept exemplars. 
Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised 
concept representation learning as well as unsupervised concept representation learning based on concept exemplars. Since, 
11 
 
in real-world scenarios, concepts and their associated data are almost always collected in an incremental manner, a good",N/A,N/A
"concept representation learning system must support incremental and continual learning (using concept exemplars). Also, to 
be effective, in CODL one should focus on learning and using concept representations for basic-level concepts. 
By focusing on learning and using concept representations and concept exemplars, CODL is able to address some of the 
major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled",N/A,N/A
"training data.  
References 
 
[1] W. Houghton, Engineering Subject Centre Guide: Learning and Teaching Theory for Engineering Academics 
(Loughborough: HEA Engineering Subject Centre, 2004). 
[2] Julie Stern, Krista Ferraro and Juliet Mohnkern, Tools for Teaching Conceptual Understanding, Secondary: Designing 
Lessons and Assessments for Deep Learning (Corwin, 2017). 
[3] Jean Donham, “Deep Learning through Concept-based Inquiry,” School Library Monthly, Volume XXVII, Number 1, 8 
(2010).",N/A,N/A
"(2010). 
[4] Josh Patterson and Adam Gibson, Deep Learning A Practitioner’s Approach (O’Reilley, 2017). 
[5] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning (MIT Press, 2016) 
[6] Francois Chollet, Deep Learning with Python (Manning, 2018) 
[7] John Launchbury, A DARPA Perspective on Artificial Intelligence (DARPA, 2017). 
[8] Z. C. Lipton, “The mythos of model interpretability,” arXiv preprint arXiv:1606.03490 (2017).",N/A,N/A
"[9] G. L. Murphy, The Big Book of Concepts (MIT Press, 2002). 
[10] Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Zhu, “Probase: A Probabilistic Taxonomy for Text 
Understanding,”  in ACM International Conference on Management of Data (SIGMOD), May 2012. 
[11] Zhongyuan Wang, Haixun Wang, Ji-Rong Wen, and Yanghua Xiao, “An Inference Approach to Basic Level of 
Categorization,”  in ACM International Conference on Information and Knowledge Management (CIKM), ACM –",N/A,N/A
"Association for Computing Machinery, October 2015. 
[12] Yangqiu Song, Haixun Wang, Zhongyuan Wang, Hongsong Li, and Weizhu Chen, “Short Text Conceptualization using 
a Probabilistic Knowledgebase,” in IJCAI, 2011. 
[13] Zhongyuan Wang, Haixun Wang, and Zhirui Hu, “Head, Modifier, and Constraint Detection in Short Texts,” in 
International Conference on Data Engineering (ICDE), 2014. 
[14] Zhongyuan Wang, Kejun Zhao, Haixun Wang, Xiaofeng Meng, and Ji-Rong Wen, “Query Understanding through",N/A,N/A
"Knowledge-Based Conceptualization,”  in IJCAI, July 2015. 
[15] Wen Hua, Zhongyuan Wang, Haixun Wang, Kai Zheng, and Xiaofang Zhou, “Short Text Understanding Through 
Lexical-Semantic Analysis,” in International Conference on Data Engineering (ICDE), April 2015.  
[16] Zhongyuan Wang and Haixun Wang, “Understanding Short Texts,” in the Association for Computational Linguistics 
(ACL) (Tutorial), August 2016.",N/A,N/A
"(ACL) (Tutorial), August 2016. 
[17]  A. Garcia-Garcia, S. Orts-Escolano, S. Oprea, V. Villena-Martinez, and J. Garcia-Rodriguez, “A Review on Deep 
Learning Techniques Applied to Semantic Segmentation,” arXiv preprint arXiv:1704.06857 (2017). 
[18] Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, and Thomas Brox, “Discriminative 
Unsupervised Feature Learning with Exemplar Convolutional Neural Networks,” arXiv preprint arXiv: 1406.6909 (2015).",N/A,N/A
"[19] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and Stefan Wermter, “Continual Lifelong Learning 
with Neural Networks: A Review,” arXiv preprint arXiv:1802.07569 (2018) 
[20] I. J. Goodfellow, M. Mirza, X. Da, A. Courville, and Y. Bengio, “An Empirical Investigation of Catastrophic Forgeting 
in Gradient-Based Neural Networks,” arXiv preprint arXiv:1312.6211 (2015).",N/A,N/A
"[21] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “iCaRL: Incremental Classifier and Representation 
Learning,” CVPR’14, pages 2001–2010 (2017).",N/A,N/A
"Deep learning research landscape & roadmap in a nutshell:
past, present and future - Towards deep cortical learning
Aras R. Dargazany
August 7, 2019
Abstract
The past, present and future of deep learning is presented in this work. Given this landscape
& roadmap, we predict that deep cortical learning will be the convergence of deep learning &
cortical learning which builds an artiﬁcial cortical column ultimately.
1
Past: Deep learning inspirations",N/A,N/A
"1
Past: Deep learning inspirations
Deep learning horizon, landscape and research roadmap in nutshell is presented in this ﬁgure 1.
The historical development and timeline of deep learning & neural network is separately illustrated
Figure 1: Deep learning research landscape & roadmap: past, present, future.
The future is
highlighted as deep cortical learning.
in ﬁgure 2. The Origin of neural nets [WR17] is thoroughly reviewed in terms of the evolutionary",N/A,N/A
"history of deep learning models. Vernon Mountcastle discovery of cortical columns in somatosen-
sory cortex [Mou97] was a breakthrough in brain science. The big bang was the discovery of Hubel
& Wiesel of simple cells and complex cell in visual cortex [HW59] which won the Nobel prize for
this discovery in 1981. This work was heavily founded on Vernon Mountcastle discovery of cortical
columns in somatosensory cortex [Mou97]. After the discovery of Hubel & Wiesel, Fukushima",N/A,N/A
"proposed a pattern recognition architecture based on the simple cell and complex cell discovery,
known as NeoCognitron [FM82]. In this work, a deep neural network was proposed using simple
cell layer and complex cell layer repeatedly. In 80s and maybe a bit earlier backpropagation have
been proposed by multiple people but the ﬁrst time it was well-explained and applied for learning
neural nets was done by Hinton and his colleagues in 1987 [RHW86].
1
arXiv:1908.02130v1  [cs.NE]  30 Jul 2019",N/A,N/A
"1
arXiv:1908.02130v1  [cs.NE]  30 Jul 2019
Figure 2: Neural nets origin, timeline & history made by Favio Vazquez
2
Present: Deep learning by LeCun, Bengio and Hinton
Convolutional nets was invented by LeCun [LBD+89] which led to deep learning conspiracy which
also started by the three founding fathers of the ﬁeld: LeCun, Bengio and Hinton [LBH15]. The
main hype in deep learning happened in 2012 when the state-of-the-art result in Imagenet classi-",N/A,N/A
"ﬁcation and TIMIT speech recognition task were dramatically reduced using an end-to-end deep
convolutional network [KSH12] and deep belief net [HDY+12].
The power of deep learning is scalability and the ability to learn in an end-to-end fashion.
In this sense, deep learning architectures are capable of learning big datasets such as Imagenet
[KSH12, GDG+17] and TIMIT using multiple GPUs in an end-to-end fashion meaning directly",N/A,N/A
"from raw inputs, all the way the desired outputs. Alexnet [KSH12] used two GPUs for Imagenet
classiﬁcation which is a very big dataset of images, almost 1.5 million images of size 215x215.
Kaiming He et al. [GDG+17] proposed a highly scalable approach for training on Image using
256 GPUs for almost an hour which shows an amazingly powerful approach based stochastic
gradient descent for applying big cluster of GPUs on huge datasets. Very many application domains",N/A,N/A
"have been revolutionized using deep learning architectures such as image classiﬁcations [KSH12],
machine translation [WSC+16, JSL+16], speech recognition [HDY+12], and robotics [MKS+15].
The Nobel Prize in Physiology or Medicine 2014 was given to John O’Keefe, May-Britt Moser
and Edvard I. Moser “for their discoveries of cells that constitute a positioning system in the
brain.” [Bur14].
This study of cognitive neuroscience shed light on how the world is repre-",N/A,N/A
"sented within the brain. Hinton’s Capsule network [SFH17] and Hawkins’ cortical learning al-
gorithm [HAD11] are highly inspired by this Nobel-prize winning work [Bur14].
3
Future: Brain-plausible deep learning & cortical learning
algorithms
The main direction and inclination in the deep learning for future is the ability to bridge the gap
between the cortical architecture and deep learning architectures, speciﬁcally convolutional nets.",N/A,N/A
"In this quest, Hinton proposed capsule network [SFH17] as an eﬀort to get rid of pooling layers
and replace it with capsules which are highly inspired bu cortical mini-columns in cortical columns
and layers and include the location information or pose information of parts.
Another important quest in deep learning is understanding the biological root of learning in our
brain, speciﬁcally in our cortex. Backpropagation is not biologically inspired and plausible. Hinton",N/A,N/A
"and the other founding fathers of deep learning have been trying to understand how backprop
2
might be feasible biologically in brain. Feedback alignment [LCTA16] and spike time-dependent
plasticity or STDP-based backprop [BSR+18] are some of the works which have been done by
Timothy Lillicrap, Blake Richards, and Hinton in order to model backprop biologically based on
the pyramidal neuron in the cortex.
In the far future, the main goal should be the merge of two very independent quest to build",N/A,N/A
"cortical structure in our brain: The ﬁrst one is heavily target by the big and active deep learning
community; The second one is targeted independently and neuroscientiﬁcally by Numenta and
GeoﬀHawkins [HAD11]. These people argue that the cortical structure and our neocortex is the
main source of our intelligence and for building a true intelligent machine, we should be able to
reconstruct the cortex and to do so, we should ﬁrst focus more on the cortex and understand what",N/A,N/A
"cortex is made out of.
4
Finale: Deep cortical learning as the merge of deep learning
and cortical learning
By merging deep learning and cortical learning, a very more focused and detailed architectures,
named deep cortical learning might be created. We might be able to understand and reconstruct
the cortical structure with much more accuracy and have a better idea what the true intelligence is
and how artiﬁcial general intelligence or AGI might be reproducible. Deep cortical learning might",N/A,N/A
"be the algorithm behind one cortical column in the neocortex.
References
[BSR+18]
Sergey Bartunov, Adam Santoro, Blake Richards, Luke Marris, Geoﬀrey E Hinton,
and Timothy Lillicrap. Assessing the scalability of biologically-motivated deep learning
algorithms and architectures. In Advances in Neural Information Processing Systems,
pages 9368–9378, 2018.
[Bur14]
Neil Burgess. The 2014 nobel prize in physiology or medicine: a spatial model for",N/A,N/A
"cognitive neuroscience. Neuron, 84(6):1120–1125, 2014.
[FM82]
Kunihiko Fukushima and Sei Miyake. Neocognitron: A self-organizing neural network
model for a mechanism of visual pattern recognition. In Competition and cooperation
in neural nets, pages 267–285. Springer, 1982.
[GDG+17] Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo
Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch",N/A,N/A
"sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
[HAD11]
Jeﬀ
Hawkins,
Subutai
Ahmad,
and
D
Dubinsky.
Hierarchi-
cal
temporal
memory
including
htm
cortical
learning
algorithms.
Technical
report,
Numenta,
Inc.
http://www.numenta.com/htm-
overview/education/HTM/CorticalLearningAlgorithms.pdf, 2011.
[HDY+12] Geoﬀrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep
Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep",N/A,N/A
"neural networks for acoustic modeling in speech recognition: The shared views of four
research groups. IEEE Signal Processing Magazine, 29(6):82–97, 2012.
[HW59]
David H Hubel and Torsten N Wiesel. Receptive ﬁelds of single neurones in the cat’s
striate cortex. The Journal of physiology, 148(3):574–591, 1959.
[JSL+16]
Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng
Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, et al.",N/A,N/A
"Google’s multilingual neural machine translation system: Enabling zero-shot trans-
lation. arXiv preprint arXiv:1611.04558, 2016.
[KSH12]
Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with
deep convolutional neural networks.
In Advances in neural information processing
systems, pages 1097–1105, 2012.
3
[LBD+89] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard,",N/A,N/A
"Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to handwritten zip
code recognition. Neural computation, 1(4):541–551, 1989.
[LBH15]
Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton.
Deep learning.
Nature,
521(7553):436–444, 2015.
[LCTA16] Timothy P Lillicrap, Daniel Cownden, Douglas B Tweed, and Colin J Akerman. Ran-
dom synaptic feedback weights support error backpropagation for deep learning. Nature
communications, 7:13276, 2016.",N/A,N/A
"communications, 7:13276, 2016.
[MKS+15] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,
Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg
Ostrovski, et al. Human-level control through deep reinforcement learning. Nature,
518(7540):529–533, 2015.
[Mou97]
Vernon B Mountcastle. The columnar organization of the neocortex. Brain: a journal
of neurology, 120(4):701–722, 1997.
[RHW86]",N/A,N/A
"of neurology, 120(4):701–722, 1997.
[RHW86]
David E Rumelhart, Geoﬀrey E Hinton, and Ronald J Williams. Learning representa-
tions by back-propagating errors. Nature, 323:533–536, 1986.
[SFH17]
Sara Sabour, Nicholas Frosst, and Geoﬀrey E Hinton. Dynamic routing between cap-
sules. In Advances in Neural Information Processing Systems, pages 3859–3869, 2017.
[WR17]
Haohan Wang and Bhiksha Raj.
On the origin of deep learning.
arXiv preprint
arXiv:1702.07800, 2017.",N/A,N/A
"arXiv preprint
arXiv:1702.07800, 2017.
[WSC+16] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang
Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural
machine translation system: Bridging the gap between human and machine translation.
arXiv preprint arXiv:1609.08144, 2016.
4",N/A,N/A
"arXiv:gr-qc/0612006v1  1 Dec 2006
The Ξ-transform for conformally ﬂat
space-time
George A.J. Sparling
Laboratory of Axiomatics
Department of Mathematics
University of Pittsburgh
Pittsburgh, Pennsylvania, 15260, USA
Abstract
The Ξ-transform is a new spinor transform arising naturally in
Einstein’s general relativity. Here the example of conformally ﬂat
space-time is discussed in detail. In particular it is shown that
for this case, the transform coincides with two other naturally de-",N/A,N/A
"ﬁned transforms: one a two-variable transform on the Lie group
SU(2, C), the other a transform on the space of null split octaves.
The key properties of the transform are developed.
Introduction
The Ξ-transform is a transform arising naturally in general relativity, which was
found earlier this year by the author as the culmination of a long development [1]-
[12]. If M is a space-time (space and time orientable, with a ﬁxed spin structure),",N/A,N/A
"denote by S∗the co-spin bundle of M, the space of all pairs (x, π), with x ∈M
and π a Weyl co-spinor at x, so S∗is a complex vector bundle over M, whose
complex ﬁber dimension is two. For convenience, we delete the zero section, so
π ̸= 0. Denote by N the horizontal vector ﬁeld on S∗, that represents the null
geodesic spray. A twistor function f(x, π) is by deﬁnition a function on S∗that is
killed by N [13]-[15]. The function f(x, π) is said to be homogeneous of integral",N/A,N/A
"degree k if and only if f(x, tπ) = tkf(x, π), for any real non-zero t. Denote
by Hk the space of all twistor functions, homogeneous of degree k. Then the Ξ-
transform is a conformally invariant transform mapping H−4 to H−2. The basic
deﬁnition of the transform is given in detail in the author’s preprint [1]. In this
work we analyze the transform for the case of conformally ﬂat space-time. We
discuss three versions of the transform, here denoted by Ξ1, Ξ2 and Ξ3:
• Ξ1(f)(g, h) =
Z
p∈G",N/A,N/A
"• Ξ1(f)(g, h) =
Z
p∈G
f(p, g−1ph)ωp.
Here G is a compact Lie group, ωp is Haar measure, and f is a smooth
function of two G-variables. Then the output Ξ1(f) is a smooth function of
its two arguments.
• Ξ2(f)(x, η) = i
Z
πA′ηA′=1
f(xa + sηAηA′, πC′)dsπB′dπB′πBdπB.
Here we use two-component spinor notation [13]-[15]. The function f(xa, πA′)
is a twistor function, so is constant along null geodesics: πA′πA∂af(xb, πB′) =
0 and is homogeneous of degree minus four: f(x, tπ) = t−4, for t real and",N/A,N/A
"non-zero. Then the output function Ξ2(f) is also a twistor function, this
time homogeneous of degree minus two.
At ﬁrst sight, these two transformations may seem unrelated. We link them by
invoking a third transformation, which uses the triality theory of Elie Cartan for
spinors associated to the group O(4, 4, R) [16]-[17], [12], [2]. This employs three
eight-dimensional real vector spaces, Vα, Vβ and Vγ, each equipped with a dot",N/A,N/A
"product of neutral signature (4, 4) and linked by the triality map, denoted (xyz) ∈
R, for any x, y and z in Vα, Vβ and Vγ. Dualizing, we obtain product maps, such
that (xyz) = (yz).x = (zx).y = (xy).z, for any x, y and z in Vα, Vβ and Vγ,
where the products (yz), (zx) and (xy) take values in Vα, Vβ and Vγ, respectively.
2
The triality obeys the key relations: ((yz)y) = y.yz, (z(yz)) = z.zy, (x(zx)) =
x.xz, ((zx)z) = z.zx, (y(xy)) = y.yx and ((xy)x) = x.xy, for any x, y and z in",N/A,N/A
"Vα, Vβ and Vγ and the whole theory is invariant under permutations of the three
vector spaces. Such a triality is usually studied in the positive deﬁnite case, in
which case, if (xy) = 0, for x in Vα and y in Vβ, then it follows immediately that
either x or y is zero. Here however, if (xy) = 0, we have 0 = ((xy)x) = x.xy
and 0 = (y(xy)) = y.yx, from which we see that it is conceivable that x and y
can be both non-zero, provided that they are both null vectors. Then for y a ﬁxed",N/A,N/A
"non-zero null vector in Vβ, it emerges that the space Ny of solutions x ∈Vα, of
the equation (xy) = 0 is a four-dimensional completely null self-dual subspace of
Vα. Then the following integral is well-deﬁned:
• ξ3(f)(y)abcd =
Z
(xy)=0
f(x)x[adxbdxcdxd].
Here f is a smooth function, homogeneous of degree minus four in the
variable x ∈Vα and the integral is taken over an oriented three-sphere rep-
resenting the fundamental homology class of the complement of the origin",N/A,N/A
"in the four-space Ny. It emerges that ξ3(f)(y)abcd factorizes:
• ξ3(f)(y)abcd = Ξ3(f)(y)σabcd(y).
Here σabcd = σabcd
e′f′ ye′yf′ and σabcd
e′f′ = σ[abcd]
(e′f′) and σabcd
e′f′ is trace-free in its
index pair e′f ′. Then σ[abcd]
e′f′
gives a natural isomorphism of the space of
trace-free symmetric tensors of Vβ with the space of self-dual four skew
four-index tensors of the space Vα, both spaces being thirty-ﬁve dimen-
sional. Then the coefﬁcient Ξ3(f)(y) is smooth and homogeneous of degree",N/A,N/A
"minus two in the non-zero null vector y. This gives us our third transform.
There are now two main results in this work:
• All three transforms are equivalent, provided we take G = SU(2, C) for the
case of the transform Ξ1.
• All three transforms obey an equation of the form Ξ ◦□= □◦Ξ = 0,
where □is a second-order conformally invariant wave operator (for the
ultra-hyperbolic signature (3, 3)), whose existence follows from the general",N/A,N/A
"theory of C. Robin Graham, Ralph Jenne, Lionel Mason and the present
author [18].
We suspect that a stronger result is true: namely that the kernels and images of
Ξ and □exactly match. However we only prove this here under the technical as-
sumption that the input function has a ﬁnite spherical harmonic decomposition.
3
• In sections one and two below, we organize the theory of Casimir differen-
tial operators on a Lie group.",N/A,N/A
"tial operators on a Lie group.
• In section three, we describe the spherical harmonics of the group SU(2, C).
• In section four, we reformulate the spherical harmonic theory in terms of
two-component spinors.
• In section ﬁve, we introduce the transform and prove its basic properties,
for the case of an arbitrary compact Lie group. In particular for the case
when the group is SU(2, C), we prove the relation C ◦Ξ = Ξ ◦C = 0,
where C = C+ −C−and C+ and C−are the standard quadratic Casimir",N/A,N/A
"differential operators of SU(2, C), deﬁned in terms of the ﬁrst and second
variable of the transformed function Ξ(f)(g, h), respectively.
• In section six, we analyze the kernel and the image of the Ξ-transform under
the technical assumption that the input function has a ﬁnite decomposition
in spherical harmonics.
• In section seven, we introduce the basic null twistor space, which after re-
moving a real scaling degree of freedom has topology the product of two",N/A,N/A
"three-spheres and which is metrically conformal to the metric G+ −G−,
where G± are unit three-sphere metrics on the two factors of the product.
Geometrically this space represents the space of null geodesics in confor-
mally compactiﬁed Minkowksi space-time, where the geodesic is supplied
with a tangent co-spinor, deﬁned up to a non-zero real scaling and parallelly
propagated along the null geodesic. Note that the six-dimensional confor-",N/A,N/A
"mal geometry is of the type of Charles Fefferman, associated to the invariant
Cauchy-Riemann structure of the null twistor space [8].
• In section eight, we introduce the basic symmetry groups of the twistor
space, the groups U(2, 2, C) and O(4, 4, R).
• In sections nine and ten, we give two different formulations of the null
twistor wave operator, □, one using the ambient non-null twistors and the
other purely intrinsic.
4",N/A,N/A
"other purely intrinsic.
4
• In sections eleven, twelve and thirteen, we translate the twistor symme-
try generators and the null twistor wave operator into the language of two-
component spinors.
• In section fourteen, we introduce the spinor version of the Ξ-transform and
then in sections ﬁfteen and sixteen, we prove the basic relations Ξ ◦□=
□◦Ξ = 0.
• In section seventeen, we develop the theory of O(4, 4) triality using quater-",N/A,N/A
"nion variables and we discuss the incidence relation for null vectors of the
triality: the systematic use of quaternion variables tightens up and simpliﬁes
the earlier treatment of the author and Philip Tillman [2].
• In section eighteen, we use twistor variables to parametrize the triality.
• In section nineteen, we introduce the invariant transform using the twistor
variables and prove that the invariant transform encodes the same informa-
tion as the spinor version of the transform.",N/A,N/A
"tion as the spinor version of the transform.
• Finally in section twenty, we reduce the invariant transform to the two-
variable group transform, ﬁnishing the proof that all three transforms are
equivalent. In particular the group structure of the ﬁrst transform is under-
stood to arise from a particular choice of conformal factor for the invariant
approach. Thus in the group approach the underlying conformal invariance
is not manifest and the relevant functions are not conformally weighted,",N/A,N/A
"unlike in the other two cases.
5
1
Left and right invariant vector ﬁelds
Let G be a compact real Lie group, so G is also naturally a smooth (even real
analytic) compact manifold. For each g ∈G denote by Lg : G →G and Rg :
G →G the smooth operations of left multiplication and right multiplication,
respectively. So Lg(k) = gk and Rgk = kg, for any h ∈G. Note that Lg
and Rh commute for any g and h in G. Also denote by Adg : G →G the",N/A,N/A
"adjoint representation of G on itself, so we have Adg = LgRg−1, for any g ∈G.
Denote by ω the Haar measure for the Lie group, which we represent smoothly
by a volume-form ω with value ωg at g ∈G. Then ω is invariant under the
operations of left multiplication and right multiplication by elements of G, so ω
is also invariant under the adjoint map. Denote by ∇α the Lie algebra of left-
invariant vector ﬁelds on G. Here we use Greek indices for the tensors based on",N/A,N/A
"the tensor algebra of the tangent and cotangent spaces at the identity of G. Then
we have the Lie bracket:
[∇α, ∇β] = C
γ
αβ ∇γ.
Here C
γ
αβ
= −C
γ
βα
are the structure constants of the Lie algebra. Similarly,
denote by ∆α the Lie algebra of right-invariant vector ﬁelds on G. Then we have
the Lie brackets:
[∇α, ∆β] = 0,
[∆α, ∆β] = −C
γ
αβ ∆γ.
Here we have the normalization that at the identity of G, ∆α and ∇α are equal",N/A,N/A
"(and are equal to the Kronecker delta tensor at that point). Denote by Ad(g)β
α the
adjoint action of the Lie group G on the tangent space to G at its identity element.
Then we have:
(∆α)g = Ad(g−1)β
α(∇β)g.
For each vector vα in the tangent space at the identity of G, denote by ∇v = vα∇α
the corresponding left-invariant vector ﬁeld. Integrating the vector ﬁeld ∇v gives
a one-parameter group of transformations of G, denoted by Rv(t), with t ∈R.",N/A,N/A
"We have Rv(t) = Rgv(t), where expv(t) is the integral curve passing through
the identity element of the vector ﬁeld ∇v. Also denote by ∆v = vα∆α the
corresponding right-invariant vector ﬁeld. Integrating the vector ﬁeld ∆v gives a
one-parameter group of transformations of G, denoted by Lv(t), with t ∈R. Then
we have Lv(t) = Lexpv(t). Note that expv(−t) = (expv(t))−1, for any v in the Lie
algebra and any real t.
6
2
Casimir operators",N/A,N/A
"algebra and any real t.
6
2
Casimir operators
A Casimir operator C for the Lie group G is, by deﬁnition, a differential operator
on G, that is both left and right-invariant. Such an operator may be written as a
polynomial in the operators ∇α or ∆α with constant coefﬁcients. Modulo the Lie
algebra relations, it then has a unique expression as a sum combination of terms
Cn, n = 0, 1, 2, . . . , where C0 is a constant multiple of the identity and if n ≥1,
Cn takes the following form:",N/A,N/A
"Cn takes the following form:
Cn = Cα1α2...αn∇α1∇α2 . . . ∇αn = Cα1α2...αn∆α1∆α2 . . . ∆αn.
Here the coefﬁcient tensor Cα1α2...αn is totally symmetric and is both left-invariant
and right-invariant. If Cn = 0 for all odd n, we say that the Casimir operator is
even; if Cn = 0, for all even n, we say that the Casimir operator is odd. If only
Ck is non-zero, we say that the Casimir operator is of order k.
In the special case that the Lie group is semi-simple, we introduce the Killing",N/A,N/A
"form, deﬁned by the formula:
gαβ = C
δ
αγ C
γ
βδ .
Then it is standard that gαβ is symmetric and invertible and left and right invariant.
Denoting its inverse by gαβ, we have a preferred second order Casimir operator,
denoted by □:
□= gαβ∇α∇β = gαβ∆α∆β.
In general, if the Lie group has rank m, there are m independent Casimir oper-
ators, that together with the identity operator generate the algebra of all Casimir
operators. For example in the case of the special unitary group SU(n, C), consist-",N/A,N/A
"ing of all unitary n × n complex matrices of unit determinant, we may write the
Lie algebra as:
[Eα
β , Eγ
δ ] = δγ
βEα
δ −δα
δ Eδ
β.
Here Eα
β is trace-free and hermitian. Then any polynomial in the operator Eα
β
traced over all its indices, in any fashion, gives a (possibly identically zero) Casimir
operator. The algebra has rank n−1, the independent Casimirs being given by the
quantities tr(Ek), for k = 2, 3, . . . n (where Ek is the k-fold matrix product of E",N/A,N/A
"with itself). In particular, for the case n = 2, the only independent Casimir opera-
tor is the Killing operator, which is proportional to the operator tr(E2) = Eα
β Eβ
α.
7
3
The case of the Lie group SU(2, C); harmonics
The case we need for later is the case of the group SU(2, C), which we will usually
represent as the group of quaternions q that are unit: qq = qq = 1. If we write
q = t + xi + yj + zk, where (t, x, y, z) ∈R4, i2 = j2 = k2 = ijk = −1,",N/A,N/A
"then the group is represented as the unit real three-sphere in R4, with equation
t2 + x2 + y2 + z2 = 1. A basis for the left invariant vector ﬁelds is obtained
from the one parameter groups eis, ejs and eks, where s is real. The corresponding
left-invariant vector ﬁelds are as follows:
J = t∇−x∂t −x × ∇.
Here we have x = [x, y, z] and ∇= [∂x, ∂y, ∂z] and we use standard vector
notation for Euclidean three-space with co-ordinate vector x. Then we have:
J × J = (t∇−x∂t −x × ∇) × (t∇−x∂t −x × ∇)",N/A,N/A
"J × J = (t∇−x∂t −x × ∇) × (t∇−x∂t −x × ∇)
= (x × ∇)t∂t + t(∇× (∇× x)) −x∂t × (t∇) + x × (x × ∇)∂t
−(x × ∇) × (t∇−x∂t −x × ∇)
= −x × ∇+ t∇(3 + x.∇) −t(∇.∇)x −(x.x)∇∂t + x(x.∇)∂t
+x(∇.(t∇−x∂t)) −∇(x.(t∇−x∂t)) + t∇−x∂t −x × ∇
= 2t∇−2x × ∇−(x.x)∇∂t −4x∂t + ∇(x.x)∂t = 2J.
Written out in components, we have:
[Ji, Jj] = 2ǫijkJk.
Here ǫijk is the alternating symbol on three elements, with ǫ123 = 1. The right-
invariant vector ﬁelds are obtained similarly:
K = t∇−x∂t + x × ∇.",N/A,N/A
"K = t∇−x∂t + x × ∇.
Note that at the identity, where t = 1 and x = 0, the vectors J and K agree, since
they each reduce to just ∇. Then we have:
[Ki, Kj] = −2ǫijkKk,
[Ji, Kj] = 0.
8
There is one non-trivial Casimir operator, associated to the Killing form, which
we may take to be:
J.J = (t∇−x∂t −x × ∇).(t∇−x∂t −x × ∇)
= t2∇.∇−(3 + x.∇)t∂t −x.∇(1 + t∂t) + x.x∂2
t + (x × ∇).(x × ∇)
= t2∇.∇−(3 + 2x.∇)t∂t −x.∇+ x.x∂2
t −((x × ∇) × (∇)).x
= t2∇.∇−(3 + 2x.∇)t∂t −x.∇+ x.x∂2",N/A,N/A
"= t2∇.∇−(3 + 2x.∇)t∂t −x.∇+ x.x∂2
t + x(∇.∇).x −(x.∇)(3 + x.∇)
= (t2 + x.x)(∂2
t + ∇.∇) −(2 + 2x.∇)t∂t −(t∂t)2 −(x.∇)(2 + x.∇)
= (t2 + x.x)(∂2
t + ∇.∇) −2(t∂t + x.∇) −(t∂t + x.∇)2
= (gabxaxb)gcd∂c∂d −xa∂a(xb∂b + 2).
Here xa = (t, x, y, z) and gab is represented by the identity matrix, so we have:
gabxaxb = t2 + x2 + y2 + z2 = t2 + x.x,
gcd∂c∂d = ∂2
t + ∂2
x + ∂2
y + ∂2
z = ∂2
t + ∇.∇,
xa∂a = t∂t + x∂x + y∂y + z∂z = t∂t + x.∇.
Note that K.K is the same operator as J.J.",N/A,N/A
"Note that K.K is the same operator as J.J.
A harmonic polynomial of degree k, p(xa), on SU(2, C) is the restriction to the
three-sphere gabxaxb = 1 of a polynomial in xa that is harmonic gab∂a∂bp = 0
and is homogeneous of non-negative integral degree k: xa∂ap = kp. So we see
that a harmonic polynomial is an eigen-state of J.J of eigen-value −k(k + 2).
The polynomial is then said to have spin k
2. Finally by the Peter-Weyl theorem",N/A,N/A
"2. Finally by the Peter-Weyl theorem
a smooth function on the group may be uniquely decomposed into its harmonic
components. Explicitly, the harmonic transformation H(f) of f(x) is:
H(f)(y) =
Z
S3
f(x)ωx
(x −y).(x −y),
y.y < 1.
Here the dot product is the standard Euclidean dot product of vectors in R4. Also
the integral is taken over the unit three-sphere, S3, with equation x.x = 1 and ωx
is the invariant volume form of the three-sphere, normalized so that the integral of",N/A,N/A
"the constant function 1 over the three-sphere gives the result 1. The homogeneous
components of the Taylor expansion of H(f)(y), in powers of the vector variable
ya, give the various spherical harmonics of f. Note that ∂y.∂yH(f)(y) = 0,
so each component is a harmonic polynomial of the form ha1a2...akya1ya2 . . . yak
where the (constant) tensor ha1a2...ak is totally symmetric and trace-free on any
pair of indices.
9
4
The spinor approach to SU(2, C)",N/A,N/A
"9
4
The spinor approach to SU(2, C)
We work with a complex two-dimensional vector space S, called the spin space.
S is equipped with a quaternionic conjugation: a conjugate complex linear map
from S to itself, whose square is the negative of the identity. If α ∈S, then its
conjugate is denoted α. If α ∈S, then {α, α} forms a basis for S, over C, if
and only if α is non-zero. We use upper case Latin indices for the tensor algebra",N/A,N/A
"over C of S. Then the conjugate of the spinor αA is the spinor αA. We give S a
complex symplectic structure, denoted ǫAB which is self-conjugate. If αA is any
non-zero spinor, we have 2α[AαB] = kǫAB, where k is real and non-zero. It is
easily seen that the sign of k is independent of the choice of the spinor α. We
say that ǫAB is positively oriented, relative to the given conjugation, if and only
if k is always positive. Note that if ǫAB is not positively oriented, then −ǫAB is",N/A,N/A
"positively oriented. Henceforth we take ǫAB to be positively oriented. Then α is
said to be normalized if and only if k = 1. In index-free notation, ǫ is positively
oriented if and only if there exists a non-zero spinor α, such that 2α∧α = ǫ. Then
any such spinor α is normalized. If α is normalized and β is any spinor, then we
have β = pα + qα, for some complex numbers p and q. Then β = −qα + p α and
β ∧β = (|p|2 + |q|2)α ∧α, so β is itself normalized if and only if |p|2 + |q|2 = 1.",N/A,N/A
"The matrix m of the transformation α →β is:
m =
p
−q
q
p , det(m) = |p|2 + |q|2 = 1.
The group of all such transformations is the group SU(2, C). Using indices, the
elements of SU(2, C) are represented by endomorphisms m B
A
which are self-
conjugate and preserve ǫAB:
m B
A = m B
A , m A
C m B
D ǫCD = ǫAB.
Spinor indices are raised and lowered using ǫAB and its inverse ǫAB, as appropriate
according to the rules vA = vBǫBA and vA = ǫABvB. In particular, we have",N/A,N/A
"ǫABǫAB = 2. Also a spinor αA is normalized if and only if αAαA = 1.
10
The Lie algebra of SU(2, C) is represented by self-conjugate vector ﬁelds JCD =
JDC on the group, which obey the relations at any point m B
A of the group:
2JCDm B
A = −mA(Cδ
B
D) .
For any spinors α and β, put Jα = αAαBJAB, Jβ = βAβBJAB and Jαβ =
αAβBJAB = Jβα. Then we have, for any spinors α and β:
2Jαm B
A = m C
A αCαB,
4JαJβm B
A = 2Jαm C
A βCβB = −αDβDm C
A αCβB,
2(JαJβ −JβJα)m B
A = αDβDmAC(α(CβB) = 2αEβEJCDαCβDm B
A ,",N/A,N/A
"A = αDβDmAC(α(CβB) = 2αEβEJCDαCβDm B
A ,
[Jα, Jβ] = αEβEJαβ.
Here the bracket denotes the Lie bracket of vector ﬁelds on the group. Polarizing
appropriately, with respect to α and β, we get also:
2[Jα, Jαβ] = αEβEJα,
2[Jβ, Jαβ] = −αEβEJβ.
Take α to be normalized and put β = α, J3 = iJαα, J+ = Jα and J−= Jα. Then
we have:
[J+, J−] = J3,
2[J±, J3] = ±J±,
JCD = αCαDJ−+ αCαDJ+ + 2iα(CαD)J3.
Finally write J± = J1 ± iJ2 and put J = [J1, J2, J3]. Then J1, J2 and J3 are real
vector ﬁelds and we have:",N/A,N/A
"vector ﬁelds and we have:
2[Ji, Jj] = ǫijkJk.
Then we have: JCDJCD = J−J+ + J+J−+ 2J2
3 = 2(J2
1 + J2
2 + J2
3) = 2J.J.
Comparing with our previous J operator, which obeyed the commutation relations
[Ji, Jj] = 2ǫijkJk, we see that if we were to multiply each of our present operators
by a factor of four, the commutation relations would be the same. So the operator
JCDJCD is one-eighth of our previous Casimir operator, whose eigen-values were",N/A,N/A
"−k(k + 2) with k a non-negative integer. Thus the operator JCDJCD has eigen-
values −1
8k(k + 2). In particular, acting on m B
A we have:
8JCDJCDm B
A = −4JCDm C
A ǫDB = 2mA(Cδ
C
D) ǫDB = −3m B
A .
So k = 1 and we say that m B
A is (pure) spin one-half (the parameter k correspond-
ing to twice the spin). Similarly, for n any positive integer and for any constant
spinors pB and qA, the spinor function (m B
A pBqA)n is of spin n
2.
11
5
The Ξ-transform for compact Lie groups",N/A,N/A
"2.
11
5
The Ξ-transform for compact Lie groups
Let f(g, h) denote a smooth function of variables g and h in G. So f : G×G →R.
Denote by ∇+
αf and ∆+
αf the action of the invariant vector ﬁelds ∇α and ∆α of
G on the ﬁrst argument of f, respectively and by ∇−
αf and ∆−
αf the action of the
invariant vector ﬁelds on the second argument of f, respectively. If C is a Casimir
operator of G, denote by C+ its action on the ﬁrst argument of f(g, h) and by",N/A,N/A
"C−its action on the second argument of f(g, h). If C is of degree k, deﬁne its
extension to two variables, denoted C, by the formula:
C = C+ −(−1)kC−.
For each smooth f(g, h), deﬁne Ξ(f), called the Ξ-transform of f, by the formula:
Ξ(f)(g, h) =
Z
f(p, g−1ph)ωp.
Here ωp is the Haar measure in the p-variable, represented as a smooth real volume
form on G. In these and the subsequent integrals, the variable p ∈G is understood",N/A,N/A
"to range over the whole Lie group G. Note that using the bi-invariance of the form
ωp, we can rewrite this transform in the various ways:
Ξ(f)(g, h) =
Z
f(p, g−1ph)ωp =
Z
f(gp, ph)ωp =
Z
f(gph−1, p)ωp =
Z
f(ph−1, g−1p)ωp.
It is clear that Ξ(f) is a smooth function on G × G. We calculate the operators
C± acting on Ξ(f)(g, h):
• First multiply h on the right by expv(t). Then we have, for any real t and
any vα:
Ξ(f)(g, h expv(t)) =
Z
f(p, g−1ph expv(t))ωp
=
Z
f(p, uRv(t))u=g−1phωp",N/A,N/A
"Z
f(p, g−1ph expv(t))ωp
=
Z
f(p, uRv(t))u=g−1phωp
Differentiating with respect to t and putting t = 0, we have:
(∇−
αΞ(f))(g, h) =
Z
(∇−
αf)(p, u)u=g−1phωp.
Then we have, by repeated differentiation of the last formula:
(C−Ξ(f))(g, h) =
Z
(C−f)(p, u)u=g−1phωp.
12
• Second, we multiply g on the right by expv(t) in the formula for Ξ(f)(g, h).
Then we have, for any real t and any vα:
Ξ(f)(g expv(t), h) =
Z
f(p, expv(−t)g−1ph)ωp =
Z
f(p, Lv(−t)u)u=g−1phωp",N/A,N/A
"f(p, expv(−t)g−1ph)ωp =
Z
f(p, Lv(−t)u)u=g−1phωp
Differentiating with respect to t and putting t = 0, we have:
(∇+
αΞ(f))(g, h) = −
Z
(∆−
αf)(p, u)u=g−1phωp.
Then we have, for C a Casimir operator of order k, after iteration of this
formula:
(C+Ξ(f))(g, h) = (−1)k
Z
(C−f)(p, u)u=g−1phωp.
Subtracting these two relations, we have proved:
• If C is a Casimir operator of G of order k, then the function Ξ(f)(g, h)
obeys the invariant partial differential equation of order k:
(CΞ(f))(g, h) = 0.",N/A,N/A
"(CΞ(f))(g, h) = 0.
Next we rewrite the Ξ-transform with the arguments g and h moved to the ﬁrst
argument of f:
Ξ(f)(g, h) =
Z
f(gph−1, p)ωp.
Then we have, as above:
Ξ(f)(g, expv(t)h) =
Z
f(gph−1 expv(−t), p)ωp,
(∆−
αΞ(f))(g, h) = −
Z
(∇+
αf)(gph−1, p)ωp,
(C−Ξ(f))(g, h) = (−1)k
Z
(C+f)(gph−1g, p)ωp = (−1)k
Z
(C+f)(p, g−1ph)ωp.
But earlier we proved the relation: (C−Ξ(f))(g, h) =
R
(C−f)(p, g−1ph)ωp.
Hence, by subtraction, we have the formula:
0 =
Z
(C+ −(−1)kC−)(f)(p, g−1ph)ωp.",N/A,N/A
"0 =
Z
(C+ −(−1)kC−)(f)(p, g−1ph)ωp.
We have shown the key result:
• For any Casimir operator C on G, the Ξ-transform obeys the relations:
C ◦Ξ = Ξ ◦C = 0.
13
6
The kernel of the Ξ-transform in the SU(2, C) case
In this section, we make the simplifying assumption that all functions involved
are linear combinations of only ﬁnitely many spherical harmonics. We expect the
results to go through without this assumption, but we do not prove this here.",N/A,N/A
"Henceforth we assume that G = SU(2, C), which is also the Lie group of unit
quaternions under multiplication. Denote by C its second-order Casimir oper-
ator, determined by the negative of the inverse of its Killing form, so that its
eigen-values are n(n + 2), for n a non-negative integer. For non-negative inte-
gers k and l, denote by Hk,l the space of all (necessarily real analytic) harmonics
f(g, h) on SU(2, C) × SU(2, C) that obey the relations C+f = k(k + 2)f and",N/A,N/A
"C−f = l(l + 2)f. Also for N any non-negative integer, put:
H+
N = ⊕N
k=0Hk,k,
H−
N = ⊕N
k=0,l=0,k̸=lHk,l,
HN = H+
N ⊕H−
N = ⊕N
k=0,l=0Hk,l.
The spaces H+
N and H−
N are mutually orthogonal with respect to Haar measure.
Henceforth we ﬁx N and assume f ∈HN. Suppose that the Ξ-transform of f
vanishes, so we have Ξ(f)(g, h) =
R
f(p, g−1ph)ωp = 0. The harmonic parts fk,l
of f with k ̸= l are killed by the Ξ-transform, since such parts lie in the image",N/A,N/A
"of C = C+ −C−, since Cfk,l = (k −l)(k + l + 2)fk,l, or equivalently, since the
eigen-value function x(x + 2) of C is one-to-one for x real and non-negative. So
the Ξ-transform kills the space H−
N. Our aim is to show that nothing else lies in
the kernel of Ξ acting on HN. Accordingly, we need only look at functions f(g, h)
of the form: f = P
k fk(g, h) where fk(g, h) obeys C+fk = C−fk = k(k + 2)fk,
so f ∈H+
N. Then we may write the condition that f be in the kernel:
X
k
Z
fk(xa, xbma
b)ωx = 0.",N/A,N/A
"X
k
Z
fk(xa, xbma
b)ωx = 0.
Here xa = (t, x, y, z) ∈R4 and each fk(xayb) is bi-harmonic, so may be written:
fk(xa, yb) = f b1b2...bk
a1a2...akxa1xa2 . . . xakyb1yb2 . . . ybk.
Here f b1b2...bk
a1a2...ak is a constant tensor and is symmetric and trace-free on any pair of
its upper indices and symmetric and trace-free on any pair of its lower indices.
Also the matrix ma
b is an arbitrary SO(4) transformation and ωx is the invariant",N/A,N/A
"volume measure on the unit three-sphere: gabxaxb = 1. Here gab is the Euclidean
metric tensor for R4.
14
We can do the integral explicitly, leaving the following sum to be analyzed:
0 =
X
ckf b1b2...bk
a1a2...akma1
b1 ma2
b2 . . . mak
bk .
Here ck is a positive (computable) constant, depending only on k. Since ma
b is a
SO(4, R) transformation, it obeys the equation:
m a
b m c
d gac = gbd.
We can differentiate this relation with vector ﬁelds Jca = me[c∂e
a]. We have:
mec∂e
am p
b m q",N/A,N/A
"a]. We have:
mec∂e
am p
b m q
d gpq = mecδp
aδe
bm q
d gpq + mecδq
aδe
dm p
b gpq = mbcmda + mdcmba
So taking the skew part in the indices ca, we ﬁnd that Jca kills the deﬁning relation
for SO(4, R). Then Jca gives the Lie algebra of SO(4, R). Also we have:
Jcdm b
a = me[cδ
b
d] δe
a = ma[cδ
b
d] .
Now we differentiate our sum, using the Lie algebra operators Jcd. The result is:
0 =
X
kckmb1[cf b1b2...bk
d]a2...ak ma2
b2 . . . mak
bk .",N/A,N/A
"d]a2...ak ma2
b2 . . . mak
bk .
We differentiate again, using the generators Jef, giving the formula:
0 =
X
k(k−1)ckmb2[em|b1|[cf b1b2b3...bk
d]f]a3...ak . . . mak
bk +kck(Jefmb1[c)f b1b2...bk
d]a2...ak ma2
b2 . . . mak
bk
=
X
k(k−1)ckmb2[em|b1|[cf b1b2b3...bk
d]f]a3...ak ma3
b3 . . . mak
bk +kckmb1[egf][cf b1b2...bk
d]a2...akma2
b2 . . . mak
bk .
Trace this relation with −2gecgfd:
0 =
X
−2gecgfdk(k−1)ckmb2em|b1|[cf b1b2b3...bk
d]fa3...ak ma3
b3 . . . mak
bk −2gecgfdkckmb1egf[cf b1b2...bk",N/A,N/A
"b3 . . . mak
bk −2gecgfdkckmb1egf[cf b1b2...bk
d]a2...ak ma2
b2 . . . mak
bk
=
X
−2gfdk(k−1)ckm c
b2 m|b1|[cf b1b2b3...bk
d]fa3...ak ma3
b3 . . . mak
bk −2kckm c
b1 δd
[cf b1b2...bk
d]a2...ak ma2
b2 . . . mak
bk
=
X
k(k + 2)ckf b1b2b3...bk
a1a2a3...akm a1
b1 m a2
b2 ma3
b3 . . . mak
bk .
So each term ckf b1b2...bk
a1a2...akma1
b1 ma2
b2 . . . mak
bk is an eigenstate of the second order SO(4)-
Casimir operator −2gecgfdJcdJef = −2JcdJcd of eigenvalue k(k + 2). Eigen-",N/A,N/A
"states of different eigen-values are orthogonal with respect to the Haar measure
of SO(4). Since the function k(k + 2) is single-valued, when k is non-negative,
the various terms in the sum are mutually orthogonal. Since the sum is zero, each
individual term must be zero, giving the relation, for each non-negative integer k:
0 = f b1b2...bk
a1a2...akma1
b1 ma2
b2 . . . mak
bk .
15
We would like to conclude that f b1b2...bk
a1a2...ak vanishes identically.
To do this we",N/A,N/A
"a1a2...ak vanishes identically.
To do this we
may henceforth assume that k ≥1. We re-write the relation using spinors and
the isomorphism of the spin group of SO(4) (a double cover of SO(4)) with
SU(2, C) × SU(2, C):
0 = f
B1B2...BkB′
1B′
2...B′
k
A1A2...AkA′
1A′
2...A′
k m A1
B1 m A2
B2 . . . m Ak
Bk m
A′
1
B′
1 m
A′
2
B′
2 . . . m
A′
k
B′
k .
Here m B
A and m B′
A′ are elements of SU(2, C), independent of each other. So it is
sufﬁcient to prove:
0 = f B1B2...Bk
A1A2...Ak m A1
B1 m A2",N/A,N/A
"0 = f B1B2...Bk
A1A2...Ak m A1
B1 m A2
B2 . . . m Ak
Bk
=⇒f B1B2...Bk
A1A2...Ak = 0.
Here we may assume, without loss of generality, that f B1B2...Bk
A1A2...Ak is symmetric un-
der the simultaneous interchange of an (Ap, Bp)-pair with an (Aq, Bq)-pair, for
any p and q. Then f B1B2...Bk
A1A2...Ak has
 k+3
3

= 1
6(k+3)(k+2)(k+1) independent com-
ponents. Decomposing this relation into irreducible representations in the upper
indices, using the fact that m C
[A m D
B] = δ
C
[A δ
D",N/A,N/A
"[A m D
B] = δ
C
[A δ
D
B] , since SU(2, C) transformations
have unit determinant, the relation becomes:
0 =
k
X
r=0
gB1B2...Br
A1A2...Ar m A1
B1 m A2
B2 . . . m Ar
Br .
Here gB1B2...Br
A1A2...Ar is obtained from f B1B2...Bk
A1A2...Ak by tracing over pairs (A1, A2), (B1, B2)
. . . (A2s−1, A2s), (B2s−1, B2s) with a skew spinor symplectic form ǫCD, or its in-
verse ǫCD, as appropriate (here r + 2s = k, so k −r is necessarily even), sym-",N/A,N/A
"metrizing over the remaining B-indices and over the remaining A-indices and
multiplying by a suitable positive constant, depending only on r. We have (r+1)2
independent components for each gB1B2...Br
A1A2...Ar, in agreement with the simple combi-
natorial identities:
• When k = 2s is even:
2s + 3
3

= 1
6(2s + 3)(2s + 2)(2s + 1) = 12 + 32 + 52 + . . . (2s + 1)2.
• When k = 2s + 1 is odd.
2s + 4
3

= 1
6(2s+4)(2s+3)(2s+2) = 22 +42 +· · ·+(2s)2 +(2s+2)2.
16",N/A,N/A
"16
We now need to show that necessarily each gB1B2...Br
A1A2...Ar vanishes. We may further
decompose into irreducible spinor representations, so the required sum now takes
the form:
0 =
X
0≤p,q≤k
(hp,q)B1B2...Bp
A1A2...Apm A1
B1 m A2
B2 . . . m Ap
Bp (m C
C )q.
Here the quantities (hp,q)B1B2...Bp
A1A2...Ap for p + q = r are the irreducible spinor parts
of the spinor gB1B2...Br
A1A2...Ar , so (hp,q)B1B2...Bp
A1A2...Ap is trace-free on any index pair (Aj, Bk)",N/A,N/A
"and is symmetric in its upper indices and symmetric in its lower indices. We need
only to prove that each (hp,q)B1B2...Bp
A1A2...Ap vanishes identically.
Note that the matrix mB
A may be written uniquely as follows:
m B
A =
t + iz
x + iy
−x + iy
t −iz
.
Here we have (t, x, y, z) ∈R4 and t2 + x2 + y2 + z2 = t2 + x.x = 1. Also
x = (x, y, z) lies in R3, equipped with its usual Euclidean dot product. Note that
we have also m A
A = 2t = ±2√1 −x.x. In this language, we now need to analyze",N/A,N/A
"the relation, valid whenever x.x ≤1:
0 =
X
p,q
2qtqhp,q(x).
Here x ∈R3 and the function hp,q(x) is a polynomial: (hp,q)a1a2...apxa1xa2 . . . xap,
where 1 ≤aj ≤3, for each j. The coefﬁcient tensor (hp,q)a1a2...ap is totally
symmetric and trace-free on any index pair. First put x.x = 1, which entails that
t = 0, giving the formula:
0 =
X
p
hp,0(x),
x.x = 1.
But, as p varies, the functions hp,0(x) are spherical harmonics on the two-sphere",N/A,N/A
"x.x = 1, of different eigenvalues with respect to the Laplacian operator of the two-
sphere, so are mutually orthogonal. So hp,0(x) = 0 on the two-sphere, for each p.
But hp,0(x) is homogeneous in x of degree p, so hp,0(x) vanishes identically on
R3, so (hp,0)B1B2...Bp
A1A2...Ap vanishes identically, for each p. Then the remaining sum has
a factor of 2t, so we may factor out and reduce to the relation:
0 =
X
p,q
2qtqhp,q+1(x).
17
Again put x.x = 1, so t = 0, giving the formula:
0 =
X
p
hp,1(x),",N/A,N/A
"0 =
X
p
hp,1(x),
x.x = 1.
As before we conclude that each (hp,1)B1B2...Bp
A1A2...Ap vanishes identically. Now we
iterate and conclude that each (hp,q)B1B2...Bp
A1A2...Ap vanishes identically, as required, for
all p and q and we are done. Summarizing, we have given a proof of the following
result:
• The kernel of Ξ acting on the space HN is the image of C acting on the same
space.
Finally, we notice that in the course of this proof, we have found that the image",N/A,N/A
"of Ξ acting on HN does not involve harmonics apart from those of the form fk,k
for 0 ≤k ≤N. This follows from the relation C+ = C−= −2JcdJcd, acting
on functions of the form: f b1b2...bk
a1a2...akma1
b1 ma2
b2 . . . mak
bk . We describe this ﬁrst, before
ﬁnishing our argument.
We compare our normalizations of the Casimir operators for the groups SO(4, R)
and SU(2, C) × SU(2, C) as follows. Using spinors the group elements m b
a of
SO(4, R) decompose as products of SU(2, C) elements:
m b
a = m B",N/A,N/A
"m b
a = m B
A m B′
A′ .
The Lie algebra operator Jcd = −Jdc decomposes as:
Jcd = ǫCDJC′D′ + ǫC′D′JCD.
Here JCD = JDC and JC′D′ = JD′C′ generate the independent factors of SU(2, C).
Acting on m b
a , we get:
2JCDm b
a = ǫC′D′Jcdm b
a = ǫC′D′ma[cδ
b
d] = ǫC′D′mA′C′mA(Cδ
B
D) δ B′
D′ = −m B′
A′ mA(Cδ
B
D) .
So we have:
JCDm B′
A′ = 0,
JCDm B
A = −1
2mA(Cδ
B
D) ,
JC′D′m B
A = 0,
JC′D′m B′
A′ = −1
2mA′(C′δ
B′
D′) .
18
Now we can compare Casimir operators. We have:
JcdJcdmab = Jcdma[cgd]b = Jcbm c",N/A,N/A
"JcdJcdmab = Jcdma[cgd]b = Jcbm c
a = ma[cδ
c
b] = −3
2mab,
JCDJCDm B
A = −1
2JCDmA(Cδ
B
D) = 1
2ǫBDJCDm C
A = −1
4ǫBDmA(Cδ
C
D) = −3
8m B
A .
Similarly we have JC′D′JC′D′m B′
A′ = −3
8m B′
A′ . The group elements m B
A are of
spin one-half, so the second-order Casimir operator C, acting on m B
A , has the
eigen-value 1(1+2) = 3. So we have JCDJCD = −1
8C+. Similarly, we have also
JC′D′JC′D′ = −1
8C−. These equations are consistent with the identity JcdJcd =",N/A,N/A
"2(JCDJCD + JC′D′JC′D′), which follows immediately from the deﬁnition of the
spinor operators JCD and JC′D′ in terms of Jcd. Acting on polynomials in m b
a we
then have:
JCDJCD = JC′D′JC′D′ = 1
4JcdJcd.
So, ﬁnally we have C+ = C−= −2JcdJcd. In particular the various polyno-
mials f b1b2...bk
a1a2...akma1
b1 ma2
b2 . . . mak
bk used above, which we showed are eigen-states of
−2JcdJcd of eigen-value k(k + 2) are also eigen-states of C+ and C−, each with
the same eigen-value k(k + 2).",N/A,N/A
"the same eigen-value k(k + 2).
So acting on HN, the Ξ-transform annihilates H−
N and has zero kernel acting on
H+
N. But we have just shown that the image of each Hk,k under Ξ lies in Hk,k.
Since the kernel is zero and each Hk,k is ﬁnite dimensional, the restriction of Ξ
to each Hk,k is an isomorphism with its image. So the kernel of Ξ acting on HN
is precisely the space H−
N and the image of Ξ acting on HN is precisely the space
H+",N/A,N/A
"H+
N. The latter space is also the kernel of the operator C = C+ −C−acting on
HN. We have proved, for any non-negative integer N:
• The kernel of C acting on the space HN is the image of Ξ, acting on the
same space.
• The kernel of Ξ acting on the space HN is the image of C, acting on the
same space.
19
7
The null twistor geometry
The twistor space for conformally ﬂat space-time may be taken to be a four di-
mensional complex vector space T, whose elements are called twistors [13]-[15].",N/A,N/A
"Complexiﬁed, conformally compactiﬁed space-time is recovered as the Grassma-
nian Gr(2, T) of all two-dimensional complex subspaces of T, with the conformal
structure such that x and y in Gr(2, T) are null related if and only if they have a
non-zero twistor in common. The space T is equipped with a pseudo-hermitian
structure of signature (2, 2). If Zα denotes a twistor, then its conjugate is denoted
Zα, which lies in the complex dual space T∗of T. Then the (real ) inner prod-",N/A,N/A
"uct of Zα with itself is ZαZα. The space T is the disjoint union of three sets,
T± = {Zα ∈T : ±ZαZα > 0} and N = {Zα ∈T : ZαZα = 0}. The twistors
of N are called null. Put N′ = N −{0}. Then N′ is a smooth real manifold of
dimension seven. We say that x ∈Gr(2, T) is real if and only if x ⊂N. The key
fact relating twistor theory to space-time is that the subset X of all real elements of
Gr(2, T) is a smooth four-manifold, equipped with the induced natural structure",N/A,N/A
"conformal structure, which makes X a conformal compactiﬁcation of Minkowksi
space-time. Each element Z in N′ belongs to a one-parameter family γ(Z) (a cir-
cle) of elements of X, which forms a null geodesic in X and every null geodesic
arises in this way. Also γ(Z) = γ(Z′) if and only if Z′ = λZ, for 0 ̸= λ ∈C.
The twistor space T carries a natural ﬂat pseudo-K¨ahler metric g = dZαdZα,
whose signature is (4, 4). Restricting to the space N′, this metric degenerates,",N/A,N/A
"with the direction of degeneracy given by the homogeneity vector ﬁeld H =
Zα∂α + Zα∂
α, where ∂α =
∂
∂Zα and ∂
α =
∂
∂Zα
. The one parameter group for
this vector ﬁeld is the transformation Zα →etZα with t real. Quotienting N′
out by this vector ﬁeld, we get a smooth six-manifold, denoted M, with a confor-
mally ﬂat conformal structure of signature (3, 3), naturally induced by the pseudo-
K¨ahler structure of T. We may assign co-ordinates Z = (α, β, γ, δ) ∈C4 for T,
such that:",N/A,N/A
"such that:
ZαZα = |α|2 + |β|2 −|γ|2 −|δ|2.
Then the twistors of N′ satisfy |α|2 + |β|2 = |γ|2 + |δ|2 > 0. When we quotient
by the scaling Z →etZ, we may take |α|2 + |β|2 = |γ|2 + |δ|2 = 1, so M is the
product S3 × S3, where S3 is the real three-sphere. Further the induced metric is
the metric |dα|2 + |dβ|2 −|dγ|2 −|dδ|2 which gives M the metric G+ −G−(of
signature (3, 3)), where the G± are unit three-sphere metrics, applied to the ﬁrst",N/A,N/A
"and second factors of the product S3 ×S3 in the cases of G+ and G−, respectively.
20
8
The twistor symmetry Lie groups and algebras
The symmetry group O(T) of T, equipped with its pseudo-K¨ahler structure, is the
group of real linear transformations of T to itself preserving the pseudo-K¨ahler
metric. Then O(T) is isomorphic to the twenty-eight dimensional real Lie group
O(4, 4, R). The subgroup U(T) of O(T) is the subgroup that preserves the com-",N/A,N/A
"plex structure. It has sixteen real dimensions and is isomorphic to the Lie group
U(2, 2, C). The Lie algebra o(T) of O(T) is represented on the twistor space by
the operators:
Eαβ = 2Z[α∂
β],
Eαβ = 2Z[α∂β],
Eα
β = Zα∂β −Zβ∂
α.
The operators Eαβ and Eαβ have six complex degrees of freedom, counting for
twelve real dimensions. The operator Eα
β obeys E
α
β = −Eα
β , so has sixteen de-
grees of freedom. The Lie algebra commutators are easily computed directly, with
the result:
[Eαβ, Eγδ] = 0,",N/A,N/A
"the result:
[Eαβ, Eγδ] = 0,
[Eαβ, Eγδ] = 0,
[Eα
β , Eγδ] = −2δ[γ
β Eδ]α,
[Eα
β , Eγδ] = 2δα
[γEδ]β,
[Eα
β , Eγ
δ ] = δγ
βEα
δ −δα
δ Eγ
β,
[Eαβ, Eγδ] = −4δ[α
[γ Eβ]
δ] .
Note that the operator Eα
β generates the Lie algebra u(T) of U(T). The operator
H = Zα∂α +Zα∂
α commutes with the whole algebra of o(T). Also introduce the
(pure imaginary) operator E:
E = Eα
α = Zα∂α −Zα∂
α.
Then iE, generates phase transformations of the twistor space: eitE maps Zα to",N/A,N/A
"eitZα, for any real t. Note that E grades the algebra o(T):
[E, Eαβ] = 2Eαβ,
[E, Eα
β ] = 0,
[E, Eαβ] = −2Eαβ.
Also put h = Zα∂α and h = Zα∂
α. Then we have:
H = h + h,
E = h −h,
h = 1
2(H + E),
h = 1
2(H −E).
Note that all four operators h, h, E and H mutually commute. Finally note that
operators of o(T) kill the function ZαZα so naturally induce operators on N′. Also
the operator H preserves ZαZα up to a scale, so it too induces an operator on N′.
21
9
The null twistor wave operator □",N/A,N/A
"21
9
The null twistor wave operator □
We consider the Laplacian operator associated to the pseudo-K¨ahler structure of
T, the operator □= ∂α∂
α. We compute the following commutator:
[□, ZβZβ] = [∂α∂
α, ZβZβ] = ∂α[∂
α, ZβZβ] + [∂α, ZβZβ]∂
α
= ∂αZα + Zα∂
α = 4 + Zα∂α + Zα∂
α = H + 4.
Then, by induction, it easily follows that for each positive integer n, we have the
relation:
□nZβZβ = ZβZβ□n + n□n−1(H + 5 −n).
Now let g(Z) be a given smooth function on N′. Extend g(Z) locally to a smooth",N/A,N/A
"function ˜g(Z), deﬁned on an open set in T containing the space N′. Then apply
the operator □n and restrict back to N′. Denote the result by □n(g). So we have:
g →˜g →□n(˜g)|N′ = □n(g).
Note that the vector ﬁeld H is tangent to N′, so gives a well-deﬁned smooth vector
ﬁeld, still called H on N′. For k an integer, denote by Hk the space of smooth
functions f(Z) on N′, obeying the relation, for any Z ∈N′ and any real t ̸= 0:
f(tZ) = tkf(Z).",N/A,N/A
"f(tZ) = tkf(Z).
We use the same notation Hk, for the associated sheaf and presheaf, the context
determining which interpretation is relevant. Suppose now that g ∈Hk, so g
obeys Hg = kg. Then we may consistently require that the extension ˜g obeys
the analogous relation H˜g = k˜g. Let ˜g′ be another such extension of g. Then we
have H˜g′ = k˜g′ and ˜g −˜g′ vanishes on N′, so by the Malgrange division theorem,
we may write ˜g −˜g′ = ZαZαh(Z), where (H −k + 2)h(Z) = 0. Then by our",N/A,N/A
"calculation above, we have:
(□n(˜g−˜g′))(Z) = □n(ZαZαh(Z)) = ZαZα(□n(h))(Z)+n(□n−1(H+5−n)h)(Z)
= ZαZα(□n(h))(Z) + n(k −n + 3)(□n−1h)(Z).
In the special case that k = n −3, the last term vanishes and restricting to N′ we
get: □n(˜g)|N′ = □n(˜g′)|N′. Hence we have □n(g) independent of the choice of
the extension of g into T, so □n(g) is canonically deﬁned. We have shown:
• The operator □n induces naturally a map from the space (or sheaf) Hn−3 to
the space or sheaf H−3−n.",N/A,N/A
"the space or sheaf H−3−n.
Only the case n = 1 will be analyzed further here. The operator □then induces
a natural second-order differential operator taking H−2 to H−4, which we call the
null twistor wave operator.
22
10
The null twistor wave operator constructed in-
trinsically in terms of the operators of the Lie
algebra o(T)
An alternative approach to the twistor wave operator uses the operator Eαβ =
2Z[α∂
β], which operates intrinsically to the space N′, since it kills the quantity",N/A,N/A
"ZαZα. We have the following relations, using the notation of the previous section:
EαβEαγ = 4Z[α∂
β]Z[α∂γ]
= Zα∂
βZα∂γ −Zβ∂
αZα∂γ + Zβ∂
αZγ∂α −Zα∂
βZγ∂α
= ZαZα∂
β∂γ −Zβ∂γ(h + 2) + ZβZγ∂
α∂α −(δβ
γ + Zγ∂
β)h,
[Eαβ, Eαγ] = −4δ[α
[αEβ]
γ] = −(δα
α −2)Eβ
γ −δβ
γE = −2Eβ
γ −δβ
γE,
1
2(EαβEαγ + EαγEαβ) = EαβEαγ −1
2[Eαβ, Eαγ]
= ZαZα∂
β∂γ −Zβ∂γ(h + 1) −Zγ∂
β(h + 1) + ZβZγ∂
α∂α −1
2δβ
γ(h + h)
= ZαZα∂
β∂γ−1
2(Zβ∂γ+Zγ∂
β+δβ
γ)(H+2)+1
2(Zβ∂γ−Zγ∂
β)(h−h)+ZβZγ∂
α∂α+δβ
γ.
= ZαZα∂
β∂γ −1
2(Zβ∂γ + Zγ∂
β + δβ",N/A,N/A
"α∂α+δβ
γ.
= ZαZα∂
β∂γ −1
2(Zβ∂γ + Zγ∂
β + δβ
γ)(H + 2) + 1
2Eβ
γ Eα
α + ZβZγ∂
α∂α + δβ
γ.
Rearranging the terms of this relation we have:
1
2(EαβEαγ+EαγEαβ−Eβ
γ Eα
α−2δβ
γ ) = ZαZα∂
β∂γ−1
2(Zβ∂γ+Zγ∂
β+δβ
γ)(H+2)+ZβZγ∂
α∂α.
In particular, when ZαZα = 0 and H + 2 = 0, we have just:
1
2(EαβEαγ + EαγEαβ −Eβ
γ Eα
α −2δβ
γ) = ZβZγ∂
α∂α.
The left-hand side of this equation is intrinsic to N′, so therefore, so is the right-
hand side, acting on H−2. In the language of our conformal six manifold, M, the",N/A,N/A
"bundles whose sections give the spaces Hk are conformally weighted line bundles.
In this language, we then can rephrase the result on the wave operator as follows:
• The operator □naturally induces a conformally invariant second order wave
operator on M from the line bundle of conformal weight −2 to the line
bundle of conformal weight −4.
23
11
The co-spin bundle approach to twistor space
In Minkowski space-time, we use complex two-component spinors, with spinor",N/A,N/A
"index pairs AA′ corresponding to vector indices a; conjugation interchanges primed
and unprimed indices [13]-[15]. The metric, gab, and its inverse, gab, factorize:
gab = ǫABǫA′B′,
gab = ǫABǫA′B′,
ǫAB = −ǫBA,
ǫABǫAC = δ C
B .
Here ǫAB and ǫAB are the complex conjugates of ǫA′B′ and ǫA′B′, respectively.
Spinor indices are raised and lowered according to the scheme vB = vAǫAB,
vA = ǫABvB and their conjugates, as appropriate. The points of the co-spin bundle",N/A,N/A
"are labelled by pairs (xa, πB′), with πB′ a co-spinor at the point xa. The co-spin
bundle has real dimension eight and maps naturally to the co-tangent bundle via
the map (xa, πB′) →(xa, pb), with pb = πB′πB. Two points in the co-spin bundle
map to the same image, with pa non-zero, if and only if their co-spinors are phase
multiples of each other. The image is the part of the cotangent bundle of space-
time with pb either zero or null and future pointing. There are natural indexed",N/A,N/A
"vertical vector ﬁelds ∂A′ and ∂
A, which annihilate xb and which obey the relations:
∂A′πB′ = δ A′
B′ ,
∂A′πB = 0,
∂
AπB′ = 0,
∂
AπB = δ A
B .
The spinor translation of the operators h, h, H and E is as follows:
h = πA′∂A′,
h = πA∂
A,
H = h+h = πA′∂A′+πA∂
A,
E = h−h = πA′∂A′−πA∂
A.
H generates the real scaling πA′ →etπA′; iE generates the phase transformation
πA′ →eitπA′. The space-time covariant derivative extends to the co-spin bundle",N/A,N/A
"such that ∂aπB′ = 0. The null geodesic spray, denoted N , is the vector ﬁeld:
N = πA′πA∂a.
The equation N f = 0 gives the twistor functions. The twistor variables are:
Zα = (ixaπA′, πA′),
Zα = (πA, −ixaπA).
Note that N Zα = 0, N Zα = 0 and ZαZα = 0. Any function killed by N
may be regarded as a function of Zα. The space of afﬁnely parametrized null
geodesics, with attached covariantly constant non-zero spinor πA′ is isomorphic",N/A,N/A
"to the space N with a complex two-plane I removed (this two-plane corresponds to
the vertex of the null cone at inﬁnity, when Minkowski space-time is appropriately
conformally compactiﬁed). The functions f ∈Hk are deﬁned by the formulas:
N f = (H −k)f = 0,
f(xa, sπA′) = skf(xa, πA′), where 0 ̸= s ∈R.
Using the twistor variables, we have f(sZα) = skf(Zα), for s real and non-zero.
24
12
The spinor translation of the operators of o(T)
We write out the operators Eαβ, its conjugate Eαβ and Eα",N/A,N/A
"β on the spin bundle.
First, for the operator Eαβ = Zα∂
β −Zβ∂
α, we have the derivatives:
Eαβ(Zγ, Zγ) = (0, Zαδβ
γ −Zβδα
γ ).
Write:
Eαβ = Aαβd∂d + Aαβ
C ∂
C + Aαβ
C′ ∂C′.
Then we have:
0 = (Aαβd∂d + Aαβ
C ∂
C + Aαβ
C′ ∂C′)(ixcπC′, πC′) = (iAαβcπC′ + Aαβ
C′ xc, Aαβ
C′ ).
So Aαβ
C′ = 0 and Aαβc = πC′XαβC. Then we have:
πCEαβ = πCXαβDπD′∂d + πCAαβ
E ∂
E = XαβπC′∂c + πCAαβ
E ∂
E.
Here Xαβ = πCXαβC. Finally we need:
πCEαβ(−ixdπD, πD) = (XαβπC′∂c + πCAαβ
E ∂
E)(−ixdπD, πD)
= πC(−iXαβπD′ −iAαβ",N/A,N/A
"E ∂
E)(−ixdπD, πD)
= πC(−iXαβπD′ −iAαβ
D xd, Aαβ
D ).
So we get:
(−iXαβπC′ −iAαβ
C xc, Aαβ
C ) = 2Z[αδβ]
γ .
So we have:
Aαβ
C = 2Z[αδβ]
C ,
Xαβ = 2Z[αXβ],
XβπC′ + δβ
Cxc = iδC′β + λC′Zβ,
XBπC′ + xBC′ = iλC′xBB′πB′,
XB′πC′ = λC′πB′ + iδC′
B′ = λB′πC′ + (i + πE′λE′)δC′
B′,
πC′λC′ = −i,
XB′ = λB′,
XBπC′ = −xBC′ + iλC′xBB′πB′ = iλB′xBB′πC′,
Xβ = (ixbλB′, λB′), πC′λC′ = −i.
25
So ﬁnally we may write:
πCEαβ = XαβπC′∂c + 2πCZ[αδβ]
E ∂
E,
πC′Eαβ = XαβπC∂c + 2πC′Z[αδβ]E′∂E′.
Here Xαβ has entries:",N/A,N/A
"Here Xαβ has entries:
XAB = ǫABxcπC′xB′CλB′ = i
2ǫABx2,
XA′B′ = −iǫA′B′,
XA
B′ = ZAXB′ −ZB′XA = xA
B′.
In particular, we have then the contractions:
XαβXδβ = 0,
XαβZβ = 0.
Also we have:
πC′∂cXαβ = (−iǫABπC′xC′
C , πB′δA
C, 0) = −2Z[αδβ]
C ,
Xα
B′πB′ = (−xaπA′, iπA′) = iZα,
∂E′Zα = (ixAE′, δE′
A′) = ǫE′B′(ixA
B′, ǫA′B′) = iǫE′B′Xα
B′,
πA′∂aZβ = −iπA(0, πB′).
Next consider the operator:
Eα
β = Zα∂β −Zβ∂
α.
We have Eα
β Zγ = δγ
βZα and Eα
β Zγ = −δα
γ Zβ. Also we have:
Eα
β πC′ = δβC′Zα,
Eα",N/A,N/A
"γ Zβ. Also we have:
Eα
β πC′ = δβC′Zα,
Eα
β πC = −δα
CZβ.
Next we have:
(Eα
β xc)πC′ = −i(Eα
β ZC) −xcEα
β πC′ = −iZα(δC
β −ixcδβC′)
= −i(ixDC′δα
D + δαC′)(δC
β −ixCD′δβD′)πC′.
(Eα
β xc)πC = i(Eα
β Z
C′
) −xcEα
β πC = −iZβ(δαC′ + ixcδα
C).
So we may take:
Eα
β xc = −i(ixDC′δα
D + δαC′)(δC
β −ixCD′δβD′).
Then we have:
Eα
β = −i(ixDC′δα
D + δαC′)(δC
β −ixCD′δβD′)∂c + ZαδβC′∂C′ −Zβδα
C∂
C
= −iXα
E′XδE∂e + ZαδβC′∂C′ −Zβδα
C∂
C.
Taking the trace, we get the expected formulas:
Eα
α = πC′∂C′ −πC∂",N/A,N/A
"Eα
α = πC′∂C′ −πC∂
C = h −h = E.
26
13
The spinor description of the null twistor wave
operator
We now are able to compute, in the spinor formalism, the following quantity,
which gives the main part of the twistor wave operator:
πC′πCEαβEδβ = πCEαβπC′Eδβ
= (XαβπE′∂CE′ + 2πCZ[αδβ]
E ∂
E)(XδβπF∂F C′ + 2πC′Z[δδβ]F ′∂F ′)
= Xαβ(πE′∂CE′Xδβ)πF∂F C′+πC′Xα
E′(πE′∂CE′Zδ)∂E′−πC′Xαβ(πE′∂CE′Zβ)δδE′∂E′
+πC′ZδXα
F ′πE′∂CE′∂F ′+πCZαXδβδβ
E∂
EπF∂F C′+4πCπC′Z[αδβ]
E ∂
EZ[δδβ]F ′∂F ′
= ZαXδCπF∂F C′ −iπC′πCXα",N/A,N/A
"E ∂
EZ[δδβ]F ′∂F ′
= ZαXδCπF∂F C′ −iπC′πCXα
E′(0, πD′)∂E′ −πC′πCZαδδE′∂E′
+πC′ZδXα
F ′πE′∂CE′∂F ′ −πCZαXδE∂E
C′ + πCZαXδEπF∂F C′∂
E
−4iπCπC′Z[αδβ]
E (ǫEFX[δ|F |)δβ]F ′∂F ′ + 4πCπC′Z[αδβ]
E Z[δδβ]F ′∂
E∂F ′
= ZαXδCπF∂F C′ −iπC′πCXα
E′(0, πD′)∂E′ −πC′πCZαδδE′∂E′
+πC′ZδXα
F ′πE′∂CE′∂F ′ −πCZαXδE∂E
C′ + πCZαXδEπF∂F C′∂
E
+iπCπC′Zα(ǫEFXEF)δδF ′∂F ′ + iπCπC′δα
E(ǫEFXδF)πF ′∂F ′
−πCπC′ZαδδF ′πE∂
E∂F ′ −πCπC′δα
EZδπF ′∂
E∂F ′
Conjugating and adding, we get:
πC′πC(EαβEδβ + EδβEαβ)",N/A,N/A
"πC′πC(EαβEδβ + EδβEαβ)
= Zα(XδCπF∂F C′−πC′πCδδE′∂E′+πCXδFπE∂EC′∂
F−πCXδE∂E
C′+πCXδEπF∂F C′∂
E
−2πCπC′δδF ′∂F ′ −πCπC′δδF ′πE∂
E∂F ′ −πCπC′δE′δπF∂E′∂
F)
−iπC′πC(Xα
F ′δδE′πE′ −δα
E(ǫEFXδF )πF ′)∂F ′ + c.c.
Now we have:
Xα
B′ = (XA
B′, XA′B′) = (xA
B′, −iǫA′B′)
= −iǫC′B′(ixAC′, δC′
A′) = −iǫC′B′(ixcδα
C + δαC′).
27
So we get:
Xα
F ′δδE′πE′ −δα
E(ǫEFXδF)πF ′ = Xα
F ′δδE′πE′ −iδα
E(ǫEFǫCF(−ixcδC′δ+δC
δ )πF ′
= Xα
F ′δδE′πE′ −iδα
C(−ixcδC′δ + δC
δ )πF ′
= ǫE′B′Xα
B′δδE′πF ′ + Xα
G′πG′δδF ′ −iδα",N/A,N/A
"δ )πF ′
= ǫE′B′Xα
B′δδE′πF ′ + Xα
G′πG′δδF ′ −iδα
C(−ixcδC′δ + δC
δ )πF ′
= −i(ixcδα
C + δαC′)δδC′πF ′ + iZαδδF ′ −iδα
C(−ixcδC′δ + δC
δ )πF ′
= −iδα
δ πF ′ + iZαδδF ′.
So we now have the formula, using the relations h = πA′∂A′, h = πA∂
A, H =
h + h and E = h −h:
πC′πC((δα
δ +ZαδδE′∂E′+Zδδα
E∂
E)(H+2)+EαβEδβ+EδβEαβ−2δα
δ −(ZαδδE′∂E′−Zδδα
E∂
E)E)
= Zα(XδCπF∂F C′ −πCXδE∂E
C′ + 2πCXδF πE∂EC′∂
F) + c.c.
= Zα(XδCπF∂F C′−πCXδE∂E
C′+2πCǫEGXδGπF∂EC′∂
F+2πCXδDπD∂F C′∂
F)+c.c.
= Zα(−XδCπE∂E
C′+πCXδE∂E",N/A,N/A
"F+2πCXδDπD∂F C′∂
F)+c.c.
= Zα(−XδCπE∂E
C′+πCXδE∂E
C′+πCǫEGXδG∂EC′(H−E+2)−2iZδπC∂F C′∂
F)+c.c.
= Zα(XδEπE∂CC′ + πCǫEGXδG∂EC′(H −E + 2) −2iZδπC∂F C′∂
F) + c.c.
= Zα(πCǫEGXδG∂EC′(H −E + 2) −2iZδπC∂F C′∂
F) + c.c.
We re-write the −E-coefﬁcient of the right-hand side of this equation; this coefﬁ-
cient is:
Y α
δ = ZαπCǫEGXδG∂EC′ −c.c.
= iπCXα
E′πE′XδG∂G
C′ −c.c.
= iπC′πCXα
E′XδG∂GE′ + iXα
C′πD′πCXδG∂G
D′ −c.c.
= iπC′πCXα
E′XδG∂GE′ + iXα
C′πD′πGXδG∂D′C −iXα
C′XδCπD′πD∂D′D −c.c.
= iπC′πCXα",N/A,N/A
"C′XδCπD′πD∂D′D −c.c.
= iπC′πCXα
E′XδG∂GE′ + ZδXα
C′πD′∂D′C −iXα
C′XδCπD′πD∂D′D −c.c.
= iπC′πCXα
E′XδG∂GE′−ZδXα
D′πC′∂D′
C +ZδXα
E′πE′∂C′C−iXα
C′XδCπD′πD∂D′D−c.c.
= iπC′πCXα
E′XδG∂GE′−ZδXα
D′πC′∂D′
C +iZαZδ∂C′C−iXα
C′XδCπD′πD∂D′D−c.c.
= iπC′πCXα
E′XδG∂GE′−ZδXα
D′πC′∂D′
C +iZαZδ∂C′C−iXα
C′XδCπD′πD∂D′D−c.c.
= −Y α
δ + 2iπC′πCXα
E′XδG∂GE′ + 2iZαZδ∂C′C −2iXα
C′XδCπD′πD∂D′D
= iπC′πCXα
E′XδE∂EE′ + iZαZδ∂C′C −iXα
C′XδCπD′πD∂D′D
28
Now assume that H + 2 = 0 and N = πD′πD∂D′D = 0. Also note that the",N/A,N/A
"operators N and E commute. Then we have:
πC′πC(EαβEδβ + EδβEαβ −2δα
δ −(−iXα
D′XδD∂DD′ + ZαδδE′∂E′ −Zδδα
E∂
E)E)
= −iZαZδ(2πC∂F C′∂
F −2πC′∂F ′C∂F ′ + ∂CC′E).
From the work of the last section, we recognize the term −iXα
D′XδD∂DD′ +
ZαδδE′∂E′ −Zδδα
E∂
E as being exactly the operator Eα
δ . So, substituting, we have,
provided H + 2 = N = 0:
πC′πC(EαβEδβ + EδβEαβ −2δα
δ −Eα
δ E)
= −iZαZδ(2πC∂F C′∂
F −2πC′∂F ′C∂F ′ + ∂CC′E).",N/A,N/A
"= −iZαZδ(2πC∂F C′∂
F −2πC′∂F ′C∂F ′ + ∂CC′E).
The left-hand side of this equation is exactly 2πC′πC times the twistor wave op-
erator. We have proved that the spinor description of the operator □, induced by
∂α∂
α, on twistor functions f, of total degree minus two, is given by the formula:
πC′πC □(f) = i

πC′∂F ′∂F ′Cf −πC∂
F∂F C′∂
Ff −1
2∂CC′Ef

.
It is not immediately obvious that the right-hand side of this equation is propor-",N/A,N/A
"tional to πC′πC. To verify this directly, ﬁrst note that since N f = 0, we may write
∂af = πA′fA + πAf A′, for some fA. Then we have:
πC′∂F ′∂F ′Cf −πC∂
F∂F C′f −1
2∂CC′Ef
= πC′(h + 2)fC −πC(h + 2)f C′ + πC′πC(∂F ′f F ′ −∂
FfF) −1
2E∂CC′f
= 1
2((2h + 2 −E)(πC′fC) −(2h + 2 + E)(πCf C′)) + πC′πC(∂F ′f F ′ −∂
FfF)
= 1
2(H + 2)(πC′fC −πCf C′) + πC′πC(∂F ′f F ′ −∂
FfF).
It remains to show that the quantity hc = (H +2)(πC′fC −πCf C′) is proportional",N/A,N/A
"to πC′πC. Since the co-vector hc is purely imaginary, it sufﬁces to show that
πC′hc = 0. We have:
πC′hc = πC′(H + 2)(πC′fC −πCf C′)
= (H + 1)(πC′(πC′fC −πCf C′)) = (H + 1)(πC′(−πC′fC −πCf C′))
= −(H + 1)(πC′∂cf) = −πC′(H + 2)∂cf = −πC′∂c(H + 2)f = 0.
Here we used that f has total degree minus two and that the operators ∂a and H
commute, whereas HπA′ = πA′(H + 1).
29
Next we verify that the quantity i(πC′∂F ′∂F ′Cf −πC∂
F∂F C′∂
Ff −1
2∂CC′Ef)",N/A,N/A
"F∂F C′∂
Ff −1
2∂CC′Ef)
is killed by the operator N and is of total degree −2. That the degree is −2
is immediate, since f is of degree minus two and since H commutes with the
operators E, ∂a, πA′∂B′ and πA∂
B. It follows that □(f) has total degree −4, as
expected. Then we have, since N commutes with ∂a and with E and kills f:
πD′πD∂d(i(πC′∂F ′∂F ′Cf −πC∂
F∂F C′∂
Ff −1
2∂CC′Ef))
= −i(πC′πD∂d∂D′Cf −πCπD′∂d∂DC′∂
Ff) = −i
2πC′πC(∂a∂af −∂a∂af) = 0.",N/A,N/A
"Ff) = −i
2πC′πC(∂a∂af −∂a∂af) = 0.
Since N also commutes with πC′πC, we have shown that the function □(f) lies
in H−4, as expected. We introduce the Lorentz generators of the co-spin-bundle:
∂B′
A′ = πA′∂B′ −1
2πC′∂C′.
Note that ∂A′
A′ = 0, so ∂A′B′ = ∂B′A′. Then we may write our operator on H−2 as:
πC′πC □= i(∂F ′
C′∂F ′C −∂
F
C∂F C′).
Finally, let gA and hA′ be any smooth functions, not necessarily complex conju-
gates of each other, such that ∂af = πA′gA + πAhA′. So we have gA = fA + πAp",N/A,N/A
"and hA′ = f A′ −πA′p, for some smooth function p. Then we have:
1
2(H + 2)(πC′gC −πChC′) + πC′πC(∂F ′hF ′ −∂
FgF)
= −iπC′πC □(f) + (H + 2)(πC′πCp) −πC′πC(∂F ′(πF ′p) + ∂
F(πFp))
= πC′πC(−i□(f) + (H + 4)p −(h + 2)p −(h + 2)p) = −iπC′πC□(f).
We have proved that the twistor wave operator □maps H−2 to H−4. Acting on a
function f(x, π), which obeys N f = (H + 2)f = 0 and f(x, −π) = f(x, π), we
have:
πA′πA □(f) = i(∂B′
A′ ∂B′A −∂
B
A∂BA′).",N/A,N/A
"have:
πA′πA □(f) = i(∂B′
A′ ∂B′A −∂
B
A∂BA′).
Alternatively, we ﬁrst write ∂af = πA′fA +πAfA′, with fA and fA′ smooth. Then:
−iπA′πA □(f) = 1
2(H + 2)(πA′fA −πAfA′) + πA′πA(∂B′fB′ −∂
BfB).
In particular, if we arrange that (H + 3)fA = 0 and (H + 3)fA′ = 0 (or indeed, if
we arrange just one of these relations, since the other then follows automatically),
then we have just:
∂af = πA′fA+πAfA′,
(H+3)fA = 0,
(H+3)fA′ = 0,
□(f) = i(∂B′fB′−∂
BfB).
30
14
The spinor integral operator: the Ξ-transform",N/A,N/A
"14
The spinor integral operator: the Ξ-transform
We next construct a spinor integral operator which goes back from H−4 to H−2.
Let f(x, π) be a twistor function of total degree −4 (i.e. f ∈H−4), so we have:
0 = πA′πA∂af(x, π) = (πA′∂A′ + πA∂
A + 4)f(x, π),
f(x, −π) = f(x, π).
Then we deﬁne the Ξ-transform Ξ(f)(x, η) of f by the formula:
Ξ(f)(x, η) = i
Z
πA′ηA′>0
f(xa + sηAηA′, πC′)dsπB′dπB′πBdπB.
Here the variable s ranges over the whole real line. Also the spinor integral is",N/A,N/A
"taken in the space of spinors πA′ such that πA′ηA′ is real and positive. We assume
that f is sufﬁciently smooth and well-behaved at inﬁnity such that all the integrals
under consideration converge nicely. Note that the requirement that f(x, π) be
of degree minus four is natural, since the differential form πB′dπB′πBdπB has
weight four, so the total weight of the integrand is zero, as required for the integral
to be well-deﬁned. If we write the transform out with the symplectic spinor forms",N/A,N/A
"written in explicitly, we have:
Ξ(f)(x, η) = i
Z
πA′ηB′ǫA′B′>0
f(xa+sǫABǫA′B′ηBηB′, πC′)dsǫD′E′ǫDEπD′dπE′πDdπE.
The point here now is that under a real conformal transformation ǫAB →uǫAB
with u > 0 real, combined with the replacement s →u−2s the integral is invari-
ant. So the integral is conformally invariant.
We need to check that the differential form being integrated is closed. So we need
to show that if f(πA′) is smooth and obeys the relation: 0 = (πA′∂A′+πA∂
A+4)f,",N/A,N/A
"A+4)f,
then the following differential three-form vanishes identically on the space where
πA′ηA′ is real and πA′ is non-zero, for any ﬁxed non-zero spinor ηA′:
d(fπB′dπB′πBdπB)
= (dπA′∂A′f +dπA∂
Af)πB′dπB′πBdπB+fdπB′dπB′πBdπB−fπB′dπB′dπBdπB
= 1
2((πA′∂A′ + 2)f)dπB′dπB′πBdπB −1
2((πA∂
A + 2)f)πB′dπB′dπBdπB
= 1
2((πA′∂A′ + 2)f)ξ,
ξ = dπB′dπB′πBdπB + πB′dπB′dπBdπB.
31
So it remains to be shown that the differential form ξ vanishes identically. To do",N/A,N/A
"this efﬁciently, ﬁrst note that since πA′ηA′ is real, by assumption, for each ﬁxed
ηA′, the space of allowable spinors πA′ lies in a real vector space of three real
dimensions. So the four-form Ξ = dξ = 2dπB′dπB′dπBdπB vanishes identically.
Also the vector ﬁeld H = πA′∂A′ +πA∂
A is tangent to the relation obeyed by πA′:
0 = πA′ηA′ −πAηA. Contracting Ξ with H gives the form 4ξ. Since the form Ξ
vanishes, so does any contraction of Ξ, so ξ vanishes also, as required and we are
done.",N/A,N/A
"done.
Note that using the transformation (πA′, ηB′) →(−πA′, −ηB′), we ﬁnd that Ξ(f)(x, η) =
Ξ(f)(x, −η). Next note that under the replacement xa →xa + kηAηA′, com-
bined with the variable replacement s →s −k, the integral remains invariant, so
Ξ(f)(x, η) is constant along the null geodesic spray, so is a twistor function:
ηA′ηA∂af(x, η) = 0.
Next if we scale ηA′ →pηA′, where p is real and positive, combined with a vari-",N/A,N/A
"able change s →sp−2, then the integral scales as Ξ(f)(x, pη) = p−2Ξ(f)(x, η).
So we have proved the desired relation:
• The transform f →Ξ(f) maps the space H−4 to the space H−2.
We call this transform the Ξ transform. We can rewrite the Ξ-transform to obviate
the requirement that πA′ηA′ be real as follows:
Ξ(f)(x, η) = i
Z
f

xa + sηAηA′,
πC′
πE′ηE′

dsπB′dπB′πBdπB
(πE′ηE′πEηE)2 .
Here we have used the fact that f is of homogeneous of degree minus four in",N/A,N/A
"the variable πA′ under positive real scalings. The point now is that the integrand
is invariant under complex scalings πA′ →sπA′ with s any non-zero complex
number, so in the integral we no longer need to constrain πA′ by the requirement
that πA′ηA′ be real. Note, however, the key fact that the integral is not in general
invariant under phase transformations ηA′ →ληA′ with |λ| = 1. The integral may
now be construed as taken over R × S2, where the R-factor corresponds to the",N/A,N/A
"s variable and the S2-factor represents the Riemann sphere corresponding to the
complex projective space of the co-spin space with its origin deleted. Since this
formula is homogeneous in the variable πA′, we can also normalize the spinor πA′
by the relation πA′ηA′ = 1 and then the transform formula reads:
Ξ(f)(x, η) = i
Z
πA′ηA′=1
f(xa + sηAηA′, πC′)dsπB′dπB′πBdπB.
32
15
The equation □◦Ξ = 0
We begin by re-writing the basic Ξ-transform formula, using the fact that f(x, π)",N/A,N/A
"is a twistor function, so may be written as f(ωA, πA′), where ωA = ixaπA′:
Ξ(f)(x, η) = i
Z
f
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′

dsπB′dπB′πBdπB
(πE′ηE′πEηE)2 .
Note that, since f ∈H−4, the function f(ωA, πA′) obeys the scaling relation
f(tωA, tπA′) = t−4f(ωA, πA′), for any positive real number t. Inside the integral,
denote the operator
∂
∂ωA by ∂A, with conjugate ∂A′. Note that the quantity ∂Af
obeys the scaling relation (∂Af)(tωA, tπA′) = t−5f(ωA, πA′), for any positive real",N/A,N/A
"number t. Applying the derivative ∂a to the integral formula, inside the integral
we have:
∂aΞ(f)(x, η) = −
Z  πA′
πE′ηE′ ∂A −
πA
πEηE ∂A′

f
 ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′
 dsπB′dπB′πBdπB
(πE′ηE′πEηE)2
We re-write the operator part of the integrand, acting on the function f
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′

as follows:
−
1
(πE′ηE′πEηE)2
 πA′
πE′ηE′ ∂A −
πA
πEηE ∂A′

= −
1
(πE′ηE′πEηE)3(πBηBπA′∂A−πB′ηB′πA∂A)
=
1
(πE′ηE′πEηE)3(πA′πBηA∂B −πAπB′ηA′∂B′ −πA′πA(ηC∂C −ηC′∂C′))
=
1",N/A,N/A
"=
1
(πE′ηE′πEηE)3

πA′πBηA∂B −πAπB′ηA′∂B′ + iπA′πA
∂
∂s

.
Integrating out the ∂
∂s term, we get the relation:
∂aΞ(f)(x, η) = ηA′f A(x, η) + ηAfA′(x, η),
fA′(x, η) =
Z
πA′πB(∂Bf)
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′
 dsπB′dπB′πBdπB
(πE′ηE′πEηE)3 .
Note that under the replacement ηA′ →−ηA′, we get fA′(x, −η) = −fA′(x, η).
33
Next note that under the scaling transformation ηA′ →tηA′, with t > 0, combined
with the transformation s →t−2s, the function (∂Bf)
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′
",N/A,N/A
"ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′

scales by a factor of t5. Also the differential form dsπB′dπB′πBdπB
(πE′ηE′πEηE)3
scales by a
factor of t−8. So the integral scales by a factor of t−3 and we have the relation:
f(x, tη) = t−3f(x, η), for non-zero real number t.
Denote the derivative operator
∂
∂ηA′ by DA′, with conjugate D
A. Then the quan-
tity fA′(x, η) obeys the homogeneity relation:
(ηB′DB′ + ηBD
B + 3)fA′ = 0.",N/A,N/A
"(ηB′DB′ + ηBD
B + 3)fA′ = 0.
Next we have, using the fact that πA′DA′ annihilates both the quantities πA′ηA′
and πAηA:
DA′fA′ =
Z
πA′DA′πB(∂Bf)
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′
 dsπB′dπB′πBdπB
(πE′ηE′πEηE)3
=
Z
−isπB′πB(∂B′∂Bf)
ixaπA′
πE′ηE′ + isηA,
πC′
πE′ηE′
 dsπB′dπB′πBdπB
(πE′ηE′πEηE)3 .
The right-hand side of this equation is real, so immediately we have the differential
equation:
DA′fA′ −D
Af A = 0.
Comparing with our calculations of the twistor wave operator, we have proved",N/A,N/A
"that the function Ξ(f)(x, η) automatically obeys the twistor wave equation:
(□(Ξ(f)))(x, η) = 0.
We have proved:
• The composition of operators □◦Ξ : H−4 →H−4 vanishes identically.
34
16
The equation Ξ ◦□= 0
Suppose that a twistor function f of degree minus four lies in the image of □
acting on H−2, so we have, for some function g(x, π) ∈H−2 the relations:
∂ag = πA′gA + πAgA′,
(H + 3)gA = 0,
(H + 3)gA′ = 0,
i(∂A′gA′ −∂AgA) = f.",N/A,N/A
"(H + 3)gA′ = 0,
i(∂A′gA′ −∂AgA) = f.
Henceforth assume that πA′ηA′ ̸= 0. Then we may write gA′ = ηA′q+πA′p, where
p and q are functions of xa and πA′, with (H + 3)q = 0 and (H + 4)p = 0. Put
r = p + p, so (H + 4)p = 0. Note that:
∂A′gA′ = ∂A′ηA′q + ∂A′πA′p = ηA′∂A′q + (h + 2)p
= ηA′∂A′q + 1
2(h −h)p.
Then we have:
∂ag(x, π) = πA′ηAq + πAηA′q + πAπA′r,
(H + 3)q = 0, (H + 4)r = 0,
iηA∂
Aq −iηA′∂A′q −i
2(h −h)r = f.
Here r = |πC′ηC′|2ηA′ηA∂ag and πA′∂ag = −πC′ηC′πAq. We show that replacing",N/A,N/A
"f by the left-hand side of this equation in the integral for Ξ(f), all terms integrate
to zero. We take the deﬁning integral for Ξ(f) in the form:
Ξ(f) = i
Z
πE′ηE′=1
f(xa + sηA′ηA, πA′)dsπC′dπC′πCdπC.
First consider the r term. Note that we have, when πE′ηE′ ̸= 0:
1
|πC′ηC′|2ηA′ηA∂a(h −h)g = (h −h)r.
Then we have:
((h −h)r)(xa + sηA′ηA, πA′) =
1
|πC′ηC′|2ηA′ηA(∂a(h −h)g)(xa + sηA′ηA, πA′)
= ∂
∂s
1
|πC′ηC′|2((h −h))g(xa + sηA′ηA, πA′).",N/A,N/A
"= ∂
∂s
1
|πC′ηC′|2((h −h))g(xa + sηA′ηA, πA′).
Inserting this term into the integral for Ξ(f), the term involving r integrates out to
zero.
35
It remains to show that the term −iηA′∂A′q integrates to zero. Since the operator
ηA′∂A′ preserves the quantities πC′ηC′ and πCηC, we can assume that πC′ηC′ = 1.
Then dπA′ = −ηA′πC′dπC′. In particular dπA′dπB′ = 0 and dπAdπB = 0. Then
we have, for w a function of πA′:
d(wπCdπC) = ∂A′wdπA′πCdπC
= −(ηA′∂A′w)πC′dπC′πCdπC.
Then we have, when πA′ηA′ = 1:",N/A,N/A
"Then we have, when πA′ηA′ = 1:
(ηE′∂E′q)(xa+sηAηA′, πA′)dsπC′dπC′πCdπC = d(q(xa+sηAηA′, πA′)dsπCdπC).
So this term integrates to zero; then by complex conjugation, the q term also
integrates to zero. So Ξ(f) = 0, as required. We have proved:
• The composition of operators Ξ ◦□: H−2 →H−2 vanishes identically.
Summarizing, we have proved:
• □◦Ξ = 0 vanishes identically, so the kernel of □contains the image of Ξ.
• Ξ ◦□= 0 vanishes identically, so the kernel of Ξ contains the image of □.
36
17",N/A,N/A
"36
17
O(4, 4) triality using quaternions
Consider three eight-dimensional metric vector spaces Vα, Vβ and Vγ, whose
elements λ are represented as pairs of quaternions λ = (P, Q), equipped with an
O(4, 4)-metric λ.λ = |Q|2−|P|2. Typical elements of Vα, Vβ and Vγ are denoted
α = (A, B), β = (C, D) and γ = (X, Y ), respectively. We introduce a triality τ,
a real trilinear form, and three associated products, given as follows:
2τ = 2(αβγ) = 2α.(βγ) = 2α.(γβ) = 2β.(γα) = 2β.(αγ) = 2γ.(αβ) = 2γ.(βα)",N/A,N/A
"= −A(CY + XD) + B(CX + Y D) −(Y C + DX)A + (XC + DY )B
= −C(AY −XB) + D(Y B −AX) −(Y A −BX)C + (BY −XA)D
= −X(AD −CB) + Y (BD −CA) −(DA −BC)X + (DB −AC)Y.
Note that τ = (αβγ) ∈R. Here the three real bilinear products are:
(βγ) = (γβ) = (C, D)(X, Y ) = (CY + XD, CX + Y D) ∈Vα,
(γα) = (αγ) = (X, Y )(A, B) = (AY −XB, Y B −AX) ∈Vβ,
(αβ) = (βα) = (A, B)(C, D) = (AD −CB, BD −CA) ∈Vγ.
Then we have the inner products:
(βγ).(βγ) = −|CY +XD|2+|CX+Y D|2 = (|C|2−|D|2)(|X|2−|Y |2) = (β.β)(γ.γ),",N/A,N/A
"(γα).(γα) = −|AY −XB|2+|Y B−AX|2 = (|A|2−|B|2)(|X|2−|Y |2) = (γ.γ)(α.α),
(αβ).(αβ) = −|AD−CB|2+|BD−CA|2 = (|A|2−|B|2)(|C|2−|D|2) = (α.α)(β.β).
Next we have the following relations:
(α(αβ)) = (AD −CB, BD −CA)(A, B)
= (A(DB −AC) −(AD −CB)B, (DB −AC)B −A(AD −CB))
= −(AA −BB)(C, D) = (α.α)β,
(β(αβ)) = (C, D)(AD −CB, BD −CA)
= (C(BD −CA) + (AD −CB)D, C(AD −CB) + (BD −CA)D)
= −(CC −DD)(A, B) = (β.β)α,
37
(α(γα)) = (A, B)(AY −XB, Y B −AX)
= (A(Y B −AX) −(AY −XB)B, B(BY −XA) −(Y A −BX)A)",N/A,N/A
"= (A(Y B −AX) −(AY −XB)B, B(BY −XA) −(Y A −BX)A)
= −(AA −BB)(X, Y ) = (α.α)γ,
(γ(γα)) = (AY −XB, Y B −AX)(X, Y )
= ((AY −XB)Y + X(BY −XA), (Y A −BX)X + Y (Y B −AX))
= −(XX −Y Y )(A, B) = (γ.γ)α,
(β(βγ)) = (CY + XD, CX + Y D)(C, D)
= ((CY + XD)D −C(CX + Y D), (CX + Y D)D −C(CY + XD))
= −(CC −DD)(X, Y ) = (β.β)γ,
(γ(βγ)) = (X, Y )(CY + XD, CX + Y D)
= ((CY + XD)Y −X(XC + DY ), Y (CX + Y D) −A(CY + XD))
= −(XX −Y Y )(C, D) = (γ.γ)β.",N/A,N/A
"= −(XX −Y Y )(C, D) = (γ.γ)β.
By polarizing these relations with respect to the reals, we get a series of identities.
For example, when γ′ ∈Vγ, we have:
γ(γ′α) + γ′(γα) = 2(γ.γ′)α.
The other key identities for a triality may be veriﬁed directly:
((γα)(αβ)) = 2(αβγ)α −(α.α)(βγ),
((βγ)(γα)) = 2(αβγ)γ −(γ.γ)(αβ),
((αβ)(βγ)) = 2(αβγ)β −(β.β)(γα).
We can also prove these identities as follows; pick any α′ ∈Vα. Then we have:
α′.((γα)(αβ)) = (α′(γα)).(αβ) = −(α(γα′)).(αβ) + 2(α.α′)γ.(αβ)",N/A,N/A
"= −α(αβ)).(γα′) + 2(α.α′)γ.(αβ) = α′.(−α.α(βγ) + 2(αβγ)).
Since this formula holds for all α′, and since the inner product is non-degenerate,
we infer the relation ((γα)(αβ)) = 2(αβγ)α −(α.α)(βγ). The other identities
are proved similarly.
38
Alternatively we can adopt the following approach, using the fact that the products
are generically surjective: for example, write β = (αγ′), whenever α.α ̸= 0 (here
γ′ = (αβ)(α.α)−1 ∈Vγ). Then we have:",N/A,N/A
"γ′ = (αβ)(α.α)−1 ∈Vγ). Then we have:
((γα)(αβ))−2α(αβγ)+α.α(βγ) = ((γα)(α(αγ′)))−2α(α(αγ′)).γ+α.α((αγ′)γ)
= (α.α)((γ′(γα)) + (γ(γ′α)) −2(γ′.γ)α) = 0.
Since this relation holds for almost all α ∈Vα, by continuity, it holds for all α.
Finally given any α ∈Vα, there is a natural mapping denoted ˆα : Vβ ⊕Vγ →
Vβ ⊕Vγ given by the formula: ˆα(β ⊕γ) = ((αγ) ⊕(αβ)). Then the operators
{ˆα : α ∈Vα}, which depend linearly on α, represent the Clifford algebra of",N/A,N/A
"O(4, 4), since we have ˆα2 = (α.α)I, where I is the identity operator on Vβ ⊕Vγ.
In particular the space Vβ ⊕Vγ may be regarded as the spin space for Vα. It then
follows from the structure theory of the representations of Clifford algebras that
the O(4, 4)-triality we have constructed is unique up to isomorphism. Of course,
we also have that Vγ⊕Vα may be considered as the spin space for Vα and Vα⊕Vβ
may be considered as the spin space for Vγ.",N/A,N/A
"may be considered as the spin space for Vγ.
We say that α ∈Vα and β ∈Vβ are incident if and only if (αβ) = 0. Multi-
plying this condition by α, we get (α.α)β = 0; multiplying instead by β, we get
(β.β)α = 0. It follows that if α and β are incident, then either α = 0, or β = 0 or
both α and β are null vectors. Given α ̸= 0, with α.α = 0, the space of all β such
that αβ = 0 turns out to be four-dimensional. Note also that if (αβ) = (αβ′) = 0,
then we have:
0 = β′(αβ) + β(αβ′) = 2(β.β′)α.",N/A,N/A
"then we have:
0 = β′(αβ) + β(αβ′) = 2(β.β′)α.
So β and β′ are necessarily orthogonal, if α ̸= 0. Using our quaternionic formal-
ism, the condition (A, B)(C, D) = 0 becomes:
AD −CB = BD −CA = 0.
For (A, B) non-zero and null we have |A|2 = |B|2 ̸= 0. So we may write
(C, D) = (As, tB), for some quaternions s and t. Then we need:
0 = AtB −AsB,
0 = BBt −sAA = |B|2(t −s).
The general solution is just s = t and we have (C, D) incident with (A, B) ̸= 0 if",N/A,N/A
"and only if |A|2 = |B|2 ̸= 0 and (C, D) = (At, tB), for some quaternion t. Note
that the space of solutions is a four-dimensional completely null subspace of Vβ,
the maximal possible dimension for such a completely null subspace.
39
18
The twistor approach to O(4, 4)-triality
We represent a twistor Zα by a pair of quaternions: Zα = (C, D). The O(4, 4)-
inner product of Zα with itself is −|C|2 + |D|2 = ZαZα. We select a unit imagi-",N/A,N/A
"nary quaternion i and write any quaternion q uniquely as sum q = q1 + q2, where
q1i = iq1 (equivalently iq1i = −q1) and q2i = −iq2 (equivalently iq2i = q2);
explicitly we have and q1 = 1
2(q −iqi) and q2 = 1
2(q + iqi). If j and k are unit
imaginary quaternions, such that ij = −ji = k and if q = t + xi + yj + zk,
with t, x, y, z real numbers, then iqi = −t −xi + yj + zk, so q1 = t + xi and
q2 = yj + zk = (y + iz)j = j(y −iz). We identify the (commutative) subalgebra",N/A,N/A
"of all the quaternions q such that q = q1, equivalently qi = iq, with the complex
numbers C. Then, for any q ∈C and Zα = (C, D), we deﬁne (qZ)α = (Cq, qD),
making the space of all twistors into a four-dimensional complex vector space.
Write C = c0 + jc1 and D = d0 + d1j, where c0, c1, d0 and d1 are complex
numbers. Then we may represent Zα by the complex four-vector (c0, c1, d0, d1),
with the action of C just given by left multiplication. The conjugate (dual) vector",N/A,N/A
"is then Zα = (−c0, −c1, d0, d1). Consider the twistor description of the triality
transformation Zα = (C, D) →Uα = (CY + XD, CX + Y D), where (X, Y )
are given quaternions. This is real linear in the variables X and Y , so to under-
stand this action it sufﬁces to take the four cases: Y = x ∈C, Y = j, Y = k,
X = x0 + jx1, where x0 and x1 are complex numbers.
• Y = x is just the transformation Zα →Uα = xZα.
• Y = j maps Zα = (c0, c1, d0, d1) to Uα = (−c1, c0, −d1, d0) = AβαZβ,
with matrix:
A =
0",N/A,N/A
"with matrix:
A =
0
1
0
0
−1
0
0
0
0
0
0
−1
0
0
1
0
.
(The matrix multiplication here is acts on Zβ from the left with Zβ treated
as a column matrix).
• Y = k maps Zα = (c0, c1, d0, d1) to Uα = (ic1, −ic0, −id1, id0) = BβαZβ,
with matrix:
B =
0
−i
0
0
i
0
0
0
0
0
0
−i
0
0
i
0
.
40
• X = x0 + jx1 maps Zα = (c0, c1, d0, d1) to Uα = (x0d0 + x1d1, x1d0 −
x0d1, x0c0 + x1c1, x1c0 + x0c1) = CβαZβ, with matrix:
C =
0
0
x0
x1
0
0
x1
−x0
−x0
−x1
0
0
−x1
x0
0
0
.",N/A,N/A
"C =
0
0
x0
x1
0
0
x1
−x0
−x0
−x1
0
0
−x1
x0
0
0
.
Combining these transformations the full transformation is of the form:
Zα →Uα = xZα + XβαZβ.
Here Xαβ = pAαβ + qBαβ + Cαβ = −Xβα, where Y = x + pj + qk, with p and
q real. It is easily checked that the skew twistor Xαβ obeys the reality condition:
Xαβ = 1
2ǫαβγδXγδ.
Here ǫαβγδ is completely skew and is chosen such that ǫ1234 = −1. Finally the
space of all skew twistors Xαβ obeying the reality condition is a six-dimensional",N/A,N/A
"vector space over the reals and may be parametrized by the quaternion X together
with the part, pj + qk, of the quaternion Y that obeys Y i = −iY . The matrix for
Xαβ is:
Xαβ =
0
p −iq
x0
x1
−p + iq
0
x1
−x0
−x0
−x1
0
−p −iq
−x1
x0
p + iq
0
.
We have 1
4XαβXαβ + |x|2 = −|X|2 + |Y |2. Also note that we have:
UαUα = |x|2ZαZα + XβαZβXγαZγ =
1
4XαβXαβ + |x|2

ZγZγ.
41
Note that the O(4, 4)-triality 2τ relating Zα = (C, D), (X, Y ) and W
α = (A, B)
is then the (doubled) inner product W",N/A,N/A
"α = (A, B)
is then the (doubled) inner product W
αU α + UαWα of W
α = (A, B) with Uα, so
is
2τ = xZαWα + xW
αZα + XαβZαWβ + XαβZαW
β.
The three triality products are now:
(Zα, (x, Xαβ)) = Wα = xZα + XβαZβ,
(Wα, (x, Xαβ)) = Zα = xW
α −XβαWβ,
(Zα, Wβ) = (x, Xαβ) =

W
αZα, 2Z[αW
β] + ǫαβγδZγWδ

.
For the last of these products, note that we have:
|x|2 + 1
4XαβXαβ = |W
αZα|2 + 2Z[αW β]ZαW β = ZαZαW
βWβ.
We verify directly the triality product structure:
(Z(Z, (x, X))) = (Zα, xZα + XβαZβ)",N/A,N/A
"(Z(Z, (x, X))) = (Zα, xZα + XβαZβ)
= (xZα + XβαZβ)Zα, 2Z[α(xZβ] −Xβ]γZγ) + ǫαβγδZγ(xZδ −XδǫZǫ))
= (xZαZα, −2Z[αXβ]γZγ −ǫαβγδZγXδǫZǫ)
Now we have:
−2Z[αXβ]γZγ −ǫαβγδZγXδǫZǫ
= XαβZγZγ −3Z[αXβγ]Zγ + 1
2ǫδαβγZγǫδǫζηXζηZǫ
= XαβZγZγ −3Z[αXβγ]Zγ + 3ZγX[αβZγ] = XαβZγZγ.
So we have Z(Z, (x, X)) = ZαZα(x, X), as required. The other veriﬁcations are
similar and will be omitted.
42
19
Triality and the invariant Ξ-transform
We assume that the twistor space is equipped with a ﬁxed alternating tensor, ǫαβγδ,",N/A,N/A
"with complex conjugate ǫαβγδ, normalized by the relation ǫαβγδǫαβγδ = 24. Ex-
plicitly we may take ǫAB
C′D′ = ǫABǫC′D′ and any spinor parts of ǫαβγδ, with three
or more unprimed indices, or three or more primed indices, vanish. Let Zα be a
twistor, Wα a dual twistor and let Xαβ be a skew twistor, which obeys the real-
ity condition Xαβ =
1
2ǫαβγδXγδ. If the twistor Xαβ has entries XAB = uǫAB,
XA
B′ = ixA
B′, XA′B′ = vǫA′B′ with u and v complex and xa a complex four-
vector, then Y αβ =
1",N/A,N/A
"vector, then Y αβ =
1
2ǫαβγδXγδ has entries Y AB =
1
2ǫABǫC′D′uǫC′D′ = uǫAB,
Y A′B′ = 1
2ǫA′B′ǫCDvǫCD = vǫA′B′ and Y A
B′ = −ǫACǫB′D′X
D
C′
= −ixA
B′. Then
the reality condition boils down to the requirement that u and v be real numbers
and that xa be a real four vector. Note that this reality condition entails the rela-
tion:
4XαβXγβ = δα
γ XρσXρσ.
Also we have XαβXαβ = 2uv + 2vu + 2XA
B′X
B
A′
= 2(uv + vu + xaxa). In",N/A,N/A
"B′X
B
A′
= 2(uv + vu + xaxa). In
particular if Xαβ obeys the reality condition, then XαβXαβ = 4uv+2xaxa (where
now (u, v, xa) are real). Note that the signature of the quadratic form XαβXαβ is
(4, 8), for general Xαβ and (2, 4), when Xαβ obeys the reality condition. As
studied in the previous section, the twistor triality formula is:
τ = ZαW
βXαβ + ZαWβXαβ + xZαWα + xZαW
α.
Differentiating τ with respect to Wα, we get the incidence relations:
ZαXαβ + xZβ = 0,",N/A,N/A
"ZαXαβ + xZβ = 0,
Multiplying this formula by 4Xγβ, we get:
0 = XρσXρσZγ −4xZβXβγ = Zα(XρσXρσ + 4xx).
It quickly follows that either Zα = 0, or Xαβ = 0 and x = 0, or ZαZα =
XαβXαβ + 4xx = 0. Note that provided Xαβ obeys the reality condition, the
signature of the quadratic form XαβXαβ + 4xx = 2(2uv + xaxa + 2xx) is (4, 4),
the same as that of the basic twistor spaces. Differentiating τ with respect to x
and Xαβ we get the incidence relations for the twistors Zα and Wα:
ZαWα = 0,
2Z[αW",N/A,N/A
"ZαWα = 0,
2Z[αW
β] = −ǫαβγδZγWδ.
43
Note that the incidence condition is invariant under real scalings of the twistors
Zα and Wα, but not under complex scalings. Assume that Zα is incident with
W α, where Wα ̸= 0 is given and Zα is variable. If W
αWα ̸= 0, the only solution
is Zα = 0. When W
αWα = 0, the solution space is a real vector space of four
dimensions and every solution is null: ZαZα = 0. Henceforth we take Wα to",N/A,N/A
"be non-zero and null. In (conformally compactiﬁed) real Minkowski space-time,
since Wα is null, Wα selects a null geodesic. For convenience, we assume that
Wα does not lie on the null cone at inﬁnity. Also for convenience, we delete from
our solution space the solutions Zα, for which Zα and W
α are linearly dependent
over the complex numbers. Then Zα is non-zero and null, so it also determines a
(variable) null geodesic. For convenience, we assume that these null geodesics do",N/A,N/A
"not meet at inﬁnity. Then, since ZαWα = 0, the null geodesic represented by Zα
meets that of Wα at a (variable, ﬁnite) point of the null geodesic of Wα. We may
write Wα = (ηA, −ixBA′ηB), for some ﬁxed real vector xa and ﬁxed non-zero
spinor ηA. Then, conjugating, we have W
α = (ixB′AηB′, ηA′). Also the twistor
Zα may be written: Zα = (i(xAB′ + sηAηB′)πB′, πA′), where s is a real variable
and πA′ is a non-zero variable spinor subject to the condition that πA′ηA′ be pure",N/A,N/A
"imaginary and non-zero. Write πA′ηA′ = iu, where u is real and non-zero. Note
that the condition u ̸= 0 guarantees that Zα and W
α are linearly independent over
the complex numbers and that they meet at a ﬁnite point, as required. Then we
have:
dZα = −uds(ηA, 0) + (i(xAB′ + sηAηB′)dπB′, dπA′).
Now we may write dπA′ = απA′+βηA′, where the one-form β is complex whereas
the one-form α is real. Note that πA′dπA′ = −iuβ. Also deﬁne the ﬁxed auxiliary",N/A,N/A
"twistor Uα = (ηA, 0) (so U α = (0, ηA′). Note that the twistors Uα, Zα and W
α
are linearly independent. Also we have ZαU α = iu. Then we have:
dZα = −udsUα + αZα + βW
α.
In particular we have for the contact form:
iZαdZα = u2ds.
44
Next let θα be an auxiliary twistor-valued (constant) Grassman variable that anti-
commutes with itself, with the exterior derivative operator and with its conjugate,
θα. Consider the four-form:
ω4 = 1
24(θαdZα + θαdZα)4.",N/A,N/A
"ω4 = 1
24(θαdZα + θαdZα)4.
Put U = Uαθα + U αθα, Z = Zαθα + Zαθα and W = Wαθα. Then we have:
ω4 = 1
24(−uUds+Zα+Wβ+Wβ)4 = −uUdsZαWβWβ = (UZWW)udsαββ.
The real vector ﬁeld H = Zα∂α + Zα∂
α is tangent to the relations obeyed by Zα.
Contracting dZα with H gives the relation:
ιHdZα = Zα = ιH(−Uαuds + αZα + βW
α).
It follows that ιH(ds) = ιH(β) = 0 and ιH(α) = 1. Deﬁne ω3 = −ιHω4. Then
we have:
ω3 = −ιHω4 = 1
6(θαZα + θαZα)(θβdZβ + θβdZβ)3 = UZWWudsββ.",N/A,N/A
"6(θαZα + θαZα)(θβdZβ + θβdZβ)3 = UZWWudsββ.
Note that ω3 is a projective form of weight four: under the scaling Zα →t(Z)Zα,
where t(Z) is a non-zero function of Zα, we have ω3 →t(Z)4ω3. Next we work
out the Grassman element UZWW. Put φA = θA −ixaθA′ and υ = Uαθα =
ηA′θA′. Then we have:
W = Wαθα = ηAθA −ixaηAθA′ = ηAφA,
U = υ + υ,
Zαθα = −i(xa + sηAηA′)πAθA′ + πAθA = πAφA −isηAπAυ,
Z = πAφA + πA′φ
A′
−isηAπAU,
UZWW = (υ + υ)(πAφA + πA′φ
A′
)(ηBφBηB′φ
B′
)
= −i
2u(υ + υ)(φBηB′ −ηBφB′)φBφ
B′",N/A,N/A
"B′
)
= −i
2u(υ + υ)(φBηB′ −ηBφB′)φBφ
B′
= iuΨ,
Ψ = −1
2(υ + υ)(ηB′φB −ηBφB′)φBφ
B′
= Ψ.
45
We next show that the quantity Ψ may be neatly expressed as a quadratic in the
twistor Wα. Note that:
θαθαWW = (θAθA + θA′θ
A′
)WW
= ((φA + ixaθA′)θA + θA′(φ
A′
−ixaθA))WW
= (φAθA + θA′φ
A′
)ηBφBηB′φ
B′
= −1
2(υφBηB′ −υφB′ηB)φBφ
B′
.
Also put θαθβθγ = ǫαβγδΣδ, so Σα = −1
6ǫαβγδθβθγθδ. We have:
ΣA = −1
2ǫABǫC′D′θBθC′θD′ = 1
2φAθC′θC′,
ΣA′ = −1
2ǫA′B′ǫCDθB′θCθD = −1
2θA′θCθC
= −1
2θA′(φC + 2ixD′",N/A,N/A
"2θA′θCθC
= −1
2θA′(φC + 2ixD′
C θD′)φC = −1
2θA′φCφC −i
2xaφAθC′θC′
= −1
2θA′φCφC −ixaΣA,
W
αΣα = ηA′ΣA′ + ixaηA′ΣA = −1
2ηA′θA′φCφC = 1
2υφCφC,
W
αW
βΣαθβ = 1
2υηB′φ
B′
φCφC.
Expanding out Ψ, we get:
Ψ = −1
2υηB′φ
B′
φBφB −1
2υηBφBφB′φ
B′
+ c.c.
= W
αW
βθαΣβ + θαθαWW + WαWβθαΣ
β.
So now we have a concrete expresssion for the three-form ω3:
ω3 = UZWWudsββ
= (W
αW
βθαΣβ + θαθαWW + WαWβθαΣ
β)iu2dsββ
= i(W
αW
βθαΣβ + θαθαWW + WαWβθαΣ
β)dsπC′πCdπC′dπC.
46",N/A,N/A
"αW
βθαΣβ + θαθαWW + WαWβθαΣ
β)dsπC′πCdπC′dπC.
46
Let f(Z) be a given twistor function of degree minus four: f(tZ) = t−4f(Z),
for any real non-zero real number t. The invariant Ξ-transform of f(Z) is by
deﬁnition:
Ξ(f, θ, W) =
Z
Z incident with W
f(Z)ω3.
Here Wα is any non-zero null twistor and f(Z) is deﬁned on N′. The integral is
taken over a three-sphere and always converges, with the result varying smoothly
with W. Comparing with our original deﬁnition of the transform Ξ(f), we ﬁnd",N/A,N/A
"that we have proved the fundamental fact:
• Ξ(f, θ, W) = ΨΞ(f) = (W
αW
βθαΣβ + WαW
βθγθγθαθβ + WαWβθαΣ
β)Ξ(f).
Note that since the left-hand side of this equation is plainly invariant under the
scaling Wα →tWα, where t is any real non-zero number, so we see immediately
that Ξ(f) must be of degree minus two in Wα, which was previously established
by direct calculation.
47
20
The reduction of the invariant Ξ-transform to the
SU(2, C) transform
We consider the invariant Ξ-transform:
Ξ(f)(W, θ) =
Z",N/A,N/A
"Ξ(f)(W, θ) =
Z
Z incident with W
f(Z)Z.θ(dZ.θ)3.
Here θ is a vector-valued Grassman variable. We represent Z by the quaternion
pair (C, D) and W by the quaternion pair (A, B), such that the incidence condition
of Z with W reads (C, D) = (At, tB), for some quaternion t, where |C| = |D| ̸=
0 and |A| = |B| ̸= 0. Also f(Z) is homogeneous of degree minus four, so
the integral is both projectively invariant and invariant under the non-zero real",N/A,N/A
"scalings of W, so we may assume without loss of generality that |A|2 = |B|2 =
|C|2 = |D|2 = |t|2 = 1. Write θ = (α, β), where α and β are quaternion-
valued Grassman variables, such that Z.θ = αC + Dβ + Cα + βD and dZ.θ =
−αdC + dDβ + dCα −βdD. Substituting for Z in terms of W, we have:
Z.θ = αAt + tBβ + tAα + βBt,
dZ.θ = −αAdt + dtBβ + dtAα −βBdt.
Next write α = Aγ and β = δB, where γ = Aα and δ = βB are Grassman
variables.
Then we have:
Z.θ = γt + tδ + tγ + δt,
dZ.θ = −γdt + dtδ + dtγ −δdt.",N/A,N/A
"dZ.θ = −γdt + dtδ + dtγ −δdt.
Using R4 indices, we may write:
Z.θ = ǫata,
dZ.θ = −ǫbdtb,
ǫa = 2(γa + δa).
We then have:
Z.θ(dZ.θ)3 = ǫaǫbǫcǫdtadtbdtcdtd
= 1
6ΩW(θ)ǫabcdtadtbdtcdtd,
ΩW(θ) = 1
4ǫabcdǫaǫbǫcǫd.
48
So after factoring out the form ΩW(θ), and writing p for t, g for A and h for B,
the transformation becomes just:
Ξ(f)(g, h) =
Z
G
f(gp, ph)ωp.
This exactly agrees with our original Ξ-transform on the Lie group SU(2, C) ×",N/A,N/A
"SU(2, C, completing the demonstration that all three transformations are equiva-
lent.
Note that written invariantly, without the use of the Grassman variable θ, we have
the following expression for the transform:
Ξ(f)(W)σabcd
αβ W αW β =
Z
Z incident with W
f(Z)Z[adZbdZcdZd].
Here, as in the last section, the quantity σabcd
αβ
gives a natural isomorphism from
trace-free symmetric tensors Xαβ in eight dimensions to real self-dual four forms",N/A,N/A
"Xabcd in eight dimensions, each space being thirty-ﬁve dimensional.
49
References
[1] George Sparling, Esquisse d’une Synth`ese, gr-qc/0610069, 19 pages, sub-
mitted October 2006.
[2] George Sparling, Philip Tillman, A primordial theory, cond-mat/0401015,
55 pages, submitted October 2006.
[3] Jonathan Bain,
Condensed Matter Physics and the Nature of Space-time,
Polytechnic University, New York, preprint September 2006.
[4] Roger Penrose, The road to reality: a complete guide to the laws of the",N/A,N/A
"universe, Alfred A. Knopf, New York, 2005.
[5] Dana Mihai, George Sparling and Philip Tillman, Non-Commutative Time,
the Quantum Hall Effect and Twistor Theory, cond-mat/0401224, 14 pages,
2004.
[6] George Sparling,
Twistor theory and the four-dimensional Quantum Hall
Effect of Zhang and Hu, cond-mat/0211679, 31 pages, 2002.
[7] Shou-Cheng Zhang, To see a world in a grain of sand, hep-th/0210162, 14
pages, 2002.
[8] George Sparling,
The twistor theory of hypersurfaces in space-time,
in",N/A,N/A
"in
Further Advances in Twistor Theory, Volume III, editors Lionel Mason, Lane
Hughston, Piotr Kobak and Klaus Pulverer, London: Pitman Press, 2001.
[9] Shou-Cheng Zhang and Jiangping Hu, A Four-Dimensional Generalization
of the Quantum Hall Effect, Science, 294(5543), 823-828, 2001.
[10] George
Sparling,
Zitterbewegung,
S´eminaires
et
Congr`es,
Societ´e
Math´ematique de France, 4, 275-303, 2000.
[11] Devendra Kapadia and George Sparling, A class of conformally Einstein",N/A,N/A
"metrics, Classical and Quantum Gravity, 24, 4765-4776, 2000.
[12] Lane Hughston, Applications of the Geometry of SO(8) Spinors to Laplace’s
Equation in Six Dimensions, in Further Advances in Twistor Theory, Vol-
ume I, Research Notes in Mathematics 231, Longman, 1990.
50
[13] Roger Penrose and Wolfgang Rindler, Spinors and Space-Time. Volume 2:
Spinor and Twistor Methods in Space-Time Geometry, Cambridge: Cam-
bridge University Press, 1986.",N/A,N/A
"bridge University Press, 1986.
[14] Roger Penrose and Malcolm MacCallum, Twistor Theory: an approach to
the quantization of ﬁelds and space-time, Physics Reports, Physics Letters
C, 6, 241-315, 1970.
[15] Roger Penrose,
Twistor Algebra, Journal of Mathematical Physics, 8-2,
345-366, 1967.
[16] John Baez, The Octonions, Bulletin of the American Mathematical Society,
39, 145-205, 2002.
[17] Elie Cartan, Le principe de dualit´e et la th´eorie des groupes simple et semi-",N/A,N/A
"simples, Bulletin de Science Math´ematique, 49, 361-374, 1925.
[18] C. Robin Graham, Ralph Jenne, Lionel Mason and George Sparling, Con-
formally invariant powers of the Laplacian, Journal of the London Mathe-
matical Society, 46(3), 557-565, 1992.
51",N/A,N/A
"arXiv:1310.1984v2  [math.CA]  10 Mar 2014
Multiple basic hypergeometric transformation
formulas arising from the balanced duality
transformation
Yasushi KAJIHARA
Abstract
Some multiple hypergeometric transformation formulas arising from the balanced du-
ality transformation formula are discussed through the symmetry. Derivations of some
transformation formulas with diﬀerent dimensions are given by taking certain limits of",N/A,N/A
"the balanced duality transformation. By combining some of them, some transformation
formulas for An basic hypergeometric series is given. They include some generalizations of
Watson, Sears and 8W7 transformations.
Keywords: basic hypergeometric series, multivariate basic hypergeometric series
1
Introduction
This paper can be considered as a continuation of our paper [13]. Namely, we discuss some
multiple hypergeometric transformation formulas arising from the balanced duality transfor-",N/A,N/A
"mation formula through the symmetry in this paper. We obtain some transformation formulas
with diﬀerent dimensions by taking certain limits of the balanced duality transformation. By
combining some of them, we give some transformation formulas for An basic hypergeometric
series. They include some generalizations of Watson, Sears and nonterminating and terminating
8W7 transformations.
The hypergeometric series r+1Fr is deﬁned by
r+1Fr

a0,
a1,
a2,
· · · ,
ar
b1,
b2,
· · · ,
br ; z

:=
X
k∈N",N/A,N/A
"a2,
· · · ,
ar
b1,
b2,
· · · ,
br ; z

:=
X
k∈N
[a0, a1, · · · , ar]k
k! [b1, · · · , br]k
zk,
(1.1)
where [c]k = c(c + 1) · · · (c + k −1) is Pochhammer symbol and [d1, · · · , dr]k = [d1]k · · · [dr]k.
The very well-poised hypergeometric series have nice properties such as the existence of
various kinds of summation and transformation formulas which contains more parameters than
other hypergeometric series and they have reciprocal structure (For precise see an excellent",N/A,N/A
"exposition by G.E. Andrews [1]).
In [2], W.N.Bailey derived the following transformation
formula for terminating balanced and very well-poised 9F8 series which is nowadays called the
Bailey transformation formula:
9F8

a,
a/2 + 1,
b,
c,
d,
a/2,
1 + a −b,
1 + a −c,
1 + a −d,
(1.2)
e,
f,
g,
−N
1 + a −e,
1 + a −f,
1 + a −g,
1 + a + N ; 1

=
[1 + a, 1 + λ −e, 1 + λ −f, 1 + λ −g]N
[1 + λ, 1 + a −e, 1 + a −f, 1 + a −g]N
×
9F8
 λ,
λ/2 + 1,
λ + b −a,
λ + c −a,
λ + d −a,
λ/2,
1 + a −b,
1 + a −c,",N/A,N/A
"λ + c −a,
λ + d −a,
λ/2,
1 + a −b,
1 + a −c,
1 + a −d,
1
e,
f,
g,
−N
1 + λ −e,
1 + λ −f,
1 + λ −g,
1 + λ + N ; 1

,
where λ = 1 + 2a −b −c −d, and the parameters are subject to the restriction (called as
balancing condition) that
2 + 3a = b + c + d + e + f + g −N.
(1.3)
Among various hypergeometric transformation formulas, the Bailey transformation itself
(1.2) and its special and limiting cases, including their basic and elliptic analogues, have many",N/A,N/A
"signiﬁcant applications in various branches of mathematics and mathematical physics.
On the other hand, Holman, Biedenharn and Louck [9], [10] introduced a class of multi-
ple generalization of hypergeometric series in need of the explicit expressions of the Clebsch-
Gordan coeﬃcients of the tensor product of certain irreducible representations of the Lie group
SU(n + 1). In the series of papers, S.Milne [19] introduced its basic analogue and investigated",N/A,N/A
"further. In the course of works (see the expository paper by Milne [22] and references therein),
he and his collaborators succeeded to obtain some multiple hypergeometric transformation and
summation formulas by using a certain rational function identity which is nowadays referred as
Milne‘s fundamental lemma. After that, many methods of the derivation of multiple hyperge-
ometric identities have been worked out such as ingenious uses of certain matrix techniques by",N/A,N/A
"Krattenthaler, Schlosser, Milne, Lilly and Newcomb, see [4], [21], [23], [24].
In the previous work [13], we derived a certain generalization of the Euler transformation
formula for multiple (basic) hypergeometric series with diﬀerent dimensions by using the tech-
niques in the theory of Macdonald polynomials and Macdonald‘s q-diﬀerence operators. By
interpreting our multiple Euler transformation formula as the generating series, we further",N/A,N/A
"obtained several types of multiple hypergeometric summations and transformations.
Among these, we consider the (balanced) duality transformation formula (2.12) which gen-
eralize the following 9F8 transformation (see Bailey‘s book [3]):
9F8
 a,
a/2 + 1,
b,
c,
d,
a/2,
1 + a −b,
1 + a −c,
1 + a −d,
(1.4)
e,
f,
g,
−N
1 + a −e,
1 + a −f,
1 + a −g,
1 + a + N ; 1

=
[1 + a, 1 + a −b −c, 1 + a −b −d, 1 + a −b −e, 1 + a −b −f, g]N
[1 + a −b, 1 + a −c, 1 + a −d, 1 + a −e, 1 + a −f, g −b]N
×
9F8
",N/A,N/A
"×
9F8

b −g −N,
(b −g −N)/2 + 1,
b,
1 + a −c −g,
1 + a −d −g,
(b −g −N)/2,
1 −g −N,
b + c −a −N,
b + d −a −N,
1 + a −e −g,
1 + a −f −g,
b −a −N,
−N
b + e −a −N,
b + f −a −N,
1 + a −g,
1 + b −g ; 1

,
with the balancing condition (1.3), as the formula of particular importance. (1.4) is diﬀerent
from (1.2), but (1.4) can be obtained by duplicating (1.2). In the joint work with M.Noumi [15],
we derived an analogous formula ((3.17) of [15]) for elliptic hypergeometric series introduced",N/A,N/A
"by Frenkel and Turaev [5] by starting from the Frobenius determinant and proposed the notion
of (balanced) duality transformation there.
In this paper, we present an alternative approach by starting from the balanced duality
transformation formula for multiple hypergeometric series of type A. In Section 3, we present
some transformation formula for basic hypergeometric series of type A with diﬀerent dimension.",N/A,N/A
"They include most of results in our previous work [13]. What is remarkable is that from the
balanced duality transformation formula, one can obtain multiple Euler transformation formula
itself.
By iterating twice a special case of our Sears transformation formula (see section 7 in [13]),
we veriﬁed an An Sears transformation formula in [12]. Later by the same idea as above, we
obtained in [15] two types of An Bailey transformation formulas: one of which is previously
2",N/A,N/A
"2
known by Milne and Newcomb [24] in basic case and Rosengren [27] in elliptic case and another
has appeared to be new in both cases. In Section 4, we further employ this idea to obtain several
An basic hypergeometric transformations which generalize Watson, Sears and nonterminating
8W7 transformations. They includes known ones due to Milne and his collaborators. We will
see here that our class of multiple hypergeometric transformations shed a light to the structure",N/A,N/A
"of some An hypergeometric transformation formulas.
2
Preliminaries
In this section, we give some notations for multiple basic hypergeometric series and present the
balanced duality transformation formula. We basically refer the notations of q-series and basic
hypergeometric series from the book by Gasper and Rahman [7]. Throughout of this paper,
we assume that q is a complex number under the condition 0 < |q| < 1. We deﬁne q−shifted
factorial as
(a)∞:= (a; q)∞=
Y
n∈N
(1 −aqn),
(a)k := (a; q)k =",N/A,N/A
"(a)∞:= (a; q)∞=
Y
n∈N
(1 −aqn),
(a)k := (a; q)k =
(a)∞
(aqk)∞
for k ∈C.
(2.1)
where, unless stated otherwise, we omit the basis q. In this paper we employ the notation as
(a1)k · (a2)k · · · (an)k = (a1, a2, · · · , an)k.
(2.2)
The basic hypergeometric series r+1φr is deﬁned by
r+1φr

a1, a2, . . . ar+1
c1, . . . cr
; q; u

= r+1φr

a0, {ai}r
{ci}r
; q; u

(2.3)
:=
X
k∈N
(a0, a1, . . . , ar+1)k
(c1, . . . , cr, q)k
uk",N/A,N/A
"(a0, a1, . . . , ar+1)k
(c1, . . . , cr, q)k
uk
with r+1 numerator parameters a0, a1, · · · , ar+1 and r denominator parameters c1, · · · , cr. We
call r+1φr series k-balanced if qka1a2 · · · ar+1 = c1 · · · cr and u = q: a 1-balanced series is called
balanced (or Saalsch¨utzian). An r+1φr series is called well-poised if a0q = a1c1 = · · · = arcr.
In addition, if a1 = q√a0 and a2 = −q√a0, then the r+1φr is called very well-poised. We",N/A,N/A
"denote the very well-poised basic hypergeometric series r+3φr+2 as r+3Wr+2 series deﬁned by
the following:
r+3Wr+2 [s; {ai}r; q; u] := r+3φr+2

s,
q√s,
−q√s,
{ai}r
√s,
−√s,
{sq/ai}r; q; u

(2.4)
=
X
k∈N
1 −sq2k
1 −s
(s, a1 · · · , ar)k
(q, sq/a1, · · · , sq/ar)k
uk.
Furthermore, all of the very well-poised basic hypergeometric series r+3Wr+2 in this paper, the
parameters s, a1, · · · ar and the argument satisfy the very-well-poised-balancing condition
a1 · · · aru =

±(sq)
1
2
r−1
(2.5)",N/A,N/A
"a1 · · · aru =

±(sq)
1
2
r−1
(2.5)
with either the plus and minus sign. We call a r+3Wr+2 series very-well-poised-balanced if (2.5)
holds. Note that a very-well-poised-balanced r+3Wr+2 series is (1-)balanced if
a1 · · · ar = s
r−1
2 q
r−3
2
(2.6)
and u = q.
3
Now, we note the conventions for naming series as An basic hypergeometric series (or basic
hypergeometric series in SU(n + 1)). Let γ = (γ1, · · · , γn) ∈Nn be a multi-index. We denote
∆(x) :=
Y
1≤i<j≤n
(xi −xj)
and
∆(xqγ) :=
Y
1≤i<j≤n",N/A,N/A
"Y
1≤i<j≤n
(xi −xj)
and
∆(xqγ) :=
Y
1≤i<j≤n
(xiqγi −xjqγj),
(2.7)
as the Vandermonde determinant for the sets of variables x = (x1, · · · , xn) and xqγ = (x1qγ1, · · · , xnqγn)
respectively. In this paper we refer multiple series of the form
X
γ∈Nn
∆(xqγ)
∆(x)
H(γ)
(2.8)
which reduce to basic hypergeometric series r+1φr for a nonnegative integer r when n = 1 and
symmetric with respect to the subscript 1 ≤i ≤n as An basic hypergeometric series. We call",N/A,N/A
"such a series balanced if it reduces to a balanced series when n = 1. Very well-poised and so on
are deﬁned similarly. The subscript n in the label An attached to the series is the dimension of
the multiple series (2.8).
In our previous work [13], we derived a hypergeometric transformation formula for multiple
basic hypergeometric series of type A generalizing the following transformation for terminating
balanced 10W9 series in the one dimensional case:
10W9
a; b, c, d, e, f, µfqN, q−N; q; q
",N/A,N/A
"10W9
a; b, c, d, e, f, µfqN, q−N; q; q

= (µbf/a, µcf/a, µdf/a, µef/a, aq, f)N
(aq/b, aq/c, aq/d, aq/e, µq, µf/a)N
(2.9)
×10W9
µ; aq/bf, aq/cf, aq/df, aq/ef, µf/a, µfqN, q−N; q; q

,
where µ = a3q2/bcdef 2. Note that (2.9) is a basic analogue of (1.4). The transformation (2.9)
can be obtained by iterating the Bailey transformation formula for 10W9 series
10W9

a; b, c, d, e, f, λaqN+1/ef, q−N; q; q

= (aq, aq/ef, λq/e, λq/f)N
(aq/e, aq/f, λq, λq/ef)N
(2.10)
×10W9
",N/A,N/A
"(aq/e, aq/f, λq, λq/ef)N
(2.10)
×10W9

λ; λb/a, λc/a, λd/a, e, f, λaqN+1/ef, q−N; q; q

(λ = a2q/bcd),
twice. Note also that (2.10) is a basic analogue of (1.2).
To simplify the expressions for multiple very well-poised series, we introduce the notation
of W n,m series as the following:
W n,m

{ai}n
{xi}n
 s; {uk}m; {vk}m; q; z

(2.11)
:=
X
γ∈Nn
z|γ|
Y
1≤i<j≤n
∆(xqγ)
∆(x)
Y
1≤i≤n
1 −sq|γ|+γixi
1 −sxi
×
Y
1≤j≤n
(sxj)|γ|
((sq/aj)xj)|γ|

Y
1≤i≤n
(ajxi/xj)γi
(qxi/xj)γi


×
Y
1≤k≤m",N/A,N/A
"
Y
1≤i≤n
(ajxi/xj)γi
(qxi/xj)γi


×
Y
1≤k≤m
(vk)|γ|
(sq/uk)|γ|

Y
1≤i≤n
(ukxi)γi
((sq/vk)xi)γi

,
where |γ| = γ1 + · · · + γn is the length of a multi-index γ.
The very starting point of all the discussions of the present paper is the balanced duality
transformation formula (Corollary 6.3 of [13] with a diﬀerent notation) between the W n,m+2
series (An 2m+8W2m+7 series) and W m,n+2 series (Am 2n+8W2n+7 series):
W n,m+2

{bi}n
{xi}n
 a; {ckyk}m, d, e; {fy−1
k }m, µfqN, q−N; q; q
",N/A,N/A
"k }m, µfqN, q−N; q; q

(2.12)
4
= (µdf/a, µef/a)N
(aq/d, aq/e)N
Y
1≤k≤m
((µckf/a)yk, fy−1
k )N
(µqyk, (aq/ck)y−1
k )N
Y
1≤i≤n
(aqxi, (µbif/a)x−1
i )N
((aq/bi)xi, (µf/a)x−1
i )N
×W m,n+2

{aq/ckf}m
{yk}m
 µ; {(aq/bif)xi}n, aq/df, aq/ef;
{(µf/a)x−1
i }n, µfqN, q−N; q; q

,
where µ = am+2qm+1/BCdef m+1. Here we denote B = b1 · · · bn and C = c1 · · · cm. In this
paper, we frequently use such notations.
In the case when m = 1 and y1 = 1, (2.12) reduces to
W n,3

{bi}n
{xi}n",N/A,N/A
"W n,3

{bi}n
{xi}n
 a; c, d, e; f, µfqN, q−N; q; q

(2.13)
= (µcf/a, µdf/a, µef/a, f)N
(aq/c, aq/d, aq/e, µq)N
Y
1≤i≤n
(aqxi, (µbif/a)x−1
i )N
((aq/bi)xi, (µf/a)x−1
i )N
×2n+8W2n+7 [µ; {(aq/bif)xi}n, aq/cf, aq/df, aq/ef,
{(µf/a)xn/xi}n, µfqN, q−N; q; q

,
(µ = a3q2/Bcdef 2).
Note that m = n = 1 and x1 = y1 = 1 case of the balanced duality transformation formula
(2.12) is terminating balanced 10W9 transformation (2.9).",N/A,N/A
"In [13], (2.12) was obtained by taking the coeﬃcients of uN in both sides of ”0-balanced”
case of the multiple Euler transformation formula for multiple basic hypergeometric series of
type A with diﬀerent dimensions (Theorem 1.1 of [13])
X
γ∈Nn
u|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(bkxiyk)γi
(cxiyk)γi
(2.14)
= (ABu/cm)∞
(u)∞
X
δ∈Nm
ABu
cm
|δ| ∆(yqδ)
∆(y)
×
Y
1≤k,l≤m
((c/bl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
.",N/A,N/A
"Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
.
From this point of view, we can state the balanced duality transformation (2.12) in more general
form: (Proposition 6.2 in [13])
X
γ∈Nn,|γ|=N
∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(bkxiyk)γi
(cxiyk)γi
(2.15)
=
X
δ∈Nm,|δ|=N
∆(yqδ)
∆(y)
Y
1≤k,l≤m
((c/bl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
,
when AB = cm.
The balanced duality transformation formula (2.12) corresponds to the case when m, n ≥2",N/A,N/A
"of (2.15) by a rearrangement of parameters in the multiple basic hypergeometric series. Note
that, in the case when m = n = 1, (2.15) becomes tautological. We shall also remark that
the remaining case (m = 1, n ≥2) corresponds to the An Jackson summation formula for
terminating balanced W n,2 series
W n,2

{bi}n
{xi}n
 a; c, e; d, q−N; q; q

(2.16)
= (aq/Bc, aq/cd)N
(aq/Bcd, aq/c)N
Y
1≤i≤n
((aq/bid)xi, aqxi)N
((aq/bi)xi, (aq/d)xi)N
5",N/A,N/A
"((aq/bid)xi, aqxi)N
((aq/bi)xi, (aq/d)xi)N
5
provided a2qN+1 = Bcde, which is originally due to S.Milne [20] in a diﬀerent notation. For
these facts, the informed readers might see [13] for ordinary and basic case and Noumi and the
author [15] for elliptic case.
Remark 2.1. In the case when n = 1 and x1 = 1, (2.16) reduces to the Jackson summation
formula for terminating balanced 8W7 series:
8W7[a; b, c, d, e, q−N; q; q]
=
(aq, aq/bc, aq/bd, aq/cd)N
(aq/bcd, aq/b, aq/c, aq/d)N
,",N/A,N/A
"(aq/bcd, aq/b, aq/c, aq/d)N
,
(a2qN+1 = bcde).
(2.17)
We also mention that (2.16) can be obtained by letting aq = ef in (2.13) and by relabeling the
parameters.
3
Limit cases
In this section, we shall show that several transformation formulas with diﬀerent dimension can
be obtained from the balanced duality transformation formula (2.12) by taking certain limits.
We see that most of principal transformation formulas in [13] which have been obtained by",N/A,N/A
"taking a certain coeﬃcient in the multiple Euler transformation formula (2.14) can be recovered
and we ﬁnd some new transformation formulas. Furthermore we show that (2.14) itself can be
acquired in this manner.
In addition, we shall write down the cases when the dimension of summand in each side
of the transformation is one with particular attention. We consider them as particularly sig-
niﬁcant ones since they have an extra symmetry. We will explore some An hypergeometric",N/A,N/A
"transformations by using some of them in the next section.
3.1
(Non-balanced) Duality transformation formula and its inverse
(Non-balanced) Duality transformation formula
Proposition 3.1.
W n,m+1

{bi}n
{xi}n
 a; c, {dkyk}m; q−N, {ey−1
k }m; q; am+1qN+m+1
BcDem

(3.1)
= (am+1qm+1/BcDem)N
(aq/c)N
Y
1≤i≤n
(aqxi)N
((aq/bi)xi)N
Y
1≤k≤m
(ey−1
k )N
((aq/di)y−1
k )N
×
X
δ∈Nm
q|γ| ∆(yqδ)
∆(y)
(q−N)|γ|
(am+1qm+1/BcDem)|γ|
Y
1≤k,l≤m
((aq/dle)yk/yl)δk
(qyk/yl)δk
×
Y
1≤i≤n,1≤k≤m
((aq/bie)xiyk)δk",N/A,N/A
"(qyk/yl)δk
×
Y
1≤i≤n,1≤k≤m
((aq/bie)xiyk)δk
((aq/e)xiyk)δk
Y
1≤k≤m
((aq/ce)yk)δk
(q1−Ne−1yk)δk
,
where B = b1 · · · bm and D = d1 · · · dn.
Proof. Take the limit e →∞in (2.12). By rearranging the parameter as f →e, we arrive at
the desired identity.
Remark 3.1. The transformation formula (3.1) has already appeared in Section 6.1 of our
previous work [13] with a diﬀerent notation. Later Rosengren has also obtained in [26] by using",N/A,N/A
"his reduction formula of Karlsson-Minton type. In contract to that we see here, as is mentioned
in [26], the balanced duality transformation formula (2.12) can also be considered as a special
case of (3.1). Indeed, in [13] though we have started the derivation of (3.1) from the multiple
Euler transformation (2.14) in general case, (2.12) has been obtained from the ”zero”-balanced
case of (2.14).
6
In the case when m = n = 1 and x1 = y1 = 1, (3.1) reduces to
8W7

a; b, c, d, e, q−N; q; a2qN+2",N/A,N/A
"8W7

a; b, c, d, e, q−N; q; a2qN+2
bcde

(3.2)
= (a2q2/bcde, e, aq)N
(aq/b, aq/c, aq/d)N
4φ3

q−N, aq/be, aq/ce, aq/de
q1−N/e, a2q2/bcde, aq/e; q; q

.
In [13], (3.1) is referred as Watson type transformation formula. But, hereafter we shall
propose to call (3.1) (non balanced) duality transformation formula.
In the case when m = 1 and y1, (3.1) reduces to
W n,2

{bi}n
{xi}n
 a; c, d; q−N, e; q; a2qN+2
Bcde

= (a2q2/Bcde, e)N
(aq/c, aq/d)N
Y
1≤i≤n
(aqxi)N
((aq/bi)xi)N
×n+3φn+2
",N/A,N/A
"Y
1≤i≤n
(aqxi)N
((aq/bi)xi)N
×n+3φn+2

q−N, {(aq/bie)xi}n, aq/ce, aq/de
q1−N/e, {(aq/e)xi}n, a2q2/Bcde,; q; q

.
(3.3)
In the case of n = 1 and x1 = 1, (3.1) reduces to
2m+6W2m+5

a; b, {ckyk}m, d, {ey−1
k }m, q−N; q; am+1qN+m+1
bCdem

(3.4)
= (am+1qm+1/bCdem, aq)N
(aq/b, aq/d)N
Y
1≤k≤m
(ey−1
k )N
((aq/ck)y−1
k )N
×
X
δ∈Nm
q|δ| ∆(yqδ)
∆(y)
Y
1≤k,l≤m
((aq/cle)yk/yl)δk
(qyk/yl)δk
×
(q−N)|δ|
(am+1qm+1/bCdem)|δ|
Y
1≤k≤m
((aq/be)yk, (aq/de)yk)δk
((aq/e)yk, (q1−N/e)yk)δk
.",N/A,N/A
"((aq/e)yk, (q1−N/e)yk)δk
.
Further, by letting aq = de in (3.3), we obtain Milne‘s An generalization of Rogers‘ summa-
tion formula for terminating very well-poised 6W5 series:
W n,1

{bi}n
{xi}n
 a; c; q−N; q; aqN+1
Bc

=
(aq/Bc)N
(aq/c)N
Y
1≤i≤n
(aqxi)N
((aq/bi)xi)N
.
(3.5)
Remark 3.2. In the case when n = 1 and x1 = 1, (3.5) reduces to the Rogers‘ summation
formula ( (2.4.2) in [7] ):
6W5

a; b, c, q−N; q; aqN+1
bc

=
(aq, aq/bc)N
(aq/b, aq/c)N
.
(3.6)",N/A,N/A
"bc

=
(aq, aq/bc)N
(aq/b, aq/c)N
.
(3.6)
The inverse of the duality transformation
Proposition 3.2.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(bkxiyk)γi
(exiyk)γi
(3.7)
×(q−N)|γ|
(d)|γ|
Y
1≤i≤n
(cxi)γi
((ABcq1−N/dem)xi)γi
= (dem/AB)N
(d)N
Y
1≤k≤m
((dembk/ABc)yk)N
((dem+1/ABc)yk)N
Y
1≤i≤n
((demai/ABc)x−1
i
)N
((dem/ABc)x−1
i
)N
7
×W m,n+1

{e/bk}m
{yk}m
 dem+1q−1/ABc; e/c, {(e/ai)xi}n;
q−N, {(dem/ABc)x−1
i
}n; q; dqN
.",N/A,N/A
"q−N, {(dem/ABc)x−1
i
}n; q; dqN
.
Proof. Substitute the parameters e and f as aq/e and aq/f respectively in (2.12). Then take
the limit a →∞. Finally, by rearranging the parameters as bi →ai (1 ≤i ≤n), ck →bk (1 ≤
k ≤m), d →c, e →d, f →e, we have the desired result.
In the case when m = 1 and y1 = 1, (3.7) reduces to
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi, cxi)γi
(exi, (Abcq1−N/de)xi)γi
(3.8)
×(q−N)|γ|
(d)|γ|
= (de/Ac, de/Ab)N
(de2/Abc, d)N
Y
1≤i≤n
((deai/Abc)x−1",N/A,N/A
"(de2/Abc, d)N
Y
1≤i≤n
((deai/Abc)x−1
i
)N
((de/Abc)x−1
i
)N
× 2n+6W2n+5

de2q−1/Abc; {(e/ai)xi}n, {(deq−1/Abc)x−1
i
}n, e/b, e/c, q−N; q; dqN
.
In the case when n = 1 and x1 = 1, (3.7) reduces to
m+3φm+2

q−N, a, {bkyk}m, c
d, {eyk}m, aBcq1−N/dem; q; q

(3.9)
= (dem/aB, dem/Bc)N
(d, dem/aBc)N
Y
1≤k≤m
((dembk/aBc)yk)N
((dem+1/aBc)yk)N
×W m,2

{e/bk}m
{yk}m
 dem+1q−1/aBc; e/c, e/a; q−N, dem/ABc; q; dqN

.",N/A,N/A
"
.
Remark 3.3. The reason why we call (3.7) as the inverse of the (non-balanced) duality transfor-
mation (3.1) is that the transformations which one obtain by applying (3.1) and (3.7) in both
order turn out to be identical as a (multiple) hypergeometric series. Note also that (3.7) can be
obtained by relabeling parameters in (3.1) appropriately. However, we will use special cases of
these transformations to establish an An generalization of basic hypergeometric transformation",N/A,N/A
"formulas in the next section.
In the case when m = n = 1, (3.7) reduces to
4φ3

q−N, a, b, c
d, e, abcq1−N/de; q; q

= (de/bc, de/ac, de/ab)N
(de2/abc, de/abc, d)N
(3.10)
×8W7

de2q−1/abc; e/a, deq−1/abc, e/b, e/c, q−N; q; dqN
.
We also mention that by letting e = c in (3.8) and then rearranging the parameter d as
Abq1−N/c, we recover an An generalization of Pfaﬀ-Saalsch¨utz summation formula for termi-
nating balanced 3φ2 series due to Milne (Theorem 4.15 in [21])
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y",N/A,N/A
"X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi)γi
(cxi)γi
(3.11)
×
(q−N)|γ|
(Abq1−N/c)|γ|
= (c/b)N
(c/Ab)N
Y
1≤i≤n
((c/ai)xi)N
(cxi)N
.
Remark 3.4. In the case when n = 1, (3.11) reduces to Jackson‘s Pfaﬀ-Saalsch¨utz summation
formula for terminating balanced 3φ2 series (the formula (1.7.2) in [7])
3φ2
 a, b, q−N
c, abq1−N/c; q; q

= (c/a, c/b)N
(c, c/ab)N
.
(3.12)
8
Remark 3.5. Similarly to the expression (2.15) for the balanced duality transformation formula",N/A,N/A
"(2.12), (3.7) can be stated in more general form:
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(bkxiyk)γi
(cxiyk)γi
(3.13)
×
(q−N)|γ|
(ABq1−N/cm)|γ|
=
(q)N
(cm/AB)N
X
δ∈Nm, |δ|=N
∆(yqδ)
∆(y)
×
Y
1≤k,l≤m
((c/bl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
.
Note that (3.13) can be obtained by taking the coeﬃcient of uN in the multiple basic Euler
transformation formula (2.14). We remark that (3.7) corresponds to the m ≥2 case of (3.13) by",N/A,N/A
"rearrangement of parameters and in the case when m = 1, (3.13) reduces to An Pfaﬀ-Saalsch¨utz
summation formula (3.11).
3.2
4φ3 transformation formulas of type A
Sears transformation of type A
Proposition 3.3.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(ckxiyk)γi
(dxiyk)γi
(3.14)
×
(q−N, a)|γ|
(e, aBCq1−N/dme)|γ|
= (e/a, dme/BC)N
(e, dme/aBC)N
X
δ∈Nm
q|δ| ∆(yqδ)
∆(y)
×
(q−N, a)|δ|
(q1−Na/e, dme/BC)|δ|
Y
1≤k,l≤m
((d/cl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((d/bi)xiyk)δk",N/A,N/A
"(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((d/bi)xiyk)δk
(dxiyk)δk
.
Proof. Replace the parameters in (2.12) d, e and f with aq/d, aq/e and aq/f respectively. Then
put a = 0. Then rearranging parameters f →d and def mqN−1/BC →a leads to the desired
identity.
In the case when m = 1 and y1 = 1, (3.14) reduces to
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
(q−N, a)|γ|
(e, aBcq1−N/de)|γ|
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(3.15)
= (e/a, de/Bc)N
(e, de/aBc)N
n+3φn+2
q−N, a, {(d/bi)xi}n, d/c",N/A,N/A
"(e, de/aBc)N
n+3φn+2
q−N, a, {(d/bi)xi}n, d/c
q1−Na/e, {dxi}n, de/Bc; q, q

.
Remark 3.6. The multiple Sears transformation formula (3.14) was originally established in [13]
(the formula (7.1) in [13]). In the case when m = n = 1 and x1 = y1 = 1, (3.14) reduces to the
Sears transformation formula for terminating balanced 4φ3 series:
4φ3

q−N, a, b, c
d, e, abcq1−N/de; q, q

=
(e/a, de/bc)N
(e, de/abc)N
4φ3

q−N, a, d/b, d/c
d, aq1−N/e, de/bc; q, q

.
(3.16)",N/A,N/A
"d, aq1−N/e, de/bc; q, q

.
(3.16)
Further informations for multiple Sears transformation (3.14) can also be found in [12].
We shall add a few remarks that we have missed in our previous works in [13] and [12].
Let N tend to inﬁnity in (3.14), we get the following transformation formula for multiple
nonterminating 3φ2 series of type A:
9
Corollary 3.1.
X
γ∈Nn
 dme
aBC
|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(ckxiyk)γi
(dxiyk)γi
(3.17)
× (a)|γ|
(e)|γ|
= (e/a, dme/BC)∞",N/A,N/A
"(dxiyk)γi
(3.17)
× (a)|γ|
(e)|γ|
= (e/a, dme/BC)∞
(e, dme/aBC)∞
X
δ∈Nm
e
a
|δ| ∆(yqδ)
∆(y)
×
(a)|δ|
(dme/BC)|δ|
Y
1≤k,l≤m
((d/cl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((d/bi)xiyk)δk
(dxiyk)δk
holds if it satisfy the convergence condition max(|dme/aBC|, |e/a|) < 1.
Remark 3.7. (3.17) was already established as the equation (3.2) in [12]. In the case when
m = n = 1 and x1 = y1 = 1, (3.17) reduces to the following nonterminating 3φ2 transformation
formula
3φ2
a, b, c
d, e ; q, de
abc

=",N/A,N/A
"formula
3φ2
a, b, c
d, e ; q, de
abc

=
(e/a, de/bc)∞
(e, de/abc)∞
3φ2
a, d/b, d/c
d, de/bc ; q, e
a

.
(3.18)
In the case when m = 1 and y1 = 1, (3.17) reduces to
X
γ∈Nn
 de
aBc
|γ| ∆(xqγ)
∆(x)
(a)|γ|
(e)|γ|
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(3.19)
= (e/a, de/Bc)∞
(e, de/aBc)∞
n+2φn+1

d/c, a, {(d/bi)xi}n
de/Bc, {dxi}n
; q; e
a

holds if it satisfy the convergence condition max(|dme/aBC|, |e/a|) < 1.
Here we give a remark on the convergence of multiple series.",N/A,N/A
"Remark 3.8. (Convergence of the multiple series) In the course of obtaining an inﬁnite
multiple sum identity such as (3.17), one needs to ensure the limiting procedure. To justify
the process, one is required to use the dominated convergence theorem. Furthermore, to ﬁnd
the convergence condition of the dominated series such as the series in (3.17), one can quote
the ratio test for multiple power series in classical work by J.Horn [11]. Since the details of",N/A,N/A
"such justiﬁcations in this paper are all in the same line as the corresponding discussions in
Milne-Newcomb [24] (see also Milne [21] and Milne-Newcomb [25]), we shall omit in this paper.
We shall propose the following special case, namely a transformation formula between An
m+2φm+1 series with integer parameter diﬀerences and Am terminating balanced n+2φn+1 series:
X
γ∈Nn

q1−|M|/A
|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
(3.20)
× (b)|γ|
(bq)|γ|
Y
1≤i≤n,1≤k≤m
(cqmkxiyk)γi
(cxiyk)γi",N/A,N/A
"(bq)|γ|
Y
1≤i≤n,1≤k≤m
(cqmkxiyk)γi
(cxiyk)γi
= (q, q1−|M|b/A)∞
(b, q1−|M|/A)∞
X
δ∈Nm
q|δ| ∆(yqδ)
∆(y)
Y
1≤k,l≤m
(q−mlyk/yl)δk
(qyk/yl)δk
×
(b)|δ|
(q1−|M|b/A)|δ|
Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
.
In the case when n = 1 and x1 = 1, the multiple series in the right hand side in (3.20) can
be summed by the following An generalization of q-Pfaﬀ-Saalsch¨utz summation formula
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi)γi
(cxi)γi
(3.21)
10
×
(a)|γ|
(abq1−|M|/c)|γ|
=",N/A,N/A
"(cxi)γi
(3.21)
10
×
(a)|γ|
(abq1−|M|/c)|γ|
=
(c/b)|M|
(c/ab)|M|
Y
1≤i≤n
((c/a)xi)mi
(cxi)mi
,
which can be obtained from (3.11) by elementary polynomial argument (see the proof of Corol-
lary 4.1), to recover Gasper’s q-analogue of Minton-Karlsson summation formula for n+2φn+1
series [6]:
n+2φn+1

a, b, {cqmixi}n
bq, {cxi}n
; q; a−1q1−|M|

= b|M| (q, bq/a)∞
(bq, q/a)∞
Y
1≤i≤n
((c/b)xi)mi
(cxi)mi
.(3.22)
In the case when m = 1 and y1 = 1, (3.20) reduces to:
X
γ∈Nn
 q1−m/A
|γ| ∆(xqγ)
∆(x)
Y",N/A,N/A
"X
γ∈Nn
 q1−m/A
|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cqmxi)γi
(cxi)γi
(3.23)
× (b)|γ|
(bq)|γ|
= (q, q1−Mb/A)∞
(b, q1−M/A)∞
n+2φn+1
q−M, b, {(c/ai)xi}n
q1−Mb/A, {cxi}n ; q; q

.
In the case when m = n = 1 and x1 = y1 = 1, (3.20) reduces to:
3φ2
a, b, cqM
bq, c
; q; q1−M/a

=
bM (q, bq/a, c/b)∞
(bq, q/a, c)∞
.
(3.24)
It may be of worth to note that, furthermore, if we replace e →aBCu/dm and take limit",N/A,N/A
"a →∞in (3.17), we recover multiple basic Euler transformation formula of type A (2.14)
X
γ∈Nn
u|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(bkxiyk)γi
(cxiyk)γi
= (ABu/cm)∞
(u)∞
X
δ∈Nm
ABu
cm
|δ| ∆(yqδ)
∆(y)
×
Y
1≤k,l≤m
((c/bl)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((c/ai)xiyk)δk
(cxiyk)δk
,
when max(|u|, |ABu/cm|) < 1.
Reversing version
Proposition 3.4. Under the balancing condition
amBcq1−N = dEf,
(3.25)
we have the following:
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi",N/A,N/A
"X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
Y
1≤k≤m
(ayk)|γ|
(ekyk)|γ|
(3.26)
×(q−N)|γ|
(f)|γ|
= (Ef/amB)N
(f)N
Y
1≤k≤m
(ayk)N
(ekyk)N
Y
1≤i≤n
((Ef/amc)zi)N
((Ef/amBc)zi)N
11
×
X
δ∈Nm
q|δ| ∆(wqδ)
∆(w)
Y
1≤k,l≤m
((el/a)wk/wl)δk
(qwk/wl)δk
Y
1≤k≤m
((f/a)wk)δk
((dEf/am+1Bc)wk)δk
×
(q−N)|δ|
(Ef/amB)|δ|
Y
1≤i≤n
((Ef/ambic)zi)|δ|
((Ef/amc)zi)|δ|
where zi = bi/Bxi, (1 ≤i ≤n) and wk = y−1
k , (1 ≤k ≤m) respectively.",N/A,N/A
"k , (1 ≤k ≤m) respectively.
Proof. Rewrite the parameters ck →aq/ck (1 ≤k ≤m) and e →aq/e in (2.12). Then put
a = 0. Finally by rearranging the parameters f →a, d →c, Bdf mq1−N/Ce →d, ck →
ek
(1 ≤k ≤m), e →f, we arrive at the desired identity.
In the case when m = 1 and y1 = 1, (3.26) reduces to
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(3.27)
×(q−N, a)|γ|
(e, f)|γ|
= (ef/aB, a)N
(e, f)N
Y
1≤i≤n
((ef/ac)zi)N
((ef/aBc)zi)N
×n+3φn+2
",N/A,N/A
"Y
1≤i≤n
((ef/ac)zi)N
((ef/aBc)zi)N
×n+3φn+2

q−N, e/a, f/a, {(ef/abic)zi}n
def/a2Bc, ef/aB, {(ef/ac)zi}n; q; q

,
when the following balancing condition holds:
aBcq1−N = def,
(3.28)
and where zi = bi/Bxi, i = 1, 2, · · · n. By letting f = a in (3.27) and relabeling the parameters
appropriately, we also recover the An Pfaﬀ-Saalsch¨utz summation (3.11).
Remark 3.9. (3.26) has already appeared as the 2nd Sears transformation formula (Proposition",N/A,N/A
"7.2.) in [13], up to relabeling parameters. In the case when m = n = 1 and x1 = y1 = 1, (3.26)
reduces to a transformation formula for terminating balanced 4φ3 series
4φ3
q−N, a, b, c
d, e, f
; q; q

= (ef/ab, ef/ac, a)N
(e, f, ef/abc)N
(3.29)
×4φ3

q−N, ef/abc, e/a, f/a
def/a2bc, ef/ab, ef/ac; q; q

when
abcq1−N = def.
(3.30)
Note that this is obtained by reversing the order of the summation of the Sears transformation",N/A,N/A
"(3.16) and is also veriﬁed by iterating Sears transformation twice in a proper fashion.
Let N →∞in (3.26). Then we have
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 Ef
amBc
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(3.31)
×

(f)|γ|
−1
Y
1≤k≤m
(ayk)|γ|
(ekyk)|γ|
= (Ef/amB)∞
(f)∞
Y
1≤k≤m
(ayk)∞
(ekyk)∞
Y
1≤i≤n
((Ef/amc)zi)∞
((Ef/amBc)zi)∞
×
X
δ∈Nm
w−δ1
1
· · · w−δm
m
a|δ|qe2(δ) ∆(wqδ)
∆(w)
Y
1≤k,l≤m
((el/a)wk/wl)δk
(qwk/wl)δk
Y
1≤k≤m
((f/a)wk)δk
12
×

(Ef/amB)|δ|
−1 Y
1≤i≤n",N/A,N/A
"1≤k≤m
((f/a)wk)δk
12
×

(Ef/amB)|δ|
−1 Y
1≤i≤n
((Ef/ambic)zi)|δ|
((Ef/amc)zi)|δ|
,
where zi = bi/Bxi, (1 ≤i ≤n), wk = y−1
k , (1 ≤k ≤m) respectively and e2(γ) is the second
elementary symmetric function of the variable γ = (γ1, γ2, · · · , γn).
The case m = 1 and y1 = 1 of (3.31) is
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 ef
aBc
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
(3.32)
× (a)|γ|
(e, f)|γ|
Y
1≤i≤n
(cxi)γi = (ef/aB, a)∞
(e, f)∞
Y
1≤i≤n
((ef/ac)zi)∞
((ef/aBc)zi)∞
×n+2φn+1",N/A,N/A
"Y
1≤i≤n
((ef/ac)zi)∞
((ef/aBc)zi)∞
×n+2φn+1
e/a, f/a, {(ef/aBc)zi}n
ef/aB, {(ef/ac)zi}n ; q; a

,
where zi = bi/Bxi for i = 1, · · · , n.
We mention that one yield an An Gauss summation
theorem by putting f = a and relabeling the parameters:
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 ef
aBc
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
(3.33)
×(c)|γ|
−1 Y
1≤i≤n
(axi)γi = (c/B)∞
(c)∞
Y
1≤i≤n
((cB/abi)x−1
i
)∞
((c/abi)x−1
i
)∞
.",N/A,N/A
"(c)∞
Y
1≤i≤n
((cB/abi)x−1
i
)∞
((c/abi)x−1
i
)∞
.
Remark 3.10. In the case when m = n = 1 and x1 = y1 = 1, (3.31) reduces to 3φ2 transforma-
tion formula
3φ2

a, b, c
e, f ; q; ef
abc

= (ef/ab, ef/ac, a)∞
(e, f, ef/abc)∞
3φ2

e/a, f/a, ef/abc
ef/ab, ef/ac ; q; a

.
In the case when mn = 1 and x1 = 1, (3.33) reduces to the basic Gauss summation formation
formula for 2φ1
2φ1
a, b
c, ; q; c
ab

= (c/a, c/b)∞
(c, c/ab)∞
.",N/A,N/A
"a, b
c, ; q; c
ab

= (c/a, c/b)∞
(c, c/ab)∞
.
We also remark that (3.31) and (3.33) have already appeared in our previous work [14]. But
they contain errors, so we restate them here.
3.3
8W7 transformations
Nonterminating 8W7 transformation formula
By taking the limit N →∞in (2.12), we have the following:
Proposition 3.5. Assume that

am+1qm+1
BCdef m x−1
i
 < 1 for all i = 1, · · · , n and |fy−1
k | < 1 for all
k = 1, · · · , m. Then we have
X
γ∈Nn
x−γ1
1
· · · x−γn
n
am+1qm+1",N/A,N/A
"X
γ∈Nn
x−γ1
1
· · · x−γn
n
am+1qm+1
BCdef m
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.34)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(ckxiyk)γi
((aq/f)xiyk)γi
×
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
Y
1≤k≤m
(fy−1
k )|γ|
((aq/ck)y−1
k )|γ|
13
×
1
(aq/d, aq/e)|γ|
Y
1≤i≤n
((dxi, exi)γi)
=
(µdf/a, µef/a)∞
(aq/d, aq/e)∞
Y
1≤k≤m
((µckf/a)yk, fy−1
k )∞
(µqyk, (aq/ck)y−1
k )∞
×
Y
1≤i≤n
(aqxi, (µbif/a)x−1
i )∞
((aq/bi)xi, (µf/a)x−1
i )∞
×
X
δ∈Nm
y−δ1
1
· · · y−δm
m
f |δ|qe2(δ) ∆(yqδ)
∆(y)",N/A,N/A
"δ∈Nm
y−δ1
1
· · · y−δm
m
f |δ|qe2(δ) ∆(yqδ)
∆(y)
Y
1≤k≤m
1 −µq|δ|+δkyk
1 −µyk
×
Y
1≤k,l≤m
((aq/clf)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((aq/bif)xiyk)δk
((aq/f)xiyk)δk
×
Y
1≤k≤m
(µyk)|δ|
((µckf/a)yk)|δ|
Y
1≤i≤n
((µf/a)x−1
i
)|δ|
((µbif/a)x−1
i )|δ|
×
1
(µdf/a, µef/a)|δ|
Y
1≤k≤m
((aq/df)yk, (aq/ef)yk)δk,
where µ = am+2qm+1/BCdef m+1.
For the justiﬁcation of this limiting procedure for (3.34), see Remark 3.7.
In the case when m = 1 and y1 = 1, (3.34) reduces to
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 a2q2",N/A,N/A
"X
γ∈Nn
x−γ1
1
· · · x−γn
n
 a2q2
Bcdef
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.35)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi, dxi, exi)γi
((aq/f)xi)γi
×
(f)|γ|
(aq/c, aq/d, aq/e)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
= (µcf/a, µdf/a, µef/a, f)∞
(aq/c, aq/d, aq/e, µq)∞
Y
1≤i≤n
(aqxi, (µbif/a)x−1
i )∞
((aq/bi)xi, (µf/a)x−1
i )∞
×2n+4W2n+3

µ; {(aq/bif)xi}naq/cf, aq/df, aq/ef, {(µf/a)x−1
i }n; q; f

,
where µ = a3q2/Bcdef 2.",N/A,N/A
"i }n; q; f

,
where µ = a3q2/Bcdef 2.
Remark 3.11. In the case when m = n = 1 and x1 = y1 = 1, (3.34) reduces to the following
transformation formula for nonterminating 8W7 series
8W7

a; b, c, d, e, f; q; a2q2
bcdef

= (µbf/a, µcf/a, µdf/a, µef/a, aq, f)∞
(aq/b, aq/c, aq/d, aq/e, µq, µf/a)∞
(3.36)
×8W7

µ; aq/bf, aq/cf, aq/df, aq/ef, µf/a; q; f

,
where µ = a3q2/bcdef 2, under the convergence condition max(|a2q2/bcdef|, |f|) < 1.",N/A,N/A
"We mention that by assuming e = aq/f in (3.35), we get the following:
Corollary 3.2. Assume that
 aq
Bcdx−1
i
 < 1 for all i = 1, · · · , n. Then
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 aq
Bcd
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.37)
14
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi, dxi)γi
×

(aq/c, aq/d)|γ|
−1 Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
(aq/Bc, aq/Bd)∞
(aq/c, aq/d)∞
Y
1≤i≤n
(aqxi, (aqbi/Bcd)x−1
i )∞
((aq/bi)xi, (aq/Bcd)x−1
i )∞
.",N/A,N/A
"i )∞
((aq/bi)xi, (aq/Bcd)x−1
i )∞
.
Remark 3.12. In the case when n = 1 and x1 = 1, (3.37) reduces to the Bailey summation
formula for nonterminating 6W5 series (See [7])
6W5
h
a; b, c, d; q; aq
bcd
i
=
(aq, aq/cd, aq/bd, aq/bc)∞
(aq/bcd, aq/b, aq/c, aq/d)∞
.
(3.38)
An nonterminating 6W5 summation formula (3.37) is due to S.C. Milne and has appeared as
Theorem 4.27 in [20] with a diﬀerent expression (See also Theorem A.4 in Milne-Newcomb [25]).",N/A,N/A
"Note that (3.37) can also be obtained by taking the limit N →∞in An Jackson summation
formula (2.16).
Terminating 8W7 transformation
Proposition 3.6.
X
γ∈Nn
xγ1
1 · · · xγn
n
am+1qm+N+1
BCdme
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.39)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n,1≤k≤m
(ckxiyk)γi
((aq/d)xiyk)γi
×
Y
1≤i≤n
1
(aqN+1xi, (aq/e)xi)γi
×(q−N, e)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
Y
1≤k≤m
(dy−1
k )|γ|
((aq/ck)y−1
k )|γ|
=
Y
1≤k≤m
((aq/cke)y−1
k , dy−1
k )N
((aq/ck)y−1",N/A,N/A
"=
Y
1≤k≤m
((aq/cke)y−1
k , dy−1
k )N
((aq/ck)y−1
k , (d/e)y−1
k )N
Y
1≤i≤n
((aq/bie)xi, aqxi)N
((aq/bi)xi, (aq/e)xi)N
×
X
δ∈Nm
yδ1
1 · · · yδm
m
BCdm−1
am
|δ|
q−e2(δ) ∆(yqδ)
∆(y)
Y
1≤k≤m
1 −(q−Ne/d)q|δ|+δkyk
1 −(q−Ne/d)yk
×
Y
1≤k,l≤m
((aq/cld)yk/yl)δk
(qyk/yl)δk
Y
1≤i≤n,1≤k≤m
((aq/bid)xiyk)δk
((aq/d)xiyk)δk
×
Y
1≤k≤m
1
((e/d)yk, (q1−N/d)yk)δk
×(q−N, e)|δ|
Y
1≤k≤m
((q−Ne/d)yk)|δ|
((q−Ncke/a)yk)|δ|
Y
1≤i≤n
((q−Ne/a)x−1
i )|δ|
((q−Nbie/a)x−1
i )|δ|
.",N/A,N/A
"1≤i≤n
((q−Ne/a)x−1
i )|δ|
((q−Nbie/a)x−1
i )|δ|
.
Proof. Relabel e as µfqN, i.e. interchange e ↔µfqN. Then let d tend to inﬁnity. Finally, by
relabeling f as d, we arrive at (3.39).
In the case when m = 1 and y1 = 1, (3.39) reduces to
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q2+N
Bcde
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.40)
15
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
((aq/d)xi, (aq/e)xi, aqN+1xi)γi
×(q−N, d, e)|γ|
(aq/c)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
(aq/ce, d)N",N/A,N/A
"Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
(aq/ce, d)N
(aq/c, d/e)N
Y
1≤i≤n
((aq/bie)xi, aqxi)N
((aq/bi)xi, (aq/e)xi)N
×2n+6W2n+5

q−Ne/d; {(aq/bid)xi}n, {(q−Ne/a)x−1
i }n, aq/cd, e, q−N; q; Bc
a

.
Remark 3.13. In the case when m = n = 1 and x1 = y1 = 1, (3.39) reduces to transformation
formula for terminating 8W7 series
8W7

a; b, c, d, e, q−N; q; a2qN+2
bcde

(3.41)
=
(aq/be, aq/ce, aq, d)N
(aq/b, aq/c, aq/e, d/e)N
8W7

q−Ne/d; aq/bd, q−Ne/a, aq/cd, e, q−N; q; bc
a

.",N/A,N/A
"q−Ne/d; aq/bd, q−Ne/a, aq/cd, e, q−N; q; bc
a

.
Let aq = cd in (3.40). Then, by rearranging parameters, we have
X
γ∈Nn
xγ1
1 · · · xγn
n
aq1+N
Bc
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(3.42)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n

((aq/c)xi, aq1+Nxi)γi
−1
× (q−N, c)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
Y
1≤i≤n
((aq/bic)xi, aqxi)N
((aq/bi)xi, (aq/c)xi)N
.
Remark 3.14. In the case when n = 1 and x1 = 1, (3.42) reduces to the Rogers‘ summation",N/A,N/A
"formula for terminating 6W5 series (3.6).
As we have seen in this section, one can recover our previous results in [13] from the bal-
anced duality transformation formula (2.12) by limiting procedures. Combining with results in
[13] and Rosengren [26], one can consider the master formula for multiple basic hypergeomet-
ric transformations of type A with diﬀerent dimensions presented in this section to either of",N/A,N/A
"multiple basic Euler transformation (2.14), Sears transformation (3.14), (non balanced) duality
transformation (3.1) and balanced duality transformation formula (2.12).
4
An hypergeometric transformations
In this section, we present several hypergeometric transformation formulas with same dimension
n (for multiple basic hypergeometric series of type An) by combining some special cases of hy-
pergeometric transformation with diﬀerent dimensions which we have obtained in the previous",N/A,N/A
"section. It contains new transformation formulas and some of these are previously known by
Milne and his collaborators (see [23], [24], and [22]). However, our proofs of them are completely
diﬀerent from theirs and seem to be simpler.
4.1
An Watson transformations
In this subsection and next, we derive several An generalization of the Watson transformation
formula between terminating 8W7 series and terminating balanced 4φ3 series ( (2.5.1) in [7] ):
8W7

a; b, c, d, e, q−N; q; a2q2+N
bcde
",N/A,N/A
"8W7

a; b, c, d, e, q−N; q; a2q2+N
bcde

(4.1)
16
=
(aq, aq/de)N
(aq/d, aq/e)N
4φ3

q−N, d, e, aq/bc
aq/b, aq/c, deq−N/a; q; q

.
Especially, we give two types of An Watson transformation formula whose series in the left
hand side are expressible in terms of W n,2 series here. We will use a special case (m = 1 (3.3))
of the (non-balanced) duality transformation formula (3.1) and special cases of 4φ3 series of",N/A,N/A
"type A to the identities below. To be precise, we produce them according to the following
diagram.
W n,2 series
4φ3 series in An
✲
Watson trans.
n+3φn+2 series
◗◗◗◗◗◗
s
✑✑✑✑✑✑
✸
(3.3)
(B) 4φ3 transformation of type A
The 1st one
Proposition 4.1.
W n,2

{bi}n
{xi}n
 a; c, d; e, q−N; q; a2qN+2
Bcde

(4.2)
= (aq/Bd)N
(aq/d)N
Y
1≤i≤n
(axi)N
((aq/bi)xi)N
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
×
(q−N, aq/ce)|γ|
(Bdq−N/a, aq/c)|γ|
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(dxi)γi
((aq/e)xi)γi
.",N/A,N/A
"(qxi/xj)γi
Y
1≤i≤n
(dxi)γi
((aq/e)xi)γi
.
Proof. We combine (3.3) and n = 1 and m →n case of (3.14)
n+3φn+2

q−N, a, c, {ui}n
e, {vi}n, acUq1−N/eV ; q, q

(4.3)
= (e, eV/acU)N
(e/a, eV/cU)N
X
γ∈Nn
q|γ| ∆(vqγ)
∆(v)
×
(q−N, a)|γ|
(q1−Na/e, eV/cU)|γ|
Y
1≤i,j≤n
(vi/uj)γi
(qvi/vj)γi
Y
1≤i≤n
(vi/c)γi
(vi)γi
,
here we give in the useful form for the present proof and latter uses in this section, as (B) in
the above diagram. Note that both of the series in the right hand side of (3.3) and that in the",N/A,N/A
"left hand side of (4.3) satisfy same condition as basic hypergeometric series: namely they are
terminating balanced n+3φn+2 series. On the set of variables
({(aq/bie)xi}n, aq/ce, aq/de, a2q2/Bcde, {(aq/e)xi}n),
(4.4)
we consider the following change of variables:
˜a = aq/ce,
˜c = aq/de,
˜e = a2q2/Bcde
˜ui = (aq/bie)xi,
˜vi = (aq/e)xi
(i = 1, · · · , n).
(4.5)
For given function ψ, we denote by ˜ψ = ψ(a, c, e, {ui}n, {vi}n) the function that is obtained by",N/A,N/A
"replacing the variables (a, c, e, {ui}n, {vi}n) by (˜a, ˜c, · · · ). In this case, the change of variables
17
(4.5) is a transposition inside of each sets of numerator parameters in n+3φn+2 series and of
denominator parameters. Hence, the right hand side of (3.3) is invariant under this change of
variables. By applying (4.3) to the series the right hand side in (3.3), this invariance implies
(4.2).
We also give similar transformation formula for multiple series which terminates with respect",N/A,N/A
"to a certain multi-index. In this paper, we call such transformation formulas as rectangular and
transformations for the multiple series which terminates with respect to the length of multi-
indices as triangular.
Corollary 4.1.
W n,2

{q−mi}n
{xi}n
 a; c, d; b, e; q; a2q|M|+2
bcde

(4.6)
= (aq/bd)|M|
(aq/d)|M|
Y
1≤i≤n
(aqxi)mi
((aq/b)xi)mi
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
×
(b, aq/ce)|γ|
(bdq−|M|/a, aq/c)|γ|
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(dxi)γi
((aq/e)xi)γi
.",N/A,N/A
"(qxi/xj)γi
Y
1≤i≤n
(dxi)γi
((aq/e)xi)γi
.
Proof. We ﬁrst write the product factor in the right hand side of (4.2) as a quotient of inﬁnite
products using (2.1). Set bi = q−mi in (4.2), and notice that (4.6) is true for b = q−N for all
nonnegative integer N. Clear the denominators in (4.6). Then we ﬁnd that it is a polynomial
identity in b−1 with an inﬁnite number of roots. Thus, (4.6) is true for arbitrary b.",N/A,N/A
"All the corollaries in this section can be proved by similar arguments from the formulas in
the preceding propositions. So, hereafter we will not repeat this procedure in the rest of this
paper.
Remark 4.1. (4.6) has appeared in Theorem 6.1 of Milne and Lilly [23].
The 2nd one
Proposition 4.2.
W n,2

{bi}n
{xi}n
 a; c, d; e, q−N; q; a2qN+2
Bcde

(4.7)
=
Y
1≤i≤n
(axi, (aq/bie)xi)N
((aq/bi)xi, (aq/e)xi)N
X
γ∈Nn
q|γ| ∆(zqγ)
∆(z)
×
(q−N, e)|γ|
(aq/c, aq/d)|γ|
Y
1≤i,j≤n
(bjzi/zj)γi
(qzi/zj)γi
Y",N/A,N/A
"Y
1≤i,j≤n
(bjzi/zj)γi
(qzi/zj)γi
Y
1≤i≤n
((aq/cd)zi)γi
((Beq−N/a)zi)γi
,
where zi = bi/Bxi for 1 ≤i ≤n.
Proof. We combine (3.3) and n = 1 and m →n case of (3.26)
n+3φn+2

q−N, a, c, {ui}n
e, {vi}n, acUq1−N/eV ; q, q

(4.8)
= (eV/aU, eV/cU)N
(eV/acU, e)N
Y
1≤i≤n
(ui)N
(vi)N
X
γ∈Nn
q|γ| ∆(u−1qγ)
∆(u−1)
× (q−N, eV/acU)|γ|
(eV/aU, eV/cU)|γ|
Y
1≤i,j≤n
(vj/ui)γi
(quj/ui)γi
Y
1≤i≤n
(e/ui)γi
(q1−N/ui)γi
,
18",N/A,N/A
"(quj/ui)γi
Y
1≤i≤n
(e/ui)γi
(q1−N/ui)γi
,
18
here we present in a modiﬁed form, as (B). Notice that both of the series in the right hand side
of (3.3) and that in the left hand side of (4.8) are terminating balanced n+3φn+2 series. In this
case, we consider the following change of variables
˜a = aq/ce,
˜c = aq/de,
˜e = a2q2/Bcde
˜ui = (aq/bie)xi,
˜vi = (aq/e)xi
(i = 1, · · · , n).
(4.9)
Since this change of variables is same as (4.5) in the proof of Proposition 4.1. one can obtain",N/A,N/A
"the desired identity (4.7) by plugging (4.8) to the series in the right hand side of (3.3) according
to this change of variables.
Rectangular version
Corollary 4.2.
W n,2

{q−mi}n
{xi}n
 a; c, d; b, e; q; a2q|M|+2
bcde

(4.10)
=
Y
1≤i≤n
(aqxi, (aq/be)xi)mi
((aq/b)xi, (aq/e)xi)mi
X
γ∈Nn
q|γ| ∆(zqγ)
∆(z)
×
(b, e)|γ|
(aq/c, aq/d)|γ|
Y
1≤i,j≤n
(q−mjzi/zj)γi
(qzi/zj)γi
Y
1≤i≤n
((aq/ce)xi)γi
((beq−|M|/a)xi)γi
,
where zi = q−mi+|M|x−1
i
for i = 1, · · · , n.",N/A,N/A
",
where zi = q−mi+|M|x−1
i
for i = 1, · · · , n.
Remark 4.2. In the case when n = 1 and x1 = 1, all of (4.2), (4.6), (4.7) and (4.10) reduce to
the Watson transformation formula (4.1). (4.7) can be proved by a similar limiting procedure
as the previous section from the following An Bailey transformation formula for terminating
balanced 10W9 series:
W n,3

{ei}n
{xi}n
 a; b, c, d; q−N, f, aλq1+N/Ef; q

(4.11)
=
Y
1≤i≤n
(aqxi, (aq/eif)xi, (λq/ei)zi, (λq/f)zi)N",N/A,N/A
"Y
1≤i≤n
(aqxi, (aq/eif)xi, (λq/ei)zi, (λq/f)zi)N
((aq/ei)xi, (aq/f)xi, λqzi, (λq/eif)zi)N
×W n,3

{ei}n
{zi}n
 λ; aq/cd, aq/bd, aq/bc; q−N, f, aλq1+N/Ef; q

where λ = a2q/bcd and zi = ei/Exi for 1 ≤i ≤n, which has ﬁrst appeared as (4.36) in [15],
and by rearranging the parameters.
4.2
Another type of An Watson transformation
Here, we present a yet another An Watson transformation with a diﬀerent form in the series
in both sides from those in the previous subsection.",N/A,N/A
"We will use the m = 1 case of the
terminating 8W7 transformation (3.40) of type A in Section 3.3. and the n = 1 case of the
duality transformation formula in a modiﬁed form to produce. We construct it according to
the following procedure:
W n,2 series
4φ3 series in An
✲
Watson trans.
2n+6W2n+5 series
◗◗◗◗◗◗
s
✑✑✑✑✑✑
✸
(3.40)
Duality trans. (4.13)
19
Proposition 4.3.
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q2+N
Bcde
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.12)
×
Y
1≤i,j≤n
(bjxi/xj)γi",N/A,N/A
"1 −axi
(4.12)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
((aq/d)xi, (aq/e)xi, aqN+1xi)γi
×(q−N, d, e)|γ|
(aq/c)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
(aq/Bc)N
(aq/c)N
Y
1≤i≤n
(aqxi)N
((aq/bi)xi)N
X
δ∈Nn
q|δ| ∆(xqδ)
∆(x)
×
(q−N)|δ|
(q−NBc/a)|δ|
Y
1≤i,j≤n
(bjxi/xj)δi
(qxi/xj)δi
Y
1≤i≤n
((aq/de)xi, cxi)δi
((aq/d)xi, (aq/e)xi)δi
.
Proof. We use (3.40) and (3.4) with a modiﬁed form
2n+6W2n+5

a; b, {ui}n, d, {vi}n, q−N; q; an+1qN+n+1
bdUV

(4.13)
= (an+1qn+1/bdUV, aq)N
(aq/b, aq/d)N
Y
1≤i≤n",N/A,N/A
"= (an+1qn+1/bdUV, aq)N
(aq/b, aq/d)N
Y
1≤i≤n
(vi)N
(aq/ui)N
X
δ∈Nn
q|δ| ∆(v−1qδ)
∆(v−1)
×
(q−N)|δ|
(an+1qn+1/bdUV )|δ|
Y
1≤i,j≤n
(aq/ujvi)δi
(qvj/vi)δi
Y
1≤i≤n
(aq/bvi, aq/dvi)δi
(aq/vi, q1−N/vi)δi
.
to obtain. It is not hard to see that both of the series in the right hand side of (3.40) and in
the left hand side of (4.13) satisfy the same condition: they are 2n+6W2n+5 series and very-
well-poised-balanced. We consider the following change of variables:
˜a = q−Ne/d,
˜b = aq/cd,
˜d = e,
(4.14)",N/A,N/A
"˜a = q−Ne/d,
˜b = aq/cd,
˜d = e,
(4.14)
˜ui = (aq/bid)xi,
˜vi = (q−Ne/a)x−1
i
(i = 1, · · · , n),
which is a transposition of the variables in 2n+6W2n+5 series in (3.40). Note that r+3Wr+2
series is symmetric with respect to the variables a1, · · · , ar. So the series in the right hand side
of (3.40) is invariant under this change of variables. This invariance implies (4.12) by applying
(4.13) according to the change of variables (4.14).
Rectangular version
Corollary 4.3.
X
γ∈Nn
xγ1
1 · · · xγn",N/A,N/A
"Corollary 4.3.
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q2+|M|
bcde
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.15)
×
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
((aq/b)xi, (aq/d)xi, (aq/e)xi)γi
×(b, d, e)|γ|
(aq/c)|γ|
Y
1≤i≤n
(axi)|γ|
((aqmixi)|γ|
=
(aq/bc)|M|
(aq/c)|M|
Y
1≤i≤n
(aqxi)mi
((aq/b)xi)mi
X
δ∈Nn
q|δ| ∆(xqδ)
∆(x)
20
×
(b)|δ|
(q−|M|bc/a)|δ|
Y
1≤i,j≤n
(q−mjxi/xj)δi
(qxi/xj)δi
Y
1≤i≤n
((aq/de)xi, cxi)δi
((aq/d)xi, (aq/e)xi)δi",N/A,N/A
"Y
1≤i≤n
((aq/de)xi, cxi)δi
((aq/d)xi, (aq/e)xi)δi
Remark 4.3. In the case when n = 1 and x1 = 1, (4.12) and (4.15) reduce to the Watson
transformation formula (4.1).
Remark 4.4. In a similar fashion as we yield (4.12), we also obtain the following transformation
formula between An 8W7 series and An terminating balanced 4φ3 series:
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q2+N
Bcde
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.16)
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi",N/A,N/A
"Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
((aq/d)xi, (aq/e)xi, aqN+1xi)γi
×(q−N, d, e)|γ|
(aq/c)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
BN (aq/Bc)N
(aq/c)N
Y
1≤i≤n
(aqxi, (aq/bid)xi, (aq/bie)xi)N
((aq/bi, (aq/d)xi, (aq/e)xi)xi)N
×
X
δ∈Nn
q|δ| ∆(x−1qδ)
∆(x−1)
Y
1≤i,j≤n
(bjxj/xi)δi
(qxj/xi)δi
×
(q−N)|δ|
(q−NBc/a)|δ|
Y
1≤i≤n
((q−1−Nbicde/a2)x−1
i
, (q−Nbi/a)x−1
i )δi
((q−Nbid/a)x−1
i , (q−Nbie/a)x−1
i )δi
.
We obtain it by applying the change of variables:
˜a = q−Ne/d,
˜b = aq/cd,
˜d = e,",N/A,N/A
"˜a = q−Ne/d,
˜b = aq/cd,
˜d = e,
(4.17)
˜ui = (q−Ne/a)x−1
i ,
˜vi = (aq/bid)xi,
(i = 1, · · · , n).
The rectangular version of (4.16) is given by
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q2+|M|
bcde
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.18)
×
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
((aq/b)xi, (aq/d)xi, (aq/e)xi)γi
×(b, d, e)|γ|
(aq/c)|γ|
Y
1≤i≤n
(axi)|γ|
((aq1+m i)xi)|γ|
=
b|M| (aq/bc)|M|
(aq/c)|M|
Y
1≤i≤n
(aqxi, (aq/bd)xi, (aq/be)xi)mi
((aq/b)xi, (aq/d)xi, (aq/e)xi)xi)mi
×
X",N/A,N/A
"((aq/b)xi, (aq/d)xi, (aq/e)xi)xi)mi
×
X
δ∈Nn
q|δ| ∆(x−1qδ)
∆(x−1)
Y
1≤i,j≤n
(q−mjxj/xi)δi
(qxj/xi)δi
×
(b)|δ|
(q−|M|bc/a)|δ|
Y
1≤i≤n
((q−1−mibcde/a2)x−1
i
, (q−mib/a)x−1
i )δi
((q−mibd/a)x−1
i , (q−mibe/a)x−1
i )δi
.
In the case when n = 1 and x1 = 1, the transformation (4.16) and (4.18) reduces to the following
transformation formula between terminating 8W7 series and terminating balanced 4φ3 series:
8W7

a; b, c, d, e, q−N; q; a2q2+N
bcde

(4.19)
=
bN (aq, aq/bc, aq/bd, aq/be)N",N/A,N/A
"bcde

(4.19)
=
bN (aq, aq/bc, aq/bd, aq/be)N
(aq/b, aq/c, aq/d, aq/e)N
4φ3
q−N, b, q−1−Nbcde/a2, q−Nb/a
bcq−N/a, bdq−N/a, beq−N/a, ; q; q

.
21
4.3
An Sears transformations
In this and next subsection, we present some An generalizations of the Sears transformation
formula for terminating balanced 4φ3 series (3.16). In particular, we will prove two An Sears
transformations whose form of the series in both sides are same as that in the right hand",N/A,N/A
"side of the An Watson transformation formulas in Section 4.1. We produce these identities by
combining certain special cases of 4φ3 series of type A in Section 3.2. Our way to prove them
is ﬁgured as the following diagram:
4φ3 series in An
4φ3 series in An
✲
An Sears trans.
n+3φn+2 series
◗◗◗◗◗◗
s
✑✑✑✑✑✑
✸
4φ3 transformation of type A (A)
(B) 4φ3 transformation of type A
The 1st one
Proposition 4.4.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.20)
×",N/A,N/A
"(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.20)
×
(q−N, a)|γ|
(e, aBcq1−N/de)|γ|
= (e/B, de/ac)N
(e, de/aBc)N
X
δ∈Nn
q|δ| ∆(xqδ)
∆(x)
×
(q−N, d/c)|δ|
(de/ac, q1−NB/e)|δ|
Y
1≤i,j≤n
(bjxi/xj)δi
(qxi/xj)δi
Y
1≤i≤n
((d/a)xi)δi
(dxi)δi
.
Proof. We use (3.27) as (A) and (4.8) as (B) in the above diagram. It is not hard to see
that both of the series in the right hand side of (3.27) and in the left hand side in (4.8) are
terminating balanced n+3φn+2 series. We consider the following change of variables:",N/A,N/A
"˜a = e/a,
˜c = f/a,
˜e = def/a2Bc.
(4.21)
˜ui = ef
abiczi,
˜vi = ef
ac zi
(1 ≤i ≤n).
Note that the series in the right hand side of (3.27) is invariant under this change of variables.
Applying (4.8) to the n+3φn+2 series in the right hand side in (3.27) leads to the desired result
(4.20).
In [12], we have already shown that (4.20) can also be obtained by combining (3.15) as (A)
and (4.3) as (B). In this case, The change of variables is given by
˜a = d/c,
˜c = a,
˜e = de/Bc.
(4.22)
˜ui = d
bi",N/A,N/A
"˜a = d/c,
˜c = a,
˜e = de/Bc.
(4.22)
˜ui = d
bi
xi,
˜vi = dxi
(1 ≤i ≤n).
Rectangular version
22
Corollary 4.4.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.23)
×
(a, b)|γ|
(e, abcq1−|M|/de)|γ|
= (e/b, de/ac)|M|
(e, de/abc)|M|
X
δ∈Nn
q|δ| ∆(xqδ)
∆(x)
×
(b, d/c)|δ|
(de/ac, q1−|M|b/e)|δ|
Y
1≤i,j≤n
(q−mjxi/xj)δi
(qxi/xj)δi
Y
1≤i≤n
((d/a)xi)δi
(dxi)δi
.
The 2nd one
Proposition 4.5.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi",N/A,N/A
"Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.24)
×
(q−N, a)|γ|
(e, aBcq1−N/de)|γ|
=
(de/ac)N
(de/aBc)N
Y
1≤i≤n
((d/bi)xi)N
(dxi)N
×
X
δ∈Nn
q|δ| ∆(zqδ)
∆(z)
(q−N, e/a)|δ|
(de/ac, e)|δ|
Y
1≤i,j≤n
(bjzi/zj)δi
(qzi/zj)δi
Y
1≤i≤n
((e/c)zi)δi
((q1−NB/d)zi)δi
,
where zi = bi/Bxi for 1 ≤i ≤n.
Proof. We use (3.15) as (A) and (4.8) as (B). In this case, the change of variables is given by
˜a = a,
˜c = d/c,
˜e = de/Bc,
(4.25)
˜ui = d
bi
xi,
˜vi = dxi
(1 ≤i ≤n).",N/A,N/A
"(4.25)
˜ui = d
bi
xi,
˜vi = dxi
(1 ≤i ≤n).
For the rest, one can easily verify in a similar way as the proof of Proposition 4.4.
Note that (4.24) can also be obtained by combining (3.27) as (A) and (4.3) as (B). In this
case, the change of variables is given by
˜a = e/a,
˜c = f/a,
˜e = ef/aB,
(4.26)
˜ui = ef
abiczi,
˜vi = ef
ac zi
(1 ≤i ≤n).
Rectangular version
Corollary 4.5.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.27)
×
(a, b)|γ|",N/A,N/A
"Y
1≤i≤n
(cxi)γi
(dxi)γi
(4.27)
×
(a, b)|γ|
(e, abcq1−|M|/de)|γ|
=
(de/ac)|M|
(de/abc)|M|
Y
1≤i≤n
((d/b)xi)mi
(dxi)mi
×
X
δ∈Nn
q|δ| ∆(zqδ)
∆(z)
(e/a, b)|δ|
(de/ac, e)|δ|
Y
1≤i,j≤n
(q−mjzi/zj)δi
(qzi/zj)δi
Y
1≤i≤n
((e/c)zi)δi
((bq1−|M|/d)zi)δi
.
where zi = q−mi+|M|x−1
i
for 1 ≤i ≤n.
23
Remark 4.5. In the case when n = 1 and x1 = 1, all of An terminating balanced 4φ3 trans-
formation formulas (4.20), (4.23), (4.24) and (4.27) reduce to the Sears transformation (3.16).",N/A,N/A
"Especially, (4.20) has already appeared in our previous work [12] and (4.27) is originally due
to Milne and Lilly (Theorem 6.5 in [23]). Note also that (4.20) can be proved by duplicating
(4.24)
Remark 4.6. Two An Watson transformations (4.2) and (4.7) transpose to one another by An
Sears transformation formula (4.24). Similarly, two An Watson transformations (4.6) and (4.10)
transpose to one another by An Sears transformation formula (4.27).
4.4
Another type of An Sears transformation",N/A,N/A
"4.4
Another type of An Sears transformation
Here, we give a yet another type of An Sears transformation formula whose form of the series
in both sides are the same as that in the right hand side of An Watson transformation formulas
in Section 4.2. We use the m = 1 case (3.8) of the inversion of the duality transformation (3.7)
and a certain special case (4.13) of the duality transformation formula (3.1). Our road map is
as follows:
4φ3 series in An
4φ3 series in An
✲
An Sears trans.",N/A,N/A
"4φ3 series in An
✲
An Sears trans.
2n+6W2n+5 series
2n+6W2n+5 series
✲
transposition
❄
✻
(3.8)
(4.13)
Proposition 4.6.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(ajxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi, cxi)γi
(exi, (Abcq1−N/de)xi)γi
(4.28)
×(q−N)|γ|
(d)|γ|
=
Y
1≤i≤n
((de/bc)zi, (e/ai)xi)N
((de/aibc)zi, exi)N
X
δ∈Nn
q|δ| ∆(zqδ)
∆(z)
×(q−N)|δ|
(d)|δ|
Y
1≤i,j≤n
(ajzi/zj)δi
(qzi/zj)δi
Y
1≤i≤n
((d/b)zi, (d/c)zi)δi
((de/bc)zi, (Aq1−N/e)zi)δi
,
where zi = ai/Axi for i = 1, 2, · · · , n.",N/A,N/A
",
where zi = ai/Axi for i = 1, 2, · · · , n.
Proof. We use (3.8) and (4.13). Note that both of the series in the right hand side of (3.8) and
in the left hand side of (4.13) are very-well-poised-balanced 2n+6W2n+5 series. In this case, we
consider the following change of variables:
˜a = de2q−1
Abc
,
˜b = e/b,
˜d = e/c,
(4.29)
˜ui = (deq−1/Abc)x−1
i
,
˜vi = (e/ai)xi
(i = 1, · · · , n),
which is a transposition of the variables in 2n+6W2n+5 series in (3.8). Since the series in the",N/A,N/A
"right hand side of (3.8) is invariant under this change of variables. This invariance implies the
desired result (4.28) by applying (4.13) according to the change (4.29).
Rectangular version
Corollary 4.6.
X
γ∈Nn
q|γ| ∆(xqγ)
∆(x)
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi, cxi)γi
(exi, (abcq1−|M|/de)xi)γi
(4.30)
24
×(a)|γ|
(d)|γ|
=
Y
1≤i≤n
((de/bc)zi, (e/a)xi)mi
((de/abc)zi, exi)mi
X
δ∈Nn
q|δ| ∆(zqδ)
∆(z)
×(a)|δ|
(d)|δ|
Y
1≤i,j≤n
(q−mjzi/zj)δi
(qzi/zj)δi
Y
1≤i≤n
((d/b)zi, (d/c)zi)δi",N/A,N/A
"(qzi/zj)δi
Y
1≤i≤n
((d/b)zi, (d/c)zi)δi
((de/bc)zi, (aq1−|M|/e)zi)δi
,
where zi = qmi−|M|x−1
i
for i = 1, 2, · · · , n.
Remark 4.7. (4.30) has originally appeared as Theorem 6.8 in Milne-Lilly [23]. Though they
referred as Cr Sears transformation formula there, the sums in both side of (4.30) are An 4φ3
series. For their point of view, it may be precise to refer it as An Sears transformation formula
arising from Cn Bailey transform.",N/A,N/A
"arising from Cn Bailey transform.
In the case when n = 1 and x1 = 1, (4.28) and (4.30) reduce to the Sears transformation
(3.16). We also note that (4.28) can be obtained from An Bailey transformation (4.11) in the
following way: First we replace d →aq/d and f →aq/f in (4.11). Then let the parameter a
tends to inﬁnity in the resulting equation. Finally rearrange the parameters appropriately.
4.5
Nonterminating 8W7 transformations",N/A,N/A
"4.5
Nonterminating 8W7 transformations
Here we show a An nonterminating 8W7 transformation formula. Our tool to produce it is
m = 1 case (3.35) of of the nonterminating 8W7 transformation formula (3.34) in Section 3.3.
One can see the way to prove the identity as
8W7 series in An
8W7 series in An
✲
An nonterminating 8W7 trans.
2n+6W2n+5 series
2n+6W2n+5 series
✲
transposition
❄
✻
(3.35)
(3.35)
Proposition 4.7.
X
γ∈Nn
x−γ1
1
· · · x−γn
n
 a2q2
bcdEf
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi",N/A,N/A
"|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.31)
×
Y
1≤i,j≤n
(ejxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(bxi, cxi, dxi)γi
((aq/f)xi)γi
×
(f)|γ|
(aq/b, aq/c, aq/d)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/ei)xi)|γ|
=
Y
1≤i≤n
(aqxi, (aq/eif)xi, (λq/ei)zi, (λq/f)zi)∞
((aq/ei)xi, (aq/f)xi, (λq/eif)zi, λqzi)∞
×
X
δ∈Nn
z−δ1
1
· · · z−δn
n
 aq
Ef
|δ|
qe2(δ) ∆(zqδ)
∆(z)
Y
1≤i≤n
1 −λq|δ|+δizi
1 −λzi
×
Y
1≤i,j≤n
(ejzi/zj)δi
(qzi/zj)δi
Y
1≤i≤n
((aq/cd)zi, (aq/bd)zi, (aq/bc)zi)δi
((λq/f)zi)δi
×
(f)|δ|",N/A,N/A
"((λq/f)zi)δi
×
(f)|δ|
(aq/b, aq/c, aq/d)|δ|
Y
1≤i≤n
(λzi)|δ|
((λq/ei)zi)|δ|
where λ = a2q/bcd and zi = ei
E x−1
i
.
25
Proof. We iterate (3.35)
X
γ∈Nn
x−γi
i
· · · x−γn
n
µf
a
|γ|
qe2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
×
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
Y
1≤i≤n
(cxi, dxi, exi)γi
((aq/f)xi)γi
×
(f)|γ|
(aq/c, aq/d, aq/e)|γ|
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
=
(µcf/a, µdf/a, µef/a, f)∞
(aq/c, aq/d, aq/e, µq)∞
Y
1≤i≤n
(aqxi, (µbif/a)x−1
i )∞
((aq/bi)xi, (µf/a)x−1
i )∞
×2n+4W2n+3
",N/A,N/A
"i )∞
((aq/bi)xi, (µf/a)x−1
i )∞
×2n+4W2n+3

µ; {(aq/bif)xi}naq/cf, aq/df, aq/ef, {(µf/a)x−1
i }n; q; f

,
(µ = a3q2/Bcdef 2),
twice. On the way to obtain (4.31), we interchange (aq/bif)xi and (µf/a)x−1
i
for all i = 1, · · · , n
simultaneously in the 2n+6W2n+5 series.
Remark 4.8. In the case when n = 1 and x1 = 1, (4.31) reduces to the following nonterminating
8W7 transformation:
8W7

a; b, c, d, e, f; q; a2q2
bcdef

(4.32)
=
(aq, aq/ef, λq/e, λq/f)∞
(aq/e, aq/f, λq, λq/ef)∞
8W7
",N/A,N/A
"(aq/e, aq/f, λq, λq/ef)∞
8W7

λ; λb/a, λc/a, λd/a, e, f; q; aq
ef

,
where λ = a2q/bcd. (4.31) can also be obtained by taking the limit N →∞in An Bailey
transformation formula (4.11).
4.6
Terminating 8W7 transformations
Here we present An nonterminating 8W7 transformation formulas. We give a proof by using
m = 1 case (3.40) of of the nonterminating 8W7 transformation formula (3.39) in Section 3.3.
The proof is in the same manner as in that of (4.31). One can see the way to give the identity",N/A,N/A
"as
8W7 series in An
8W7 series in An
✲
An terminating 8W7 trans.
2n+6W2n+5 series
2n+6W2n+5 series
✲
transposition
❄
✻
(3.40)
(3.40)
Proposition 4.8.
X
γ∈Nn
xγ1
1 · · · xγn
n
a2qN+2
Bcfg
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.33)
×
Y
1≤i≤n
(axi)|γ|
((aq/bi)xi)|γ|
Y
1≤i,j≤n
(bjxi/xj)γi
(qxi/xj)γi
×(f, g, q−N)|γ|
(aq/c)|γ|
Y
1≤i≤n
(cxi)γi
(aqN+1xi, (aq/f)xi, (aq/g)xi)γi
26
=
Y
1≤i≤n
(aqxi, (aq/bif)xi, (aq/big)xi, (aq/fg)xi)N
((aq/bi)xi, (aq/f)xi, (aq/g)xi, (aq/bifg)xi)N
×
X",N/A,N/A
"((aq/bi)xi, (aq/f)xi, (aq/g)xi, (aq/bifg)xi)N
×
X
δ∈Nn
zδ1
1 · · · zδn
n
q
c
|δ|
q−e2(δ) ∆(zqδ)
∆(z)
Y
1≤i≤n
1 −(q−N−1Bfg/a)q|δ|+δizi
1 −(q−N−1Bfg/a)zi
×
Y
1≤i≤n
((q−NBfg/a)zi)|δ|
((q−Nfg/a)zi)|δ|
Y
1≤i,j≤n
(bjzi/zj)δi
(qzi/zj)δi
×(f, g, q−N)|δ|
(aq/c)|δ|
Y
1≤i≤n
((q−N−1Bcfg/a2)zi)δi
((Bfg/a)zi, (q−NBg/a)zi, (q−NBf/a)zi)δi
.
where zi = ei
E x−1
i .
Rectangular version
Corollary 4.7.
X
γ∈Nn
xγ1
1 · · · xγn
n
a2q|M|+2
bcfg
|γ|
q−e2(γ) ∆(xqγ)
∆(x)
Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.34)
×
Y
1≤i≤n",N/A,N/A
"Y
1≤i≤n
1 −aq|γ|+γixi
1 −axi
(4.34)
×
Y
1≤i≤n
(axi)|γ|
(aq|M|+1xi)|γ|
Y
1≤i,j≤n
(q−mjxi/xj)γi
(qxi/xj)γi
×(b, f, g)|γ|
(aq/c)|γ|
Y
1≤i≤n
(cxi)γi
((aq/b)xi, (aq/f)xi, (aq/g)xi)γi
=
Y
1≤i≤n
(aqxi, (aq/bf)xi, (aq/bg)xi, (aq/fg)xi)mi
((aq/b)xi, (aq/f)xi, (aq/g)xi, (aq/bfg)xi)mi
×
X
δ∈Nn
zδ1
1 · · · zδn
n
q
c
|δ|
q−e2(δ) ∆(zqδ)
∆(z)
Y
1≤i≤n
1 −(q−|M|−1bfg/a)q|δ|+δizi
1 −(q−|M|−1bfg/a)zi
×
Y
1≤i≤n
((q−|M|bfg/a)zi)|δ|
((q−|M|fg/a)zi)|δ|
Y
1≤i,j≤n
(q−mjzi/zj)δi
(qzi/zj)δi
×(b, f, g)|δ|
(aq/c)|δ|
Y",N/A,N/A
"(qzi/zj)δi
×(b, f, g)|δ|
(aq/c)|δ|
Y
1≤i≤n
((q−|M|−1bcfg/a2)zi)δi
((q−|M|fg/a)zi, (q−|M|bg/a)zi, (q−|M|bf/a)zi)δi
.
where zi = qmi−|M|x−1
i .
Remark 4.9. In the case when n = 1 and x1 = 1, (4.33) and (4.34) reduces to the following
terminating 8W7 transformation:
8W7

a; b, c, f, g, q−N; q; a2q2+N
bcfg

= (aq, aq/bf, aq/bg, aq/fg)N
(aq/b, aq/f, aq/g, aq/bfg)N
(4.35)
8W7
h
q−N−1bfg/a; b, q−N−1bcfg/a2, f, g, q−N; q; q
c
i
.
(4.33) can also be obtained by taking the limit d →∞in (4.11).",N/A,N/A
"Remark 4.10. An Watson transformation (4.12) can be obtained by combining (4.33) and (4.16)
and by combining (4.16) and An Sears transformations formula (4.28).
27
8W7 series in An
8W7 series in An
✲
(4.33)
4φ3 series in An
4φ3 series in An
✲
(4.28)
❄
❄
(4.16)
(4.16)
❳❳❳❳❳❳❳❳❳❳❳❳
③
(4.12)
As we have seen in this section, our discussion here may implies not only that our class of
multiple hypergeometric transformations in the previous section are broader class than Milne‘s",N/A,N/A
"class of transformation in An but also that our class contains more precise informations. In
our terminology, one may see that Milne‘s hypergeometric transformations have extra hidden
symmetries in the one dimensional (generalized) hypergeometric series.
Acknowledgments
I would like to express my sincere thanks to Professors Etsuro Date and Masatoshi Noumi for
their encouragements.
References
[1] G.E. Andrews: The well-poised thread: an organized chronicle of some amazing summa-",N/A,N/A
"tions and their implications. Ramanujan J. 1 (1997), 7–23.
[2] W.N. Bailey: Some identities involving generalized hypergeometric series. Proc. London
Math. Soc. (2), 29(1929), 503–516.
[3] W.N. Bailey: Generalized hypergeometric series. Cambridge Tracts (1935).
[4] G. Bhatnagar, M .Schlosser: Cn and Dn very-well-poised 10φ9 transformations. Constr.
Approx. 14, (1998), 531–567.
[5] I.B. Frenkel, V.G. Turaev: Elliptic solution of Yang-Baxter equation and modular hyper-",N/A,N/A
"geometric functions. The Arnold-Gelfand seminars, Birkhauser Boston 1997, 171–204.
[6] G. Gasper: Summation formulas for basic hypergeometric series. SIAM J. Math. Anal. 12
(1981), no. 2, 196–200.
[7] G. Gasper, M. Rahman: Basic hypergeometric series. (2nd. ed.) Encyclopedia of Mathe-
matics and Its Applications, (G.C.Rota, ed.), vol. 35, Cambridge Univ. press, Cambridge,
2004.
[8] R.A.Gustafson: A Whipple transformation for hypergeometric series in U(n) and multi-",N/A,N/A
"variable hypergeometric orthogonal polynomials. SIAM J. Math. Anal. 18 (1987), 495–530.
[9] W. J. Holman: Summation theorems for hypergeometric series in U(n). SIAM J. Math
Anal. 11(1980), 523–532.
[10] W. J. Holman, L.C, Biedenharn, J.D.Louck:
On hypergeometric series well-poised in
SU(n). SIAM J. Math Anal. 7(1976), 529–541.
[11] J. Horn:
Ueber die Convergenz der hypergeometrische Reihen zweier und dreier
Ve¨anderlichen. Math. Ann 34 (1889), 544-600.",N/A,N/A
"Ve¨anderlichen. Math. Ann 34 (1889), 544-600.
[12] Y. Kajihara: Some remarks on multiple Sears transformation formula. Contemp. Math
291 (2001), 139–45.
28
[13] Y. Kajihara: Euler transformation formula for multiple basic hypergeometric series of type
A and some applications. Adv in Math 187 (2004), 53–97.
[14] Y.Kajihara: Multiple Generalizations of q-Series Identities and Related Formulas. in ”Par-
tition, q-series and Modular form. (ed. K. Alladi and F. Garvan)” Development of Math.",N/A,N/A
"23 (2012), 159–pp 180.
[15] Y. Kajihara, M. Noumi: Multiple Elliptic hypergeometric series – An approach from Cauchy
determinant – Indag. Math. New Ser. 14 (2003), 395–421.
[16] P.W. Karlsson: Hypergeometric functions with integral parameter diﬀerences.
J. Math.
Phys. 12 (1971), 270–271.
[17] S.C. Milne: An elementary proof of Macdonald identities for A(1)
l
. Adv. in Math. 57,
(1985), 34–70.
[18] S.C. Milne: A q-analogue of hypergeometric series well-poised in SU(n) and invariant",N/A,N/A
"G-functions. Adv. in Math. 58 (1985), 1–60.
[19] S.C. Milne. A q-analogue of the Gauss summation theorem for hypergeometric series in
U(n). Adv. in Math. 72 (1988), pp 59–131.
[20] S.C. Milne: A q-analogue of a Whipple’s transformation of hypergeometric series in U(n).
Adv. in Math. 108, (1994), 1–76.
[21] S.C. Milne: Balanced 3φ2 summation formulas for U(n) basic hypergeometric series. Adv.
in Math. 131, (1997), 93–187.",N/A,N/A
"in Math. 131, (1997), 93–187.
[22] S.C. Milne: Transformations of U(n + 1) multiple basic hypergeometric series. in ”Physics
and combinatorics 1999 (Nagoya)”, 201–243, World Sci. publishing, River Edge, NJ, 2001.
[23] S.C. Milne, G. Lilly Consequences of the Al and Cl Bailey transform and Bailey lemma.
Discrete Math 139, (1995), 319–345.
[24] S.C. Milne, J.W. Newcomb: U(n) very-well-poised 10φ9 transformations. J. Comput. Appl.
Math. 68 (1996), no.1-2, 239–285.",N/A,N/A
"Math. 68 (1996), no.1-2, 239–285.
[25] S.C. Milne, J.W. Newcomb. Nonterminating q-Whipple transformation for basic hyperge-
ometric series in U(n). in ”Partition, q-series and Modular form. (ed. K. Alladi and F.
Garvan)” Development of Math. 23 (2012), 181–224.
[26] H. Rosengren: Reduction formulas for Karlsson-Minton-type hypergeometric function. Con-
str. Approx. 20 (2004), 525–548.
[27] H. Rosengren: Elliptic hypergeometric series on root systems. Adv. Math. 181 (2004),
417–447.",N/A,N/A
"417–447.
[28] H. Rosengren, M. Schlosser: Summations and transformations for multiple basic and ellip-
tic hypergeometric series by determinant evaluations. Indag. Math. New Ser. 14, 481–513.
[29] F.J.W. Whipple: A group of generalized hypergeometric series: relations between 120 allied
series of the type F[a, b, c; d, e]. Proc. London Math.Soc. (2) 23 (1925), 104–114.
29",N/A,N/A
"arXiv:1605.08683v1  [math.CV]  27 May 2016
THE FOURIER AND HILBERT TRANSFORMS
UNDER THE BARGMANN TRANSFORM
XING-TANG DONG AND KEHE ZHU
ABSTRACT. There is a canonical unitary transformation from L2(R)
onto the Fock space F 2, called the Bargmann transform. We study the
action of the Bargmann transform on several classical integral opera-
tors on L2(R), including the fractional Fourier transform, the fractional
Hilbert transform, and the wavelet transform.
1. INTRODUCTION",N/A,N/A
"1. INTRODUCTION
The Fock space F 2 is the Hilbert space of all entire functions f on the
complex plane C such that
∥f∥2 =
Z
C
|f(z)|2 dλ(z) < ∞,
where
dλ(z) = 1
πe−|z|2 dA(z)
is the Gaussian measure. Here dA is ordinary area measure. The inner
product on F 2 is inherited from L2(C, dλ). The Fock space is a convenient
setting for many problems in functional analysis, mathematical physics, and
engineering. See [12] for a recent survey of the mathematical theory of Fock
spaces.",N/A,N/A
"spaces.
Another Hilbert space we consider is L2(R) = L2(R, dx). We will study
the (fractional) Fourier transform, the (fractional) Hilbert transform, and
the wavelet transform as bounded linear operators on L2(R). The books
[6, 7, 8, 10] are excellent sources of information for these operators.
2010 Mathematics Subject Classiﬁcation. Primary 30H20; Secondary 42A38; 44A15.
Key words and phrases. Bargmann transform, Fock space, fractional Fourier transform,",N/A,N/A
"fractional Hilbert transform, wavelet transform.
Dong was supported in part by the National Natural Science Foundation of China
(Grant No. 11201331); Zhu was supported by the National Natural Science Foundation
of China (Grant No. 11371234) and the Project of International Science and Technol-
ogy Cooperation Innovation Platform in Universities in Guangdong Province (Grant No.
2014KGJHZ007).
1
2
DONG AND ZHU
The Bargmann transform B is the operator from L2(R) →F 2 deﬁned by
Bf(z) = c
Z
R",N/A,N/A
"Bf(z) = c
Z
R
f(x)e2xz−x2−(z2/2) dx,
where c = (2/π)1/4. It is well known that B is a unitary operator from
L2(R) onto F 2. Furthermore, the inverse of B is also an integral operator,
namely,
B−1f(x) = c
Z
C
f(z)e2xz−x2−(z2/2) dλ(z).
See [7, 8, 12].
The Bargmann transform is an old tool in mathematical analysis and
mathematical physics. See [1, 2, 3, 5, 7, 8] and references there. In this
article we study the action of the Bargmann transform on several classical",N/A,N/A
"integral operators on L2(R). The unitarily equivalent version of these op-
erators on F 2 sometimes takes amazingly simple form, sometimes reveals
interesting properties, and sometimes suggests natural new questions. It is
our hope that this article will generate some new interest in this classical
area of mathematical analysis.
This paper was completed while the ﬁrst author visited the Department of
Mathematics and Statistics at the State University of New York at Albany",N/A,N/A
"for the 2015-2016 academic year. He wishes to thank SUNY-Albany for
hosting his visit.
2. PRELIMINARIES
The standard monomial orthonormal basis for F 2 is given by
en(z) =
r
1
n! zn,
n ≥0.
Thus the reproducing kernel of F 2 is
K(z, w) =
∞
X
n=0
en(z)en(w) =
∞
X
n=0
(zw)n
n!
= ezw.
The identity
f(z) =
Z
C
f(w)K(z, w) dλ(w) =
Z
C
f(w)ezw dλ(w),
f ∈F 2, z ∈C,
is then called the reproducing formula for functions in the Fock space.",N/A,N/A
"To exhibit an orthonormal basis for L2(R), recall that for any n ≥0 the
function
Hn(x) = (−1)nex2 dn
dxne−x2
BARGMANN TRANSFORM
3
is called the nth Hermite polynomial. It is well known that the functions
hn(x) =
c
√
2nn!
e−x2Hn(
√
2x),
n ≥0,
form an orthonormal basis for L2(R), where c = (2/π)1/4 again. See [11,
12] for more information about the Hermite functions.
Lemma 1. For every n ≥0 we have Bhn = en.
Proof. See Theorem 6.8 of [12].
□",N/A,N/A
"Proof. See Theorem 6.8 of [12].
□
As a consequence of Lemma 1 we see that the Bargmann transform is a
unitary operator from L2(R) onto F 2.
The following elementary result along with some of its close relatives
will be used many times later in the paper.
Lemma 2. Let a, b ∈R with a > 0. Then we have
Z
R
e−(a+ib)(x+z)2 dx =
√π
√
a + ib
for every complex number z.
Proof. Write
I(z) =
Z
R
e−(a+ib)(x+z)2 dx,
z ∈C.
It is clear that I(z) is an entire function. Moreover, if we write z = s + it",N/A,N/A
"for real s and t, then
e−(a+ib)(x+z)2 = exp

−ax2 · (x + s)2 −t2 −2tb(x + s)/a
x2

→0
as x →±∞. Differentiating under the integral sign, we obtain
I′(z) = −2(a + ib)
Z
R
(x + z)e−(a+ib)(x+z)2dx = e−(a+ib)(x+z)2

+∞
−∞
= 0
for any z ∈C. It follows that
I(z) = I(0) =
Z
R
e−(a+ib)x2dx = 2
Z +∞
0
e−(a+ib)x2dx.
Since a > 0, we can write
a + ib =
√
a2 + b2 eiγ,
γ ∈

−π
2 , π
2

.
If γ = 0, then b = 0 and the desired result follows immediately. So we
assume γ ̸= 0.",N/A,N/A
"assume γ ̸= 0.
For large positive R we consider the sector
DR =

z = reiθ : 0 < r < R, min(0, γ/2) < θ < max(0, γ/2)
	
4
DONG AND ZHU
in the right half-plane. The domain DR has boundary consisting of three
curves: the interval −→
OA on the real axis, the line segment −−→
BO on the ray
θ = γ/2, and the arc d
AB on the circle |z| = R. Since the function e−z2 is
analytic on DR, it follows form Cauchy’s theorem that
Z
−−→
OB
e−z2dz =
Z
−→
OA
e−z2dz +
Z
d
AB
e−z2dz.
Since γ ∈(−π/2, π/2), we have",N/A,N/A
"Z
d
AB
e−z2dz.
Since γ ∈(−π/2, π/2), we have

Z
d
AB
e−z2dz
 ≤max
z∈d
AB
e−z2 · |γ|R
2
= |γ|Re−R2cosγ
2
→0
as R →+∞. Therefore,
Z +∞
0
e−(a+ib)x2dx =
lim
R→+∞
Z R/ 4√
a2+b2
0
e−(a+ib)x2dx
=
lim
R→+∞
1
√
a + ib
Z
−−→
OB
e−z2dz
=
lim
R→+∞
1
√
a + ib
Z
−→
OA
e−z2dz
=
1
√
a + ib
Z +∞
0
e−x2dx =
√π
2
√
a + ib.
This proves the desired result.
□
3. THE FOURIER TRANSFORM
There are several normalizations for the Fourier transform. We deﬁne the
Fourier transform by
F(f)(x) =
1
√π
Z
R",N/A,N/A
"Fourier transform by
F(f)(x) =
1
√π
Z
R
e−2ixtf(t) dt.
It is well known that the Fourier transform is a unitary operator on L2(R),
and its inverse is given by
F −1(f)(x) =
1
√π
Z
R
e2ixtf(t) dt.
More generally, the notion of fractional Fourier transforms in the form of
fractional powers of the Fourier transform was introduced as early as 1929
(see [11]), and it has become one of the most valuable and powerful tools in
mathematics, quantum mechanics, optics, and signal processing. Thus for",N/A,N/A
"any real angle α we deﬁne the α-angle fractional Fourier transform by
Fα(f)(x) =
√1 −i cot α
√π
eix2 cot α
Z
R
e−2i(xt csc α−cot α
2
t2)f(t) dt,
BARGMANN TRANSFORM
5
where the square root √1 −i cot α is deﬁned such that
arg
√
1 −i cot α ∈(−π/2, π/2].
Obviously, the integral representation above is well deﬁned if sin α ̸= 0.
We deﬁne Fα(f)(x) = f(x) if α = 0 and Fα(f)(x) = f(−x) if α = ±π.
This is consistent with the integral representation above in the sense that
lim
ε→0 Fα+ε = Fα",N/A,N/A
"lim
ε→0 Fα+ε = Fα
for these special values.
Since the trigonometric functions csc and cot are periodic with period
2π, it sufﬁces for us to consider the case α ∈[−π, π]. Clearly, when α = π
2
and α = −π
2, the α-angle fractional Fourier transform becomes the usual
Fourier transform and the inverse Fourier transform, respectively. See [4,
10] for more information about the fractional Fourier transforms.
It is not at all clear from the deﬁnition that Fα is bounded and invertible",N/A,N/A
"on L2(R). There are also issues concerning convergence: it is not clear that
the integral deﬁning Fα(f) converges in L2(R) for arbitrary f ∈L2(R).
The situation will change dramatically once we translate Fα to an operator
on the Fock space. In other words, we will show that, under the Bargmann
transform, the operator Fα : L2(R) →L2(R) is unitarily equivalent to an
extremely simple operator on the Fock space F 2.
Theorem 3. The operator
T = BFαB−1 : F 2 →F 2",N/A,N/A
"Theorem 3. The operator
T = BFαB−1 : F 2 →F 2
is given by Tf(z) = f(e−iαz) for all f ∈F 2.
Proof. For the purpose of applying Fubini’s theorem in the calculations be-
low, we assume that f is any polynomial. Recall that the polynomials are
dense in F 2, and under the inverse Bargmann transform, they become the
Hermite polynomials times the Gauss function, which have very good inte-
grability properties on the real line. We still write c = (2/π)1/4 and also
c′ =
√1 −i cot α
√π
.
6
DONG AND ZHU",N/A,N/A
"c′ =
√1 −i cot α
√π
.
6
DONG AND ZHU
It follows from Fubini’s theorem that
Fα(B−1f)(x)
= cc′eix2 cot α
Z
R
e−2i(xt csc α−cot α
2
t2) dt
Z
C
f(z)e2tz−t2−z2
2 dλ(z)
= cc′eix2 cot α
Z
C
f(z)e−z2
2 dλ(z)
Z
R
e2t(z−ix csc α)−(1−i cot α)t2 dt
= cc′eix2 cot α
Z
C
f(z)e−z2
2 + (z−ix csc α)2
1−i cot α
dλ(z)
Z
R
e−(1−i cot α)(t−z−ix csc α
1−i cot α )2 dt.
By Lemma 2, we have
Fα(B−1f)(x) = ceix2 cot α
Z
C
f(z)e−z2
2 + (z−ix csc α)2
1−i cot α
dλ(z)
= ce(i cot α−
csc2 α
1−i cot α)x2 Z
C
f(w)e
1+i cot α",N/A,N/A
"csc2 α
1−i cot α)x2 Z
C
f(w)e
1+i cot α
2(1−i cot α) w2−2i csc α
1−i cot αxw dλ(w).
After simpliﬁcation, the expression above becomes
Fα(B−1f)(x) = ce−x2 Z
C
f(w)e−e−2iαw2/2+2e−iαxw dλ(w).
(1)
Therefore,
BFαB−1f(z)
= c2
Z
R
e2xz−z2
2 −2x2 dx
Z
C
f(w)e−e−2iαw2/2+2e−iαxw dλ(w)
= c2e−z2
2
Z
C
f(w)e−e−2iαw2/2 dλ(w)
Z
R
e2x(z+e−iαw)−2x2 dx
= c2e−z2
2
Z
C
f(w)e−e−2iαw2
2
+ (z+e−iαw)2
2
dλ(w)
Z
R
e
−2

x−z+e−iαw
2
2
dx.
It follows from Lemma 2 again that
Z
R
e
−2

x−z+e−iαw
2
2
dx =
rπ
2 = 1
c2.",N/A,N/A
"Z
R
e
−2

x−z+e−iαw
2
2
dx =
rπ
2 = 1
c2.
Therefore, we have
BFαB−1f(z) =
Z
C
f(w)ee−iαzw dλ(w).
This together with the reproducing formula for functions in F 2 gives
BFαB−1f(z) = f(e−iαz),
which completes the proof of the theorem.
□
BARGMANN TRANSFORM
7
Since the classical Fourier transform F is just Fα with α = π
2, we see
that the Fourier transform on L2(R) is unitarily equivalent to the operator
f(z) →f(−iz) on F 2. This is well known to experts in the ﬁeld and can
be found in [1, 2].",N/A,N/A
"be found in [1, 2].
As a consequence of Theorem 3, we immediately derive a number of
basic properties for the fractional Fourier transform Fα. In particular, we
obtain an alternative proof of the fractional Fourier inversion formula and
the associated Plancherel’s formula.
Corollary 4. The α-angle fractional Fourier transform Fα is a unitary op-
erator on L2(R), so thatZ
R
|Fα(f)|2 dx =
Z
R
|f|2 dx
for all f ∈L2(R). Furthermore, (Fα)−1 = F−α.",N/A,N/A
"for all f ∈L2(R). Furthermore, (Fα)−1 = F−α.
Proof. This is obvious from the unitarily equivalent form of Fα on the Fock
space.
□
The following result is also clear from our new representation of the
fractional Fourier transform on the Fock space, because an entire function
uniquely determines its Taylor coefﬁcients.
Corollary 5. For each n ≥0 the Hermite function hn is an eigenvector
of the fractional Fourier transform Fα and the corresponding eigenvalue is
e−inα.",N/A,N/A
"e−inα.
The corollary above actually gives the complete spectral picture for the
unitary operator Fα on L2(R). More speciﬁcally, if α is a rational multiple
of π, then the spectrum of Fα : L2(R) →L2(R) is given by
σ(Fα) =

e−inα : n = 0, 1, 2, · · ·
	
,
which consists of only ﬁnitely many points on the unit circle. If α is an
irrational multiple of π, then σ(Fα) is the entire unit circle. In particular,
if we specialize to the case α = π/2, we obtain the following spectral",N/A,N/A
"decomposition for the classical Fourier transform F.
Corollary 6. For each 0 ≤k ≤3 let Xk denote the closed subspace
of L2(R) spanned by the Hermite functions hk+4m, m ≥0, and let Pk :
L2(R) →Xk be the orthogonal projection. Then
L2(R) =
3
M
k=0
Xk,
and the corresponding spectral decomposition for the unitary operator F :
L2(R) →L2(R) is given by F = P0 −iP1 −P2 + iP3. In particular, the
8
DONG AND ZHU
ﬁxed points of the Fourier transform F are exactly functions of the form
f(x) =
∞
X
n=0",N/A,N/A
"f(x) =
∞
X
n=0
cnh4n(x),
{cn} ∈l2.
Each Xk is nothing but the eigenspace of the Fourier transform F corre-
sponding to the eigenvalue (−i)k. If we write α = aπ/2, then the eigenval-
ues of Fα and F for eigenfunctions hn have the following relation:
e−inα =
 e−in π
2 a ,
n ≥0.
Since the functions hn(x) form an orthonormal basis for L2(R), it is then
clear that we can naturally think of the fractional Fourier transform Fα as a
fractional power of the Fourier transform F.
4. THE HILBERT TRANSFORM",N/A,N/A
"4. THE HILBERT TRANSFORM
The Hilbert transform is the singular integral operator deﬁned by
Hf(x) = 1
π
Z
R
f(t)dt
x −t ,
where the improper integral is taken in the sense of principal value. It is well
known that the Fourier transform of Hf(x) is −i sgn(x)F(f)(x). Thus H
is a unitary operator on L2(R) and
Hf(x) = F −1 [−i sgn(x)F(f)(x)] .
Observe that
−i sgn(x) = e−iπ/2h(x) + eiπ/2h(−x),
where h(x) is the Heaviside step function: h(x) = 1 for x ≥0 and h(x) = 0",N/A,N/A
"for x < 0. So it is natural to deﬁne fractional Hilbert transforms as follows.
Hα
φ f(x) = F −1
α
 e−iφh(x) + eiφh(−x)

Fα(f)(x)

,
where α and φ are real parameters. For φ = π/2 and α = π/2 we recover
the classical Hilbert transform.
Since each fractional Fourier transform Fα is a unitary operator on L2(R),
the fractional Hilbert transform Hα
φ is also a unitary operator on L2(R). The
operators Hα
φ play an important role in optics and signal processing. See",N/A,N/A
"[4, 9] for more information about fractional Hilbert transforms.
In order to identify the operator on the Fock space that corresponds to
the fractional Hilbert transform Hα
φ : L2(R) →L2(R), we need the entire
BARGMANN TRANSFORM
9
function
Aφ(z) =
√π
2
 e−iφ + eiφ
+
Z z
0
 e−iφ −eiφ
e−u2 du
= √π cos φ −2i sin φ
Z z
0
e−u2 du.
Theorem 7. The operator
T = BHα
φ B−1 : F 2 →F 2
is given by
Tf(z) =
1
√π
Z
C
f(w)ezwAφ
eiαz + e−iαw
√
2

dλ(w)
for all f ∈F 2.",N/A,N/A
"eiαz + e−iαw
√
2

dλ(w)
for all f ∈F 2.
Proof. For c = (2/π)1/4 again and f ∈F 2 (we may start out with a poly-
nomial in order to justify the use of Fubini’s theorem), it follows from (1)
that
B
 e−iφh(x) + eiφh(−x)

Fα
 B−1f

(x)

= c2
Z
R
e2xz−z2
2 −2x2  e−iφh(x) + eiφh(−x)

dx
Z
C
f(w)e−(e−iαw)2
2
+2e−iαxw dλ(w)
= c2
Z
C
f(w)ee−iαzwdλ(w)
Z
R
e
−2

x−z+e−iαw
2
2  e−iφh(x) + eiφh(−x)

dx.
By Theorem3, we have
BF −1
α B−1f(z) = f(eiαz).",N/A,N/A
"By Theorem3, we have
BF −1
α B−1f(z) = f(eiαz).
Combining this with the integral formula above, we obtain
Tf(z)
= BF −1
α B−1B
 e−iφh(x) + eiφh(−x)

Fα
 B−1f

(x)

= c2
Z
C
f(w)ezw dλ(w)
Z
R
e
−2

x−eiαz+e−iαw
2
2  e−iφh(x) + eiφh(−x)

dx
=
1
√π
Z
C
f(w)ezw dλ(w)
Z
R
e
−

x−eiαz+e−iαw
√
2
2  e−iφh(x) + eiφh(−x)

dx.
Consider the entire function
J(z) =
Z
R
e−(x+z)2  e−iφh(x) + eiφh(−x)

dx.
10
DONG AND ZHU
By the same argument used in the proof of Lemma 2, we have
J′(z) = d
dz

e−iφ",N/A,N/A
"J′(z) = d
dz

e−iφ
Z +∞
0
e−(x+z)2 dx + eiφ
Z 0
−∞
e−(x+z)2 dx

= −2e−iφ
Z +∞
0
(x + z) e−(x+z)2 dx −2eiφ
Z 0
−∞
(x + z) e−(x+z)2 dx
= e−iφe−(x+z)2
+∞
0
+ eiφe−(x+z)2
0
−∞
= −e−iφe−z2 + eiφe−z2,
and
J(0) = e−iφ
Z +∞
0
e−x2 dx + eiφ
Z 0
−∞
e−x2 dx =
√π
2
 e−iφ + eiφ
.
Therefore,
J(z) =
Z z
0
 −e−iφ + eiφ
e−u2du +
√π
2
 e−iφ + eiφ
= Aφ(−z).
Thus
Tf(z) =
1
√π
Z
C
f(w)ezwJ

−eiαz + e−iαw
√
2

dλ(w)
=
1
√π
Z
C
f(w)ezwAφ
eiαz + e−iαw
√
2

dλ(w).
This proves the desired result.
□",N/A,N/A
"√
2

dλ(w).
This proves the desired result.
□
The operator T above appears to be a very interesting integral opera-
tor on the Fock space, although we are unable to verify directly that T is
bounded on F 2. A natural problem here is to study the spectral proper-
ties of the integral operator T above on F 2, or equivalently, the fractional
Hilbert transform as an operator on L2(R). Not much seems to be known,
which is in sharp contrast to the case of the fractional Fourier transform.",N/A,N/A
"Corollary 8. For any real α and φ we have
Hα
φ = (cos φ)I + (sin φ)Hα
π/2
and
Hπ/2
φ
= (cos φ)I + (sin φ)H,
where I is the identity operator.
Proof. The desired results follow easily from the decomposition
Aφ(z) = √π cos φ + (sin φ)Aπ/2(z)
and the reproducing formula for functions in the Fock space.
□
BARGMANN TRANSFORM
11
As a generalization of the Hilbert transform, the second formula in the
corollary above was actually used as one of the deﬁnitions for the fractional",N/A,N/A
"Hilbert transform in [9].
Corollary 8 also shows clearly how Hα
φ depends on φ. It appears that
introducing an extra angle φ (other than π/2) does not really produce some-
thing new. In particular, for any φ ∈(0, π/2) the operator Hπ/2
φ
is a convex
combination of the identity operator I and the ordinary Hilbert transform
H.
As a consequence of Theorem 7 we also obtain the following result which
can be found in [13, Theorem 1].",N/A,N/A
"can be found in [13, Theorem 1].
Corollary 9. Suppose A(z) is the anti-derivative of ez2 with A(0) = 0 and
S = BHB−1. Then
Sf(z) =
2
√π
Z
C
f(w)ezwA
z −w
√
2

dλ(w)
for all f ∈F 2 and z ∈C.
Proof. Since H = Hα
φ with φ = π
2 and α = π
2, and
Aπ/2(z) = −2i
Z z
0
e−u2 du = 2
Z −iz
0
eu2 du = 2A(−iz),
it follows from Theorem 7 that
Sf(z) =
1
√π
Z
C
f(w)ezwAπ/2
iz −iw
√
2

dλ(w)
=
2
√π
Z
C
f(w)ezwA
z −w
√
2

dλ(w),
as desired.
□
5. SINGULAR INTEGRAL OPERATORS ON F 2",N/A,N/A
"□
5. SINGULAR INTEGRAL OPERATORS ON F 2
Motivated by Corollary 9, the second author in [13] proposed to study
the boundedness of more general “singular integral operators” on F 2 of the
form
Sϕf(z) =
Z
C
f(w)ezwϕ (z −w) dλ(w),
where ϕ is any function in F 2. In view of Theorem 7, it is also natural for
us to consider integral operators on F 2 of the form
Sα
ϕf(z) =
Z
C
f(w)ezwϕ
 eiαz −e−iαw

dλ(w),
where α is a real parameter. Note that we have made an adjustment here so
that Sα",N/A,N/A
"that Sα
ϕ becomes Sϕ when α = 0.
12
DONG AND ZHU
The most fundamental problem in this direction is to characterize those
ϕ ∈F 2 such that Sϕ is bounded on F 2. The extra parameter α in Sα
ϕ does
not yield additional difﬁculty, because Sα
ϕ is unitarily equivalent to Sϕ via
the Fock space version of the fractional Fourier transform Fα. In fact, if we
write Uα = BFαB−1, so that Uαf(z) = f(e−iαz) for f ∈F 2, then Uα is a
unitary operator on F 2 and by the simple change of variables w = e−iαu,
Sα",N/A,N/A
"Sα
ϕf(z) =
Z
C
f(e−iαu)ezeiαuϕ(eiαz −u) dλ(u) = U−αSϕUαf(z).
Thus Sα
ϕ and Sϕ are unitarily equivalent as operators on F 2.
Several non-trivial examples of Sϕ were considered in [13]. It is still an
open question to characterize the boundedness of Sϕ in terms of properties
of ϕ. In this section we will construct additional examples of bounded
operators Sϕ on F 2. Our construction is based on the wavelet transform as
an operator on L2(R).",N/A,N/A
"an operator on L2(R).
Fix g ∈L2(R) and s ∈R with s ̸= 0, the continuous wavelet transform
of f with respect to the “wavelet” g is deﬁned to be
Wg(f)(x) =
1
p
|s|π
Z
R
f(t)g(s−1(t −x)) dt,
f ∈L2(R).
It is well known that the Fourier transform of Wg(f) is given by
|s|1/2F(g)(sx)F (f) (x).
See [8] for more information about the wavelet transform. So the corre-
sponding operator on the Fock space is deﬁned by
BWgB−1f(z) = BF −1 h
DsF(g)F
 B−1f
i
(z),
f ∈F 2,",N/A,N/A
"DsF(g)F
 B−1f
i
(z),
f ∈F 2,
where Ds : L2(R) →L2(R) is the dilation operator deﬁned by
Dsg(x) = |s|1/2g(sx).
Lemma 10. The operator
T = BWgB−1 : F 2 →F 2
is given by
Tf(z) =
r
|s|
π
Z
C
f(w)ezw dλ(w)
Z
R
g(t)e−s2
2 t2−st(z−w) dt
for all f ∈F 2.
Proof. For c = (2/π)1/4 and any polynomial f in F 2, it follows from (1)
that
F
 B−1f

(x) = ce−x2 Z
C
f(w)e
w2
2 −2ixw dλ(w).
BARGMANN TRANSFORM
13
Therefore,
B
h
DsF(g)F
 B−1f
i
(z)
= c2p
|s|
√π
Z
R
e2xz−z2
2 −2x2 dx
Z
C
f(w)e
w2
2 −2ixwdλ(w)
Z
R",N/A,N/A
"R
e2xz−z2
2 −2x2 dx
Z
C
f(w)e
w2
2 −2ixwdλ(w)
Z
R
g(t)e2ixst dt
= c2p
|s|
√π
Z
C
f(w)dλ(w)
Z
R
g(t) dt
Z
R
e2x(z−iw+ist)−2x2−z2
2 + w2
2 dx
= c2p
|s|
√π
Z
C
f(w)e−izw dλ(w)
Z
R
g(t)e−s2
2 t2+ist(z−iw)dt
Z
R
e−2(x−z−iw+ist
2
)
2
dx
=
p
|s|
√π
Z
C
f(w)e−izw dλ(w)
Z
R
g(t)e−s2
2 t2+ist(z−iw) dt.
Recall from Theorem 3 that
BF −1B−1f(z) = f(iz).
Thus we have
T(f)(z) = BF −1B−1B
h
DsF(g)F
 B−1f
i
(z)
=
p
|s|
√π
Z
C
f(w)ezw dλ(w)
Z
R
g(t)e−s2
2 t2−st(z−w) dt.
This proves the desired result.
□",N/A,N/A
"This proves the desired result.
□
As a consequence of Lemma 10 we obtain a class of functions ϕ ∈F 2
such that the associated singular integral operator Sϕ is bounded on F 2.
Corollary 11. For any g ∈L1(R) ∩L2(R) and s ̸= 0 the function
ϕ(z) =
r
|s|
π
Z
R
g(t)e−s2
2 t2−tsz dt
belongs to the Fock space F 2 and the corresponding operator Sϕ is bounded
on F 2.
Proof. By an obvious change of variables, there is a constant C1 such that
ϕ(z) = C1
Z
R
g
 
−
√
2
s x
!
e−x2+
√
2xz dx.
The function",N/A,N/A
"Z
R
g
 
−
√
2
s x
!
e−x2+
√
2xz dx.
The function
h(x) = g
 
−
√
2
s x
!
is still in L2(R) and there is another constant C2 such that
ϕ(z) = C2e
1
4z2Bh(z/
√
2),
14
DONG AND ZHU
where B is the Bargmann transform. Since the function Bh is in F 2, we
have
Z
C
|ϕ(z)|2 dλ(z) = |C2|2
Z
C
e
1
4z2Bh
 z
√
2

2
dλ(z)
= 2|C2|2
Z
C
|Bh(w)|2|ew2|e−|w|2 dλ(w)
≤2|C2|2
Z
C
|Bh(w)|2 dλ(w) < ∞.
This shows that the function ϕ is in F 2.",N/A,N/A
"This shows that the function ϕ is in F 2.
By Lemma 10, the wavelet transform Wg is unitarily equivalent to Sϕ.
Since g ∈L1(R), it is clear from Young’s inequality for the convolution
operator that Wg is bounded on L2(R). This proves the desired result.
□
We will consider two special cases of ϕ ∈F 2 that arise from Corol-
lary 11.
First, for any nonnegative integer n, let gn be the monomial xn times the
Gauss function e−x2, and let ϕn denote the corresponding function from",N/A,N/A
"Corollary 11. We have g0(x) = e−x2 and g1(x) = xe−x2. It follows that
ϕ0(z) =
r
|s|
π
Z
R
e−(s2+2)
2
t2−tsz dt =
r
2|s|
s2 + 2e
s2
2(s2+2) z2
and
ϕ1(z) =
r
|s|
π
Z
R
te−(s2+2)
2
t2−tsz dt = −
sz
s2 + 2ϕ0(z).
For gn(x) = xne−x2 with n ≥2 we have
ϕn(z) =
r
|s|
π
Z
R
tne−(s2+2)
2
t2−tsz dt
=
r
|s|
π
Z
R

t +
sz
s2 + 2

tn−1 −
sz
s2 + 2tn−1

e−(s2+2)
2
t2−tsz dt
= −
sz
s2 + 2ϕn−1(z) + n −1
s2 + 2ϕn−2(z).
Therefore, by induction on n, we obtain
ϕn(z) = (anzn + · · · + a1z + a0) e
s2
2(s2+2) z2
,",N/A,N/A
"s2
2(s2+2) z2
,
where
an =
r
2|s|
s2 + 2
(−1)nsn
(s2 + 2)n ̸= 0.
BARGMANN TRANSFORM
15
Second, we consider s = 1 and
g(x) = e−ε
2 x2+bx,
ε > 0, b ∈R.
It is easy to check that the corresponding function ϕ in Corollary 11 is given
by
ϕ(z) =
1
√π
Z
R
e−1+ε
2 t2−t(z−b) dt =
r
2
1 + εe
1
2(1+ε) (z−b)2.
It follows that the operator Sϕ induced by ϕ(z) = ea(z−b)2 ∈F 2, where
0 < a < 1/2 and b ∈R, is bounded on F 2. Furthermore, the range for a is
best possible. The case b = 0 was proved in [13].",N/A,N/A
"best possible. The case b = 0 was proved in [13].
It is natural to wonder whether Corollary 11 might suggest a characteri-
zation for the boundedness of Sϕ on F 2, namely, is it true that Sϕ is bounded
on F 2 if and only if ϕ came from a function g ∈L1(R) ∩L2(R) via the
integral transform in Corollary 11. Unfortunately, the answer is negative.
In fact, if we take s = −1 and g(x) =
1
√πx, then g is not in L1(R) ∩L2(R),
Wg(f)(x) = 1
π
Z
R
f(t)
x −t dt = H(f)(x),",N/A,N/A
"Wg(f)(x) = 1
π
Z
R
f(t)
x −t dt = H(f)(x),
and the corresponding function ϕ is given by
ϕ(z) = 1
π
Z
R
e−t2
2 +tz
t
dt = 1
π
Z
R
e−t2+
√
2tz
t
dt,
where the integral above is a “principle value” integral. We can rewrite this
PV-integral in the form of an ordinary integral as follows:
ϕ(z) = 1
π
Z
R
e−t2(e
√
2tz −1)
t
dt.
The singularity at t = 0 and the singularity at inﬁnity are both gone. Thus
we can differentiate inside the integral sign to get
ϕ′(z) =
√
2
π
Z
R
e−t2+
√
2tz dt =
√
2
π e
z2
2",N/A,N/A
"ϕ′(z) =
√
2
π
Z
R
e−t2+
√
2tz dt =
√
2
π e
z2
2
Z
R
e−(t−z/
√
2)2 dt =
r
2
πe
z2
2 .
Recall that A(z) is the anti-derivative of ez2 with A(0) = 0. Since ϕ(0) = 0,
we must have
ϕ(z) =
2
√πA
 z
√
2

.
It follows from the Taylor expansion of ϕ, the standard orthonormal ba-
sis of F 2, and Stirling’s formula that ϕ ∈F 2. Moreover, it follows from
Lemma 10 that BHB−1 = Sϕ. Recall that the Hilbert transform H is a
unitary operator on L2(R), so Sϕ is also bounded on F 2. This gives an
16",N/A,N/A
"16
DONG AND ZHU
alternative proof of Corollary 9 and shows that the functions ϕ in Corol-
lary 11 generated by g ∈L1(R) ∩L2(R) cannot characterize all bounded
operators Sϕ on F 2.
REFERENCES
[1] V. Bargmann, On a Hilbert space of analytic functions and an associated integral
transform I, Comm. Pure Appl. Math. 14 (1961), 187-214.
[2] V. Bargmann, On a Hilbert space of analytic functions and an associated integral
transform II, Comm. Pure Appl. Math. 20 (1967), 1-101.",N/A,N/A
"[3] C. Berger and L. Coburn, Heat ﬂow and Berezin-Toeplitz estimates, Amer. J. Math.
116 (1994), 563-590.
[4] A. Bultheel and H. Mart´ınez, Recent developments in the theory of the fractional
Fourier transforms and linear canonical transforms. Bull. Belg. Math. Soc. Simon
Stevin 13 (2007), 971-1005.
[5] L. Coburn, The Bargmann isometry and Gabor-Daubechies wavelet localization op-
erators, in Systems, Approximation, Singular Integral Operators, and Related Topics,",N/A,N/A
"(Bordeaux 2000), 169-178; Oper. Theory Adv. Appl. 129, Birkhauser, Basel, 2001.
[6] G. Folland, Fourier Analysis and Its Applications, Brooks/Cole Publishing Company,
1992.
[7] G. Folland, Harmonic Analysis in Phase Space, Ann. Math. Studies 122, Princeton
University Press, 1989.
[8] K. Gr¨ochenig, Foundations of Time-Frequency Analysis, Birkh¨auser, Boston, 2001.
[9] A.W. Lohmann, D. Mendlovic, and Z. Zalevsky, Fractional Hilbert transform. Optics
Letters, 21 (1996), 281-283.",N/A,N/A
"Letters, 21 (1996), 281-283.
[10] H.M. Ozaktas, Z. Zalevsky, and M.A. Kutay, The Fractional Fourier Transform: with
Applications in Optics and Signal Processing, Wiley, Chichester, 2001.
[11] N. Wiener, Hermitian polynomials and Fourier analysis. J. Math. Phys., 8 (1929),
70-73.
[12] K. Zhu, Analysis on Fock Spaces, Springer, New York, 2012.
[13] K. Zhu, Singular integral operators on the Fock space, Integr. Equat. Oper. Theory,
81 (2015), 451-454.",N/A,N/A
"81 (2015), 451-454.
[14] K. Zhu, Towards a dictionary for the Bargmann transform (arXiv:1506.06326, June
2015), manuscript not for publication.
DEPARTMENT OF MATHEMATICS, TIANJIN UNIVERSITY, TIANJIN 300354, CHINA.
E-mail address: dongxingtang@163.com
DEPARTMENT OF MATHEMATICS, SHANTOU UNIVERSITY, SHANTOU, GUANGDONG
515063, CHINA, AND DEPARTMENT OF MATHEMATICS AND STATISTICS, SUNY, AL-
BANY, NY 12222, USA.
E-mail address: kzhu@math.albany.edu",N/A,N/A
"arXiv:math/0208009v1  [math.GM]  1 Aug 2002
2000]83F05 Cosmology.
THE MATHEMATICAL UNIVERSE IN A NUTSHELL
K. K. NAMBIAR
Abstract. The mathematical universe discussed here gives models of possible
structures our physical universe can have.
Keywords—Cosmology, White Hole, Black Whole.
1. Introduction
When we talk about the universe, we usually mean the physical universe around
us, but then we must recognize that we are capable of visualizing universes which",N/A,N/A
"are quite diﬀerent from the one we live in. The possible universes that we can
reasonably imagine is what we collectively call the mathematical universe. There is
yet another universe which we may call the spiritual universe, a universe hard to
avoid and to deﬁne. We will accept a weak deﬁniton of the spiritual universe as the
collection of unveriﬁable persistent emotional beliefs within us that are diﬃcult to
analyze. Our description makes it clear that spiritual universe is beyond and the",N/A,N/A
"physical universe is within the mathematical universe. As a matter of record, here
are the three universes we are interested in:
• Physical universe
• Mathematical universe
• Spiritual universe
The purpose of this paper is to discuss the mathematical universe in some detail,
so that we may have a deeper understanding of the physical universe and a greater
appreciation for the spiritual universe.
2. Mathematical Logic
We want to talk about what the mathematicians call an axiomatic derivation",N/A,N/A
"and what the computer scientists call a string manipulation. A familiar, but unem-
phasized fact is that it is the string manipulation of the four Maxwell’s equations
that allowed us to predict the radiation of electromagnetic waves from a dipole
antenna. Similarly, it is the derivations in Einstein’s theory of relativity that con-
vinced us about the bending of light rays due to gravity. It is as though nature
dances faithfully to the tune that we write on paper, as long as the composition",N/A,N/A
"strictly conforms to certain strict mathematical rules.
It was the Greeks who ﬁrst realized the power of the axiomatic method, when
they started teaching elementary geometry to their school children. Over the years
logicians have perfected the method and today it is clear to us that it not necessary
to draw geometrical ﬁgures to prove theorems in geometry. Without belaboring the
point, we will make a long story short, and state some of the facts of mathematical",N/A,N/A
"logic that we have learned to accept.
Date: July 12, 2002.
1991 Mathematics Subject Classiﬁcation. [.
1
2
K. K. NAMBIAR
Mathematical logic reaches its pinnacle when it deals with Zermelo-Fraenkel set
theory (ZF theory). Here is a set of axioms which deﬁne ZF theory.
• Axiom of Extensionality: ∀x(x ∈a ⇔x ∈b) ⇒(a = b).
Two sets with the same members are the same.
• Axiom of Pairing: ∃x∀y(y ∈x ⇔y = a ∨y = b).
For any a and b, there is a set {a, b}.
• Axiom of Union: ∃x∀y(y ∈x ⇔∃z ∈x(y ∈z)).",N/A,N/A
"• Axiom of Union: ∃x∀y(y ∈x ⇔∃z ∈x(y ∈z)).
For any set of sets, there is a set which has exactly the elements of the sets
of the given set.
• Axiom of Powerset: ∀x∃y(y ∈x ⇔∀z ∈y(z ∈a)).
For any set, there is a set which has exactly the subsets of the given set as its
elements.
• Axiom of Inﬁnity: ∃x(∅∈x ∧∀y ∈x(y ∪{y} ∈x)).
There is a set which has exactly the natural numbers as its elements.
• Axiom of Separation: ∃x∀y(y ∈x ⇔y ∈a ∧A(y)).",N/A,N/A
"• Axiom of Separation: ∃x∀y(y ∈x ⇔y ∈a ∧A(y)).
For any set a and a formula A(y), there is a set containing all elements of a
satisfying A(y).
• Axiom of Replacement: ∃x∀y ∈a(∃zA(y, z) ⇒∃z ∈xA(y, z)).
A new set is created when every element in a given set is replaced by a new
element.
• Axiom of Regularity: ∀x(x ̸= ∅⇒∃y(y ∈x ∧x ∩y = ∅)).
Every nonempty set a contains an element b such that a ∩b = ∅.
These axioms assume importance when they are applied to inﬁnite sets. For ﬁnite",N/A,N/A
"sets, they are more or less obvious. The real signiﬁcance of these axioms is that
they are the only strings, other than those of mathematical logic itself, that can be
used in the course of a proof in set theory. Here is an example of a derivation using
the axiom of regularity, which saved set theory from disaster.
Theorem 2.1. a /∈a.
Proof: a ∈a leads to a contradiction as shown below.
a ∈a ⇒a ∈[{a} ∩a] ... (1).
b ∈{a} ⇒b = a ... (2).
Using axiom of regularity and (2),",N/A,N/A
"Using axiom of regularity and (2),
{a} ∩a = ∅, which contradicts, a ∈[{a} ∩a] in (1).
Even though we are in no position to prove it, over a period of time we have built
up enough conﬁdence in set theory to believe that there are no contradictions in it.
3. Generalized Anthropic Principle and The Book
It is generally accepted that all of mathematics can be described in terms of the
concepts of set theory, which in turn means that we can, in principle, axiomatize",N/A,N/A
"any branch of science, if we so wish. This allows us to conceive of an axiomatic
theory which has all of known science in it, and all the phenomena we observe in the
universe having corresponding derivations. Since every derivation in a theory can
be considered as a well-formed formula, we can claim that the set of derivations in
our all-encompassing theory can be listed in the lexicographic order, with formulas
of increasing length. A book which lists all the proofs of this all-encompassing",N/A,N/A
"mathematics is called The Book.
The concept of The Book is an invention of
the mathematician, Paul Erd¨os, perhaps the most proliﬁc mathematician of the
THE MATHEMATICAL UNIVERSE IN A NUTSHELL
3
twentieth century. Note that the book contains an inﬁnite number of proofs, and
also that the lexical order is with respect to the proofs and not with respect to
theorems. It was this book that David Hilbert, the originator of formalism, once",N/A,N/A
"wanted to rewrite with theorems in the lexical order, which of course, turned out
to be an unworkable idea.
Note that a computer can be set up to start writing the book.
We cannot
expect the computer to stop, since there are an inﬁnite number of proofs in our
theory. Thus, a computer generated book will always have to be unﬁnished, the big
diﬀerence between a computer generated book and The Book is that it is a ﬁnished
book.",N/A,N/A
"book.
When discussing cosmology, a notion that is often invoked is called the anthropic
principle. The principle states that we see the universe the way it is, because if it
were any diﬀerent, we would not be here to see it [1]. We generalize this concept
as follows.
Generalized Anthropic Principle: Every phenomenon in the universe
has a corresponding derivation in The Book.
Note that the generalized anthropic principle does not claim that there is a phenom-",N/A,N/A
"enon corresponding to every derivation. Such derivations are part of mathematics,
but not of physics, in other words, we consider the physical universe as part of the
mathematical universe.
4. Expanding Universe
As a preliminary to the understanding of the expanding universe, we will ﬁrst
talk about a perfectly spherical balloon whose radius is increasing with velocity
U, starting with 0 radius and an elapsed time T . If we write UT as R, we have",N/A,N/A
"the volume of the balloon as (4/3)πR3, surface area as 4πR2 and the length of
a great circle as 2πR. In our expanding balloon it is easy to see that two points
which are a distance Rθ apart from each other will be moving away from each other
with velocity Uθ. Since (R/U) = T , it follows that a measurement of the relative
movement of two spots on the balloon will allow us to calculate the age of the
balloon.
The facts about the expanding universe is more or less like that of the balloon,",N/A,N/A
"except that instead of a spherical surface, we have to deal with the hyper surface of
a 4-dimensional sphere of radius R. If we use the same notations as before, we have
the hyper volume of the hyper sphere as (π2/2)R4, the hyper surface as 2π2R3, and
the length of a great circle as 2πR. We can calculate the age of the universe by
measuring the velocity of a receding galaxy near to us. If we assume the velocity
of expansion of the hyper sphere as U, we have UT = R and the volume of the",N/A,N/A
"universe as 2π2R3.
We would have been more realistic, if we were to start oﬀour analysis with a
warped balloon, but then our intention here is only to discuss what is mathemati-
cally possible and not what the actual reality is.
5. Intuitive Set Theory
ZF theory which forms the foundations of mathematics gets simpliﬁed further
to Intuitive Set Theory (IST), if we add two more axioms to it as given below [2].
If k is an ordinal, we will write
 ℵα
k
",N/A,N/A
"If k is an ordinal, we will write
 ℵα
k

for the cardinality of the set of all subsets of
ℵα with the same cardinality as k.
4
K. K. NAMBIAR
Axiom of Combinatorial Sets:
ℵα+1 =
ℵα
ℵα

.
We will accept the fact that every number in the interval (0, 1] can be represented
uniquely by an inﬁnite nonterminating binary sequence. For example, the inﬁnite
binary sequence
.10111111 · · ·
can be recognized as the representation for the number 3/4 and similarly for other",N/A,N/A
"numbers. This in turn implies that an inﬁnite recursive subset of positive integers
can be used to represent numbers in the interval (0, 1]. It is known that the cardi-
nality of the set R of such recursive subsets is ℵ0. Thus, every r ∈R represents a
real number in the interval (0, 1].
We will write
ℵα
ℵα

r
,
to represent the cardinality of the set of all those subsets of ℵα of cardinality ℵα
which contain r, and also write
(ℵα
ℵα

r
 r ∈R
)
=
ℵα
ℵα

R
.",N/A,N/A
"(ℵα
ℵα

r
 r ∈R
)
=
ℵα
ℵα

R
.
We will deﬁne a bonded sack as a collection which can appear only on the left
side of the binary relation ∈and not on the right side. What this means is that
a bonded sack has to be considered as an integral unit from which not even the
axiom of choice can pick out an element. For this reason, we may call the elements
of a bonded sack ﬁgments.
Axiom of Inﬁnitesimals:
(0, 1] =
ℵα
ℵα

R
.",N/A,N/A
"Axiom of Inﬁnitesimals:
(0, 1] =
ℵα
ℵα

R
.
The axiom of inﬁnitesimals makes it easy to visualize the unit interval (0, 1].
We derive the generalized continuum hypothesis from the axiom of combinatorial
sets as below:
2ℵα =
ℵα
0

+
ℵα
1

+
ℵα
2

+ · · ·
ℵα
ℵ0

+ · · ·
ℵα
ℵα

.
Note that
 ℵα
1

= ℵα. Since, there are ℵα terms in this addition and
 ℵα
k

is a
monotonically nondecreasing function of k, we can conclude that
2ℵα =
ℵα
ℵα

.
Using axiom of combinatorial sets, we get",N/A,N/A
"ℵα

.
Using axiom of combinatorial sets, we get
2ℵα = ℵα+1.
The concept of a bonded sack is signiﬁcant in that it puts a limit beyond which
the interval (0, 1] cannot be pried any further. The axiom of inﬁnitesimals allows
us to visualize the unit interval (0, 1] as a set of bonded sacks, with cardinality ℵ0.
Thus,
 ℵα
ℵα

r represents an inﬁnitesimal or white hole or white strip corresponding
to the number r in the interval (0, 1].
THE MATHEMATICAL UNIVERSE IN A NUTSHELL
5",N/A,N/A
"THE MATHEMATICAL UNIVERSE IN A NUTSHELL
5
6. Universal Number System
A real number in the binary number system is usually deﬁned as a two way
binary sequence around a binary point, written as
xxx.xxxxx . . .
in which the left sequence is ﬁnite and the right sequence is nonterminating. Our
discussion earlier, makes it clear that the concept of a real number and a white
strip are equivalent. The two way inﬁnite sequence we get when we ﬂip the real
number around the binary point, written as",N/A,N/A
"number around the binary point, written as
. . . xxxxx.xxx
we will call a supernatural number or a black stretch. The set of white strips we
will call the real line and the set of black stretches the black whole. Since there is
a one-to-one correspondence between the white strips and the black stretches, it
follows that there is a duality between the real line and the black whole.
The name black stretch is supposed to suggest that it can be visualized as a set",N/A,N/A
"of points distributed over an inﬁnite line, but it should be recognized as a bonded
sack, which the axiom of choice cannot access. Our description of the black whole
clearly indicates that it can be used to visualize what is beyond the ﬁnite physical
space.
7. Conclusion
We will conclude with a few remarks about mathematical logic, which give us
some indication why we cannot aﬀord to ignore the spiritual universe. G¨odel tells",N/A,N/A
"us that there is no logical way to establish that there are no contradictions in ZF
theory, which forms the foundations of mathematics. We are conﬁdent about our
mathematics only because it has worked well for us for the last two thousand years.
Since, any set of axioms is a set of beliefs, it follows that any theory is only a set
of beliefs. Since, any individual is the sum total of h(is)er beliefs (axioms) and",N/A,N/A
"rational thoughts (derivations), no individual, including scientists, can claim to be
infallible on any subject matter. If an honest scientist is called to appear in the
ultimate court of nature, (s)he can use The Book for taking the oath, and the most
(s)he can say is: I solemnly swear that if I am sane, I will tell nothing but the truth,
but never the whole truth.
References
1. S. W. Hawking, The Universe in a Nutshell, Bantam Books, New York, NY, 2001.",N/A,N/A
"2. K. K. Nambiar, Visualization of Intuitive Set Theory, Computers and Mathematics with Ap-
plications 41 (2001), no. 5-6, 619–626.
Formerly, Jawaharlal Nehru University, New Delhi, 110067, India
Current address: 1812 Rockybranch Pass, Marietta, Georgia, 30066-8015
E-mail address: kannan@rci.rutgers.edu",N/A,N/A
"1 
 
 
Situating “Ethics in Mathematics“ as a  
Philosophy of Mathematics Ethics Education 
 
Dennis Müller 
RWTH Aachen University, Germany 
dennis.mueller3@rwth-aachen.de 
 
Abstract 
In this paper, we situate the educational movement of “Ethics in Mathematics,” as 
outlined by the Cambridge University Ethics in Mathematics Project, in the wider 
area of mathematics ethics education. By focusing on the core message coming out",N/A,N/A
"of Ethics in Mathematics, its target group, and educational philosophy, we set it 
into relation with “Mathematics for Social Justice” and Paul Ernest’s recent work 
on ethics of mathematics. We conclude that, although both Ethics in Mathematics 
and Mathematics for Social Justice appear antagonistic at first glance, they can be 
understood as complementary rather than competing educational strategies.  
Keywords: Ethics in Mathematics, Mathematics for Social Justice, practical ethics,",N/A,N/A
"Introduction 
Ethics and mathematics are often perceived as two entirely different disciplines: one dealing with the 
questions of leading a moral life and the other dealing with abstract truths (Ernest 2020c). Particularly, 
pure mathematics is often seen as ethically pure and neutral, posing a challenge to those engaging in 
educational work on ethics of mathematics (Ernest 2020a). Few philosophers study the making of",N/A,N/A
"mathematical knowledge with a focus on ethics (Rittberg 2020), and ethics courses specifically 
designed for mathematicians can be found in even fewer universities. Understandably so: Questions 
about the ethics of mathematics, like all ethical questions, entail explosive potential. They can be 
challenging and uncomfortable. Members of the community had a first-hand experience when Colin 
Rittberg spoke about the notion of epistemic injustice at the 2nd Workshop on Ethics in Mathematics",N/A,N/A
"in Cambridge (Rittberg et al. 4/3/2019). Building on anecdotal evidence, Rittberg presented the case 
study of Olivia Caramello who tried to publish a paper about a theorem whose proof had never been 
formally published. Her initial publication was initially denied since the result was supposed to be 
“common knowledge” among a small group of experts. She later on successfully published her work 
(Rittberg et al. 2018). Some workshop participants familiar with the Caramello case left the room",N/A,N/A
"before Rittberg began his talk. Rittberg described these events as a schism in the conference:  
“[S]ome mathematicians got quite upset when I gave this case study. […] It was a 
conference that had a schism and was by far the most exciting conference I ever went 
to.” (Rittberg 10/25/2021) 
2 
 
Rittberg’s notion of epistemic injustice does not go unchallenged in the mathematics education 
literature, and some argue in favor of calling it epistemic exclusion (Baldino and Cabral 2021), a term",N/A,N/A
"which possibly would have led to less controversy among the conference participants. At the 
conference, Rittberg’s idea of epistemic injustice clashed with a commonly found understanding of 
mathematics as an object rather than social practice. Pitsili-Chatzli (2021) outlined how through 
different methods of discourse, these views can be antagonistic when they try to fix a specific meaning 
of mathematics and its elements of proof and formality. Rittberg’s presentation critically examined",N/A,N/A
"the role of culture, power, and ideology in pure mathematics and challenged its practitioners directly.  
However, the schism did not only occur through the explosive nature of the topic but also because it 
set the stage for a heated debate: What is the right way to understand the ethical issues of 
mathematics, its teaching, and practice? Some leaned towards what we describe as “Ethics in 
Mathematics,” while others proclaimed “Mathematics for Social Justice” as the necessary point of",N/A,N/A
"view. In this paper, we try to situate Ethics in Mathematics in this debate. We first outline three 
different educational movements: Ethics in Mathematics (EiM), as developed by the Cambridge 
University Ethics in Mathematics Project, Mathematics for Social Justice, and Paul Ernest’s recent work 
on ethics of mathematics. After that, we further contrast the educational philosophy behind Ethics in",N/A,N/A
"Mathematics with that behind Mathematics for Social Justice. We conclude that Ethics in Mathematics 
and Mathematics for Social Justice can be seen as complementary rather than competing educational 
strategies.  
Overview 
Ethics in Mathematics 
The contrast between, at first glance, ethically neutral and aesthetically pure mathematical objects 
and mathematics as human activity has again come into focus and is being challenged in the small but",N/A,N/A
"growing research area called “Ethics in Mathematics.” Mathematical practice is characterized by 
remarkable freedom: mathematicians create the definitions with which they later continue to work. 
Even if proofs, understood line by line, are often a stringing together of trivial statements and their 
consequences, the overall construct of the proof, from its approach to the mathematical tools used",N/A,N/A
"and its logical structuring, is nevertheless characterized by fundamental freedom (Nickel 2005). Above 
all, mathematical practice is thus a particular form of human action. Ethics in Mathematics takes on 
this idea and presupposes that human actions can never be ethically neutral, and, hence, there are 
ethical consequences in every aspect of mathematics, from its definitions and theorems to its teaching",N/A,N/A
"and its applications, that should be studied and taught. In the following, we outline “Ethics in 
Mathematics” as described by the Cambridge University Ethics in Mathematics Society (CUEIMS 2016) 
and the Cambridge University Ethics in Mathematics Project (CUEiMP 2018).1  
Four Levels of Ethical Engagement 
Much of the early works on Ethics in Mathematics deal with the question of “Is there ethics in",N/A,N/A
"mathematics?” (Müller 2018).  The mathematician’s possible negative reply to this question is taken 
as a challenge from which Chiodo and Bursill-Hall (2018) build a level-based system for a 
mathematician’s ethical engagement: 
- 
Level 0: Believing there is no ethics in mathematics 
- 
Level 1: Realising there are ethical issues inherent in mathematics 
 
1 Other courses and projects have taken on a slightly different position on Ethics in Mathematics. 
3 
 
-",N/A,N/A
"3 
 
- 
Level 2: Doing something: speaking out to other mathematicians 
- 
Level 3: Taking a seat at the tables of power 
- 
Level 4: Calling out the bad mathematics of others 
The ordering of these levels is deeply related to common definitions of good and bad mathematics. 
Mathematicians commonly define “good” mathematics using the logical “OR” operator: mathematics 
is good if it satisfies at least one of N aspects. Tao’s reflections on good mathematics are",N/A,N/A
"representative of this view. He lists 21 different aspects of good mathematics ranging from good 
problem-solving and technique, exposition, taste, and pedagogy, to deep, strong, and intuitive 
mathematics (Tao 2007). Mathematics can thus be judged on utilitarian grounds when it helps to build 
other mathematics and on intrinsic values, including aesthetics. Most importantly, however, good 
mathematics is mostly judged within mathematics, without reference to external societal and ethical",N/A,N/A
"factors.  
But while the common notions of good mathematics are intra-mathematical, those of bad 
mathematics often not only reference logical mistakes but specifically include negative societal and 
ethical consequences. For example, Mouhot outlined a typology of bad mathematics that included 
following a wrong argument, building on false axioms, or practicing math-science washing to boost an 
opinion by making it look more scientific and mathematical (Mouhot 4/4/2019). Through the latter,",N/A,N/A
"practitioners can give mathematics “excessive authority and direct it in ways that [can] cause harm 
and exploit others” (Chiodo and Müller 2018, p. 6). This leads to a first problem: what mathematicians 
consider good might only be good from a limited perspective, while it can appear bad by changing 
one’s point of view and by considering extra-mathematical consequences and motivational aspects.",N/A,N/A
"Consider, for example, an explicit construction or even hypothetical proof of fast integer factorization. 
It would undeniably provide deep insight into mathematics, and hence, it would correctly be identified 
as good mathematics according to Tao’s definition. However, the societal consequences of it could be 
deleterious because much of our modern digital security builds on this very problem being hard to 
solve.",N/A,N/A
"solve.  
This common definitional approach to good and bad mathematics leads to a second related problem 
for anyone considering the ethics of mathematics. It raises a communicational barrier between the 
ethicist and the mathematician. Our common-sense understanding of good and bad is mutually 
exclusive: something is either good or bad, but it is not both. However, if you define “good” using the 
logical “OR” operator and exclude extra-mathematical consequences and motivational aspects, this",N/A,N/A
"implies that the definition of “bad” must be “not one of the 21 aspects is satisfied.” But this will likely 
never be satisfied for correct higher mathematics. From an ethics perspective, a much better 
definition of good mathematics would therefore be split up into “ethically good” and “mathematically 
good,” i.e., “mathematics is good if it satisfies at least one of N aspects, and if at the same time, it does",N/A,N/A
"not do one of these M ethically bad aspects.” The standard definitions of bad mathematics do not 
adequately address this issue. Standing on their own, Mouhot’s and Tao’s definitions appear sound at 
first, but when judged in combination, they are insufficient to talk about the ethics of mathematics. 
This proves to be an immense communicative challenge that implicitly finds much attention in Ethics",N/A,N/A
"in Mathematics. Its difficulty is a critical aspect to why calling out bad mathematics is identified as the 
highest level of ethical awareness for mathematicians. 
4 
 
A primary desideratum of any work in ethics of mathematics is currently the lack of data. There are 
few qualitative studies on research mathematics, mathematicians, and their understanding of ethics. 
Existing studies of research mathematicians are limited to questions about basic philosophical",N/A,N/A
"assumptions (Sriraman 2004), the art of doing mathematics (Heintz 2000b, 2000a; Kiesow 2016), 
including the impact of computational and AI-driven maths (Sørensen 2016; Ebert 2016) and about 
the understanding of numbers (Heintz 2007). Existing studies about ethical mathematics 
understanding focus on high school students and non-mathematics majors (Stephan et al. 2021; 
Demattè 2021). To the author’s knowledge, questions about the ethical self-understanding of the",N/A,N/A
"discipline have neither been explored through quantitative nor qualitative interview-based studies. 
Only a little work has gone into why beliefs about the certainty of mathematical knowledge and ethical 
neutrality seem to be so widespread among students and practitioners alike (Ernest 2016a). Recent 
research has analyzed the public attitudes towards artificial intelligence, but studies about expert",N/A,N/A
"practitioners’ attitudes towards AI and its ethics are still missing (Ikkatai et al. 2022). Further research 
is urgently needed to shed light on the apparently common practitioner’s belief that “there is no ethics 
in mathematics,” which Chiodo and Bursill-Hall (2018) described in the first Ethics in Mathematics 
Discussion paper.  
Core Message: Preventing Harm 
Müller et al. (2021) outlined that until a few years ago, the normative studies that mathematicians",N/A,N/A
"undertook about mathematics consisted mainly of many investigations of individual sub-fields. Over 
the years, individual mathematical disciplines came into the spotlight of ethical attention, including 
statistics, mathematical physics, financial mathematics, cryptography, and today’s widely popular 
machine learning. Most of these ethical analyses have one thing in common. Rather often, there was",N/A,N/A
"quite a loud bang beforehand - sometimes proverbially, as with the atomic bombs dropped on Japan 
at the end of the Second World War, sometimes metaphorically, as in the global financial crisis of 
2008. But in contrast to these events, many of the involved mathematical disciplines were very 
abstract in their origins and were widely considered ethically neutral until their applications became 
apparent. Indeed, the line between applied and pure mathematics can be “irritatingly vague” (Hersh",N/A,N/A
"1990, p. 22) and very much depends on the mathematical questions asked (Brown 2008). Thus, even 
during World War II and only a few years before the development of atomic bombs, Hardy still referred 
to quantum mechanics as an abstract and useless science (Hardy 1940). Number theory, too, long had 
the whiff of the ethically pure about it. Beginning with Plato and ending with the most abstract",N/A,N/A
"considerations in algebraic number theory, for a long time, these considerations had little influence 
on the everyday life of most people. However, at the latest, just how big the ethical questions are that 
number theory and cryptography have imposed on our modern digital society have become apparent 
after the many recent global surveillance disclosures.  
Hence, it is not surprising that both the Cambridge University Ethics in Mathematics Project and the",N/A,N/A
"Cambridge University Ethics in Mathematics Society pursue “preventing harm” as their declared 
objective: 
“It is […] obvious that high-powered and sophisticated mathematics is ubiquitous in 
modern technology, finance, the nation’s infrastructure and defense, and social media. 
And pretty much anywhere else in the 21st century. Much of mathematics can be used 
for good – but simply put: it can also be a tool for harm. We think it is clear that",N/A,N/A
"mathematical research and practice may take its practitioners to deep and professionally 
specific ethical issues.” (CUEiMP 2018) 
5 
 
The old view of ethics of mathematics as sub-field investigations is consistent with a problematic 
approach found in modern risk analysis. It frequently lacks focus on structural risks and puts too much 
attention on the known unknowns: we ask ourselves if this one technology, one drug, or one fertilizer",N/A,N/A
"is safe, and we too rarely ask how individual technologies and methods interact structurally (Jasanoff 
2016). Ethics in Mathematics attempts to avoid this trap by abstracting from subdisciplines and 
studying the ethical aspects valid for all mathematical practitioners (CUEiMP 2018). By its founders, 
this new approach is perceived as sorely needed (Chiodo and Clifton 2019).  
Practical Ethics for the Working Mathematician",N/A,N/A
"Practical Ethics for the Working Mathematician 
Ethics in Mathematics specifically targets working mathematicians and tries to prepare them to 
engage in societal discourses about their field. For instance, the close connection between civilian and 
military research in mathematics (e.g., Gruber 2017, 2018) was put into the spotlight during the 2017 
to 2019 CUEiMS Ethics in Mathematics seminars. Through a series of guest speakers ranging from",N/A,N/A
"whistle-blowers, such as Edward Snowden, William Binney, and Julian Assange, to mathematicians 
and computer scientists, including Richard Stallman,  Tanja Lange, and Martin Hellman (CUEIMS 2016), 
the society complemented the regular lectures to hear from frontline practitioners about 
mathematical responsibility.  
Since its early years, both the Cambridge Project and Society have also intently addressed",N/A,N/A
"undergraduate mathematicians without any formal training in philosophy while maintaining a certain 
degree of neutrality in their educational approach. Unlike Mathematics for Social Justice, neither the 
Project nor the Society has actively taken on a specific theory from education. Their understanding of 
neutrality went so far that it was suggested to address ethics issues in mathematics within the",N/A,N/A
"framework of a student’s definition of pure mathematics instead of challenging a possibly misleading 
or false definition itself (Müller 2018). Both project and society are interdisciplinary, if not 
transdisciplinary, in their educational approach, inviting speakers from various backgrounds to their 
seminar series and conferences (CUEiMP 2018; CUEIMS 2016). Ernest writes about the Cambridge 
University Ethics in Mathematics Project that",N/A,N/A
"University Ethics in Mathematics Project that  
“[o]verall, this project can be seen as a valuable and exemplary first attempt to plug the 
hole left by the widespread neglect of ethics for mathematicians. It is primarily practice-
driven and does not include any elements of theoretical ethics. This means that good and 
bad, vice and virtue are not analyzed. It is assumed that bad or harmful applications can 
be identified as such through everyday ethical common-sense. The organizers are",N/A,N/A
"probably right in making this judgment call with regard to developing an undergraduate 
course.” (Ernest 2021, p. 20) 
The description for its eight lectures can be found in the term cards of the student society (CUEIMS 
2016). They are titled as follows: 
1. An introduction to ethics in mathematics and why it is important 
2. Financial mathematics and modeling 
3. Cryptography, surveillance, and privacy 
4. Fairness and impartiality in algorithms and AI",N/A,N/A
"5. Regulation, accountability, and the law 
6. Understanding the behavior of the mathematical community 
7. Psychology 101: How to survive as a mathematician at work 
6 
 
8. Looking into the future, what more can mathematicians do? 
Lecture 7, as described in the Michaelmas 2021 term card, outlines that as future mathematicians, 
students will work in complex work environments, subject to the “usual workplace interactions, issues,",N/A,N/A
"conflicts, and dangers that may arise in other professions.” It tries to prepare the students by making 
them understand their strengths and weaknesses, building on the cultural analysis of the 
mathematical community in lecture 6.  Both lectures can also be understood in what Hersh calls “front 
mathematics” (Hersh 1991). The formal, precise, ordered, and abstract positions that the field projects",N/A,N/A
"to the outside are not necessarily going to protect the individual mathematician in the workplace, as 
it merely protects the mathematical endeavor as a whole. As such, the lecture series is concerned with 
making mathematicians perceive the ethical relevance of their mathematics and tries to challenge 
some conservative tendencies in the field. As Lovász put it, “mathematicians are conservative people;",N/A,N/A
"I don’t mean  that  we  are  right-wing, but  we don’t push for changes:  We are reluctant to spend 
time on anything other than trying to prove that P != NP.” (Lovász 1998, p. 33).  
Relationship to Other Courses 
The history of mathematics and history of science classes at the faculty of mathematics at Cambridge 
University are running in parallel to the ethics seminars. They address the time-varying normative",N/A,N/A
"power ascribed to and coming from mathematics through its uses in the natural sciences, including 
but not limited to changing notions of the relationship between mathematical models and the physical 
world, and different modes of mathematical reasoning in the biological sciences. In its applications, 
mathematics has not only a descriptive but also a normative function in many areas of our lives, as it",N/A,N/A
"is often used to create and introduce new economic and social rules (Nickel 2013). In these areas, the 
ethical discourse usually does not end with their mathematization but often raises new ethical 
questions through its very introduction (Nickel 2014). The introduction of a new mode of discourse 
extends to the use of mathematics within the natural sciences and engineering. In the former, it is the",N/A,N/A
"relationship between mathematical models and nature that introduced new normative elements into 
society. In the latter, it happens through the consequences coming from mathematical technologies.  
The history lectures particularly stress the complexity of the historian’s work and the difficulty it takes 
to understand the slowly changing notions of descriptive and normative power related to 
mathematics resting on Owen Gingerich’s work, among others. Over a 35 year spanning project,",N/A,N/A
"Gingerich showed that Copernicus’s De revolutionibus orbium coelestium sections on calculations 
were widely annotated and read by mathematicians and astronomers (Gingerich 1992, 2002, 1993, 
2004). Gingerich found severely annotated sections on calculations, but the section on cosmology was 
lacking marginalia, which suggested to him that it was mostly ignored by contemporary 
mathematicians and astronomers. Copernicus was likely read as a calculational improvement over",N/A,N/A
"Ptolemy’s Almagest. The shift that mathematical models should be representative of the physical 
world had neither reached religious, societal, nor philosophical consensus immediately after 
Copernicus’s publication. The debates went on to Galileo, Kepler, and Newton, who in increasing detail 
introduced a new understanding of the relationship between mathematical models and the physical 
world.  
Galileo famously exclaimed that the book of nature was written in the language of mathematics and",N/A,N/A
"understood through inductive reasoning using experimental knowledge, breaking with the 
Aristotelean tradition of deductive reasoning from book knowledge. But while Galileo considered 
7 
 
repeatable physical experiments from which he inferred the physical laws written in mathematics, 
Darwin could not build on experiments but merely on his observations of nature. He had to infer the 
meaning based on what he could observe in nature and combined it with probabilistic reasoning to",N/A,N/A
"arrive at his theory of evolution. This subtle difference of Darwin’s use of probabilistic thinking in his 
Origins of Species which is now found in many applications of probability and statistics, was not 
covered in the ethics seminar, but those interested in it could hear about it in the accompanying 
history classes. Thus, two of the most important examples of how we see mathematics today were 
not directly part of the Ethics in Mathematics seminar. 
Mathematics for Social Justice",N/A,N/A
"Mathematics for Social Justice 
In contrast, a different approach can be found in the many works on Mathematics for Social Justice, 
which (for most authors) finds its roots in the more extensive critical pedagogy literature. Critical 
pedagogy builds on the intimate relationships between culture, power, public discourse, and 
democracy and their connections to education. Questions of race, class, and gender play a central role",N/A,N/A
"in this approach. Therefore, its proponents argue that critical scholars and educators need to take a 
position that promotes human freedom and social justice (e.g., Giroux 2007). As an educational 
approach “concerned with the intersection of power, identity, and knowledge“ (Giroux 2007, p. 29), 
it advocates that all educators and teachers in a multicultural setting must be able to analyze the",N/A,N/A
"politics of education (Kincheloe and Steinberg 1997). As Freire puts it succinctly, critical pedagogy is 
about developing a critical consciousness by „learning to perceive social, political, and economic 
contradictions, and to take action against the oppressive elements of reality” (Freire 2000, p. 35). 
Given that societal power asymmetries can be (unknowingly) reproduced in educational settings, 
critical pedagogy argues for a humanizing classroom experience by advocating an educational",N/A,N/A
"philosophy that centers on the students’ life experiences. Students are understood as “knowers” and 
“active participants,” and the classroom should be an environment open for creativity, reflection, and 
action (Bartolome 1996). Through the assigned tasks, discussions, and self-reflection, educators and 
students are invited to develop a “critical ontology” and an “agency for change” of social and cultural 
issues (Meyer 2011; Kincheloe 2011).",N/A,N/A
"issues (Meyer 2011; Kincheloe 2011). 
Thus, the historical roots of Mathematics for Social Justice trace back to K-12 school education at the 
turn of the millennium. Later on, it became a topic of college classroom education. From the start, the 
goal was not to sacrifice mathematical content for social justice but to enrich the learning experience 
through critical pedagogy and to provide students with a positive mathematics identity (Buell and",N/A,N/A
"Shulman 2019). In college mathematics courses, projects have successfully been used to promote civic 
engagement among mathematics majors (Unfried and Canner 2019), while quantitative literacy and 
project-based general education courses have proven useful to equip students with the knowledge 
necessary to analyze fake news, misinformation, and promote good decision making in civil society 
(e.g., Branson 2019; O’Donovan and Geary 2019; Simic-Muller 2019). In calculus classes, students have",N/A,N/A
"shown particular responsiveness to case studies addressing social justice issues rather than to the 
classical physical problems that dominate much of calculus (Hoke et al. 2019). Common among all 
these approaches is the understanding that the student should be an active member of society, make 
moral decisions, use mathematics for social good, and be able to critically examine other peoples’ 
mathematics while being able to reflect their own social background. For the non-STEM major, the",N/A,N/A
"goal is to have quantitative literate citizens. Robert Moses, one of the founding fathers of the 
Mathematics for Social Justice movement, understood mathematical literacy as a civil right (Moses 
and Cobb 2002). In turn, mathematics majors should become mathematicians with a social awareness 
of their work’s cultural and social problems, including bias, discrimination, diversity, inclusion, 
fairness, equality, and equity.  
8",N/A,N/A
"fairness, equality, and equity.  
8 
 
Critical pedagogy itself traces its roots back to the critical theory developed by the Frankfurt school. 
Just like the writers from the Institute of Social Research at the University of Frankfurt perceived the 
world in an “urgent […] need of reinterpretation” after World War 1 and the economic collapse during 
the Weimar republic (Kincheloe and Mclaren 2011, p. 286), the recent writings from Mathematics for",N/A,N/A
"Social Justice perceive society (and thus the education system) in a similar need of reinterpretation 
and restructuring. In doing so, critical pedagogy does not build on the assumption of human objectivity 
and universal foundations for culture but generally rejects any such predisposition in its approach 
(Leistyna et al. 1996). Hence, it is unsurprising that Mathematics for Social Justice can also challenge",N/A,N/A
"existing beliefs about what counts as mathematics, including but not limited to its universality across 
cultures (Nolan and Graham 2021) and who can participate in its practice (Walshaw 2021). More 
generally, Mathematics for Social Justice is closely intertwined with questions of equity. So much so 
that the definitions of equity and social justice and the lines between them are often blurred or can",N/A,N/A
"even be non-existing for some authors (for an overview, we refer to Xenofontos et al. 2021).  
To summarize, Mathematics for Social Justice is as much about “learning to play the game“ as it is 
about “learning to change the game”(Gutiérrez 2009). It is a view towards education which is perhaps 
best described in the following fictional student’s course evaluation for a social justice-themed 
mathematics course:",N/A,N/A
"mathematics course: 
“I finally get that [...] teaching mathematics about, or through, social justice isn’t just 
about poverty statistics and world population figures... it’s also in the thoughts and 
actions of the teacher toward his/her students and in the thoughts and actions of 
students toward each other. It’s about feeling safe to be who I am and, at the same time, 
to critically question who I want to become and what (and who) I value. And, most of all,",N/A,N/A
"I think it’s also about opening up the content of mathematics […] to this same kind of 
critical questioning.“ (Nolan 2009, pp. 214–215) 
Paul Ernest’s Philosophy of Mathematics Ethics Education 
A similar view regarding the ethical challenges coming from mathematics can be found in the recent 
works of the philosopher Paul Ernest. In light of his perceived overvaluation of mathematics in society,",N/A,N/A
"Ernest calls for mathematicians to acknowledge the dark side of their subject and challenges the belief 
that practicing and learning more mathematics always leads to good outcomes (Ernest 2020b). Ernest 
(2016b) argues that the overt values ascribed to mathematics, including but not limited to truth, 
purity, universality, and beauty, can make it difficult for mathematicians to spot the covert values of",N/A,N/A
"objectism and ethics. In identifying three aspects of collateral damage to learning mathematics, he 
effectively bridges Ethics in Mathematics and Mathematics for Social Justice:  
“First, the nature of pure mathematics itself leads to styles of thinking that can be 
damaging when applied beyond mathematics to social and human issues. Second the 
applications of mathematics in society can be deleterious to our humanity unless very",N/A,N/A
"carefully monitored and checked. Third, the personal impact of learning mathematics on 
learners’ thinking and life chances can be negative for a minority of less successful 
students, as well as potentially harmful for successful students.” (Ernest 2018, p. 1) 
For mathematics to have the appropriate valuation in society, we both need people trying to actively 
do good with mathematics and those trying to prevent harm. Therefore, it needs quantitatively",N/A,N/A
"literate, empowered, and self-reflected citizens who can question the existing uses of mathematics. 
But it also needs mathematicians who understand the power and dangers of their mathematics and 
9 
 
applications and who are willing to consider the limitations of mathematical problem-solving 
approaches in social and human issues. This situates Paul Ernest in a close relationship to both Ethics 
in Mathematics and Mathematics for Social Justice. 
Comparison",N/A,N/A
"Comparison 
Despite the commonly stated goal of fostering moral decision-making in students and mathematical 
practitioners, the assumptions that go into Ethics in Mathematics and Mathematics for Social Justice, 
their educational movements, and their teaching philosophies are quite different. In what follows, 
we outline some commonalities and differences and observe that their approaches to teaching and 
target groups can be understood as complementary instead of conflicting.",N/A,N/A
"Ethics in Mathematics and Mathematics for Social Justice both attempt to establish an agency for 
change in their students. However, the message coming out of Mathematics for Social Justice is more 
positive than the one uttered by Ethics in Mathematics, focusing on enabling students to do good in 
society rather than teaching them how to prevent harm. It understands students as members of 
society who need to be empowered. In contrast, Ethics in Mathematics focuses on teaching those",N/A,N/A
"already in power: people with robust mathematical training are considered powerful members of our 
civic society who need to be taught to wield the “double-edged sword of mathematics” carefully 
(Chiodo 2/13/2020). The rather technocratic view of Ethics in Mathematics as ethics from 
mathematicians for mathematicians is complemented by the non-technocratic and empowering 
messages from Mathematics for Social Justice. Through both Ethics in Mathematics and Mathematics",N/A,N/A
"for Social Justice, students are trained to have a social awareness of their work’s cultural and social 
problems, but the common-sense assumptions behind Ethics in Mathematics are philosophically much 
lighter than those going into the traditional Mathematics for Social Justice curricula. By participating 
in the Ethics in Mathematics seminars, students are supposed to level up in their ethical awareness",N/A,N/A
"and actions. However, the Ethics in Mathematics lectures only marginally address many of the 
workplace issues in the focus of Mathematics for Social Justice, including diversity, inclusivity, and 
equity. Hence, the Ethics in Mathematics lectures should at least be complemented by professional 
ethics courses dealing with these issues.  
Mathematics for Social Justice is the larger scientific and educational movement, drawing from critical",N/A,N/A
"theory and pedagogy and the activist effort of people in the fight for social justice in politics and 
society. The growing literature on Ethics in Mathematics, on the contrary, is primarily being developed 
by practicing mathematical researchers. It does not challenge claims for universal foundations of 
reason and rational objectivity, and their work is mostly independent of foundational assumptions",N/A,N/A
"about the logical nature of mathematics. Unlike Paul Ernest’s philosophy of mathematics education 
and many aspects of Mathematics for Social Justice, Ethics in Mathematics is only in minor parts social 
constructivist, in that it accepts that definitions, lemma, propositions, and theorems are coming from 
a research agenda designed by humans informed by their environment and culture. However, this is",N/A,N/A
"where their social constructivism ends, as the mathematical theorems of pure mathematics are still 
seen as universal within a specific framework of logic and set theory. Thus, the Ethics in Mathematics 
perspective on ethics of mathematics rather closely follows Gold’s criticism of social constructivist 
philosophies of mathematics (Gold 1999). It tries to distinguish mathematics from mathematical 
knowledge and builds much on its ethical reasoning on the usefulness of mathematics. The human",N/A,N/A
"aspects are restricted to research, teaching and doing mathematics, and applying mathematics to 
extra-mathematical problems. The Platonist beliefs commonly held by mathematicians (Sriraman 
10 
 
2004) are not actively challenged, but definitory questions about the nature of pure mathematics have 
been raised (Müller 2018).  The Ethics in Mathematics lectures only implicitly deal with Paul Ernest’s",N/A,N/A
"view that different philosophies of mathematics, views ascribed to mathematics, and mathematics 
participation reinforce or hinder one another (Ernest 2003).  
Integration into the Curriculum 
Only a few practical ethics of mathematics courses have been outlined in the literature (Franklin 2005; 
Chiodo and Bursill-Hall 2019), but the necessity to properly interweave them with the existing 
mathematical curriculum is stressed in the most recent works (Chiodo and Vyas 2019; Chiodo and",N/A,N/A
"Bursill-Hall 2019). Any course on ethics must also take into account the other existing possibilities 
through which students can learn about these issues. Do they have to take a general ethics course 
focusing on proper scientific conduct? Are there accompanying philosophy and history of science 
classes on which the ethics lectures can build? Do the students have to take a minor subject or fulfill",N/A,N/A
"general education requirements? If any of these exists, those designing the curriculum must be very 
careful about the likelihood of knowledge transfer. Are students likely to transfer their knowledge to 
the ethics of mathematics? The Ethics in Mathematics founders argued that this could be particularly 
difficult for students if the mathematics faculty does not fully support the ethics course or the ethical 
elements found in other courses (Chiodo and Bursill-Hall 2019).",N/A,N/A
"Unlike the standard introductory courses on linear algebra and analysis that most mathematics 
students see at the beginning of their studies, introductory ethics courses have to be adjusted to the 
existing curriculum and the already existing (or non-existing) informal discourse on the ethics of 
mathematics found within the faculty. This can be difficult, and it also holds for attempts to introduce",N/A,N/A
"elements from Mathematics for Social Justice into the curriculum. Only recently, Mathematics for 
Social Justice has incited disagreement among parts of the mathematical community, with one 
commenting author calling it another “schism in the field” (Crowell 2022). These recent debates have 
only underlined the difference between introducing an individual course and interweaving its ideas 
with the whole curriculum. It is one of the core challenges that any ethics for mathematicians course",N/A,N/A
"faces. Ethics in Mathematics lectures at Cambridge found a way through a series of compromises: they 
are non-examinable, complemented by history of science and mathematics classes, and can build on 
a system of student societies found at few other universities. Being a seminar course specifically 
designed for and led by mathematicians, Ethics in Mathematics was able to reduce the alienation felt 
among the participating students.  
Conclusion",N/A,N/A
"among the participating students.  
Conclusion 
It is not surprising that ethical analyses of mathematics have regained prominence outside the 
educational sciences in recent years. The moral questions that mathematics has imposed on our 
society have led to new approaches, the most important of which are perhaps simple and old insights. 
Yet, it is not enough to look at individual subfields, let alone individual formulae, of mathematics when",N/A,N/A
"the digitalization and automatization of the economy and our everyday lives are driving its 
mathematization ever further.  
The commonly held beliefs about good mathematics deeply influence what mathematicians 
understand as morally good mathematics and affect their agency for change which they feel towards 
ethical aspects of their field. Despite not formally taking on a specific philosophy of education, the",N/A,N/A
"Cambridge University Ethics in Mathematics Project, as ethics from mathematicians for 
11 
 
mathematicians, nonetheless take on subtle positions which can be found in existing philosophies of 
mathematics educations and philosophies of mathematics. Coming out of practical considerations, 
these positions are closely related to the general mathematical practitioners’ positions. Ethics in 
Mathematics and Mathematics for Social Justice are different perspectives on ethical responsibility in",N/A,N/A
"mathematics. Together they provide fruitful ground for discussions and shed light on the different 
social, cultural, and ethical issues surrounding mathematical practice and education. Our analysis 
outlined some fundamental differences and provided suggestions for the missing pieces in the Ethics 
in Mathematics research agenda. Ethics in Mathematics and Mathematics for Social Justice should be",N/A,N/A
"seen as complementary, using educational philosophies specifically selected to fit their target groups.  
Publication bibliography 
Baldino, Roberto Ribeiro; Cabral, Tania Cristina Baptista (2021): Criticizing Epistemic Injustice: 
Rewarding Effort to Compensate for Epistemic Exclusion. In Philosophy of Mathematics Education 
Journal (38), pp. 1–11. 
Bartolome, L. I. (1996): Beyond the methods fetish: Toward a humanizing pedagogy. In Pepi Leistyna,",N/A,N/A
"Arlie Woodrum, Stephen A. Sherblom: Breaking free. The transformative power of critical pedagogy 
/  edited by Pepi Leistyna, Arlie Woodrum, Stephen A. Sherblom. Cambridge, Mass.: Harvard 
Educational Review (Harvard educational review. Reprint series, no.27), pp. 229–252. 
Branson, Mark (2019): Fighting Alternative Facts: Teaching Quantitative Reasoning with Social Issues. 
In PRIMUS 29 (3-4), pp. 228–243. DOI: 10.1080/10511970.2018.1506534.",N/A,N/A
"Brown, James Robert (2008): Philosophy of mathematics. A contemporary introduction to the world 
of proofs and pictures /  James Robert Brown. 2nd ed. New York, Abingdon: Routledge (Routledge 
contemporary introductions to philosophy). 
Buell, Catherine A.; Shulman, Bonnie (2019): An Introduction to Mathematics for Social Justice. In 
PRIMUS 29 (3-4), pp. 205–209. DOI: 10.1080/10511970.2018.1530707. 
Chiodo, Maurice (2020): Ethics in Mathematics - where to begin? Math in Society Seminar.",N/A,N/A
"University of Oxford, 2/13/2020. Available online at https://www.maths.ox.ac.uk/node/34805. 
Chiodo, Maurice; Bursill-Hall, Piers (2018): Four Levels of Ethical Engagement. In EiM Discussion 
Papers 1, pp. 1–25. Available online at https://www.ethics.maths.cam.ac.uk/assets/dp/18_1.pdf. 
Chiodo, Maurice; Bursill-Hall, Piers (2019): Teaching Ethics in Mathematics. In LMS Newsletter 485, 
pp. 22–26.",N/A,N/A
"pp. 22–26. 
Chiodo, Maurice; Clifton, Tobias (2019): The Importance of Ethics in Mathematics. In EMS Newsletter 
December (34-37). 
Chiodo, Maurice; Müller, Dennis (2018): Mathematicians and Ethical Engagement. In SIAM News 51 
(9), p. 6. 
Chiodo, Maurice; Vyas, Rishi (2019): The role of ethics in a mathematical education: A whitepaper. In 
EiM Discussion Papers (1), pp. 1–5. Available online at 
http://ethics.maths.cam.ac.uk/assets/dp/19_1.pdf.",N/A,N/A
"Crowell, Rachel (2022): New Math Research Group Reflects a Schism in the Field. In Scientific 
American, 1/11/2022. Available online at https://www.scientificamerican.com/article/new-math-
research-group-reflects-a-schism-in-the-field/. 
12 
 
CUEiMP (2018): Cambridge University Ethics in Mathematics Project. Cambridge, United Kingdom. 
Available online at https://www.ethics.maths.cam.ac.uk/. 
CUEIMS (2016): Cambridge University Ethics in Mathematics Society. Available online at",N/A,N/A
"https://cueims.soc.srcf.net/. 
Demattè, Adriano (2021): On student's ethical relation with a mathematical written text: meaning 
and empirical evidence. In Philosophy of Mathematics Education Journal (38), pp. 1–19. 
Ebert, Ulla Britta (2016): Computerbeweise und ihr Einfluss auf die Philosophie der Mathematik. 
Available online at https://publikationen.bibliothek.kit.edu/1000064618. 
Ernest, Paul (2003): Images of mathematics, values and gender: A philosophical perspective. In :",N/A,N/A
"Mathematics Education: Routledge, pp. 21–35. Available online at 
https://www.taylorfrancis.com/chapters/edit/10.4324/9780203465394-9/images-mathematics-
values-gender-philosophical-perspective-paul-ernest. 
Ernest, Paul (2016a): The problem of certainty in mathematics. In Educ Stud Math 92 (3), pp. 379–
393. DOI: 10.1007/s10649-015-9651-x. 
Ernest, Paul (2016b): Values and Mathematics: Overt and Covert. In Culture and Dialogue 4 (1), 
pp. 48–82. DOI: 10.1163/24683949-12340004.",N/A,N/A
"pp. 48–82. DOI: 10.1163/24683949-12340004. 
Ernest, Paul (2018): The Ethics of Mathematics: Is Mathematics Harmful? In The Philosophy of 
Mathematics Education Today, pp. 187–216. DOI: 10.1007/978-3-319-77760-3_12. 
Ernest, Paul (2020a): Mathematics, ethics and purism: an application of MacIntyre’s virtue theory. In 
Synthese 199 (1-2), pp. 3137–3167. DOI: 10.1007/s11229-020-02928-1. 
Ernest, Paul (2020b): The dark side of mathematics : Damaging effects of the overvaluation of",N/A,N/A
"mathematics. In Gwen Ineson, Hilary Povey (Eds.): Debates in mathematics education. Second 
edition /  edited by Gwen ineson, Hilary Povey. London: Routledge (Debates in subject teaching 
series), pp. 29–42. Available online at 
https://www.taylorfrancis.com/chapters/edit/10.4324/9780429021015-3/dark-side-mathematics-
paul-ernest. 
Ernest, Paul (2020c): The Ideologies of Purity and Neutrality and the Ethics of Mathematics. In 
Philosophy of Mathematics Education Journal (36), pp. 1–30.",N/A,N/A
"Ernest, Paul (2021): The Ethics of Mathematical Practice. In Bharath Sriraman (Ed.): Handbook of the 
History and Philosophy of Mathematical Practice. Cham: Springer International Publishing, pp. 1–38. 
Available online at https://doi.org/10.1007/978-3-030-19071-2_9-1. 
Franklin, James (2005): A “professional issues and ethics in mathematics” course. In Australian 
Mathematical Society Gazette 32. Available online at https://philpapers.org/rec/FRAAPI-2.",N/A,N/A
"Freire, Paulo (2000): Pedagogy of the oppressed. 30th anniversary ed. New York, Great Britain: 
Continuum. 
Gingerich, Owen (1992): The great Copernicus chase and other adventures in astronomical history. 
Gingerich, Owen (1993): The eye of heaven. Ptolemy, Copernicus, Kepler /  Owen Gingerich. New 
York, NY: American Institute of Physics. 
13 
 
Gingerich, Owen (2002): An annotated census of Copernicus' De revolutionibus (Nuremberg, 1543",N/A,N/A
"and Basel, 1566). Leiden, Boston, MA: Brill (Studia Copernicana. Brill's series, 0925-6806, v. 2). 
Gingerich, Owen (2004): The book nobody read. Chasing the revolutions of Nicolaus Copernicus /  
Owen Gingerich. New York: Walker. 
Giroux, Henry A. (2007): 1. Utopian Thinking in Dangerous Times: Critical Pedagogy and the Project 
of Educated Hope. In Mark Cote (Ed.): Utopian Pedagogy: University of Toronto Press, pp. 25–42.",N/A,N/A
"Gold, Bonnie (1999): Social Constructivism as a Philosophy of Mathematics. By Paul Ernest, What Is 
Mathematics, Really? By Reuben Hersh. In The American Mathematical Monthly 106 (4), pp. 373–
380. DOI: 10.1080/00029890.1999.12005058. 
Gruber, Thomas (2017): Im Spannungsfeld von militärischer Anwendung und Wissenschafts-
verantwortung? Zur Verquickung der mathematischen Forschung in. In Ralf Krömer, Gregor Nickel:",N/A,N/A
"Siegener Beiträge zur Geschichte und Philosophie der Mathematik. 8th ed. Siegen, Germany: universi 
- Universitätsverlag Siegen, pp. 1–26. 
Gruber, Thomas (2018): Verquickung der mathematischen und informatischen. 
Doctoral Dissertation. Universität Bremen. Fachbereich 03: Mathematik / Informatik. 
Gutiérrez, Rochelle (2009): Framing Equity: Helping Students ""Play the Game"" and ""Change the 
Game"". In Teaching for Excellence and Equity in Mathematics 1 (1), pp. 4–7.",N/A,N/A
"Hardy, G. H. (1940): A Mathematician's Apology. Cambridge: University Press. 
Heintz, Bettina (2000a): Die Innenwelt der Mathematik. Zur Kultur und Praxis einer beweisenden 
Disziplin /  Bettina Heintz. Wien: Springer (Ästhetik und Naturwissenschaften, 1430-5321). 
Heintz, Bettina (2000b): „In der Mathematik ist ein Streit mit Sicherheit zu entscheiden“ 
Perspektiven einer Soziologie der Mathematik. In Zeitschrift für Soziologie 29 (5), pp. 339–360. DOI: 
10.1515/zfsoz-2000-0501.",N/A,N/A
"10.1515/zfsoz-2000-0501. 
Heintz, Bettina (2007): Zahlen, Wissen, Objektivität: Wissenschaftssoziologische Perspektiven. In 
Andrea Mennicken, Hendrik Vollmer (Eds.): Zahlenwerk: Kalkulation, Organisation und Gesellschaft. 
Wiesbaden: VS Verlag für Sozialwissenschaften, pp. 65–85. Available online at 
https://doi.org/10.1007/978-3-531-90449-8_4. 
Hersh, Reuben (1990): Mathematics and Ethics. In Humanistic Mathematics Network Journal 1 (5), 
pp. 20–23. DOI: 10.5642/hmnj.199001.05.09.",N/A,N/A
"pp. 20–23. DOI: 10.5642/hmnj.199001.05.09. 
Hersh, Reuben (1991): Mathematics has a front and a back. In Synthese 88 (2), pp. 127–133. DOI: 
10.1007/BF00567741. 
Hoke, Kathy; Keough, Lauren; Wares, Joanna (2019): Mass Incarceration and Eviction Applications in 
Calculus: A First-Timer Approach. In PRIMUS 29 (3-4), pp. 345–357. DOI: 
10.1080/10511970.2018.1505792. 
Ikkatai, Yuko; Hartwig, Tilman; Takanashi, Naohiro; Yokoyama, Hiromi M. (2022): Octagon",N/A,N/A
"Measurement: Public Attitudes toward AI Ethics. In International Journal of Human–Computer 
Interaction 59 (5), pp. 1–18. DOI: 10.1080/10447318.2021.2009669. 
Jasanoff, Sheila (2016): The ethics of invention. Technology and the human future. First edition. New 
York: W.W. Norton & Company (The Norton global ethics series). 
14 
 
Kiesow, Christian (2016): Die Mathematik als Denkwerk. Eine Studie zur kommunikativen und",N/A,N/A
"visuellen Performanz mathematischen Wissens. 1. Aufl. 2016. Wiesbaden: Springer VS (SpringerLink 
Bücher). 
Kincheloe, Joe L. (2011): Critical Ontology - Visions of Selfhood and Curriculum. In Joe L. Kincheloe, 
Kecia Hayes, Shirley R. Steinberg, Kenneth George Tobin (Eds.): Key works in critical pedagogy. 
Rotterdam: Sense (Bold visions in educational research, v. 32), pp. 201–217. 
Kincheloe, Joe L.; Mclaren, Peter (2011): Rethinking Critical Theory and Qualitative Research. In Joe",N/A,N/A
"L. Kincheloe, Kecia Hayes, Shirley R. Steinberg, Kenneth George Tobin (Eds.): Key works in critical 
pedagogy. Rotterdam: Sense (Bold visions in educational research, v. 32), pp. 285–326. Available 
online at https://doi.org/10.1007/978-94-6091-397-6_23. 
Kincheloe, Joe L.; Steinberg, Shirley R. (1997): Changing multiculturalism. Buckingham: Open 
University Press (Changing education). 
Leistyna, Pepi; Woodrum, Arlie; Sherblom, Stephen A. (1996): Breaking free. The transformative",N/A,N/A
"power of critical pedagogy /  edited by Pepi Leistyna, Arlie Woodrum, Stephen A. Sherblom. 
Cambridge, Mass.: Harvard Educational Review (Harvard educational review. Reprint series, no.27). 
Lovász, László (1998): One Mathematics. In DMV-Mitteilungen (2), pp. 33–39. 
Meyer, Elizabeth J. (2011): Critical Ontology and Teacher Agency. In Joe L. Kincheloe, Kecia Hayes, 
Shirley R. Steinberg, Kenneth George Tobin (Eds.): Key works in critical pedagogy. Rotterdam: Sense",N/A,N/A
"(Bold visions in educational research, v. 32), pp. 219–226. 
Moses, Robert Parris; Cobb, Charles E. (2002): Radical equations. Civil rights from Mississippi to the 
Algebra Project. Boston: Beacon Press. 
Mouhot, Clement (2019): Calling out bad mathematics. EiM 2: The second meeting on Ethics in 
Mathematics. Cambridge, United Kingdom, 4/4/2019. 
Müller, Dennis (2018): Is there Ethics in Pure Mathematics? Remarks about History and Sociology. In",N/A,N/A
"EiM Discussion Papers 2, pp. 1–20. Available online at 
https://www.ethics.maths.cam.ac.uk/assets/dp/18_2.pdf. 
Müller, Dennis; Chiodo, Maurice; Franklin, James (2021): A Hippocratic Oath for mathematicians? 
Mapping the landscape of ethics in mathematics. Available online at 
https://arxiv.org/pdf/2112.07025. 
Nickel, Gregor (2005): Ethik und Mathematik: Randbemerkungen zu einem prekären Verhältnis. In 
Neue Zeitschrift für Systematische Theologie und Religionsphilosophie 47 (4), pp. 412–429.",N/A,N/A
"Nickel, Gregor (2013): Diskussion. Money out of nothing? (21 - 1) - Ein Zwischenruf. In DMV-
Mitteilungen 21 (3), p. 132. 
Nickel, Gregor (2014): Finanzmathematik - Prinzipien und Grundlagen? Nachruf auf einen 
Zwischenruf. In Ralf Krömer, Gregor Nickel: Siegener Beiträge zur Geschichte und Philosophie der 
Mathematik. Siegen, Germany: universi - Universitätsverlag Siegen (4), pp. 97–105. 
Nolan, Kathleen (2009): Mathematics in and through social justice: another misunderstood",N/A,N/A
"marriage? In J Math Teacher Educ 12 (3), pp. 205–216. DOI: 10.1007/s10857-009-9111-6. 
15 
 
Nolan, Kathleen; Graham, Shana (2021): Challenging what counts as Mathematics: Reflecting 
on Teacher's perceptions of culturally responsive pedagogy in the mathematics classroom. In 
Philosophy of Mathematics Education Journal (38), pp. 1–15. 
O’Donovan, Barbara; Geary, Krisan (2019): Measuring Income Inequality in a General Education or",N/A,N/A
"Calculus Mathematics Classroom. In PRIMUS 29 (3-4), pp. 244–258. DOI: 
10.1080/10511970.2018.1512538. 
Pitsili-Chatzi (2021): Mathematics as a social practice? Antagonisms as a conceptual tool for 
examining discourses. In Philosophy of Mathematics Education Journal (38), pp. 1–11. 
Rittberg, Colin Jakob (2020): Virtues and Vices in Mathematics. In The Reasoner 14 (6), p. 38. 
Rittberg, Colin Jakob (2021): On the epistemological relevance of the ethics of maths. Philosophy",N/A,N/A
"Seminar, University of Hertfordshire. Hertfordshire, United Kingdom, 10/25/2021. 
Rittberg, Colin Jakob; Tanswell, Fenner; Johnson, Timothy (2019): A perspective from philosophy. 
EiM 2: The second meeting on Ethics in Mathematics. Cambridge, United Kingdom, 4/3/2019. 
Rittberg, Colin Jakob; Tanswell, Fenner Stanley; van Bendegem, Jean Paul (2018): Epistemic Injustice 
in Mathematics. Available online at http://philsci-archive.pitt.edu/15133/.",N/A,N/A
"Simic-Muller, K. (2019): “There Are Different Ways You Can Be Good at Math”: Quantitative Literacy, 
Mathematical Modeling, and Reading the World. In PRIMUS 29 (3-4), pp. 259–280. DOI: 
10.1080/10511970.2018.1530705. 
Sørensen, Henrik Kragh (2016): “The End of Proof”? The Integration of Different Mathematical 
Cultures as Experimental Mathematics Comes of Age. In Brendan Larvor (Ed.): Mathematical 
cultures. The London Meetings 2012-2014 /  Brendan Larvor, editor. Cham, 2016. Switzerland:",N/A,N/A
"Birkhäuser (Trends in the history of science), pp. 139–160. 
Sriraman, Bharath (2004): The influence of Platonism on mathematics research and theological 
beliefs. In Theology and Science 2 (1), pp. 131–147. DOI: 10.1080/1474670042000196658. 
Stephan, Michelle; Register, Jordan; Reinke, Luke; Pugalee, David; Crabtree, Lenora; Robinson, 
Christine; Pugalenthi, Premkumar (2021): Ethical Mathematics Awareness in Student's Big Data",N/A,N/A
"Decision Making. In Philosophy of Mathematics Education Journal (38). 
Tao, Terence (2007): What is good mathematics? Available online at 
https://arxiv.org/pdf/math/0702396. 
Unfried, Alana; Canner, Judith (2019): Doing Social Justice: Turning Talk into Action in a Mathematics 
Service Learning Course. In PRIMUS 29 (3-4), pp. 210–227. DOI: 10.1080/10511970.2018.1510862. 
Walshaw, Margaret (2021): Who can know mathematics? In Philosophy of Mathematics Education 
Journal (38), pp. 1–10.",N/A,N/A
"Journal (38), pp. 1–10. 
Xenofontos, Constantinos; Fraser, Sally; Priestley, Andrea; Priestley, Mark (2021): Mathematics 
teachers and social justice: a systematic review of empirical studies. In Oxford Review of Education 
47 (2), pp. 135–151. DOI: 10.1080/03054985.2020.1807314.",N/A,N/A
"arXiv:0905.0227v1  [math.GM]  2 May 2009
Brief Lecture Notes on Self-Referential
Mathematics, and Beyond
Elem´er E Rosinger
Department of Mathematics
and Applied Mathematics
University of Pretoria
Pretoria
0002 South Africa
eerosinger@hotmail.com
Abstract
Recently delivered lectures on Self-Referential Mathematics, [2], at the
Department of Mathematics and Applied Mathematics, University of
Pretoria, are brieﬂy presented. Comments follow on the subject, as
well as on Inconsistent Mathematics.",N/A,N/A
"well as on Inconsistent Mathematics.
0. Prologue
The basic idea in the Self-Referential Mathematics, [2], is to replace
the Foundation Axiom, (FA), in Set Theory with a suitable Anti-
Foundation Axiom, (AFA), in such a way as to :
- keep all the sets in the usual Set Theory
while at the same time, to :
- allow a large class of new sets, sets given this time by self-referential
deﬁnitions.
In other words, one obtains a signiﬁcant extension of usual Set The-",N/A,N/A
"ory, an extension which is proved to be consistent, provided usual Set
1
Theory is consistent.
As it happens not seldom in science, the terminology used may turnout
to be rather inappropriate, if not in fact misleading. The same hap-
pens in [2], where the term ”vicious circle” is used instead of ”self-
referential”.
A likely reason for that particular terminology in [2], which has a clear
negative connotation, comes from the fact that the 1903 Russell Para-",N/A,N/A
"dox in Set Theory is based on self-reference, being but a reformulation
in mathematical, in particular, set theoretic terms of the ancient Greek
paradox of the liar.
On the other hand, when considered in the larger and longer perspec-
tive of human tradition and civilization, self-reference, together with
inﬁnity and change, have since the earliest known, in fact, prehis-
toric times been some of the fundamental ideas preoccupying human",N/A,N/A
"thought, and as such, they have not had any sort of inevitable neg-
ative connotation, see section 5. It follows, therefore, that the term
”vicious” can be seen as an overstatement resulted from a partial view
of what self-reference does in fact encompass and mean in its more full
generality.
We can in essence clarify as follows the aims and the means of the Self-
Referential Mathematics in [2]. Let us consider the following three",N/A,N/A
"groups of axioms of Set Theory, see section 6 for all the usual axioms,
in particular, those used in [2] :
ZFC−= Zermello - Fraenkel + Choice
ZFC = ZFC−+ FA
ZFA = ZFC−+ AFA
where the AFA axiom with be speciﬁed in section 2.
At ﬁrst, it may appear that the Set Theories corresponding to ZFC
and ZFA may be rather diﬀerent, since their common part corresponds
2
only to ZFC−, while the respective additional axioms FA and AFA
seem in fact to be inconsistent with one another.",N/A,N/A
"seem in fact to be inconsistent with one another.
However, as it turns out this is not the case.
And what happens
instead is that :
• The Set Theory based on the ZFA axioms contains all the sets
in the Set Theory based on the ZFC, and in addition, contains
a large class of other sets obtained by self-referential deﬁnitions.
• The axioms ZFA are consistent, provided that the axioms ZFC
are consistent.
As for the traditional and still exclusively predominant idea of the",N/A,N/A
"absolute necessity of consistency, one should consider the recent emer-
gence of Inconsistent Mathematics, see [11,12]. And in fact, as far as
everyday practice is concerned, we have for more than half a century
by now been basing much of our lives on a speciﬁc form of Inconsistent
Mathematics. Indeed, our ever more pervasive and critically impor-
tant electronic digital computers are - even when only operating on
non-negative integers - functioning according to the Peano Axioms,",N/A,N/A
"plus the Machine Inﬁnity Axiom, namely
∃M >> 1 : M + M = 1
where M is called ”machine inﬁnity”, and typically is larger than
101000.
And obviously, the Peano Axioms are trivially inconsistent
with the Machine Inﬁnity Axiom.
1. Sets, Ur-Elements and Classes
We denote by SET the class of all sets, including the unique void set
φ. As is well known, a lot of mathematics can be built up starting
alone with the void set φ. Indeed, as a ﬁrst step, and following von",N/A,N/A
"Neumann, one can deﬁne the non-negative integers by
0 = φ, 1 = {φ}, 2 = {{φ}}, . . .
3
and then, step by step build all the integers, the rational and real num-
bers, and so on. Further, one can deﬁne Cartesian products, binary
relations, functions, etc., and obtain a considerable part of mathemat-
ics in this manner.
In the sequel, it will be convenient to allow, in addition to the void
set φ, other such starting entities in the construction of mathematics.",N/A,N/A
"The class of such entities is denoted by U, and any respective element
u ∈U is called an ur-element, assumed to have only one property,
similar to that of the void set φ, namely that the relation
a ∈u
does not hold for any entity a in the theory.
In this way, there will be three types of entities in the theory, namely
1)
SET, which is the class of all sets,
2)
U which is the class of all ur-elements, and
3)
CLASS which denotes all the classes.",N/A,N/A
"3)
CLASS which denotes all the classes.
Here it is understood that any set a ∈SET is a ”small” class, while
SET itself is one of the ”proper” classes, since it is not itself a set. In
other words, SET ∈CLASS, SET /∈SET, CLASS /∈SET.
As for ur-elements, it is assumed that U ∈CLASS and it is another
instance of ”proper” class, thus in particular U /∈SET.
Brieﬂy, we have therefore
1)
SET denotes all the sets, and it is a proper class
2)
CLASS denotes all the classes
3)",N/A,N/A
"2)
CLASS denotes all the classes
3)
U denotes all the ur-elements, and it is a proper class
4)
a set is a ”small” class
4
5)
a class which is not a set is ”large”, thus it is a proper class
6)
an ur-element does not have any elements, either sets, ur-elements,
or classes
7)
non-set = proper class W ur-element
8)
non-set V non-class = ur-element
9)
every predicate determines a class
10)
a subclass of a set is a set
11)
sets are closed under a number of operations, among them,",N/A,N/A
"pairing, union, power set, see below
12)
a ∈b ∈CLASS
=⇒
a ∈SET
13)
the class SET of all sets is ”large”, thus it is a proper class
indeed, according to Russell’s Paradox, let SET be a set,
then R = {a ∈SET | a /∈a} is a set, thus R ∈SET, and
therefore R ∈R
⇐⇒
R /∈R, which is absurd
As for the binary relation ∈, we have
- set ∈set
- set ∈proper class
- set /∈ur-element
- proper class /∈set
- proper class /∈proper class
- proper class /∈ur-element
- ur-element ∈set
- ur-element ∈proper class",N/A,N/A
"- ur-element ∈set
- ur-element ∈proper class
- ur-element /∈ur-element
thus denoting ∈by →, while /∈by ↛, we have
5
set
❄
set
✲
✛
proper class
❄
proper class
❩❩❩❩❩❩❩❩❩
❩
⑦
✓✓
❩
❩
❩
❩
❩
❩
❩
❩
❩
❩
⑥
ur −element
ur −element
✻
✚✚✚✚✚✚✚✚✚
✚
❃
✚
✚
✚
✚
✚
✚
✚
✚
✚
✚
❂
❙
❙
• set
• φ
• proper class
SET
• SET = proper class
✲
• U = Ur −elements = proper class
CLASS
Note on ur-elemets
Clearly
a /∈φ
holds for all entities a in the theory, however, it is nevertheless con-
sidered that
φ ∈SET and φ /∈U
6",N/A,N/A
"sidered that
φ ∈SET and φ /∈U
6
Also, it is possible that
X ∈SET and X ∩U ̸= φ, or even X ⊆U
For instance, if x ∈U, then
X = {x} ∈SET,
X ⊆U.
Note on SET
Here we should clarify that SET denotes, in fact, all the sets which
exist in the Set Theory based on the ZFA axioms. Therefore, let us de-
note by SET0 all the sets in the Set Theory based on the ZFC axioms.
Then as mentioned in section 0, and seen later, we have SET0 ⫋SET,
thus the above diagram can be made more precise as follows
• set
• φ",N/A,N/A
"• set
• φ
• proper class
SET
• set
• SET = proper class
✲
SET0
• SET0 = proper class
✲
• U = Ur −elements = proper class
CLASS
Examples of Sets
There are only two kind of sets a ∈SET, namely
(1.1)
a = φ, which is equivalent with ¬ ( ∃b ∈SET S U : b ∈a )
(1.2)
∃b ∈SET S U : b ∈a
Operations with sets
An ordered pair is the set < a, b >
= {{a}, {a, b}}, with a, b ∈SET
7
thus < a, b >
=
< c, d >
⇐⇒
a = c, b = d
A relation R ∈SET has all its elements given by pairs
< a, b >,",N/A,N/A
"< a, b >,
where a ∈A, b ∈B, for two suitably given sets A, B ∈SET. Often
for convenience one denotes aRb for < a, b > ∈R.
If A ∈SET is such that < a, b > ∈R =⇒a, b ∈A, then R is a
relation on A.
A relational structure is < A, R >, with R relation on A.
A function is a relation R such that < a, b >, < a, c > ∈R =⇒b = c
If f is a function, then
(1.3)
dom(f) = {a | ∃b : f(a) = b}
(1.4)
rng(f) = {b | ∃a : f(a) = b}
thus
(1.5)
f ∈c →d
⇐⇒
c = dom(f), rng(f) ⊆d
The power set of a ∈SET is
(1.6)",N/A,N/A
"The power set of a ∈SET is
(1.6)
P(a) = {b | b ⊆a}
Example : if a = {φ, p}, with p ∈SET S U, then P(a) = {φ, {φ}, {p}, a}.
Consider the predicate P ( x ) given by
(1.7)
x is an ordered pair < a, b > and b = P(a)
then this deﬁnes the power set function P : SET −→SET, and
(1.8)
S dom(P) = SET
8
thus it is ”large”, and therefore, a proper class.
The natural numbers are
(1.9)
0 = φ, 1 = {0} = {φ}, 2 = {0, 1} = {φ, {φ}}, . . .
Disjoint union is A + B = ({0} × A) ∪({1} × B)
For a ∈SET, we deﬁne",N/A,N/A
"For a ∈SET, we deﬁne
(1.10)
S a = { x | ∃y ∈a : x ∈y } = {x ∈y ∈a}
2. Systems of Equations Which Deﬁne Sets
In usual, that is, ZFC Set Theory, one way to deﬁne a set X is by an
equation
X = {x | P(x)}
where P is a suitable predicate. Within ZFC, an essential restriction
on P is that it cannot in any way refer to the set X which it is sup-
posed to deﬁne. This condition is meant to avoid a ”vicious circle”,
or in more proper terms, self-referentiality, an avoidance which has",N/A,N/A
"until recently been universally accepted, and in fact required, since
Russell’s paradox.
In particular, one cannot deﬁne any set a ∈SET0, even by such a
simple equation, like
(2.1)
a = {a}
since obviously, it is a self-referential equation. On the other hand, as
seen in 1), 4), 5) in Examples 2.1. below, this equation can easily be
solved in SET, that is, based on the Anti-Foundation Axiom, (AFA).
Here we can note that one cannot deﬁne any set a ∈SET0, or for that",N/A,N/A
"matter, a ∈SET, even by the yet more simple equation
9
(2.2)
a = a
since this equation will obviously not give a unique set in SET0, or in
SET.
Also, as seen in 3) in Proposition 2.3. below, one cannot deﬁne a set
a ∈SET by the equation
(2.3)
a = P(a)
Let us consider now the equation
x = {a, x}
where a ∈SET S U is given. Then
x = {a, x} = {a, {a, x}} = {a, {a, {a, x}}} = . . .
thus an intuitive solution would be
x = {a, {a, {a, . . .}}}",N/A,N/A
"x = {a, {a, {a, . . .}}}
which however is not possible within ZFC, since it would obviously
lead to the inﬁnite descending sequence
. . . x ∈x ∈x ∈x ∈x
thus contradict the Foundation Axiom, (FA), see below.
Let us now return to the general situation and enquire what should
the solution given by sets be of a corresponding system of equations.
Let us as an example consider for that purpose the following system
of equations, where p, q ∈SET S U are given, and where we want to",N/A,N/A
"ﬁnd sets x, y, z ∈SET, such that
x = {x, y}
10
y = {p, q, y, z}
z = {p, x, y}
Let e : X = {x, y, z} −→the right-hand sides of the above equations
thus
ex = {x, y}, ey = {p, q, y, z}, ez = {p, x, y}
What is then a solution s to these equations supposed to be ?
One way is given by s : X −→SET, namely X ∋v 7−→sv ∈SET,
with
sx = {sx, sy}, sy = {p, q, sy, sz}, sz = {p, sx, sy}
or equivalently
∀v ∈X :
sv = {sw | w ∈ev ∩X} S {w | w ∈ev ∩A} =
= s[ev ∩X] S (ev ∩A)
where A = {p, q}",N/A,N/A
"= s[ev ∩X] S (ev ∩A)
where A = {p, q}
Returning now to the equation, see (2.2)
x = x
one way to avoid the inconvenience of non-unique solutions in SET,
is to take, see also (2.10) below
X = {x} ⊆U
and then the solution s, if it exists, is a function
11
s : X ∋x −→sx ∈SET
This liberty to distinguish between indeterminates, and on the other
hand, the solution is in fact familiar from usual algebra. Indeed, if for
instance we have the system of equations in real numbers
2x + 3y = 7
5x −4y = 1",N/A,N/A
"2x + 3y = 7
5x −4y = 1
then the set of indeterminates is X = {x, y}, while a solution s, which
in this case exists, is given by a function s : X ∋v −→sv ∈R. This
distinction is even more obvious when, as with a system of equations
like
3x + 2y = 5
5x −3y = 2
the indeterminates have the same value x = y = 1, thus the solution
cannot be identiﬁed with the single number 1, but only with the func-
tion s : X ∋v −→sv ∈R, for which sx = 1, sy = 1.",N/A,N/A
"tion s : X ∋v −→sv ∈R, for which sx = 1, sy = 1.
Finally we can note that, as seen in Deﬁnition 2.2. below, the require-
ment X ⊆U can on occasion be done away with.
Now, the approach in [2] to Self-Referential Mathematics will be able
to accept for sets in SET such deﬁnitions which are given by certain
systems of equations that can be self-referential. There are in this
regard three kind of systems of equations considered so far. The ﬁrst
kind of systems is given by
Deﬁnition 2.1.",N/A,N/A
"kind of systems is given by
Deﬁnition 2.1.
A structure E =
< X, A, e > is called a ﬂat system of equations, if
and only if
(2.4)
X, A ∈SET,
X ⊆U,
X T A = φ
with X the set of indeterminates and A the set of atoms, while
12
(2.5)
e : X −→P(X S A)
deﬁnes the right hand terms of the equations of the system, see (2.8)
below, with
(2.6)
X ∋v 7−→bv = ev ∩X
being the set of indeterminates on which v immediately depends, and
similarly, with
(2.7)
X ∋v 7−→cv = ev ∩A",N/A,N/A
"similarly, with
(2.7)
X ∋v 7−→cv = ev ∩A
being the set of atoms on which v immediately depends
In this way, the ﬂat system of equations is given by
(2.8)
x = ex,
x ∈X
which of course can in particular be one single equation, when X = {x}
is a set with one single element.
A solution to E is a function
(2.9)
X ∋x 7−→sx = {sy | y ∈bx} S cx ∈SET
and we denote
solution −set(E) = S {sx | x ∈X} =
= {sy | y ∈ex ∩X, x ∈X} S S
x∈X(ex ∩A) = s[X] ∈SET
as well as
V [A] = S 
solution −set(E)",N/A,N/A
"as well as
V [A] = S 
solution −set(E)
E ﬂat system of equations
with atoms A

=
13
=

c
∃E = < X, A, e > ﬂat system of equations :
c ∈solution −set(E)

=
=

sy
∃E = < X, A, e > ﬂat system of equations :
y ∈ex ∩X,
x ∈X
 S
S 
c
∃E = < X, A, e > ﬂat system of equations :
c ∈ex ∩A,
x ∈X

⊆SET
and clearly, V [A] is always a proper class, see 2) in Note 2.1. below.
✷
There are two remarkable facts about the concept of ﬂat systems of
equations given in the above Deﬁnition 2.1., namely",N/A,N/A
"• the Anti-Foundation Axiom, (AFA), upon which the whole of
Self-Referential Mathematics in [2] rests, has a most simple for-
mulation in terms of ﬂat systems of equations, as seen next,
• the ﬂat systems of equations do in fact give all the additional
new sets in SET \ SET0, that is those which due to their self-
referential deﬁnitions, cannot be obtained by the usual ZFC Set
Theory, see the equivalence Theorem 2.1. below, see also 1) in
Note 2.1. below.
ANTI-FOUNDATION AXIOM (AFA)",N/A,N/A
"Note 2.1. below.
ANTI-FOUNDATION AXIOM (AFA)
∀E ﬂat system of equations : ∃! s solution
Here, for the sake of further clarity, let us recall that in ZFC we have
AXIOM OF FOUNDATION ( FA )
∀a ∈SET :
< a, ∈> well-founded
14
where the concept of a well-founded relational structure is deﬁned as
follows.
A relational structure < S, R > is called well-founded, if and only if it
has no inﬁnite descending sequence
. . . an R an−1 R . . . R a2 R a1 R a0
with a0, a1, a2, . . . , an−1, an, . . . ∈S.",N/A,N/A
"with a0, a1, a2, . . . , an−1, an, . . . ∈S.
For a relational structure < S, R >, we denote
< S, R >wf
= {a ∈S | no inﬁnite descending sequence in R starting with a}
Clearly
< S, R > well −founded
⇐⇒
< S, R >wf
= S
For simplicity, we denote
Rwf = < S, R >wf
Remark 2.1.
In view of the above (AFA) axiom, the question arises :
• Which ﬂat systems of equations have solutions under the (FA)
axiom ?
The answer is obtained based on the following concept. A ﬂat system",N/A,N/A
"of equations E = < X, A, e > is called well-founded, if and only if the
relation < deﬁned on X by
x < y
⇐⇒
y ∈ex
is well-founded. And then we have, see [1,2]
15
Mostowski Collapsing Lemma
In ZFC−well-founded ﬂat systems of equations have unique solutions.
Corollary 2.1.
In ZFC−we have the equivalence
(FA)
⇐⇒

only well-founded ﬂat systems
of equations have solutions

Note 2.1.
1) Flat systems of equations can trivially recover all sets E ∈SET.",N/A,N/A
"Indeed, let A = E. Further, let X = {x}, with x ∈U, such that
x /∈E, which is possible since U "" E, given the fact that U is a
proper class. Then X ⊆U and X ∩A = φ, hence
ex = E
is obviously a ﬂat system of equations, thus according to (AFA),
it has a unique solution s.
Now in view of (2.6), (2.7), we have
bx = ex ∩X = φ, cx = ex ∩A = E, and then (2.9) gives
sx = {sy | y ∈ex ∩X} ∪(ex ∩A) = E
In this way, the set E was obtained as the unique solution
s : X = {x} ∋x 7−→sx = E",N/A,N/A
"s : X = {x} ∋x 7−→sx = E
of the above ﬂat system of equations.
2) In view of the above example, each x ∈U leads to a ﬂat system
of equations with the respective unique solution sx. And clearly, if
x, x ′ ∈U, x ̸= x ′, then sx ̸= sx ′. As for U, it is a proper class,
therefore, so is {sx | x ∈U}.
16
Examples 2.1.
Let us illustrate the above in the case of the equations (2.1) - (2.3).
1) For (2.1), we can take
X = {x} ⊆U,
A = {φ},
ex = {x} ∈P(X S A)",N/A,N/A
"X = {x} ⊆U,
A = {φ},
ex = {x} ∈P(X S A)
therefore, it is a ﬂat system of equations, made up of a single equation.
As for its unique solution sx ∈SET, we shall see the details in 4) and
5) below.
2) For (2.2), we can take
X = {x} ⊆U,
A = {φ},
ex = x
thus
ex ∈X S A,
ex ⊈X S A,
ex /∈P(X S A)
therefore, it is not a ﬂat system of equations.
Also, with (2.2), we can immediately note why the condition
(2.10)
X ⊆U
was requested in Deﬁnition 2.1. Indeed, without that condition, equa-",N/A,N/A
"tion (2.2) is satisﬁed by all sets a ∈SET, thus (2.2) does not have a
unique solution in SET.
3) With the equation (2.3), we can take
X = {x} S x ⊆U,
A = φ,
ex = P(x) "" X S A,
ex /∈P(X S A)
which, however, does not turn (2.3) into a ﬂat system of equations.
Also, as seen in 3) in Proposition 2.3. below, equation (2.3) does not
have any solution in SET.
17
4) In ZFA, the equation
(2.11)
x = {x}
has a unique solution Ω∈SET. Indeed, as note at 1) above, if we take
X = {x} ⊆U,
A = φ,
ex = {x}",N/A,N/A
"X = {x} ⊆U,
A = φ,
ex = {x}
then (2.11) is a ﬂat system of equations, thus in view of (AFA), it has
a unique solution sx ∈SET, and according to (2.9), we have
(2.12)
sx = {sy | y ∈bx} ∪cx
However, (2.6) gives bx = ex ∩X = {x} ∩X = X = {x}, while (2.7)
implies cx = ex ∩A = φ. Thus (2.12) becomes
sx = {sx}
5) The above unique solution Ω∈SET obviously has the property
Ω= {Ω} = {{Ω}} = {{{Ω}}} = . . .
however, this need not mean that the bracket pairs { } could be in-",N/A,N/A
"ﬁnitely many, namely, that we could have for instance
Ω= . . . {{{Ω}}} . . .
let alone that the bracket pairs { } could reach to transﬁnite ordinals,
or go through all the ordinals, see Remark 2.3. below.
6) In ZFA, there is a unique set
(2.13)
{0, {1, {2, {3, . . .}}}} ∈SET
Indeed, we consider the ﬂat system of equations
x0 = {0, x1}
x1 = {1, x2}
18
x2 = {2, x3}
x3 = {3, x4}
...
where X = {x0, x1, x2, x3, . . .} ⊆U,
A = {0, 1, 2, 3, . . .}, while exn =",N/A,N/A
"A = {0, 1, 2, 3, . . .}, while exn =
{n, xn+1}, with n ≥0. Then (AFA) gives a unique solution s, and in
view of (2.6), (2.7), (2.9), we obtain the relations
sx0 = {sx | x ∈bx0} ∪cx0 = {sx | x ∈ex0 ∩X} ∪(ex0 ∩A) = {0, sx1}
sx1 = {sx | x ∈bx1} ∪cx1 = {sx | x ∈ex1 ∩X} ∪(ex1 ∩A) = {1, sx2}
sx2 = {sx | x ∈bx2} ∪cx2 = {sx | x ∈ex2 ∩X} ∪(ex2 ∩A) = {2, sx3}
...
thus
sx0 = {0, sx1} = {0, {1, sx2}} = {0, {1, {2, sx3}}} = . . .
7) Let us consider that ﬂat system of equations without atoms, that",N/A,N/A
"is, with A = φ, namely
x0 = {y0, x1}
y0 = φ
x1 = {y1, x2}
y1 = {y0}
x2 = {y2, x3}
y2 = {y0, y1}
x3 = {y3, x4}
y3 = {y0, y1, y2}
...
where X = {x0, y0, x1, y1, x2, y2, . . .} ⊆U,
A = φ, while exn =
{yn, xn+1}, eyn+1 = {y0, . . . , yn}, for n ≥0, and ey0 = φ.
In this
case, (2.6), (2.7) give
bxn = exn ∩X = {yn, xn+1},
n ≥0
by0 = ey0 ∩X = φ
byn+1 = eyn+1 ∩X = {y0, . . . , yn},
n ≥0
cxn = cyn = φ,
n ≥0
19
therefore, in view of (2.9), the unique solution s given by (AFA), is
such that",N/A,N/A
"such that
sxn = {sx | x ∈bxn} ∪cxn = {syn, sxn+1},
n ≥0
sy0 = {sy | y ∈by0} ∪cy0 = φ
syn+1 = {sy | y ∈byn+1} ∪cyn+1 = {sy0, . . . , syn},
n ≥0
In particular
sy0 = φ
sy1 = {sy0} = {φ}
sy2 = {sy0, sy1} = {φ, {φ}}
sy3 = {sy0, sy1, sy2} = {φ, {φ}, {φ, {φ}}}
...
which means that, for n ≥0, we obtain that
syn = n in the von Neumann representation
Proposition 2.1.
Let E = < X, A, e > be a ﬂat system of equations. If A ⊆U, then set
solution −set(E) is transitive, namely",N/A,N/A
"solution −set(E) is transitive, namely
b, c ∈SET, c ∈b ∈solution −set(E)
=⇒
c ∈solution −set(E)
Proof.
We recall that
solution −set(E) = {sy | y ∈ex ∩X, x ∈X} S S
x∈X(ex ∩A)
Let b ∈solution −set(E), then
either b = sy, for some y ∈ex ∩X, with suitable x ∈X,
20
or b ∈ex ∩A, for some x ∈X.
In the ﬁrst case, if c ∈b = sy = {sz | z ∈ey ∩X} ∪(ey ∩A), then
either c = sz, thus c ∈solution −set(E),
or c ∈ey ∩A, thus again c ∈solution −set(E).",N/A,N/A
"or c ∈ey ∩A, thus again c ∈solution −set(E).
In the second case, if b ∈ex∩A, then b ∈U, thus there cannot be c ∈b.
Proposition 2.2.
If A ⊆U, then
V [A] ⊆Vafa[A]
where the operation Vafa is deﬁned in (3.5) in the next section.
Note : Here we make an advance use of some notations and results
in section 3 below. However, placing Proposition 2.2. here in section
2 helps in the better understanding of the concept of ﬂat system of
equations, as well as of its fundamental importance seen in the equiv-",N/A,N/A
"alence Theorem 2.1. below.
Proof.
Let c ∈V [A], then for some E = < X, A, e > ﬂat system of equations
we have either
c = sy, for some y ∈ex ∩X, x ∈X
or
c ∈ex ∩A, for some x ∈X
In the ﬁrst case we also have
21
c ⊆Z = solution −set(E) =
= {sy | y ∈ex ∩X, x ∈X} S S
x∈X(ex ∩A)
since in view of (2.9)
c = sy = {sz | z ∈ey ∩X} ∪(ey ∩A)
But in view of Proposition 2.1., the set Z = solution −set(E) is tran-
sitive. Therefore, for x ∈X, we have, see (3.3) below
sx ⊆TC(sx) ⊆Z
which gives",N/A,N/A
"sx ⊆TC(sx) ⊆Z
which gives
TC(sx) ∩U ⊆Z ∩U ⊆A
Indeed, if b ∈Z ∩U, then in particular
either b = sy, for some y ∈ex ∩X, with suitable x ∈X,
or b ∈ex ∩A, for some x ∈X.
In the ﬁrst case, b /∈U, since sy ∈SET.
In the second case obviously b ∈A.
In conclusion, in view of (3.5), we have c ∈Vafa[A].
Remark 2.1.
The following is, of course, a fundamental question :
• How many sets a ∈SET can be obtained as solutions of ﬂat
systems of equations ?",N/A,N/A
"systems of equations ?
In 1) in Note 2.1. above, we have seen that ﬂat systems of equations
can trivially recover as solutions all sets in SET. A more precise and
rather natural answer, and as such, best possible answer will be given
22
in Theorem 2.2. below.
Needless to say, this answer highlights the importance of ﬂat systems of
equations. However, in various contexts, other two concepts of systems
of equations will prove to be useful, concepts given in Deﬁnitions 2.2.
and 2.3. below.
✷",N/A,N/A
"and 2.3. below.
✷
Now, the second kind of systems of equations aims to eliminate the
above restriction X ⊆U in (2.10) on the ﬂat systems of equations.
And as we shall see in Theorem 2.1. below, this is in fact possible, in
spite of the above problem with lack of uniqueness of solutions, pro-
vided that the STRONG AXIOM OF PLENITUDE is accepted.
Deﬁnition 2.2.
A structure E
=
< X, A, e > is called a generalized ﬂat system of
equations, if and only if
(2.14)
X, A ∈SET,
X T A = φ",N/A,N/A
"(2.14)
X, A ∈SET,
X T A = φ
with X the set of indeterminates and A the set of atoms, while
(2.15)
e : X −→P(X S A)
✷
There is a close connection between the solutions of ﬂat, and on the
other hand, generalized ﬂat systems of equations, provided that the
following axiom holds
STRONG AXIOM OF PLENITUDE
There is an operation new(a, b), such that
1)
∀a ∈SET, b ⊂U : new(a, b) ∈U \ a
2)
∀a, a ′ ∈SET, a ̸= a ′, b ⊂U : new(a, b) ̸= new(a ′, b)
23
Theorem 2.1.",N/A,N/A
"23
Theorem 2.1.
Assuming the STRONG AXIOM OF PLENITUDE, every general-
ized ﬂat system of equations E =
< X, A, e > has a unique solution
s. Furthermore, there exists an associated ﬂat system of equations
E ′ =
< Y, A, e ′ >, such that
solution −set(E) = solution −set(E ′)
Proof.
We have to replace X by a set Y ⊂U, such that Y ∩A = φ. Thus we
take
Y = {yx | yx = new(x, A),
x ∈X}
then
Y ⊂U,
Y ∩A = φ
Let now
e ′
yx = {yz | z ∈ex ∩X} S (ex ∩A)
Clearly, E ′ =",N/A,N/A
"e ′
yx = {yz | z ∈ex ∩X} S (ex ∩A)
Clearly, E ′ =
< Y, A, e ′ > is a ﬂat system of equations, and thus, it
has a unique solutio s ′.
Now we get the solution s of E =
< X, A, e > given by
sx = s ′
yx,
x ∈X
The uniqueness of s follows from the fact that every solution t of
E =
< X, A, e > gives a solution t ′ of E ′ =
< Y, A, e ′ >. And we
must have t ′ = s ′, thus it follows that t = s.
✷
Example 2.2.
24
For every set a ∈SET, we associate the canonical generalized ﬂat",N/A,N/A
"system of equations Ea = < Xa, Aa, ea >, with, see (3.1)
Aa = TC(a) T U
Xa = TC({a}) \ Aa
and
Xa ∋x 7−→(ea)x = x ⊆Xa
S Aa
where we have to prove the inclusion in the last relation.
We note in this regard that, see (3.2∗), (3.3∗) and 1) in Examples 3.1.
Aa = {x ∈U | x ∈an ∈. . . ∈a1 ∈a0 = a,
n ≥0}
Xa = ( {a} S TC(a) ) \ ( TC(a) T U ) =
= ( {a} S {x | x ∈an ∈. . . ∈a1 ∈a0 = a,
n ≥0} )\
\ {y ∈U | y ∈bm ∈. . . ∈b1 ∈b0 = a,
m ≥0} =
= {a} S {x ∈SET | x ∈an ∈. . . ∈a1 ∈a0 = a,
n ≥0}
thus",N/A,N/A
"n ≥0}
thus
x ∈Xa =⇒x ∈SET
Furthermore
x ∈Xa =⇒x ⊆Xa
S Aa
Indeed, given x ∈Xa, then there are the two cases
(i.1)
x = a
25
(i.2)
x ∈an ∈. . . ∈a1 ∈a0 = a, for some n ≥0
Let now y ∈x.
In case (i.1), we have y ∈a, thus y ∈Xa, pro-
vided that y /∈U. Otherwise obviously y ∈Aa. In case (i.2), clearly
y ∈(Xa ∪Aa).
Assuming now the STRONG AXIOM OF PLENITUDE, we have in
view of Theorem 2.1., a unique solution sa of Ea. And in fact, we have
sa : Xa ∋x 7−→(sa)x = x ∈SET
Indeed, (2.9) gives for x ∈Xa",N/A,N/A
"Indeed, (2.9) gives for x ∈Xa
(sa)x = {(sa)y | y ∈(ea)x ∩Xa} ∪((ea)x ∩Aa) ∈SET
while
(ea)x ∩Xa = x ∩Xa,
(ea)x ∩Aa = x ∩Aa
thus
(sa)x = {(sa)y | y ∈x ∩Xa} ∪(x ∩Aa) ∈SET
which in our case becomes the identity
x = {y | y ∈x ∩Xa} ∪(x ∩Aa) ∈SET
Theorem 2.2. Equivalence
Assuming now the STRONG AXIOM OF PLENITUDE, we have for
A ⊆U the equivalence between sets in SET which have support in A,
and sets in SET which are solutions of ﬂat systems of equations with
atoms in A, namely
Vafa[A] = V [A]
Proof.",N/A,N/A
"atoms in A, namely
Vafa[A] = V [A]
Proof.
26
In view of Proposition 2.2., we have
V [A] ⊆Vafa[A]
Let now a ∈Vafa[A]. Then by deﬁnition, see (3.5) below
TC(a) ∩U ⊆A
Now, in view of Example 2.2., we consider the unique solution sa of
the canonical generalized ﬂat system of equations Ea = < Xa, Aa, ea >,
which is sa = idXa. Thus, recalling that a ∈Xa and Aa = TC(a)∩U ⊆
A, we obtain
sa = a
which gives
a ∈solution −set(Ea)
On the other hand, in view of Theorem 2.1., there is a ﬂat system of",N/A,N/A
"equations E = < X, Aa, e > with the same atoms Aa, such that
solution −set(Ea) = solution −set(E)
hence a ∈solution −set(E) ⊆V [A]
✷
Finally, the third kind of systems of equations allows considerably
more general right hand terms ex in (2.5), (2.15), although it has to
accept harder restrictions on X and A, than in Deﬁnition 2.1., that
is, in (2.10). Namely
Deﬁnition 2.3.
A structure E =
< X, A, e > is called a generalized system of equa-
tions, if and only if
(2.16)
X, A ∈SET,
X, A ⊆U,",N/A,N/A
"tions, if and only if
(2.16)
X, A ∈SET,
X, A ⊆U,
X T A = φ
27
with X the set of indeterminates and A the set of atoms, while
(2.17)
e : X −→Vafa(X S A)
where the operation Vafa is deﬁned in (3.5) in the next section.
Remark 2.2.
As we shall see in section 3, the range Vafa(X S A) of the mappings e
in (2.17) is considerably larger than P(X S A), which is the range of
the corresponding mappings in (2.5) and (2.15). Therefore, the gen-",N/A,N/A
"eralized systems of equations deﬁned above contain as a rather small
particular case the ﬂat and the generalized ﬂat systems of equations.
Examples 2.3.
1) For a given a ∈SET S U, let us consider the equation
(2.18)
x = x −→a
hence it is not a ﬂat or generalized ﬂat system of equations, if we take
X = {x},
A = {a},
ex = x −→a ⊆x × a,
ex ⊈X S A
ex /∈P(X S A)
although (2.18) has solution in SET, see 5) in Proposition 2.3. below.
2) For given p, q ∈SET S U, the equation
(2.19)
x = {{x, q}, p}",N/A,N/A
"(2.19)
x = {{x, q}, p}
is not a ﬂat or generalized ﬂat system of equations, if considered with
X = {x},
A = {p, q},
ex = {{x, q}, p} ⊈X S A,
ex /∈P(X S A)
although it can be written as a ﬂat system of equations, provided that
28
x ∈U, namely
x = {y, p}
y = {x, q}
hence
X = {x, y},
A = {p, q},
ex = {y, p}, ey = {x, q} ⊆X S A,
ex, ey ∈P(X S A)
Proposition 2.2.
Within ZFC we have
1)
∀a ∈SET : a /∈a
2)
¬∃a1, . . . , an ∈SET : a1 ∈. . . an ∈a1
3)
¬∃a, b ∈SET : a ∈TC(b) ∈a
4)
¬∃a, b ∈SET : a ∈TC(b),",N/A,N/A
"4)
¬∃a, b ∈SET : a ∈TC(b),
b ∈TC(a)
5)
∀a, b, c ∈SET : c = < a, b >
=⇒c ̸= a, c ̸= b, c /∈a, c /∈b
6)
∀A, X ∈SET : X ̸= φ =⇒X ̸= A × X
7)
∀X ∈SET : X = X × X =⇒X = φ
8)
¬∃function f = A −→B, A, B ∈SET : f ∈dom(f)
9)
¬∃functions f1 : A1 −→A2, . . . , fn : An −→A1,
A1, . . . , An ∈SET, a1 ∈A1 :
fn(. . . f1(a1) . . .) = f1
29
10)
∀A, X ∈SET : X ̸= X −→A
It is important to note that, as seen next, even in ZFC−, that is, with-
out FA, one can obtain impossibilities of self-reference.",N/A,N/A
"Proposition 2.3.
Within ZFC−we have
1)
∀function F : A −→B, A, B ∈SET :
{x ∈dom(F) | x /∈F(x)} /∈rng(F)
2)
∀function F : A −→P(A), A ∈SET :
{x ∈A | x ∈Rwf} /∈rng(F)
where R = {< x, y > | x ∈F(y)}
3)
∀X ∈SET : X ̸= P(X)
4)
∀X ∈SET : X = X −→φ
=⇒
X = {φ}
5)
∀A, X ∈SET : X = X −→A
=⇒
=⇒
A = {a}, X = {f}, f(f) = a
6)
∀X ∈SET : X = X −→X
=⇒
X = {x}, x = {< x, x >}
The proofs of the above two Propositions 2.2. and 2.3. are rather
simple and immediate, and can be found at [1, pp. 25-27]
Remark 2.3.",N/A,N/A
"Remark 2.3.
Related to 5) and 6) in Examples 2.1. above, let us note the follow-
ing two kind of situations encountered so far with sets which have
inﬁnitely many brackets, namely :
30
(2.20)
Ω
?= . . . {{{Ω}}} . . .
(2.21)
{0, {1, {2, {3, . . .}}}} ∈SET
The second one was, in 6) in Examples 2.1. above, proved to exist
uniquely, and be well deﬁned in ZFA, while the ﬁrst one will be con-
sidered in more detail in 2) below.
1) Related to (2.21), we note the following immediate generalization.",N/A,N/A
"Let α be any inﬁnite ordinal number and let us take
X = {xβ | β < α} ⊆U,
A = {β | β < α}
while
exβ = {β, xβ+1},
β < α
Then obviously, we obtain a ﬂat system of equations, therefore (AFA)
gives a unique solution s which, in view of (2.9), has the property
sxβ = {sx | x ∈bxβ} S cxβ ∈SET,
β < α
where according to (2.6), (2.7), we have
bxβ = exβ ∩X = {xβ+1},
cxβ = exβ ∩A = φ,
β < α
hence
sxβ = {sxβ+1} ∈SET,
β < α
which gives
(2.22)
sx0 = {0, sx1} = {0, {1, sx2}} = {0, {1, {2, sx3}}} = . . .",N/A,N/A
"where the pairs of brackets { } occur once for each β < α.
Thus (2.21) is the particular case of the above sx0 in (2.22) correspond-
ing to α = ω which is the ﬁrst inﬁnite ordinal. In the general case of an
31
inﬁnite ordinal α, the above sx0 in (2.22) gives instead of (2.21) the set
(2.23)
{0, {1, {2, {3, . . .{β, . . .} . . .}}}} ∈SET
which contains all β < α.
2) Let us return to (2.20) and consider it as a particular case of the
following general operation : given a ∈SET S U, deﬁne the set",N/A,N/A
"(2.24)
. . . {{{a}}} . . . ∈SET
with a pair of brackets { } for each n < ∞. For that purpose, let use
the following notation
{
0
a}
0
= a,
{
1
a}
1
= {a},
{
2
a}
2
= {{a}}, . . .
Thus the problem is :
How to deﬁne in SET
(2.25)
{
ω
a}
ω
∈SET
where ω denotes the ﬁrst inﬁnite ordinal number.
Of course, one would want to deﬁne (2.25) as a certain kind of ”limit”
of the sequence of sets {
n
a}
n
∈SET,
n ≥0.
One way to do that for an arbitrary set a ∈SET is as follows. Let us
denote
0
{a
0
} = a
1",N/A,N/A
"denote
0
{a
0
} = a
1
{a
1
} =
0
{a
0
} ∪{a} = a ∪{a}
2
{a
2
} =
1
{a
1
} ∪{a, {a}} = a ∪{a} ∪{a, {a}}
3
{a
3
} =
2
{a
2
} ∪{a, {a, {a}}} = a ∪{a} ∪{a, {a}} ∪{a, {a, {a}}}
32
4
{a
4
} =
3
{a
3
} ∪{a, {a, {a, {a}}}} =
= a ∪{a} ∪{a, {a}} ∪{a, {a, {a}}} ∪{a, {a, {a, {a}}}}
...
It follows that
(2.26)
1
{a
1
} ⊆
2
{a
2
} ⊆
3
{a
3
} ⊆
4
{a
4
} . . .
Thus one can deﬁne
(2.27)
ω
{a
ω
} = S
n<ω
n
{a
n
} ∈SET
Clearly, that procedure can be extended to all ordinal numbers α.",N/A,N/A
"Thus the above problem (2.25) got solved in general, although not
along its initial formulation.
On the other hand, in the particular case when a = Ω∈SET, then
in view of the fact that
Ω= {
n
a}
n
∈SET,
n < ω
one may come up with a deﬁnition of (2.25) considered in its initial
formulation, and which hence is simpler than the one given in (2.27),
namely
(2.28)
{
ω
a}
ω
= Ω∈SET
And again, one may extend that deﬁnition to all ordinal numbers α, by
(2.29)
{
α
a}
α
= Ω∈SET",N/A,N/A
"(2.29)
{
α
a}
α
= Ω∈SET
3) The obvious diﬀerence between (2.20) and (2.21) is that in the sec-
ond, there is an outer pair of brackets { }, while in the ﬁrst there is
none. And such an outer pair of brackets does indeed deﬁne a set in
SET, or for that matter, even in SET0, provided that what is within
33
that outer pair of brackets makes sense in the respective version of Set
Theory. And clearly, for (2.21) such is the case within SET, as seen
in 6) in Examples 2.1. above.",N/A,N/A
"in 6) in Examples 2.1. above.
One can also note that the generalization of (2.21) in (2.23) to arbi-
trary ordinals α always has an outer pair of brackets { }. On the other
hand, in the generalization (2.29) of (2.20), there is an outer pair of
brackets { }, only if α is not a limit ordinal.
4) The ﬂat system of equations in 7) in Examples 2.1., can obviously
be generalized to arbitrary ordinal numbers α, in a way similar to the
generalization in 1) above of 6) in Examples 2.1.",N/A,N/A
"generalization in 1) above of 6) in Examples 2.1.
3. Three Basic Operations
In order to pursue the theory, the following three operations, seldom
if at all encountered in usual Set Theory, although quite elementary
as such, will be needed.
We start with the deﬁnition of a fundamental concept.
Deﬁnition 3.1.
A set a ∈SET is called transitive, if and only if
b ∈a
=⇒
b ⊆a
or equivalently
c ∈b ∈a
=⇒
c ∈a
Clearly, usual sets in mathematics are not transitive. For instance,",N/A,N/A
"given a set X of open subsets in a topological space, then the transi-
tivity of X would imply that for every open subset E ∈X , we must
also have E ⊆X . In other words, X must also contain as elements all
the points x ∈E, for every E ∈X .
34
And now, the ﬁrst basic operation.
Deﬁnition 3.2.
Given a set a ∈SET, its transitive closure is by deﬁnition the smallest
transitive set which contains it, and which is denoted by TC(a).
Lemma 3.1.",N/A,N/A
"Lemma 3.1.
The transitive closure TC(a) exists for every set a ∈SET, and it is
given by
(3.1)
TC(a) = S {a, S a, S S a, . . .} ∈SET
Further, for a ∈SET, we have
(3.2)
TC(a) = {b | b ∈a} S {c ∈b ∈a} S {d ∈c ∈b ∈a} S
S {e ∈d ∈c ∈b ∈a} S . . .
Here we used the simplifying notation
{c ∈b ∈a} = { c | ∃b ∈a : c ∈b }
{d ∈c ∈b ∈a} = { d | ∃b ∈a : ∃c ∈b : d ∈c }
...
Note.
The meaning of TC(a), for a given set a ∈SET, is clear from (3.2)
which, obviously, can be written in the equivalent form
(3.2∗)",N/A,N/A
"(3.2∗)
TC(a) = {x | x ∈an ∈. . . ∈a2 ∈a1 ∈a0 = a,
n ≥0}
Proof.
35
We note that
S a = S
b∈a b = {c ∈b ∈a}
thus
S S a = S
b∈S a b = {c ∈b ∈S a} = {d ∈c ∈b ∈a}
and so on . . .
Therefore
TC(a) = {x ∈y ∈{a, S a, S S a, . . .}} =
= {x ∈y = a} S {x ∈y = S a} S
S {x ∈y = S S a} S . . . =
= a S ( S a ) S ( S S a ) S . . . =
= a S ( S
b∈a b ) S ( S
c∈S a c ) S ( S
d∈S S a d ) . . . =
= {b ∈a} S {c ∈b ∈a} S {d ∈c ∈b ∈a} . . .
Examples 3.1.
1) Given a ∈SET, then TC({a}) is the smallest transitive set which",N/A,N/A
"has a ∈SET as an element, since
TC({a}) = {a} S {c ∈b ∈{a}} S {d ∈c ∈b ∈{a}} . . . =
= {a} S {c ∈b = a} S {d ∈c ∈b = a} . . . =
= {a} S {b ∈a} S {c ∈b ∈a} . . . = {a} S TC(a)
2) TC(φ) = φ
36
3) If a ∈U, then TC({a}) = {a}
Note : if a ∈U, then TC(a) is not deﬁned, since a /∈SET
4) If a ⊆U, a ∈SET, then TC(a) = a
5) If a ∈SET, then
TC(a) = φ =⇒{b ∈a} = φ =⇒a = φ
thus
TC(a) = φ ⇐⇒a = φ
6) If a ⊆U, a ∈SET, then
TC(a) = φ =⇒a = φ ∈SET
TC(a) = φ ⇐⇒a = φ
7) If A, B ∈SET, A, B ̸= φ, a ∈A, b ∈B, then",N/A,N/A
"7) If A, B ∈SET, A, B ̸= φ, a ∈A, b ∈B, then
< a, b > = {{a}, {a, b}} ∈A × B ∈SET
and
TC(< a, b >) = < a, b > S {d ∈c ∈< a, b >} S
S {e ∈d ∈c ∈< a, b >} S . . . =
= {{a}, {a, b}} S {d ∈c = {a} W d ∈c = {a, b}} S
S {e ∈d ∈c = {a} W e ∈d ∈c = {a, b}} S . . . =
= {{a}, {a, b}} S {d ∈{a, b}} S {e ∈d ∈{a, b}} S . . . =
= {{a}, {a, b}} S {a, b} S {e ∈{a, b}} S . . . =
37
= {{a}, {a, b}} S TC({a, b}) =
< a, b > S TC({a, b})
8) If A, B ∈SET, A, B ̸= φ, R ⊆A × B, then",N/A,N/A
"8) If A, B ∈SET, A, B ̸= φ, R ⊆A × B, then
TC(R) = R S {c ∈< a, b > ∈R} S {d ∈c ∈< a, b > ∈R} S
S {e ∈d ∈c ∈< a, b > ∈R} S . . . =
= R ∪{c = {a}| < a, b > ∈R} ∪{c = {a, b}| < a, b > ∈R}∪
∪{d ∈c = {a}| < a, b > ∈R} ∪{d ∈c = {a, b}| < a, b > ∈R}∪
∪{e ∈d ∈c = {a}| < a, b > ∈R}∪
∪{e ∈d ∈c = {a, b}| < a, b > ∈R} ∪. . . =
= R ∪{{a} | < a, b > ∈R} ∪{{a, b} | < a, b > ∈R}∪
∪{a | < a, b > ∈R} ∪{b | < a, b > ∈R}∪
∪{e ∈a | < a, b > ∈R} ∪{e ∈b | < a, b > ∈R} ∪. . .",N/A,N/A
"9) The above goes in particular when R is a function f : A −→B, or
when R = A × B, and in the last case we obtain
TC(A × B) = (A × B) ∪{{a} | a ∈A} ∪{{a, b} | a ∈A, b ∈B}∪
∪{a | a ∈A} ∪{b | b ∈B}∪
∪{e ∈a | a ∈A} ∪{e ∈b | b ∈B} ∪. . . =
= (A × B) ∪{{a} | a ∈A} ∪{{a, b} | a ∈A, b ∈B} ∪TC(A) ∪TC(B)
10) If X ∈SET, then
TC(P(X)) = P(X) S {c | c ∈b ∈P(X)} S
38
S {d | d ∈c ∈b ∈P(X)} S . . . =
= P(X) S {c | c ∈Y ⊆X} S {d | d ∈c ∈Y ⊆X} S . . . =
= P(X) S {c | c ∈X} S {d | d ∈c ∈X} S . . . =",N/A,N/A
"= P(X) S {c | c ∈X} S {d | d ∈c ∈X} S . . . =
= P(X) S TC(X)
11) If x, y ∈U and a = { x, { y } }, then
TC(a) = {x, {y}, y}
since b ∈a ⇐⇒b = x W b = {y}, thus c ∈b ⇐⇒c = y, hence
TC(a) = a S {c | c ∈b ∈a} S {d | d ∈c ∈b ∈a} . . . =
= a S {c | c = y} S {d | d ∈c = y} . . . = a S {y}
✷
The second important operation is presented in
Deﬁnition 3.3.
We deﬁne for sets their support as follows
(3.3)
SET ∋a
7−→
support(a) = TC(a) T U
Further, a set a ∈SET is called pure, if and only if
(3.4)",N/A,N/A
"(3.4)
support(a) = φ
Note.
The meaning of support(a), for a set a ∈SET, is easy to see, based
on (3.2∗), namely
(3.3∗)
support(a) = {x ∈U | x ∈an ∈. . . ∈a1 ∈a0 = a,
n ≥0}
39
in other words, support(a) is the set of all ur-elements x ∈U, if there
exist any, with which ﬁnite descending sequences x ∈an ∈. . . ∈a1 ∈
a0 = a, with n ≥0, that start with the set a do terminate.
Consequently, pure sets a ∈SET do not have such ﬁnite descending
sequences, but only inﬁnite ones, namely",N/A,N/A
"sequences, but only inﬁnite ones, namely
. . . ∈an ∈an−1 ∈. . . ∈a2 ∈a1 ∈a0 = a
✷
Finally, the third important operation is presented in
Deﬁnition 3.4.
(3.5)
U ⊃A
7−→
Vafa[A] = {a ∈SET | support(a) ⊆A}
and clearly, Vafa[A] is always a proper class.
We also denote
(3.6)
Vafa[φ] = Vafa = {a ∈SET | a is a pure set}
✷
Clearly
(3.7)
Vafa[A] ⊆SET
therefore
(3.8)
Vafa[A] T U = A T Vafa[A] = φ,
A ⊆U
Also, if a ∈SET, then we have seen that
TC(a) = φ ⇐⇒a = φ
therefore
40
a = φ =⇒support(a) = φ",N/A,N/A
"therefore
40
a = φ =⇒support(a) = φ
Also, if a ⊆U, then we have seen that
TC(a) = a
therefore
support(a) = a
If x, y ∈U and a = { x, { y } }, then we have seen that
TC(a) = {x, {y}, y}
thus
support(a) = TC(a) T U = {x, {y}, y} TU = {x, y}
4. Graph Formulation
In this section we follow the presentation in [1], without however the
proofs.
We consider directed graphs (N, E), where N is the set of nodes and
V ⊆N ×N is the set of vertices. A vertex (n, n ′) ∈V can be denoted
by n →n ′. Thus",N/A,N/A
"by n →n ′. Thus
n0 →n1 →n2 →. . .
is a ﬁnite or inﬁnite path
The graph (N, E) is called a well-founded graph, if and only if it has
no inﬁnite path
We also denote
41
N ∋n 7−→[ n >= { n ′ ∈N | (n, n ′) ∈E }
N ∋n 7−→
< n ] = { n ′ ∈N | (n ′, n) ∈E }
Given a directed graph (N, E) and n0 ∈N, we call (n0 ∈N, E) a
pointed graph.
A pointed graph (n0 ∈N, E) is called an accessible graph, if and only if
∀n ∈N : ∃path n0 →. . . →n
An accessible graph (n0 ∈N, E) is called a tree with root n0, if and",N/A,N/A
"only if
∀n ∈N : ∃! path n0 →. . . →n
A decoration of a directed graph (N, E) is any mapping S : N −→Set,
such that
∀n ∈N : S(n) = { S(n ′) | n ′ ∈[ n > }
Example 4.1.
3
•
         ✠
❅
❅
❅
❅
❅
❅
❅
❅❅
❘
0 •
2
•
1
•
✛
✟
✟
✟
✟
✟
✟
✟
✟
✙
❍
❍
❍
❍
❍
❍
❍
❍
❨
❄
let S be any decoration
then [ 0 >
= φ, thus S(0) = φ = 0
and [ 1 >
= 0, thus S(1) = {S(0)} = {φ} = 1
42
while [ 2 >
= {0, 1}, thus S(2) = {S(0), S(1)} = {0, 1} = 2
ﬁnally [ 3 > = {0, 1, 2}, thus S(3) = {S(0)S(1), S(2)} = {0, 1, 2} = 3",N/A,N/A
"Mostowski’s Collapsing Lemma 4.1.
Every well-founded graph has a unique decoration.
✷
A picture of a set A is any accessible graph (n0 ∈N, E) which has a
decoration S such that A = S(n0)
Corollary 4.1.
Every well-founded accessible graph is a picture of a unique set.
Proposition 4.1.
Every set has a picture.
Proposition 4.2.
The ANTI-FOUNDATION AXIOM (AFA) has the equivalent formu-
lation :
AFA AXIOM
Every directed graph has a unique decoration.
Corollary 4.2",N/A,N/A
"Corollary 4.2
Every accessible graph is the picture of a unique set.
There exist non-well-founded sets.
43
5. Comments, and Beyond
Self-reference has for quite a while by now happened to have acquired
a rather automatic and somewhat thoughtless bad reputation as being
but a source of undesirable paradoxes.
One of the more memorable moments in this regard was in ancient
Greece, when the man from Theba came to Athens and stated in
front of Athenians that : ”All Thebans are liars !”",N/A,N/A
"Nearer to our own days, in 1903, Russell’s Paradox reformulated that
ancient story within Set Theory which was then emerging as the ba-
sis of modern mathematics, and thus further aggravated the age old
negative reﬂexes regarding self-referentiality.
On the other hand, as anthropologists tell us, three fundamental
themes in human thought deeply rooted in prehistoric and pre-literate
times have been self-referentiality, inﬁnity and change.",N/A,N/A
"Regarding the ﬁrst, which is of main interest here, countless images
of a snake biting its own tail are a testimony. Also, ancient Vedic
wisdom saw it as the foundational aspect of reality. As for the ancient
Hebrews, in Exodus 3:14 of the Old Testament, they considered it to
be nothing less than the very name of God.
In this way, with the self-referential snake - rendered harmless as long
as it is busy biting its own tail - as much as with the ancient Hindus",N/A,N/A
"or Hebrews, self-referentiality was not at all a horror to be avoided by
all means. On the contrary, it was a rather sacred foundational aspect
of the whole of reality ...
But then, later, came the man from Theba ...
And in our days, as a reinforcement in the very foundations of math-
ematics upon Set Theory, we have been facing Russell’s Paradox ...
As it happens, however, a turn was taken in [5] back to ancient, pre-
Athenian wisdom. And self-referentiality was in fact found to be of a",N/A,N/A
"positive practical interest, an interest which could not be addressed in
other ways, [1-3].
But to return to what may be seen as more of an everyday mathe-
44
matics, and actually, physics as well. Recently it was noted that such
an elementary and basic concept like orthogonality can in fact be de-
ﬁned in arbitrary vector spaces without any scalar product, provided
a self-referential deﬁnition is employed, [13].
The relevance of that in modern physics is obvious. Indeed, in Quan-",N/A,N/A
"tum Mechanics, for instance, the standard model is based on Hilbert
spaces where orthogonality is essential and has considerable physical
meaning and interpretation.
However, self-referentiality may turn out to have far larger and deeper
impact in mathematics. In this regard, let us mention a few areas
where, given long ongoing deeper underlying diﬃculties so far not
treatable without self-referentiality, one may at last ﬁnd a more ap-",N/A,N/A
"propriate approach by suitable self-referential deﬁnitions of basic con-
cepts.
For instance, the usual concept of topology, introduced by Haus-
dorﬀin 1914, suﬀers among others from the fact that the respec-
tive category is not Cartesian closed.
In other words, given three
topological spaces X, Y and Z, we typically do not have the equality
C(X × Y, Z) = C(X, C(Y, Z)) between the respective spaces of contin-
uous functions.",N/A,N/A
"uous functions.
That, as well as other deﬁciencies of the usual concept of topological
space have during the last decades been addressed by various more
general concepts of so called pseudo-topologies, [15]. The fact, how-
ever, remains that the variety of pseudo-topological concepts evolved
so far, and deﬁned of course without self-reference, give the impression
of a series of ad-hoc disparate steps which do not seem to manage to
touch in a more unifying manner the deeper meaning of topology.",N/A,N/A
"Probability theory is another area of mathematics where the standard
Kolmogorov model has manifest deﬁciencies. One that turns up from
the very beginning is that each point x ∈X = [0, 1] has the probabil-
ity zero with the usual measure, thus probabilistically it is redundant.
Yet the set of all such points cannot be eliminated, since then one
would remain with the empty set. And this is in sharp contradistinc-
tion with what happens in the case of a ﬁnite or countable probability",N/A,N/A
"space X, where each point of zero probability can be eliminated, and
45
one remains with a simpliﬁed model X0 which is isomorphic from the
point of view of probability. Further well known diﬃculties with the
standard Kolmogorv model are found in the study of continuous time
stochastic processes.
It is therefore an open question of some eﬀective interest whether a
self-referential deﬁnition of probability space may help in overcoming",N/A,N/A
"such diﬃculties. In this regard it is worth noting that, while the Loeb
nonstandard approach to probability brought with it a number of ad-
vantages, it has nevertheless not been able to address satisfactorily
the mentioned, as well as other diﬃculties.
The concept of computability has been of major interest during the
last decades. As for the nature of its deﬁnition, the present relevance
of the related Church-Turing Thesis can be seen as showing a certain",N/A,N/A
"lack of suﬃcient insight, and thus it can appear as an inadequacy. In
this regard, one may consider the possibility of a self-referential deﬁ-
nition of the concept of computability.
Complexity, among other realms in computation, is another funda-
mental modern concept in mathematics. And then, as its own name
may possibly suggest, perhaps, the present day simple non-self-referential
deﬁnitions for it may actually be rather inappropriate ...",N/A,N/A
"So much for avoiding the alleged horrors of self-referentiality ...
And as a sign of the power of persistence of age old negative conno-
tation attached to self-referentiality, one can note that major recent
contributions to the subject still use a negative terminology, such as
”non-well-founded sets” or ”vicious circles” ...
And now, let us consider a possibly yet older, more universal, and so
far incontrovertible horror, namely, that of contradiction.",N/A,N/A
"Indeed, in this regard, there seems not to be found any controversy of
any signiﬁcance whatsoever throughout known human history, with
all the evidence pointing to the universal commandment of : ”One
must avoid contradiction !”
46
And yet, so strangely, ever since we so essentially use our modern elec-
tronic digital computers, we have been basing so much, and in such
an essential manner, on a very simple, clear and sharp contradiction.",N/A,N/A
"Indeed, rather not consciously known to most of us, such computers -
even when seen as operating only on non-negative integers - function
according to the following :
CONTRADICTORY SYSTEM OF AXIOMS :
• the well known Peano Axioms
plus the axiom :
• there exists M >> 1, such that M + 1 = M
where the respective M, called machine inﬁnity, may typically be
larger than 10100.
So much for avoiding the alleged horrors of contradictions ...",N/A,N/A
"Here however, apparently not having any known ancient wisdom to
return to, a genuinely novel opening was taken with recent studies of
so called inconsistent mathematics, [11,12].
What may, beyond all that, be indeed a major new opening is the de-
velopment of mathematics which brings together both self-referentiality
and contradiction. And the unprecedented vastness of the respective
realms that may become available in such a way is only to be guessed
at present time ...
6. Axioms of Set Theory",N/A,N/A
"at present time ...
6. Axioms of Set Theory
For convenience, we recall here the ZFC Axioms of Set Theory, [8, p.
1].
AXIOM OF EXTENSIONALITY
If two sets X and Y have the same elements, then X = Y.
47
AXIOM OF PAIRING
For any two sets a and b there exists a set {a, b} that contains exactly a and b.
AXIOM SCHEMA OF SEPARATION
If P is a property with parameter p, then for any sets X and p there exists a set
Y = {u ∈X | P(u, p)} that contains all those elements u ∈X which have property P.",N/A,N/A
"AXIOM OF UNION
For any set X there exists a set Y = S X, the union of all elements of X.
AXIOM OF POWER SET
For any set X there exists a set Y = P(X), the set of all subsets of X.
AXIOM OF INFINITY
There exists an inﬁnite set.
AXIOM SCHEMA OF REPLACEMENT
If a class F is a function, then for any set X there exists a set
Y = F(X) = {F(x) | x ∈X}.
AXIOM OF REGULARITY OR FOUNDATION
Every nonempty set has an ∈−minimal element.
AXIOM OF CHOICE
Every family of nonempty sets has a choice function.",N/A,N/A
"Here, we also recall the additional axioms used above.
48
ANTI-FOUNDATION AXIOM (AFA)
∀E ﬂat system of equations : ∃! s solution
An equivalent formulation of the above Axiom of Regularity or Foun-
dation is given in
AXIOM OF FOUNDATION ( FA )
∀a ∈SET :
< a, ∈> well-founded
STRONG AXIOM OF PLENITUDE
There is an operation new(a, b), such that
1)
∀a ∈SET, b ⊂U : new(a, b) ∈U \ a
2)
∀a, a ′ ∈SET, a ̸= a ′, b ⊂U : new(a, b) ̸= new(a ′, b)
References",N/A,N/A
"References
[1] Aczel P : Non-Wellfounded Sets. CSLI Lecture Notes Number 14,
Stanford Univ., 1988
[2] Barwise J, Moss L : Vicious Circles, on the Mathematics of Non-
Wellfounded Phenomena. CSLI Lecture Notes Number 60, Stan-
ford Univ., 1996
[3] Barwise J, Etchemendy J : The Liar, an Essay on Truth and
Circularity. Oxford Univ. Press, 1987
[4] Bourbaki N : Elements of Mathematics, Set Theory. Springer,
New York, 2004
[5] Forti M, Honsell F : Set theory with free construction principles.",N/A,N/A
"Annali Scuola Normale Superiore di Pisa, Classe di Scienze, 1983,
10, 493-522
49
[6] Fraenkel A A : Abstract Set Theory, Third, Revised Edition.
North-Holland, Amsterdam, 1966
[7] Henle J M : An Outline of Set Theory. Springer, New York, 1986
[8] Jech T : Set Theory, The Third Millennium Edition, Revised and
Expanded. Springer, New York, 2003
[9] Lawvere F W, Rosenburgh R : Sets for Mathematics. Cambridge
Univ. Press, 2003
[10] Levy A : Basic Set Theory. Dover, New York, 1979",N/A,N/A
"[11] Mortensen C : Inconsistent Mathematics. Kluwer, Dordrecht,
1996
[12] Rosinger E E : On the Safe Use of Inconsistent Mathematics.
arXiv:0811.2405
[13] Rosinger E E, Van Zyl A : Self-Referential Deﬁnition of Orthog-
onality. arXiv:0904.0082
[14] Sierpinski W : Cardinal and Ordinal Numbers. Hafner, New York,
1958
[15] Van der Walt J-H : Private Communication
[16] Zuckerman M M : Sets and Transﬁnite Numbers. Macmillan, New
York, 1974
50",N/A,N/A
"arXiv:math/0611224v1  [math.ST]  8 Nov 2006
The Annals of Statistics
2006, Vol. 34, No. 4, 1646–1652
DOI: 10.1214/009053606000000524
Main article DOI: 10.1214/009053606000000515
c
⃝Institute of Mathematical Statistics, 2006
REJOINDER
By S. C. Kou, Qing Zhou and Wing H. Wong
Harvard University, Harvard University and Stanford University
We thank the discussants for their thoughtful comments and the time
they have devoted to this project. As a variety of issues have been raised,",N/A,N/A
"we shall present our discussion in several topics, and then address speciﬁc
questions asked by particular discussants.
1. Sampling algorithms.
The widely used state-of-the-art sampling algo-
rithms in scientiﬁc computing include temperature-domain methods, such
as parallel tempering and simulated tempering, energy-domain methods,
such as multicanonical sampling and the EE sampler, and methods in-
volving expanding the sampling/parameter space. The last group includes",N/A,N/A
"the Swendsen–Wang type algorithms for lattice models, as Wu and Zhu
pointed out, and the group Monte Carlo method [1]. If designed properly,
these sampling-space-expansion methods could be very eﬃcient, as Wu and
Zhu’s example in computer vision illustrated. However, since they tend to
be problem-speciﬁc, we did not compare the EE sampler with them. The
comparison in the paper is mainly between the EE sampler and parallel
tempering. Atchad´e and Liu’s comparison between the EE sampler and the",N/A,N/A
"multicanonical sampling thus complements our result. It has been more than
15 years since multicanonical sampling was ﬁrst introduced. However, we feel
that there are still some conceptual questions that remain unanswered. In
particular, the key idea of multicanonical sampling is to produce a ﬂat dis-
tribution in the energy domain. But we still do not have a simple intuitive
explanation of (i) why focusing on the energy works, (ii) why a distribu-",N/A,N/A
"tion ﬂat in the energy is sought, and (iii) how such a distribution helps the
sampling in the original sample space. The EE sampler, on the other hand,
oﬀers clear intuition and a visual picture: the idea is simply to “walk” on
the equi-energy sets, and hence focusing on the energy directly helps avoid
local trapping. In fact, the numerical results in Atchad´e and Liu’s comment
clearly demonstrate the advantage of EE over multicanonical sampling in
Received December 2005.",N/A,N/A
"Received December 2005.
This is an electronic reprint of the original article published by the
Institute of Mathematical Statistics in The Annals of Statistics,
2006, Vol. 34, No. 4, 1646–1652. This reprint diﬀers from the original in
pagination and typographic detail.
1
2
S. C. KOU, Q. ZHOU AND W. H. WONG
the 20 normal mixture example. Speciﬁcally, their Table 1 shows that in
terms of estimating the probabilities of visiting each mode, the EE sampler",N/A,N/A
"is about two to three times more eﬃcient. We think that estimating the
probability of visiting individual modes provides a more sensitive measure
of the performance, the reason being that even if a sampler misses two or
three modes in each run, the sample average of the ﬁrst and second mo-
ments could still be quite good; for example, missing one mode in the far
lower left can be oﬀset by missing one mode in the far upper right in the",N/A,N/A
"sample average of the ﬁrst moment, and missing one faraway mode can be
oﬀset by disproportionately visiting much more frequently another faraway
mode in the sample average of the second moment, and so on. Nevertheless,
we agree with Atchad´e and Liu that more studies (e.g., on the benchmark
phase transition problems in the Ising and Potts models) are needed to reach
a ﬁrmer conclusion.
2. Implementing the EE sampler for scientiﬁc computations.
The EE",N/A,N/A
"The EE
sampler is a ﬂexible and all-purpose algorithm for scientiﬁc computing. For
a given problem, it could be adapted in several ways.
First, we suggested in the paper that as a good initial start the energy and
temperature ladders could be both assigned through a geometric progression.
It is conceivable that for a complicated problem alternative assignments
might work better, as Minary and Levitt’s oﬀ-lattice protein folding example",N/A,N/A
"illustrated. A good assignment makes the acceptance rates of the EE jump
comparably across the diﬀerent chains, say all greater than 70%. This can
be achieved by a small pilot run of the algorithm, which can be incorporated
into an automatic self-tuning implementation.
Second, the energy ladder and temperature ladder can be decoupled in
the sense that they do not need to always obey (Hi+1 −Hi)/Ti ≈c. For
example, for discrete problems such as the lattice phase transition models",N/A,N/A
"and the lattice protein folding models, one could take each discrete energy
level itself as an energy ring, while keeping the temperatures as a monotone
increasing sequence. In this case an EE jump is always accepted, since it
always moves between states with the same energy level.
Third, the EE sampler can be implemented in a serial fashion as Wu
and Zhu commented. One could start the algorithm from X(K), run for
a predetermined number of iterations, completely stop it and move on to",N/A,N/A
"X(K−1), run it, completely stop, move on to X(K−2), and so on. This serial
implementation oﬀers the advantage of saving computer memory in that one
only needs to record the states visited in the chain immediately preceding the
current one. The downside is that it will not provide the users the option to
online monitor and control (e.g., determine to stop) the algorithm; instead,
one has to prespecify a ﬁxed number of iterations to run. In the illustrative",N/A,N/A
"multimodal distribution in the paper and the example we include in this
REJOINDER
3
rejoinder in Section 4, we indeed utilized the serial implementation since
the number of iterations for each chain was prespeciﬁed.
Fourth, the EE sampler constructs energy rings to record the footsteps of
high-order chains. The fact that a computer’s memory is always ﬁnite might
appear to limit the number of iterations that the EE sampler can be run.",N/A,N/A
"But as Minary and Levitt pointed out, this seeming limitation can be readily
solved by ﬁrst putting an upper bound (subject to computer memory) on
the energy ring size; once this upper bound is reached a new sample can be
allocated to a speciﬁc energy ring by replacing a randomly chosen element
in the ring. Minary and Levitt’s example involving a rough one-dimensional
energy landscape provides a clear demonstration.
Fifth, the key ingredient of the EE sampler is the equi-energy move, a",N/A,N/A
"global move that compensates for the local exploration. It is worth empha-
sizing that the local moves can adopt not only the Metropolis–Hastings type
moves, but also Gibbs moves, hybrid Monte Carlo moves as in Minary and
Levitt’s example, and even moves applied in molecular dynamic simulations,
as long as the moves provide good explorations of the local structure.
Sixth, the equi-energy move jumps from one state to another within the",N/A,N/A
"same energy ring. As Wu and Zhu commented, it is possible to conduct
moves across diﬀerent energy rings. It has pros and cons, however. It might
allow the global jump a larger range, and at the same time it might also lead
to a low move acceptance rate, especially if the energy of the current state
diﬀers much from that of the proposal jump state. The latter diﬃculty is
controlled in the equi-energy jump of the EE sampler, since it always moves",N/A,N/A
"within an energy ring, where the states all have similar energy levels. One
way to enhance the global jump range and rein in the move acceptance rate
is to put a probability on each energy ring in the jump step. Suppose the
current state is in ring Dj. One can put a distribution on the ring index
so that the current ring Dj has the highest probability to be chosen, and
the neighboring rings Dj−1 and Dj+1 have probabilities less than that of",N/A,N/A
"Dj to be chosen, and rings Dj−2 and Dj+2 have even smaller probabilities
to be chosen, and so on. Once a ring is chosen, the target state is proposed
uniformly from it.
3. Theoretical issues.
We thank Atchad´e and Liu for providing a more
probabilistic derivation of the convergence of the EE sampler that comple-
ments the one we gave in the paper. While these results assure the long-
run correctness of the sampler, we agree, however, with Wu and Zhu that",N/A,N/A
"investigating the convergence speed is theoretically more challenging and
interesting, as it is the rate of convergence that separates diﬀerent sampling
algorithms. So far the empirical evidence supports the EE sampler’s promise,
but deﬁnitive theoretical results must await future studies.
4
S. C. KOU, Q. ZHOU AND W. H. WONG
In addition to facilitating the empirically observed fast convergence, an-
other advantage oﬀered by the idea of working on the equi-energy sets is",N/A,N/A
"that it allows eﬃcient estimation by utilizing all the samples from all the
chains on an energy-by-energy basis (as discussed in Section 5 of the paper).
We thus believe that the alternative estimation strategy proposed by Chen
and Kim is very ineﬃcient, because it essentially wastes all the samples in
the chains other than the target one. To make the comparison transparent,
suppose we want to estimate the probability of a rare event under the target",N/A,N/A
"distribution Pπ0(X ∈A). Chen and Kim’s formula would give
ˆP = 1
n
n
X
i=1
K
X
j=0
wj
1(X(0)
i
∈A ∩Dj).
But since Pπ0(X ∈A) is small, say less than 10−10, there is essentially no
sample falling into A in the chain X(0), and correspondingly ˆP would be way
oﬀno matter how cleverly wj is constructed. The fact that the high-order
chains X(j) could well have samples in the set A (due to the ﬂatness of πj)
does not help at all in Chen and Kim’s strategy. But in the EE estimation",N/A,N/A
"method such high-order-chain samples are all employed. The tail probability
estimation presented in Section 5 and Table 4 illustrates the point. The
reason that the EE estimation method is much more eﬃcient in this scenario
is due to the well-known fact that in order to accurately estimate a rare event
probability importance sampling has to be used and the fact that the EE
strategy automatically incorporates importance sampling in its construction.",N/A,N/A
"We also want to point out that rare event estimation is an important problem
in science and engineering; examples include calculating surface tension in
phase transition in physics, evaluating earthquake probability in geology,
assessing the chance of bankruptcy in insurance or bond payment default
in ﬁnance, estimating the potentiality of traﬃc jams in telecommunication,
and so on.
4. Replies to individual discussants.
We now focus on some of the in-",N/A,N/A
"We now focus on some of the in-
dividual points raised. Minary and Levitt’s discussion has been covered in
Sections 1 and 2 of this rejoinder, as was Wu and Zhu’s in Sections 1 to 3;
we are sorry that space does not permit us to discuss their contributions
further.
Atchad´e and Liu questioned the derivation of (5) of the paper. This equa-
tion, we think, arises directly from the induction assumption, and does not
use any assumption on X(i+1) explicitly or implicitly. We appreciate their",N/A,N/A
"more probabilistic proof of the convergence theorem.
Chen and Kim asked about the length of the burn-in period in the ex-
amples. In these examples the burn-in period consists of 10% to 30% of the
samples. We note that this period should be problem-dependent. A rugged
REJOINDER
5
Fig. 1.
The artiﬁcial needle-in-the-haystack example. (a) The density function of the
target distribution. (b) The sample path of X(0)
1
from a typical run of the EE sampler.",N/A,N/A
"1
from a typical run of the EE sampler.
(c) The samples generated at both modes. Note the mode at the origin. (d) The samples
generated near the mode at the origin.
high-dimensional energy landscape requires longer burn-in than a smooth
low-dimensional one. There is no one-size-ﬁts-all formula.
In the discussion Chen and Kim appeared to suggest that the Gibbs sam-
pler is preferred in high-dimensional problems. But our experience with the",N/A,N/A
"Gibbs sampler tells a diﬀerent story. Though simple to implement, in many
cases the Gibbs sampler can be trapped by a local mode or by a strong
correlation between the coordinates—the very problems that the modern
state-of-the-art algorithms are trying to tackle.
We next consider the needle-in-the-haystack example raised in Chen and
Kim’s discussion, in which the variances of the normal mixture distribution
diﬀer dramatically. Figure 1(a) shows the density function of this example.",N/A,N/A
"We implemented the EE sampler using four chains (i.e., K = 3) and 200,000
iterations per chain after a burn-in period of 50,000 iterations. Following the
energy ladder setting used in Chen and Kim, we set H1 = 3.13; the other
6
S. C. KOU, Q. ZHOU AND W. H. WONG
energy levels were set between H1 and Hmin + 100 (= 93) in a geometric
progression: H1 = 3.13,H2 = 8.3,H3 = 26.8. The MH proposals were speci-
ﬁed as N2(X(i)
n ,τ 2
i TiI2), where Ti (i = 0,...,K) is the temperature of the ith",N/A,N/A
"chain. We set τi = 1 for i > 0 and τ0 = 0.05. The probability of equi-energy
jump pee = 0.3. With all the above parameters ﬁxed in our simulation, we
tested the EE sampler with diﬀerent highest temperatures TK, whereas the
remaining temperatures were evenly distributed on the log-scale between
TK and T0 = 1. We tried TK =10, 20, 30, 50 and 100; with each parameter
setting the EE sampler was performed independently 100 times. From the
target chain X(0) we calculated
ˆP = 1
n
n
X
i=1
1(
q
(X(0)",N/A,N/A
"ˆP = 1
n
n
X
i=1
1(
q
(X(0)
i1 )2 + (X(0)
i2 )2 < 0.05),
the probability of visiting the mode at the origin. From the summary statis-
tics in Table 1, we see that (i) the performance of EE is quite stable with an
MSE between 0.04 and 0.06 for diﬀerent temperature ladders; (ii) more than
98% of the times EE did jump between the two modes. In order to assess
the performance of EE on this problem, we also applied PT under exactly",N/A,N/A
"the same settings including the numbers of chains and iterations, the tem-
perature ladders and the exchange probability (pex = pee = 0.3). It turns out
that with all the diﬀerent temperature ladders PT never outperformed even
the worst performance of EE (TK = 10) in MSE (Table 1). From the best
performance of the two methods, that is, EE with TK = 30 and PT with
TK = 20, one sees that (i) the MSE of EE is about 54% of that of PT; (ii)",N/A,N/A
"the spread of the estimated probability is smaller for EE than for PT [see
the standard deviation and (5%,95%) quantiles]. We selected a typical run
of EE in the sense that the frequency of jump between the two modes of this
run is approximately the same as the average frequency, and we plotted the
samples in Figure 1. The chain mixed well in each mode and the cross-mode
jump is acceptable. Even in this artiﬁcially created extreme example of a",N/A,N/A
"needle in the haystack the performance of EE is still quite satisfactory with
only four chains (K = 3). It is worth emphasizing that we did not even ﬁne-
tune the energy or temperature ladders—they are simply set by a geometric
progression.
But we do want to point out that one can always cook up extreme ex-
amples to defeat any sampling algorithm. For instance, one can hide two
needles miles apart in a high-dimensional space, and no sampling algorithm",N/A,N/A
"is immune to this type of extreme example. In fact in Chen and Kim’s ex-
ample, if we ran EE with only 50,000 iterations (after the burn-in period)
with TK = 30, the resulting MSE increased to 0.136 and 36% of the times
EE missed the needle completely (Table 1).
REJOINDER
7
Table 1
Summary statistics of EE and PT for the needle-in-the-haystack example
E( ˆ
P )
std( ˆ
P )
5%
95%
MSE
# Jump
# Miss
EE(N = 200,TK = 10)
0.3740
0.2119
0.0289
0.7020
0.0603
36.61
1
EE(N = 200,TK = 20)
0.4298
0.2048",N/A,N/A
"0.0603
36.61
1
EE(N = 200,TK = 20)
0.4298
0.2048
0.0556
0.7492
0.0464
40.35
2
EE(N = 200,TK = 30)
0.4567
0.1973
0.1188
0.7440
0.0404
43.14
0
EE(N = 200,TK = 50)
0.3958
0.2172
0.0223
0.6939
0.0576
39.16
2
EE(N = 200,TK = 100)
0.4396
0.2122
0.0986
0.7762
0.0482
39.19
0
EE(N = 50,TK = 30)
0.3077
0.3163
0
0.8149
0.1361
6.83
36
PT(N = 200,TK = 10)
0.4241
0.2971
0
0.9276
0.0932
364.07
7
PT(N = 200,TK = 20)
0.4437
0.2692
0.0000
0.9476
0.0749
157.18
4
PT(N = 200,TK = 30)
0.4664
0.3181
0
0.9979
0.1013",N/A,N/A
"PT(N = 200,TK = 30)
0.4664
0.3181
0
0.9979
0.1013
104.20
6
PT(N = 200,TK = 50)
0.4793
0.3093
0
0.9204
0.0951
63.47
6
PT(N = 200,TK = 100)
0.4291
0.2972
0
0.9772
0.0925
36.02
7
Tabulated are the mean, standard deviation, 5% and 95% quantiles, and MSE of ˆP in 100
independent runs. Also reported here are the average number of jumps between the two
modes and the total number of runs in which the sampler missed the mode at the origin.",N/A,N/A
"N is the number of iterations for each chain in units of 1000 after the burn-in period.
5. Concluding remarks.
We thank all the discussants for their insightful
contributions. We appreciate the eﬀorts of the Editor and the Associate
Editor for putting up such a platform for exchanging ideas. We hope that the
readers will enjoy as much as we did reading these comments and thinking
about various scientiﬁc, statistical and computational issues raised.
REFERENCE",N/A,N/A
"REFERENCE
[1] Liu, J. S. and Sabatti, C. (2000). Generalised Gibbs sampler and multigrid Monte
Carlo for Bayesian computation. Biometrika 87 353–369. MR1782484
S. C. Kou
Q. Zhou
Department of Statistics
Harvard University
Science center
Cambridge, Massachusetts 02138
USA
E-mail: kou@stat.harvard.edu
zhou@stat.harvard.edu
W. H. Wong
Department of Statistics
Sequoia Hall
Stanford University
Stanford, California 94305-4065
USA
E-mail: whwong@stanford.edu",N/A,N/A
"arXiv:1307.2418v1  [math.GM]  9 Jul 2013
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
HUSEYIN CAKALLI
MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
Abstract. A real valued function f deﬁned on a subset E of R, the set
of real numbers, is statistically upward continuous if it preserves statistically
upward half quasi-Cauchy sequences, is statistically downward continuous if
it preserves statistically downward half quasi-Cauchy sequences; and a subset",N/A,N/A
"E of R, is statistically upward compact if any sequence of points in E has a
statistically upward half quasi-Cauchy subsequence, is statistically downward
compact if any sequence of points in E has a statistically downward half quasi-
Cauchy subsequence where a sequence (xn) of points in R is called statistically
upward half quasi-Cauchy if
lim
n→∞
1
n |{k ≤n : xk −xk+1 ≥ε}| = 0
is statistically downward half quasi-Cauchy if
lim
n→∞
1
n |{k ≤n : xk+1 −xk ≥ε}| = 0
for every ε > 0.",N/A,N/A
"1
n |{k ≤n : xk+1 −xk ≥ε}| = 0
for every ε > 0.
We investigate statistically upward continuity, statisti-
cally downward continuity, statistically upward half compactness, statistically
downward half compactness and prove interesting theorems. It turns out that
uniform limit of a sequence of statistically upward continuous functions is sta-
tistically upward continuous, and uniform limit of a sequence of statistically
downward continuous functions is statistically downward continuous.",N/A,N/A
"Date: July 17, 2018.
2010 Mathematics Subject Classiﬁcation. Primary: 26A15; Secondaries:40A05; 40A30.
Key words and phrases. Continuity, compactness, sequences, summability.
1
2
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
1. Introduction
Connor and Grosse-Erdmann [11] gave sequential deﬁnitions of continuity for
real functions calling G-continuity instead of E-continuity and their results cover
the earlier works related to E-continuity where a method of sequential convergence,",N/A,N/A
"or brieﬂy a method, is a linear function G deﬁned on a linear subspace of s, denoted
by cG, into R. A sequence x = (xn) is said to be G-convergent to ℓif x ∈cG and
G(x) = ℓ. In particular, lim denotes the limit function lim x = limn xn on the
linear space c.
A function f is called G-continuous at a point u provided that
whenever a sequence x = (xn) of terms in the domain of f is G-convergent to u,
then the sequence f(x) = (f(xn)) is G-convergent to f(u). A method G is called",N/A,N/A
"regular if every convergent sequence x = (xn) is G-convergent with G(x) = lim x.
A method is called subsequential if whenever x is G-convergent with G(x) = ℓ, then
there is a subsequence (xnk) of x with limk xnk = ℓ. Recently, Cakalli gave new
sequential deﬁnitions of compactness and slowly oscillating compactness in [20], and
[21], respectively. The notion of Nθ convergence was introduced, and studied by
Freedman, Sember, and M. Raphael in [30]. Using the idea of Sember and Raphael,",N/A,N/A
"Fridy and Orhan introduced lacunary statistical convergence ([32] and [12]).
A subset E of R, the set of real numbers, is compact if and only if any sequence
of points in E has a convergent subsequence whose limit in E. A subset E of R
is bounded if and only if any sequence of points in E has a Cauchy subsequence.
Boundedness coincides with not only ward compactness ([22]), but also either of the
following kinds of compactnesses, slowly oscillating compactness ([21]), statistical",N/A,N/A
"ward compactness ([16, Lemma 2]), lacunary statistical ward compactness, ([17,
Theorem 3]) Nθ-ward compactness ([4, Theorem 3.3]). Two of our results in this
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
3
paper state necessary and suﬃcient conditions for below boundedness and above
boundedness of a subset of R. Using the idea of continuity of a real function in
terms of sequences, many kinds of continuities were introduced and investigated,",N/A,N/A
"not all but some of them we recall in the following: slowly oscillating continuity
([21]), quasi-slowly oscillating continuity ([28]), ward continuity ([22], [2]), δ-ward
continuity ([14]), statistical ward continuity, ([16]), and Nθ-ward continuity ([4],
[24]) which enabled some authors to obtain conditions on the domain of a function
for some characterizations of uniform continuity in terms of sequences in the sense
that a function preserves a certain kind of sequences (see [39] and [2]).",N/A,N/A
"The purpose of this paper is to introduce the concepts of statistically upward
and statistically downward continuities, and prove interesting theorems.
2. Preliminaries
Throughout the paper, s and c will denote the set of all sequences, and the set
of convergent sequences of points in R.
The concept of statistical convergence is a generalization of the usual notion
of convergence that, for real-valued sequences, parallels the usual theory of con-",N/A,N/A
"vergence. A sequence (xk) of points in R is called statistically convergent to an
element ℓof R if for each ε
lim
n→∞
1
n|{k ≤n : |xk −ℓ| ≥ε}| = 0,
and this is denoted by st −limk→∞xk = ℓ(see [31], [29], [13], [9], [10], [26], [25]
and [33]). This deﬁnes a regular subsequential method of sequential convergence,
i.e. G(α) := st −limk→∞xk.
4
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
A lacunary sequence θ = (kr) is an increasing sequence θ = (kr) of positive",N/A,N/A
"integers such that k0 = 0 and hr : kr−kr−1 →∞. The intervals determined by θ will
be denoted by Ir = (kr−1, kr], and the ratio
kr
kr−1 will be abbreviated by qr. Sums
of the form Pkr
kr−1+1 |xk| frequently occur, and will often be written for convenience
as P
k∈Ir |xk|. Throughout this paper, we will assume that lim infr qr > 1.
A sequence (xk) of points in R is called Nθ-convergent to an element ℓof R if
lim
r→∞
1
hr
X
k∈Ir
|xk −ℓ| = 0,",N/A,N/A
"lim
r→∞
1
hr
X
k∈Ir
|xk −ℓ| = 0,
and it is denoted by Nθ −lim xk = ℓ. This deﬁnes a regular method of sequential
convergence, i.e. G(α) := Nθ −lim xk. Any convergent sequence is Nθ-convergent,
but the converse is not always true.
A real sequence (xk) is called lacunary statistically convergent to an element ℓ
of R if
lim
r→∞
1
hr
|{k ∈Ir : |xk −ℓ| ≥ǫ}| = 0,
for every ǫ > 0 where θ = (kr) is a lacunary sequence.
This deﬁnes a regular",N/A,N/A
"This deﬁnes a regular
subsequential method of sequential convergence, i.e. G(α) := Sθ −lim xk. Any
convergent sequence is Sθ-convergent, but the converse is not always true.
For
example, limit of the sequence of the ratios of Fibonacci numbers converge to the
golden mean. This ensures the regularity of lacunary sequential method obtained
via the sequence of Fibonacci numbers, i.e.
θ = (kr) is the lacunary sequence
deﬁned by writing k0 = 0 and kr = Fr+2 where (Fr) is the Fibonacci sequence, i.e.",N/A,N/A
"F1 = 1, F2 = 1, Fr = Fr−1 + Fr−2 for r ≥3 ([4]).
The concept of a Cauchy sequence involves far more than that the distance
between successive terms is tending to zero. Nevertheless, sequences which satisfy
this weaker property are interesting in their own right. A sequence (xn) of points
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
5
in R is quasi-Cauchy if (∆xn) is a null sequence where ∆xn = xn −xn+1. These
sequences were named as quasi-Cauchy by Burton and Coleman [2, page 328], while",N/A,N/A
"they were called as forward convergent to 0 sequences in [22, page 226]. A subset of
R is compact if and only if it is closed and bounded. A subset E of R is bounded
if |a| ≤M for all a ∈A where M is a positive real constant number. This is
equivalent to the statement that any sequence of points in E has a quasi-Cauchy
subsequence. A sequence (xn) of points in R is slowly oscillating if
lim
λ→1+ limn
max
n+1≤k≤[λn] |xk −xn| = 0",N/A,N/A
"lim
λ→1+ limn
max
n+1≤k≤[λn] |xk −xn| = 0
where [λn] denotes the integer part of λn (see [27, Deﬁnition 2 page 947]). Any
subsequence of a Cauchy sequence is Cauchy.
The analogous property fails for
quasi-Cauchy sequences, and fails for slowly oscillating sequences as well. A coun-
terexample for the case, quasi-Cauchy, is the sequence (an) = (√n) with the sub-
sequence (an2) = (n).
A counterexample for the case slowly oscillating is the",N/A,N/A
"sequence (log10n) with the subsequence (n). Furthermore we give more examples
without neglecting: the sequences (P∞
k=1
1
n), (ln n), (ln (ln n)), (ln (ln (lnn))),...,
(ln (ln (ln(...(lnn)...)) and combinations like that are all slowly oscillating, but
not Cauchy. The bounded sequence (cos(6log(n + 1))) is slowly oscillating, but not
Cauchy. The sequences (cos(π√n)) and (Pk=n
k=1 ( 1
k)(Pj=k
j=1
1
j )) are quasi-Cauchy, but
slowly oscillating(see [21], [39], and [18]).",N/A,N/A
"slowly oscillating(see [21], [39], and [18]).
Now we recall the concepts of ward compactness, and slowly oscillating com-
pactness: a subset E of R is called ward compact if any sequence of points in E
has a quasi-Cauchy subsequence ([22]). A subset E of R is called slowly oscillating
compact if any sequence of points in E has a slowly oscillating subsequence ([21]).
6
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY",N/A,N/A
"C¸akallı ([20, page 594], [15]) gave a sequential deﬁnition of compactness, which
is a generalization of ordinary sequential compactness, as in the following: a subset
E of R is G-sequentially compact if for any sequence (xk) of points in E there exists
a subsequence z of the sequence such that G(z) ∈A. His idea enables us obtain-
ing new kinds of compactness via most of the non-matrix sequential convergence
methods, as well as all matrix sequential convergence methods.",N/A,N/A
"Palladino ([36]) introduced a concept of upward half Cauchness, and a concept
of downward half Cauchyness as in the following:a sequence (xn) of points in R
is called upward half Cauchy if for every ε > 0 there exists an n0 ∈N so that
xn −xm < ε for m ≥n ≥n0, downward half Cauchy if for every ε > 0 there exists
an n0 ∈N so that xm −xn < ε for m ≥n ≥n0. A sequence (xn) is called half
Cauchy if the sequence is either upward half Cauchy, or downward half Cauchy, or",N/A,N/A
"both. It is clear that a sequence (xn) is Cauchy if and only if it is both upward half
Cauchy and downward half Cauchy.
Quasi-Cauchy sequences arise in diverse situations, and it is often diﬃcult to
determine whether or not they converge, and if so, to which limit. It is easy to
construct a zero-one sequence such that the quasi-Cauchy average sequence does not
converge. The usual constructions have a somewhat artiﬁcial feeling. Nevertheless,",N/A,N/A
"there are sequences which seem natural, have the quasi-Cauchy property, and do
not converge. Using the idea of the deﬁnition of an upward half Cauchy sequence,
a concept of upward half quasi-Cauchy sequence is introduced (see [5], and [7]).
A sequence (xn) of points in R is called upward half quasi-Cauchy if for every
ε > 0 there exists an n0 ∈N such that xn −xn+1 < ε for n ≥n0. A sequence
x = (xn) of points in R is upward half Cauchy if and only if every subsequence",N/A,N/A
"UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
7
of x is upward half quasi-Cauchy. A subset E of R is called upward compact if
any sequence of points in E has an upward half quasi-Cauchy subsequence.
A
subset of R is upward compact if and only if it is bounded below. A subset E of
R is called up half compact if any sequence of points in E has an up half Cauchy
subsequence (see [5], and [6]). A subset of R is up half compact if and only if it",N/A,N/A
"is upward half compact. A sequence (xn) of points in R is called downward half
quasi-Cauchy if for every ε > 0 there exists an n0 ∈N such that xn+1 −xn < ε
for n ≥n0 ([5]). A sequence (xn) of points in R is downward half Cauchy if and
only if every subsequence of (xn) is downward half quasi-Cauchy. A subset E of
R is called downward compact if any sequence of points in E has a downward half
quasi-Cauchy subsequence. A subset of R is downward compact if and only if it is",N/A,N/A
"bounded above. A subset E of R is called down half compact if any sequence of
points in E has an down half Cauchy subsequence ([5]). A subset of R is down half
compact if and only if it is downward compact . A subset of R is bounded if and
only if it is both upward and downward compact.
3. Statistically upward and downward quasi-Cauchy sequences
Weakening the condition on the deﬁnition of a statistically quasi-Cauchy se-",N/A,N/A
"quence, omitting the absolute value symbol, i.e. if we replace |xk −xk+1| ≥ε by
xk −xk+1 ≥ε in the deﬁnition of a statistically quasi-Cauchy sequence, we have
the following deﬁnition.
Deﬁnition 1. A sequence (xn) of points in R is called statistically upward half
quasi-Cauchy if
lim
n→∞
1
n|{k ≤n : xk −xk+1 ≥ε}| = 0
8
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
for every ε > 0.
Now we introduce a deﬁnition of statistically upward compactness of a subset of",N/A,N/A
"R, by using the main idea in the deﬁnition of sequential compactness.
Deﬁnition 2. A subset E of R is called statistically upward compact if any se-
quence of points in E has an statistically upward half quasi-Cauchy subsequence.
First, we note that any ﬁnite subset of R is statistically upward compact, union
of two statistically upward compact subsets of R is statistically upward compact
and intersection of any statistically upward compact subsets of R is statistically",N/A,N/A
"upward compact. Furthermore any subset of a statistically upward compact set is
statistically upward compact and any bounded subset of R is statistically upward
compact. Any compact subset of R is also statistically upward compact. We note
that any slowly oscillating compact subset of R is statistically upward compact (see
[7] for the deﬁnition of slowly oscillating compactness). These observations suggest
to us the following:",N/A,N/A
"to us the following:
Theorem 1. A subset of R is statistically upward compact if and only if it is
bounded below.
Proof. Let E be a subset of R. If E is bounded below, then it is clear that E is
statistically upward compact. Now, suppose that E is not bounded below. Pick an
element x1 of E. Then we can choose an element x2 of E such that x2 < −1 + x1.
Similarly we can choose an element x3 of E such that x3 < −1 + x2. We can",N/A,N/A
"inductively choose kn and kn+1 satisfying xn+1 < −1 + xn for each positive integer
n. Then the sequence (xn) does not have any statistically upward half quasi-Cauchy
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
9
subsequence.
Thus E is not statistically upward compact.
This contradiction
completes the proof.
□
Deﬁnition 3. A sequence (xn) of points in R is called statistically downward half
quasi-Cauchy if
lim
n→∞
1
n|{k ≤n : xk+1 −xk ≥ε}| = 0
for every ε > 0.",N/A,N/A
"1
n|{k ≤n : xk+1 −xk ≥ε}| = 0
for every ε > 0.
Throughout the paper ∆S+ and ∆S−will denote the set of all statistically
upward half quasi-Cauchy sequences, and the set of all statistically downward
half quasi-Cauchy sequences, of points in R, respectively. Any statistically quasi-
Cauchy sequence is statistically upward half quasi-Cauchy, statistically downward
half quasi-Cauchy, so any slowly oscillating sequence is statistically upward and",N/A,N/A
"downward half quasi-Cauchy, so any Cauchy sequence is, so any convergent sequence
is. Any upward half Cauchy sequence is statistically upward half quasi-Cauchy.
Now we introduce a deﬁnition of statistically downward compactness of a subset
of R.
Deﬁnition 4. A subset E of R is called statistically downward compact if any
sequence of points in E has a statistically downward half quasi-Cauchy subsequence.
First, we note that any ﬁnite subset of R is statistically downward compact,",N/A,N/A
"union of two statistically downward compact subsets of R is statistically downward
compact and intersection of any statistically downward compact subsets of R is
statistically downward compact. Furthermore any subset of a statistically down-
ward compact set is statistically downward compact and any bounded subset of
10
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
R is statistically downward compact. Any compact subset of R is also statisti-",N/A,N/A
"cally downward compact. We note that any slowly oscillating compact subset of
R is statistically downward compact (see [7] for the deﬁnition of slowly oscillating
compactness).
Theorem 2. A subset of R is statistically downward compact if and only if it is
bounded above.
Proof. Let E be a subset of R. If E is bounded above, then it is clear that E
is statistically downward compact. Now, suppose that E is not bounded above.
Pick an element x1 of E.
Then we can choose an element x2 of E such that",N/A,N/A
"Then we can choose an element x2 of E such that
x2 > 1 + x1. Similarly we can choose an element x3 of E such that x3 > 1 + x2.
We can inductively choose kn and kn+1 satisfying xn+1 > 1 + xn for each positive
integer n. Then the sequence (xn) does not have any statistically downward half
quasi-Cauchy subsequence. Thus E is not statistically downward compact. This is
a contradiction.
□
A subset E of R is called down half compact if any sequence of points in E has",N/A,N/A
"an down half Cauchy subsequence ([5]).
Corollary 1. A subset of R is down half compact if and only if it is statistically
downward compact .
Corollary 2. A subset of R is bounded if and only if it is both statistically upward
and statistically downward compact.
Corollary 3. A subset of R is statistically ward compact if and only if it is both
statistically upward and statistically downward compact.
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
11",N/A,N/A
"UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
11
Corollary 4. A subset of R is Nθ-ward compact if and only if it is both statistically
upward and statistically downward compact.
Proof. The proof follows from 2, and [4, Theorem 3.3].
□
Deﬁnition 5. A sequence (xn) of points in R is called half statistically quasi-
Cauchy if the sequence is either statistically upward, or statistically downward half
quasi-Cauchy, or both.",N/A,N/A
"quasi-Cauchy, or both.
We note that a sequence (xn) of points in R is statistically quasi-Cauchy if and
only if it is both statistically upward half quasi-Cauchy and statistically downward
half quasi-Cauchy.
4. Statistically Upward and Downward continuities
A real valued function f deﬁned on a subset of R is statistically continuous if
and only if, for each point ℓin the domain, st−limn→∞f(xn) = f(ℓ) whenever st−
limn→∞xn = ℓ. This is equivalent to the statement that (f(xn)) is a statistically",N/A,N/A
"convergent sequence whenever (xn) is. This is also equivalent to the statement that
(f(xn)) is a Cauchy sequence whenever (xn) is Cauchy. These well known results
for statistical continuity for real functions in terms of sequences might suggest to
us giving a new type continuity, namely, statistically upward continuity:
Now we give the concept of statistically upward continuity of a function deﬁned
on a subset of R to R.",N/A,N/A
"on a subset of R to R.
Deﬁnition 6. A function f is called statistically upward continuous on E if the
sequence (f(xn)) is statistically upward half quasi-Cauchy whenever x = (xn) is a
statistically upward half quasi-Cauchy sequence of points in E.
12
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
We see that sum of two statistically upward continuous functions is statistically
upward continuous and composite of two statistically upward continuous functions",N/A,N/A
"is statistically upward continuous.
In connection with statistically upward half quasi-Cauchy sequences and conver-
gent sequences the problem arises to investigate the following types of continuity
of functions on R.
(δS+): (xn) ∈∆S+ ⇒(f(xn)) ∈∆S+
(δS+c): (xn) ∈∆S+ ⇒(f(xn)) ∈c
(c): (xn) ∈c ⇒(f(xn)) ∈c
(cδS+): (xn) ∈c ⇒(f(xn)) ∈∆S+
(st): (xn) ∈S ⇒(f(xn)) ∈S
We see that (δS+) is statistically upward continuity of f, and (st) is the statistical",N/A,N/A
"continuity. It is easy to see that (δS+c) implies (δS+); (δS+) does not imply (δS+c);
(δS+) implies (cδS+); (cδS+) does not imply (δS+); (δS+c) implies (c), and (c)
does not imply (δS+c); and (c) is equivalent to (cδS+).
Now we prove that (δS+) implies (c) in the following:
Theorem 3. If f is statistically upward continuous on a subset E of R, then it is
statistically continuous on E.
Proof. Let (xn) be any statistically convergent sequence with st −limk→∞xk = ℓ.
Then",N/A,N/A
"Then
(x1, ℓ, x1, ℓ, x2, ℓ, x2, ℓ, ..., xn, ℓ, xn, ℓ, ...)
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
13
is also statistically convergent to ℓ. Thus it is statistically upward half quasi-Cauchy.
Hence
(f(x1), f(ℓ), f(x1), f(ℓ), f(x2), f(ℓ), f(x2), f(ℓ), ..., f(xn), f(ℓ), f(xn), f(ℓ), ...)
is statistically upward half quasi-Cauchy. It follows from this that
lim
n→∞
1
n|{k ≤n : f(xk) −f(ℓ) ≥ε
and
f(xk+1) −f(ℓ) ≥ε}| = 0
for every ε > 0 which implies that
lim
n→∞
1
n|{k ≤n : |f(xk) −f(ℓ)| ≥ε}| = 0",N/A,N/A
"lim
n→∞
1
n|{k ≤n : |f(xk) −f(ℓ)| ≥ε}| = 0
for every ε > 0. This completes the proof of the theorem.
□
Now we state the following result related to ordinary continuity and statistically
upward continuity.
Corollary 5. If f is statistically upward continuous, then it is ordinary continuous.
Corollary 6. If f is statistically upward continuous, then it is lacunary statistically
continuous.
Corollary 7. If f is statistically upward continuous, then it is Nθ-continuous.",N/A,N/A
"We have the following result for general sequential methods.
Corollary 8. If f is statistically upward continuous, then it is G-continuous for
any regular subsequential method G.
Corollary 9. If f is statistically upward continuous, then it is I-continuous for
any non-trivial admissible ideal I of N.
14
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
Proof. The proof follows from 3, and [8, Theorem 4].
□",N/A,N/A
"□
Theorem 4. Statistically upward continuous image of any statistically upward com-
pact subset of R is statistically upward compact.
Proof. Write yn = f(xn) where xn ∈E for each n ∈N.
Statistically upward
compactness of E implies that there is a statistically upward half quasi-Cauchy
subsequence of the sequence of x. Write (tk) = f(z) = (f(zk)). (tk) is a statistically
upward half quasi-Cauchy subsequence of the sequence f(x). This completes the
proof of the theorem.
□",N/A,N/A
"proof of the theorem.
□
Corollary 10. Statistically upward continuous image of any Nθ-sequentially com-
pact subset of R is Nθ-sequentially compact.
Corollary 11. Statistically upward continuous image of any compact subset of R
is compact.
Theorem 5. Let E be a statistically upward compact subset E of R and let f :
E −→R be a statistically upward continuous function on E. Then f is uniformly
continuous on E.
Proof. Suppose that f is not uniformly continuous on E so that there exists an ε0 >",N/A,N/A
"0 such that for any δ > 0 x, y ∈E with |x −y| < δ but |f(x) −f(y)| ≥ε0. For each
positive integer n, ﬁx |xn−yn| < 1
n, and |f(xn)−f(yn)| ≥ε0. Since E is statistically
upward compact, there exists a statistical upward half quasi-Cauchy subsequence
(xnk) of the sequence (xn). It is clear that the corresponding subsequence (ynk) of
the sequence (yn) is also statistically upward half quasi-Cauchy, since (ynk −ynk+1)
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
15",N/A,N/A
"UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
15
is a sum of three statistically upward half quasi-Cauchy sequences, i.e.
ynk −ynk+1 = (ynk −xnk) + (xnk −xnk+1) + (xnk+1 −ynk+1).
Then the sequence
(xn1, yn1, xn2, yn2, xn3, yn3, ..., xnk, ynk, ...)
is statistically upward quasi-Cauchy since the sequence (xnk −ynk+1) is statistically
upward quasi-Cauchy sequence which follows from the equality
xnk −ynk+1 = xnk −xnk+1 + xnk+1 −ynk+1.
But the transformed sequence",N/A,N/A
"But the transformed sequence
(f(xn1), f(yn1), f(xn2), f(yn2), f(xn3), f(yn3), ..., f(xnk), f(ynk), ...)
is not statistically upward half quasi-Cauchy. Thus f does not preserve statistically
upward half quasi-Cauchy sequences. This contradiction completes the proof of the
theorem.
□
It is a well known result that uniform limit of a sequence of continuous functions
is continuous. This is also true in case statistically upward continuity, i.e. uni-",N/A,N/A
"form limit of a sequence of statistically upward continuous functions is statistically
upward continuous.
Theorem 6. If (fn) is a sequence of statistically upward continuous functions
deﬁned on a subset E of R and (fn) is uniformly convergent to a function f, then
f is statistically upward continuous on E.
16
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
Proof. Let ε be a positive real number and (xk) be any statistically upward half",N/A,N/A
"quasi-Cauchy sequence of points in E. By uniform convergence of (fn) there exists
a positive integer N such that |fn(x) −f(x)| < ε
3 for all x ∈E whenever n ≥N.
As fN is statistically upward continuous on E, we have
lim
n→∞
1
n|{k ≤n : fN(xk) −fN(xk+1) ≥ε
3}| = 0.
On the other hand we have
{k ≤n : f(xk) −f(xk+1) ≥ε} ⊂{k ≤n : f(xk) −fN(xk) ≥ε
3}
∪{k ≤n : fN(xk) −fN(xk+1) ≥ε
3} ∪{k ≤n : fN(xk+1) −f(xk+1) ≥ε
3}
and so
{k ≤n : f(xk) −f(xk+1) ≥ε} ⊂{k ≤n : |f(xk) −fN(xk)| ≥ε
3}",N/A,N/A
"3}
∪{k ≤n : fN(xk) −fN(xk+1) ≥ε
3} ∪{k ≤n : |fN(xk+1) −f(xk+1)| ≥ε
3}.
Now it follows from this inclusion that
limn→∞1
n|{k ≤n : f(xk) −f(xk+1) ≥ε}|
≤lim
n→∞
1
n|{k ≤n : |f(xk) −fN(xk)| ≥ε
3}| + lim
n→∞
1
n|{k ≤n : fN(xk) −fN(xk+1) ≥ε
3}|
+ lim
n→∞
1
n|{k ≤n : |fN(xk+1) −f(xk+1)| ≥ε
3}| = 0 + 0 + 0 = 0.
This completes the proof of the theorem.
□
Now we give the deﬁnition of statistically downward continuity of a real function
in the following:",N/A,N/A
"in the following:
Deﬁnition 7. A function f is called statistically downward continuous on E if
the sequence (f(xn)) is statistically downward half Cauchy whenever x = (xn) is a
statistically downward half Cauchy sequence of points in E.
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
17
We note that sum of two statistically downward continuous functions is statis-
tically downward continuous and composite of two downward continuous functions
is downward continuous.",N/A,N/A
"is downward continuous.
Now we investigate the following types of continuity of functions on R.
(δS−): (xn) ∈∆S−⇒(f(xn)) ∈∆S−
(δS−c): (xn) ∈∆S−⇒(f(xn)) ∈c
(cδS−): (xn) ∈c ⇒(f(xn)) ∈∆S−
We see that (δS−) is downward statistical continuity of f. It is easy to see that
(δS−c) implies (δS−); (δS−) does not imply (δS−c); (δS−) implies (cδS−); (cδS−)
does not imply (δS−); (δS−c) implies (c); (c) does not imply (δS−c), and (c) is
equivalent to (cδS−).",N/A,N/A
"equivalent to (cδS−).
Now we give the implication (δS−) implies (st), i.e. any statistically downward
continuous function is statistically continuous.
Theorem 7. If f is statistically downward continuous on a subset E of R, then it
is statistically continuous on E.
Proof. Let (xn) be any statistically convergent sequence with st −limk→∞xk = ℓ.
Then
(x1, ℓ, x1, ℓ, x2, ℓ, x2, ℓ, ..., xn, ℓ, xn, ℓ, ...)
is also statistically convergent to ℓ. Thus it is statistically downward half quasi-",N/A,N/A
"Cauchy. Hence
(f(x1), f(ℓ), f(x1), f(ℓ), f(x2), f(ℓ), f(x2), f(ℓ), ..., f(xn), f(ℓ), f(xn), f(ℓ), ...)
18
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
is statistically downward half quasi-Cauchy. It follows from this that
lim
n→∞
1
n|{k ≤n : f(xk+1) −f(ℓ) ≥ε
and
f(xk) −f(ℓ) ≥ε}| = 0
for every ε > 0 which implies that
lim
n→∞
1
n|{k ≤n : |f(xk) −f(ℓ)| ≥ε}| = 0
for every ε > 0. This completes the proof of the theorem.
□",N/A,N/A
"□
Corollary 12. If f is statistically downward continuous, then it is continuous.
Corollary 13. If f is statistically downward continuous, then it is lacunary sta-
tistically continuous.
Corollary 14. If f is statistically downward continuous, then it is Nθ-continuous.
Corollary 15. If f is statistically downward continuous, then it is G-continuous
for any regular subsequential method G.
Corollary 16. If f is statistically downward continuous, then it is I-continuous",N/A,N/A
"for any non-trivial admissible ideal I of N.
Proof. The proof follows from 7, and [8, Theorem 4].
□
Theorem 8. Statistically downward continuous image of any statistically down-
ward half compact subset of R is statistically downward half compact.
Proof. Write yn = f(xn) where xn ∈E for each n ∈N. Statistically downward half
compactness of E implies that there is a statistically downward half quasi-Cauchy
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
19",N/A,N/A
"UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
19
subsequence z = (zk) = (xnk) of x. Write (tk) = f(z) = (f(zk)). Then (tk) is a
statistically downward half quasi-Cauchy subsequence of the sequence f(x). This
completes the proof of the theorem.
□
Corollary 17. Statistically downward continuous image of any Nθ-sequentially
compact subset of R is Nθ-sequentially compact.
Corollary 18. Statistically downward image of any compact subset of R is com-
pact.",N/A,N/A
"pact.
Theorem 9. Let E be a statistically downward compact subset E of R and let
f : E −→R be a statistically downward continuous function on E. Then f is
uniformly continuous on E.
Proof. Suppose that f is not uniformly continuous on E so that there exists an
ε0 > 0 such that for any δ > 0 x, y ∈E with |x −y| < δ but |f(x) −f(y)| ≥ε0.
For each positive integer n, ﬁx |xn −yn| < 1
n, and |f(xn) −f(yn)| ≥ε0. Since E",N/A,N/A
"n, and |f(xn) −f(yn)| ≥ε0. Since E
is statistically downward compact, there exists a statistical downward half quasi-
Cauchy subsequence (xnk) of the sequence (xn). It is clear that the corresponding
subsequence (ynk) of the sequence (yn) is also statistically downward half quasi-
Cauchy, since (ynk+1 −ynk) is a sum of three statistical downward half quasi-Cauchy
sequences, i.e.
ynk+1 −ynk = (ynk+1 −xnk+1) + (xnk+1 −xnk) + (xnk −ynk).
Then the sequence",N/A,N/A
"Then the sequence
(yn1, xn1, yn2, xn2, yn3, xn3, ..., ynk, xnk, ...)
20
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
is statistical downward half quasi-Cauchy since the sequence (ynk+1 −xnk) is sta-
tistically downward half quasi-Cauchy sequence which follows from the equality
ynk+1 −xnk = ynk+1 −ynk + ynk −xnk
. But the transformed sequence
(f(yn1), f(xn1), f(yn2), f(xn2), f(yn3), f(xn3), ..., f(ynk), f(xnk), ...)",N/A,N/A
"is not statistically downward half quasi-Cauchy. Thus f does not preserve statis-
tically downward half quasi-Cauchy sequences. This contradiction completes the
proof of the theorem.
□
Now we have the following result related to uniform convergence, namely, uni-
form limit of a sequence of statistically downward continuous functions is again
statistically downward continuous.
Theorem 10. If (fn) is a sequence of statistically downward continuous functions",N/A,N/A
"deﬁned on a subset E of R and (fn) is uniformly convergent to a function f, then
f is statistically downward continuous on E.
Proof. Let ε be a positive real number and (xk) be any statistically downward half
quasi-Cauchy sequence of points in E. By uniform convergence of (fn) there exists
a positive integer N such that |fn(x) −f(x)| < ε
3 for all x ∈E whenever n ≥N.
As fN is statistically downward continuous on E, we have
lim
n→∞
1
n|{k ≤n : fN(xk+1) −fN(xk) ≥ε
3}| = 0.",N/A,N/A
"lim
n→∞
1
n|{k ≤n : fN(xk+1) −fN(xk) ≥ε
3}| = 0.
On the other hand we have
{k ≤n : f(xk+1) −f(xk) ≥ε} = {k ≤n : f(xk+1) −fN(xk+1)| ≥ε
3}
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
21
∪{k ≤n : fN(xk+1) −fN(xk) ≥ε
3} ∪{k ≤n : fN(xk) −f(xk) ≥ε
3}
so we have
{k ≤n : f(xk+1) −f(xk) ≥ε} ⊂{k ≤n : |f(xk+1) −fN(xk+1)| ≥ε
3}
∪{k ≤n : fN(xk+1) −fN(xk) ≥ε
3} ∪{k ≤n : |fN(xk) −f(xk)| ≥ε
3}
Now it follows from this inclusion that
limn→∞1
n|{k ≤n : f(xk+1) −f(xk) ≥ε}|
≤lim
n→∞
1",N/A,N/A
"limn→∞1
n|{k ≤n : f(xk+1) −f(xk) ≥ε}|
≤lim
n→∞
1
n|{k ≤n : |f(xk+1) −fN(xk+1)| ≥ε
3}| + lim
n→∞
1
n|{k ≤n : fN(xk+1) −fN(xk) ≥ε
3}|
+ lim
n→∞
1
n|{k ≤n : |fN(xk) −f(xk)| ≥ε
3}| = 0 + 0 + 0 = 0.
This completes the proof of the theorem.
□
5. Conclusion
In this paper, we introduce and investigate statistically upward and statistically
downward continuities of real functions, statistically upward and statistically down-
ward compactnesses of a subset of R. We prove results related to these kinds of",N/A,N/A
"continuities, these kind of compactnesses, compactness, and some other kinds of
continuities and compactness; namely slowly oscillating continuity, slowly oscillat-
ing compactness, statistical compactness, lacunary statistical compactness, ordi-
nary compactness, ordinary continuity, and uniform continuity. It turns out that
not only the set of upward continuous functions on upward compact subsets but also
the set of downward continuous functions on downward compact subsets coincides",N/A,N/A
"with the set of uniformly continuous functions, uniform limit of a sequence of up-
ward continuous functions is upward continuous, and uniform limit of a sequence of
downward continuous functions is downward continuous. We suggest to investigate
upward and downward half quasi-Cauchy sequences of fuzzy points or soft points
22
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
(see [23] for the deﬁnitions and related concepts in fuzzy setting, and see [3], and",N/A,N/A
"[1] related concepts in soft setting), and upward and downward half quasi-Cauchy
sequences in cone metric spaces ([38], [19] and [35]). However due to the change
in settings, the deﬁnitions and methods of proofs will not always be analogous to
those of the present work. For some other further studies we suggest to investigate
upward and downward half quasi-Cauchy sequences of double sequences (see for
example [34], and [37] for the deﬁnitions and related concepts in the double case).
References",N/A,N/A
"References
[1] Aras, C.G., Sonmez, A., Cakalli H. On Soft Mappings. arxiv. 2013; 12 pp. arXiv:1305.4545v1
[math.GM] http://arxiv.org/abs/1305.4545
[2] Burton, D. and Coleman, J. Quasi-Cauchy Sequences. Amer. Math. Monthly 2010; 117: 4
328-333. MR 2011c:40004.
[3] Cagman, N., Karatas, S., Enginoglu, S. Soft topology. Comput. Math. Appl. 2011; 62:1
351-358. MR 2012d:03122
[4] Cakalli H. Nθ-ward continuity. Abstr. Appl. Anal. 2012; 2012: 8 pp. Hindawi Publ. Corp.,",N/A,N/A
"New York, Volume Article ID 680456, doi:10.1155/2012/680456.
[5] Cakalli, H. Half quasi-Cauchy sequences. Arxiv. 2012; 24 pp. arXiv:1205.3674v1 [math.GM]
http://arxiv.org/pdf/1205.3674v1.pdf
[6] Cakalli, H. Up and Down continuities. submitted
[7] Cakalli, H. Upward and Downward continuities. submitted
[8] Cakalli,
H.
and
Hazarika,
B.
Ideal
quasi-Cauchy
sequences.
J.
Inequal.
Appl.
doi:10.1186/1029-242X-2012-234 ISSN 1025-5834. 2012; 2012: 1 234.",N/A,N/A
"[9] Caserta, A. and Koˇcinac, Lj.D.R. On statistical exhaustiveness. Appl. Math. Lett. 2012; 25:
10 1447-1451. doi:10.1016/j.aml.2011.12.022
[10] Caserta, A., Di Maio, G., and Koˇcinac, Lj.D.R.
Statistical convergence in function spaces.
Abstr. Appl. Anal. 2011; 2011: 11 pp. Article ID 420419 doi:10.1155/2011/420419
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
23
[11] Connor, J. and Grosse-Erdmann, K.G. Sequential deﬁnitions of continuity for real functions.",N/A,N/A
"The Rocky Mountain Journal of Mathematics 2003; 33: 1 93-121. MR 2004e:26004
[12] C¸ akallı, H.
Lacunary statistical convergence in topological groups. Indian J. Pure Appl.
Math. 1995; 26: 2 113-119. MR 95m:40016.
[13] ............. A study on statistical convergence. Funct. Anal. Approx. Comput. 2009; 1: 2 19-24.
MR 2011c:40010.
[14] ............. δ-quasi-Cauchy sequences. Math. Comput. Modelling 2011; 53: 1-2 397-401. MR
2011m:26004",N/A,N/A
"2011m:26004
[15] ............. On G-continuity. Comput. Math. Appl. 2011; 61: 2 313-318. MR 2011m:40002.
[16] ............. Statistical ward continuity. Appl. Math. Lett. 2011;
24:
10 1724-1728. MR
2012f:40020
[17] ............. Statistical-quasi-Cauchy sequences. Math. Comput. Modelling 2011; 54: 5-6 1620-
1624. MR 2012f:40006
[18] C¸ akallı, H and Sonmez, A. Slowly Oscillating Continuity in Abstract Metric Spaces. Filomat
2013; 27: 5 925-930.",N/A,N/A
"2013; 27: 5 925-930.
[19] C¸ akallı, H. and Sonmez, A., Genc, C. On an equivalence of topological vector space valued
cone metric spaces and metric spaces. Appl. Math. Lett. 2012; 25: 3 429-433. MR 2012j:54059
[20] C¸ akalli, H. Sequential deﬁnitions of compactness. Appl. Math. Lett. 2008; 21: 6 594-598. MR
2009b:40005
[21] ............. Slowly oscillating continuity. Abstr. Appl. Anal. 2008;
2008:
5 pp. Hindawi
Publ. Corp. New York, ISSN 1085-3375, Article ID 485706 doi:10.1155/2008/485706 MR",N/A,N/A
"2009b:26004
[22] ............. Forward continuity. J. Comput. Anal. Appl. 2011; 13: 2 225-230. MR 2012c:26004
[23] C¸ akalli, H. and Das, P. Fuzzy compactness via summability. Appl. Math. Lett. 2009; 22: 11
1665-1669. MR 2010k:54006.
[24] C¸ akalli, H. and Kaplan, H. A study on Nθ-quasi-Cauchy sequences. Abstr. Appl. Anal.
2013; 2013: 4 pp. Hindawi Publ. Corp., New York, Article ID 836970, Article ID 836970,
doi:10.1155/2013/836970 http://dx.doi.org/10.1155/2013/836970
24",N/A,N/A
"24
HUSEYIN CAKALLI MALTEPE UNIVERSITY, MALTEPE, ISTANBUL-TURKEY
[25] C¸ akalli,
H
and
Khan,
M.K.
Summability
in
Topological
Spaces.
http://www.math.kent.edu/ kazim/NorthFloridaU/NorthFlor.pdf
[26] C¸ akalli, H and Khan, M.K. Summability in Topological Spaces. Appl. Math. Lett. 2011; 24:
3 348-352. MR 2011m:40026
[27] Dik, F., Dik, M., Canak, I. Applications of subsequential Tauberian theory to classical Taube-
rian theory. Appl. Math. Lett. 2007; 20: 8 946-950. MR 2008b:40007",N/A,N/A
"[28] Dik, M. and Canak, I. New Types of Continuities. Abstr. Appl. Anal. 2010; 2010: 6 pp.
Hindawi Publ. Corp., New York, ISSN 1085-3375 Article ID 258980 . doi:10.1155/2010/258980
MR 2011c:26005.
[29] Di Maio, G. and Koˇcinac, Lj.D.R. Statistical convergence in topology. Topology Appl. 2008;
156: 28-45. MR 2009k:54009
[30] Freedman, A.R., Sember, J.J. and Raphael, M. Some Cesaro-type summability spaces. Proc.
London Math. Soc. 1978; 3: 37 508-520. MR 80c:40007.",N/A,N/A
"[31] Fridy, J.A. On statistical convergence. Analysis 1985; 5: 301-313. MR 87b:40001.
[32] Fridy, J.A. and Orhan, C. Lacunary statistical convergence. Paciﬁc J. Math. 1993; 160: 1
43-51. MR 94j:40014.
[33] Mursaleen, M. λ-statistical convergence. Math. Slovaca 2000; 50: 1 111-115. MR 2001g:40003
[34] Mursaleen, M., Mohiuddine, S.A. Banach limit and some new spaces of double sequences.
Turk. J. Math. 2012; 36: 121-130. MR 2012m:46012",N/A,N/A
"Turk. J. Math. 2012; 36: 121-130. MR 2012m:46012
[35] Pal, S.K., Savas, E. and Cakalli, H. I-convergence on cone metric spaces. Sarajevo J. Math.
2013; 9 1 85-93. DOI: 10.5644/SJM.09.1.00
[36] Palladino, F.J. On half Cauchy sequences. Arxiv. 2012; 3 pp. arXiv:1102.4641v1 [math.CA]
http://arxiv.org/abs/1102.4641v1
[37] Patterson, Richard F. and Savas, E. Asymptotic Equivalence of Double Sequences. Hacet. J.
Math. Stat. 2012; 41: 4 487-497.",N/A,N/A
"Math. Stat. 2012; 41: 4 487-497.
[38] Sonmez, A., Cakalli, H. Cone normed spaces and weighted means. Math. Comput. Modelling
2010; 52: 9-10 1660-1666. MR 2012e:46032.
UPWARD AND DOWNWARD STATISTICAL CONTINUITIES
25
[39] Vallin, R.W. Creating slowly oscillating sequences and slowly oscillating continuous func-
tions. With an appendix by Vallin and H. Cakalli. Acta Math. Univ. Comenianae 2011; 25:
1 71-78. MR 2012d:26002",N/A,N/A
"1 71-78. MR 2012d:26002
Huseyin Cakalli Maltepe University, Department of Mathematics, Marmara E˘g˙It˙Im
K¨oy¨u, TR 34857, Maltepe, ˙Istanbul-Turkey Phone:(+90216)6261050 ext:2248, fax:(+90216)6261113
E-mail address: hcakalli@maltepe.edu.tr; hcakalli@gmail.com",N/A,N/A
"Applications of Information Theory:
statistics and statistical mechanics
Khizar Qureshi ∗
September 18, 2018
Abstract
The method of optimizing entropy is used to (i) conduct Asymptotic Hypothesis Testing and
(ii) determine the energy distribution for which Entropy is maximized. This paper focuses on two
related applications of information theory: Statistics and Statistical Mechanics.
Introduction
Entropy is one measure of uncertainty within a system, and is often used to describe the disorder of",N/A,N/A
"sequences of quantized random variables. However, entropy can also be extended to methods within
optimization, in which the disorder of a system of interest may be maximized or minimized.
Such
methods are prevalent within statistics, the physical sciences, and econometrics.
The concerns of a statistician observing a sequence of outcomes include the validity of an explanatory
hypothesis, its degree of signiﬁcance, and any assumptions underlying the statistical tests. While linear",N/A,N/A
"hypothesis testing is often suﬃcient, larger sequences exhibit large deviations in behavior that should
receive separate treatment. Traditional linear hypothesis testing trivially assigns a constant multiple of
an explanatory parameter β to an observation when forming a hypothesis (H0 = kβ = 0). Optimal
entropy, in which disorder is locally minimized or maximized, can be used to construct asymptotic,",N/A,N/A
"non-linear hypothesis tests. Unlike linear hypothesis testing, error probability can be minimized.
Optimizing entropy extends to thermodynamic systems. The Third Law of Thermodynamics states
that the entropy of a closed system, i.e.
one in which no mass or energy is added or removed, must
be bounded from below by zero. Achieving a non-entropic system is nearly impossible, except within a
perfect crystal lattice. A more probable state is one for which the entropy of a system is maximized, and",N/A,N/A
"observations follow a Boltzmann distribution.
In our study of optimal entropy, we will use classical Statistics and Statistical Mechanics as a lens. We
will demonstrate the concept of minimal entropy through two statistical tests: the univariate optimality
test deﬁned by Stein’s Lemma, and a multivariate optimality test, as deﬁned by the ChernoﬀBounds. We
will see that there exists a distribution, the Boltzmann distribution, that approaches maximum entropy",N/A,N/A
"as temperature goes to inﬁnity. Finally, we will apply the concept of asymptotic hypothesis testing to
Statistical Mechanics. In particular, we will test and observe the evolution of error probability with
a growing sample size. We will also compare Q-function error probability with that of the Chernoﬀ
∗Prof. Peter Shor provided generous amounts of feedback
Department of Mathematics
Massachusetts Institute of Technology
18.424: Seminar in Information Theory
1",N/A,N/A
"18.424: Seminar in Information Theory
1
arXiv:1603.02589v1  [math.ST]  5 Mar 2016
2
bound. The remainder of the paper is organized as follows. To better understand the atypicality of
sequences, we will study the method of types. We will then learn how such sequences behave through
the large deviation theory. The focus of the paper will then shift to hypothesis testing, in which we
will develop tools for recognizing the asymptotic optimality of entropy. Illustrative examples of this will",N/A,N/A
"include Stein’s Lemma and Chernoﬀbounds. For the interest of the physical sciences, we will rigorously
derive the Boltzmann distribution, for which entropy is nearly maximized. Finally, we will converge the
aforementioned topics through simulations of asymptotic statistical testing.
Hypothesis Testing
Statisticians are often concerned with not just observed data, but the several possible underlying expla-",N/A,N/A
"nations. A few examples include: testing for the eﬀectiveness of a drug, determining whether or not a
coin is biased, and the eﬀect of gender on wage growth. We begin with a simple case in which we decide
between two hypothesis, each of which is represented by an independent and identical distribution, or
i.i.d. Let X1, X2, . . . , Xn be i.i.d. ∼Q(x). For an observed outcome, we have two possible explanations:
• H1 : Q = P1
• H2 : Q = P2",N/A,N/A
"• H1 : Q = P1
• H2 : Q = P2
We now deﬁne a general decision function, whose value reﬂects the acceptance and rejection of the above
hypothesis. Namely, for general decision g(x1, x2, . . . , xn), g(x) = i indicates that Hi is accepted. In the
binary case, the set A over which g(x) = i is complemented by the set Ac, over which g(x) ̸= i.
Quite often, statisticians are concerned with accepting incorrect hypotheses and rejecting correct ones.",N/A,N/A
"Such occurrences, recognized as Type I/II errors, often occur when sequences exhibit atypicality and large
deviating behavior (See appendix). Error probabilities are reﬂected through the decision function using
weights α, β:
α = P(g(x) = 2|H1 true) = P n
1 (Ac)
β = P(g(x) = 1|H2 true) = P n
1 (A)
(1)
Notice that the general decision function takes on values contradicting those implied by the conditional",N/A,N/A
"hypothesis. The ﬁrst implies that H2 was accepted even though H1 was true, and the second implies
that H1 was accepted even though H2 was true. Type I (reject true) and Type II (accept false) errors
similarly prove detrimental to experiments, and so we wish to minimize probabilities α and β. Minimizing
α increases β, and minimizing β increases α. We will now explore methodology to minimize the overall
probability of error by optimizing entropy as a weighted sum of α and β.
Stein’s Lemma",N/A,N/A
"Stein’s Lemma
We ﬁrst ﬁx either α or β, and manipulate the other to minimize the probability of error.
Theorem 1 (Stein’s Lemma). Let X1, X2, . . . , Xn be i.i.d. ∼Q. Further, let D(P1∥P2) represent the
Kullback-Leibler distance, or relative entropy between the probability densities. Consider the hypothesis
test between two alternatives Q = P1 and Q = P2 where D(P1∥P2) < ∞. Let An ⊆Hn be an acceptance
region for hypothesis 1. Let the probabilities of error be
αn = P n
1 (Ac
n)
βn = P n
2 (An)",N/A,N/A
"αn = P n
1 (Ac
n)
βn = P n
2 (An)
(2)
3
and for 0 < ϵ < 1
2, deﬁne
βϵ
n = minAn⊆Xnβn
(3)
Then,
limϵ→0 limn→∞
1
nlogβϵ
n = −D (P1∥P2)
(4)
Proof. See Appendix
Thus, no sequence of sets Bn has an exponent better than D (P1∥P2). But the sequence An achieves
the exponent D (P1∥P2). Thus An is asymptotically optimal, and the best error exponent is D (P1∥P2).
ChernoﬀBound
Thus far, α and β have been treated separately. The approach underlying Stein’s Lemma was to set",N/A,N/A
"one error probability to be inﬁnitesimally small, and measure the eﬀect on the resulting probability.
We saw that setting α ≤ϵ achieved βn = 2−nD. However, the distribution of error amongst α and β
may be highly asymmetrical, in which case univariate optimization may not suﬃce. We now explore
methodology for a bivariate optimization.
An alternative approach is to minimize the weighted sum of α and β. The resulting error exponent is",N/A,N/A
"known as the ChernoﬀInformation. Consider a distribution of i.i.d. random variables: X1, X2, . . . , Xn
representative of the decision function.
We assign P1 to Q with probability π1 and P2 to Q with
probability π2. Upholding the deﬁnition of α and β, the overall probability of error is
P n
ϵ = π1αn + π2βn
(5)
Theorem 2 (Chernoﬀ). The best achievable exponent in the Bayesian probability of error is D∗, where
D∗= textlimn→∞minAn⊆Hn −1
nlogP n
ϵ = D (Pλ∗∥P1) = D (Pλ∗∥P2)
(6)
where
Pλ =
P λ",N/A,N/A
"ϵ = D (Pλ∗∥P1) = D (Pλ∗∥P2)
(6)
where
Pλ =
P λ
1 (x)P 1−λ
2
(x)
P
a∈X P λ
1 (a)P 1−λ
2
(a)
(7)
and λ∗the value of λ such that
D (Pλ∗∥P1) = D (Pλ∗∥P2) .
(8)
Proof. See Appendix
Physical Chemistry
Claude Shannon ﬁrst proposed that the uncertainty due to possible errors in a message could be encap-
sulated by
U(W) = logW
(9)
where W is the number of possible ways (state space) of encoding random information. Intuitively, the",N/A,N/A
"uncertainty increases with increasing W, and is zero if W=1. The concept of entropy provides a deep-
rooted link between information theory and statistical mechanics. The state with the least information
available, or greatest entropy occurs when the set of all states are equiprobable. This is also the state with
maximum uncertainty. An information theoretic perspective dictates that explicit knowledge of various",N/A,N/A
"probabilities associated with the system constitutes greater information. Similarly, the thermodynamics
4
of a system of isolated particles indicate that entropy is directly correlated with expected energy level.
Below is a molecular orbital diagram that illustrates the possible energy states, all of which depend on
the position an electron occupies.
Figure 1: The ﬁgure above is a molecular orbital diagram. When two atoms interact, and possibly share",N/A,N/A
"their valence (outermost) electrons, the electrons must occupy a particular orbital. Once occupying an
orbital, the atoms are able to form a bond. Here, we are not concerned with the type of the bond,
but rather, paired occupancy. The empty orbitals are indistinguishable, and will be occupied with equal
probability.
Entropy may also be observed in macroscopic states. The second law of thermodynamics states that",N/A,N/A
"in equilibrium, changes in entropy are proportional to changes in system heat per unit temperature.
We have dW = dQsys
T
. We can better understand this through an illustration. Consider a system of
gas particles that may be expanded or compressed. We can study the system under various entropic
regimes. The diagram below illustrates how available work decreases (increases) for gaseous expansion
(compression) under bivariate states of pressure and volume.",N/A,N/A
"Consider a perfectly structured crystal lattice structure, in which the positions of each contributing
molecule is ﬁxed. If we observe such a system, depart, and return after n periods, the position of each
molecule within the crystal will have remained the same almost surely. If the particles did not displace,
then they also carried zero kinetic energy, which is representative of a zero temperature system. This near",N/A,N/A
"certainty of a thermodynamic system is an example of an optimization in which entropy is minimized. If
instead, the system consisted of a fair coin toss, with no extra information, entropy would be maximized.
The Boltzmann Distribution
The distribution that maximizes the state space for a ﬁxed energy level is the Boltzmann distribution.
We will now derive such a distribution, and show that it uniquely maximizes entropy on each energy",N/A,N/A
"level. Consider a crystal containing Nparticles, each of which has available energy levels, ϵn. The state
space, W, is the number of ways the total energy E = P
n Nnϵn can be distributed amongst the the
particles in each energy level, across all energy levels, N = P
n Nn. The expected number of particles
in each energy level, Nn, is the product of the probability that a particle is at an energy level, Pn,",N/A,N/A
"and the total number of particles, N. The only consideration for such a distribution is the number of
5
Figure 2: The ﬁgure above is a pressure-volume diagram for a system of Argon gas particles. Expanding
or compressing a gas requires energy, the extent of which depends on the state of the system. Notice that
for an adiabatic system (dQsys = 0), compressing the gas requires the least relative energy. That is, when",N/A,N/A
"when the change in entropy in minimized, a system can be most naturally expanded/compressed. To
reach minimum work available, we move down the gradient of steepest descent until entropy is globally
minimized.
particles in each energy levels, not necessarily the amount of energy allocated to each particle. Energy
is conserved amongst states and across energy levels. While there exist several ways of assigning the",N/A,N/A
"number of particles in each energy level ϵn, we wish to ﬁnd the state with the distribution achievable in
the most number of ways for ﬁxed energy levels. Our ﬁrst constraint is that the total state space W is
the sum of individual states occupied, Wi for all possible distributions
W =
X
Wi
(10)
Amongst all possible distributions of particles, there exists one that can be achieved in more ways than
any other. A distribution that approaches maximum entropy for ﬁxed energy levels is the Boltzmann",N/A,N/A
"distribution.
logW ∼= logWB
(11)
To ﬁnd the most probable distribution that maximizes W, we ﬁrst note that each particle in the crystal
can be distinguished from the others because it occupies a deﬁned position in space. Therefore, such a
setting allows us to number the particles 1, 2, . . . , N. We assume a large N, to maintain consistency with
typical non-deﬁcient states. S A particular microstate of the crystal will place particle 1 in energy level ϵi,",N/A,N/A
"particle 2 in energy level ϵj, and so on. Initially, we seek the number of Wi microstates in a distribution
for which there are N1 particles in ϵ1, N2 particles in ϵ2,, and so on. We choose, at random, particles from
the crystal, Ni, and assign them to energy levels, ϵi. The number of ways this can be done is equal to the
number of diﬀerent orders in which the particles can be chosen from the crystal. The ﬁrst particle can be",N/A,N/A
"chosen from a group of N. With N −1 particles remaining, the second can be chosen in N −1 ways. We
see that the number of ways for selecting the ﬁrst two particles is N(N −1). Following this procedure, we
then we see that the number of ways for selecting the N particles is N(N −1)(N −2)(N −3) . . . (3)(2)(1),
or N!.
We have over counted the ways of achieving a given distribution, and have assumed that all states",N/A,N/A
"are distinguishable. Consider the placement of the ﬁrst two particles into energy level ϵ1. It makes no
6
diﬀerence whether the ﬁrst particle is placed into ϵ1 prior to or following particle 2. That is, the states
are indistinguishable. This relaxes the strictness on order, and so permutation are ignored. Thus, the
state space, Wi, for a given distribution, is N! divided by the product of all N!
Wi =
N!
Q
n Nn!
(12)",N/A,N/A
"Wi =
N!
Q
n Nn!
(12)
To ﬁnd the distribution that maximizes Wi, we note Stirling’s approximation for log N!
log N! ≈N log N −N
(13)
Finding the maximum of Wi is equivalent to ﬁnding the maximum of log Wi, so we combine equations
(13) and (14), and re-arrange as follows
log Wi ≈log N! −
X
n
logNn! = N log N −
X
n
Nn logNn =
 X
n
Nn
!
log
X
n
Nn −
X
n
Nn logNn (14)
However, the set of particles is conserved. Moreover, the net energy within the system is conserved. This",N/A,N/A
"provides the following two constraints
X
j
Nj = N
X
j
ϵjNj = E
(15)
We now use Lagrange’s method of undetermined multipliers. When Wi is maximized, its diﬀerential log
must be zero
d log Wi =
X
j
∂logWi
∂Nj
j
dNj = 0
(16)
We multiply the constraints on particle count and energy by constants α, β, and then take the diﬀerential
to obtain
α
X
j
dNj = 0
β
X
j
ϵjdNj = 0
(17)
Subtracting these two constraints from the log-entropy, we obtain
X
j
∂logWi
∂Nj
−α −βϵj

dNj = 0
(18)",N/A,N/A
"X
j
∂logWi
∂Nj
−α −βϵj

dNj = 0
(18)
Through use of log-properties and algebraic manipulation (See Appendix), the expression above is re-
duced to
logNj = logN −α −βϵj
(19)
which, after exponentiating both sides is
Nj = Ne−αe−βϵj
(20)
The signiﬁcance of this result is that it shows the occupancy of en energy state ϵj is proportional to
e−βϵj.
7
Key Result
To account for energy states, thermodynamicists often make use of temperature, an intrinsic quantity.",N/A,N/A
"Temperature is equivalent to the average kinetic energy of a system of particles. Because this varies
across systems, we normalize. For a temperature T, and the Boltzmann constant, kB,
β =
1
kBT .
(21)
Inducting on the one particle case, in which, eα = P
j e
−ϵj
kBT , and combining the preceding three expres-
sions, providing the desired result
Pn = Nn
N =
ez
P
N ez
where z = −ϵj
kBT
(22)
We have now found the Boltzmann distribution, for which entropy is maximized. The Boltzmann prob-",N/A,N/A
"ability above expresses the fraction of particles placed in each quantum state n to maximize entropy Wi
of the distribution over each energy level, ϵj.
Simulation: Asymptotic Hypothesis Testing
Thus far, we have studied various methods of statistical testing, highlighting the importance of asymptotic
tests such as the ChernoﬀInformation Bound. We have also (brieﬂy) explored Statistical Mechanics,
in which we show that entropy is maximized for a Boltzmann distribution. We now demonstrate the",N/A,N/A
"importance of our learnings through a representative example.
Robust methods of signal interpretation allow for communication, and involve the separation of signal
and noise.
A simple signal will follow a Gaussian distribution, for which entropy is maximized.
A
hypothesis consists of assigning observations as either signals, or as noise. Such hypotheses carry error
probabilities, and should be studied with both linear testing, as well as asymptotic testing.
Example: Binary Detection",N/A,N/A
"Example: Binary Detection
The classical binary detection problem involves the reception of ﬁnite-length signals realized as a random
process r[n], n = 1, 2, . . . , [3]. The signal can be attributed to either Gaussian white noise n[i] or a
deterministic signal s[i]. Basic studies involve the interpretation of the signal-to-noise ratio, a measure
of quality. Consider a binary detection problem:
r = si + n, , i ∈{1, 2}
(23)
• Detections are composed of signals and noise",N/A,N/A
"• Detections are composed of signals and noise
• n: N-dimensional noise vector
• i.i.d. Gaussian random variables and ∼(0, 1)
• s1 = (m, m, . . . , m)
• s2 = (0, 0, . . . 0)
8
Evaluate the error probability for both N = 1 and N = 4 when m ∈{1, 2, 3, 4, 5, 6}.
Traditionally, error probability is evaluated through the Q-function, which represents the probability
that a normal random variable will obtain a value larger than x standard deviations above the mean.",N/A,N/A
"It can also be thought of as the ""tail"" probability of the standard normal distribution, and is useful for
linear hypothesis testing.
Q(x) =
1
√
2π
Z ∞
x
exp
−t2
2

dt = 1
2erf
 x
√
2

(24)
Given a signal-to-noise Ratio, the Q-function can be used to determine the error probability
P e = Q
 ρ
σ

where
ρ2
σ2 = Nm2
4
(25)
We also know that any error probability is bounded from above by the ChernoﬀInformation bound.
For the Q-function,
Q(x) ≤exp

−x2
2

erf
(26)
And so,
P e = Q
 √
Nm
2
!",N/A,N/A
"
−x2
2

erf
(26)
And so,
P e = Q
 √
Nm
2
!
≤exp

−m2N
8

(27)
The ﬁgure below illustrates the growth of error in both forms of testing.
Figure 3: The ﬁgure above shows the evolution of error probability with an increasing signal length (m).
Error probability decreases as: (i) the number of bits in the signal increases, and (ii) the number of
elements in the noise vector increases.
Concluding Remarks",N/A,N/A
"Concluding Remarks
Optimizing entropy demonstrates the applicability of information theory beyond computing. Asymp-
totic testing captures error probability in atypical sequences, and a Boltzmann distribution of particles
approaches maximum entropy, as temperature goes to inﬁnity.
9
Appendix
Motivation for asymptotic testing arises from atypicality and large deviations in sequences. We brieﬂy
review this, and encourage the ambitious reader to study further.
The Method of Types",N/A,N/A
"The Method of Types
The Asymptotic Equipartition Property formalizes that although there exist several possible outcomes
of a stochastic process, there exists a set from which sequences are typical , or most frequently observed.
The centric approach underlying the AEP involves deﬁning an almost sure convergence in probability
between the expectation of a sequence to its entropy. Similarly, the Method of Types deﬁnes strong",N/A,N/A
"bounds on the number of sequences of a particular distribution, as well as the probability of each such
sequence being observed.
Large Deviation Theory
Recall that type of a sequence xn
i ∈An is representative of its empirical distribution ˆP = ˆPxn
i where:
ˆP(a) = |{i : xi = a}|
n
, a ∈A.
(28)
A distribution P on A is called an n-type if it is the type of some xn
1 ∈An. The set of all xn
1 ∈An of
type P is called the type class of the n-type P and is denoted by T n
p .",N/A,N/A
"p .
Lemma 3. The number of possible n-types is
n + |A|−1
|A|−1

(29)
Proof.
T (P) = {x ∈X n : Px = P}
(30)
The combinatoric cardinality of T (P) provides the result
Lemma 4. For any n-type P,
n + |A|−1
|A|−1
−1
2nH(P ) ≤|T n
p |≤2nH(P )
(31)
Proof. First, we prove the upper bound using P(T (P) ≤1.
1 ≥P n(T (P)) =
X
x inT (P )
P n(x) =
X
x inT (P )
2−nH(P ) = ∥T(P)∥2−nH(P )
(32)
Consequently, ∥T(P)∥≤2nH(P ). For the lower bound, using the fact that T(P) has the highest proba-",N/A,N/A
"bility amongst all type classes in P, we can bound the ratio of probabilities
P n(T(P))
P n(T( ˆP))
=
∥T(P)∥Q
a∈XP (a)nP (a)
∥T( ˆP)∥Q
a∈XP (a)n ˆ
P (a)
=
Y
a∈X
(n ˆP(a))!
(nP(a))!P(a)n(P (a)−ˆ
P (a))
(33)
10
Using the identity m!
n! ≥nm−n, we see
P n(T (P))
P n(T ( ˆP))
≥
Y
a∈X
nn(P (a)−ˆ
P (a)) = nn(1−1) = 1
(34)
So P n(T(P)) ≥P n(T( ˆP)). The lower bound can now be found as
1 =
X
Q∈Pn
P n(T(Q)) ≤
X
Q∈Pn
= maxQP n(T(Q))
=
X
Q∈Pn
P n(T(P))
≤(n + 1)∥X∥P n(T(P)) = (n + 1)∥X∥
X
x∈T (P )
P n(x)",N/A,N/A
"X
x∈T (P )
P n(x)
= (n + 1)∥X∥
X
x∈T (P )
2−nH(P )
= (n + 1)∥X∥∥T(P)∥2−nH(P )
(35)
To connect the theory of types with general probability theory, we must develop a sense of relative
entropy. For any distribution P on A, let P n denote the distribution of n independent drawings from P,
that is, P n (xn
1) = Qn
i=1 P (xi) , xn
1 ∈An.
Lemma 5. For any distribution P on A and any n-type Q
P n (xn
1)
Qn (xn
1) = 2−nD(Q∥P ), ifxn
1 ∈T n
Q
n + |A|−1
|A|−1
−1
2−nD(Q∥P ) ≤P
 T n
p

≤2−nD(Q∥P )
(36)",N/A,N/A
"|A|−1
−1
2−nD(Q∥P ) ≤P
 T n
p

≤2−nD(Q∥P )
(36)
Proof. For probability P ∈Pn, distribution Q, the probability of type class T(P) under Qn is 2−nD(P ∥Q).
We see
Qn(T(P)) =
X
x∈T (P )
Qn(x)
=
X
x∈T (P )
2−n(D(P ∥Q)+H(P ))
= ∥T(P)∥2−n(D(P ∥Q)+H(P ))
(37)
Replacing ∥T(P)∥with the result from Lemma 3, we see the result.
Corollary 6. Let ˆPn denote the empirical distribution (type) of a random sample of size n drawn from
P. Then
P

D

ˆPn∥P

≥δ

≤
n + |A|−1
|A|−1

2−nδ, ∀δ > 0
(38)",N/A,N/A
"
≥δ

≤
n + |A|−1
|A|−1

2−nδ, ∀δ > 0
(38)
Proof. Given an ϵ > 0, we can deﬁne a typical set T ϵ
Q of sequences for the distribution Q as T ϵ
Q = {xn :
11
D(Pxn∥Q) ≤ϵ}. Then the probability of an atypical sequence is
1 −Qn(T ϵ
Q) =
X
P :D(P ∥Q)≥ϵ
Qn(T(P))
≤
X
P :D(P ∥Q)≥ϵ
2−nD(P ∥Q)
≤
X
P :D(P ∥Q)≥ϵ
2−nδ
≤
n + |A|−1
|A|−1

2−nδ, ∀δ ≥0
(39)
Theorem 7. Sanov’s Theorem Let Π be a set of distributions on A whose closure is equal to the closure",N/A,N/A
"of its interior. Then for the empirical distribution of a sample from a strictly positive distribution P on
A,
−1
nlogP

ˆP ∈Π

→D (Π∥P)
(40)
Proof. Sanov’s Theorem Let Pn be the set of possible n-types and let Πn = Π∩Pn. The previous lemma
implies that
Prob

ˆPn ∈Πn

= P n  ∪Q∈ΠnT n
Q

is upper bounded by
n + |A|−1
|A|−1

2−nD(Πn∥P ) and lower bounded by
n + |A|−1
|A|−1
−1
2−nD(Πn∥P )
(41)",N/A,N/A
"n + |A|−1
|A|−1
−1
2−nD(Πn∥P )
(41)
Since D (Q∥P) is continuous in Q, the hypothesis on Π implies that D (Πn∥P) is arbitrarily close to
D (Π∥P) if n is large.
Proofs
Stein’s Lemma. To prove the theorem, we construct a sequence of acceptance regions An ⊆Xn such
that An < ϵ and βn = 2−nD(P1∥P2). We then show that no other sequence of tests has an asymptotically
better exponent.
First, we deﬁne
An =

x ∈Xn : 2+n(D(P1∥P2)−δ) ≤P1x
P2x ≤2+n(D(P1∥P2)+δ
(42)
Then, we have the following properties:",N/A,N/A
"(42)
Then, we have the following properties:
1. P n
1 (An) →1. This follows from:
P n
1 (An) = P n
1
 
1
n
n
X
i=1
logP1(Xi)
P2(Xi) ∈(D(P1∥P2) −δ1D (P1∥P2) + δ
!
(43)
by the strong LLN, since D (P1∥P2) = EP1

log P1(X)
P2(X)

. Hence, for suﬃciently large n, An < ϵ.
12
2. P n
2 (An) ≤+n(D(P1∥P2)−δ). Using the deﬁnition of An, we have
P n
2 (An) =
X
An
P2(x) ≤
X
An
P1(x)2+n(D(P1∥P2)−δ)
= 2+n(D(P1∥P2)−δ) X
An
P1(x)
= 2+n(D(P1∥P2)−δ)(1 −αn).
(44)
Similarly, P n",N/A,N/A
"= 2+n(D(P1∥P2)−δ)(1 −αn).
(44)
Similarly, P n
2 (An) ≥2+n(D(P1∥P2)+δ)(1 −αn). And so, 1
nlogβn ≤−D (P1∥P2) + δ + log(1−αn)
n
, and
1
nlogβn ≥−D (P1∥P2) −δ + log(1−αn)
n
, hence limn→∞1
nlogβn = −D (P1∥P2) .
ChernoﬀBound. The optimum hypothesis test is a likelihood ratio test, which follows the form:
D (PXn∥P2) −D (PXn∥P1) > T
(45)
The test divides the probability simplex into regions corresponding to hypothesis 1 and hypothesis 2,",N/A,N/A
"respectively. This is illustrated below: Let A be the set of types associated with hypothesis 1. From the
Figure 4: The ﬁgure above shows the probability simplex and the Chernoﬀbound. Notice that for error
probabilities P1 and P2, there exists an optimal error probability Pλ. This is determined as a weighted
argmin.
preceding discussions, it follows that the closest point in the set Ac to P1 is on the boundary of A, and",N/A,N/A
"is of the form given by [8]. Then, it is clear that Pλ is the distribution in A that is closest to P2. It is
also the distribution in Ac that is closest to P1. By Sanov’s theorem, we can calculate the associated
probabilities of error:
αn = P n
1 (Ac) = 2−nD(Pλ∗∥P1)
βn = P n
2 (A) = 2−nD(Pλ∗∥P2)
(46)
In the Bayesian case, the overall probability of error is the weighted sum of the two probabilities of error,
Pe = π12−nD(Pλ∗∥P1) + π22−nD(Pλ∗∥P2) = 2−n min{−D(Pλ∗∥P1),−D(Pλ∗∥P2)}
(47)",N/A,N/A
"(47)
since the exponential rate is determined by the worst exponent. Since D (Pλ∥P1) increases with λ and
D (Pλ∥P2) decreases with λ, the maximum value of the minimum of {D (Pλ∥P1) , D (Pλ∥P2)} is attained
when they are equal. We choose λ so that
D (Pλ∥P1) = D (Pλ∥P2) = C(P1, P2)
(48)
Thus C (P1, P2) is the highest achievable exponent for the probability of error, and is called the Chernoﬀ
13
information.",N/A,N/A
"13
information.
The closest point in the set Ac to P1 is on the boundary of A, and is of the form given by []. Then
from the previous discussion, it is clear that Pλ is the distribution in A that is closest to P2; it is also the
distribution in Ac that is closest to P1. By Sanov’s theorem, we can calculate the associated probabilities
of error:
αn = P n
1 (Ac) = 2−nD(Pλ∗∥P1)
βn = P n
2 (Ac) = 2−nD(Pλ∗∥P2)
(49)",N/A,N/A
"βn = P n
2 (Ac) = 2−nD(Pλ∗∥P2)
(49)
In the Bayesian case, the overall probability of error is the weighted sum of the individual two probabilities
of error,
Pe = π12−nD(Pλ∥P1) + π22−nD(Pλ∥P2) = 2−n min(D(Pλ∥P1),D(Pλ∥P2)
(50)
since the exponential rate is determined by the worst exponent. Since D (Pλ∥P1) = D (Pλ∥P1) increases
with λ and D (Pλ∥P2) decreases with λ, the maximum value of the minimum of D (Pλ∥P1) , D (Pλ∥P2)
is attained when they are equal.
This is illustrated below:",N/A,N/A
"This is illustrated below:
Figure 5: The ﬁgure above shows the relative entropy for each error probability as a function of λ.
We choose λ so that
D (Pλ∥P1) = D (Pλ∥P2) = C(P1, P2)
(51)
Thus C (P1, P2) is the highest achievable exponent for the probability of error, and is called the Chernoﬀ
information.
References
[1] T.M. Cover, J.A. Thomas, Elements of Information Theory, Wiley, 2nd edition, 2006.",N/A,N/A
"[2] D. Eisenberg, D. Crothers, Physical Chemistry with Applications to the Life Sciences, Benjamin
Cummings, 3rd edition, 1979.
[3] P. Gopych, Sensitivity and Bias within the Binary Signal Detection Theory, BSDT, Information
Theories & Applications, Vol. 11, 2004.",N/A,N/A
"arXiv:quant-ph/0302169v1  21 Feb 2003
PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON
COMPUTATIONAL AND APPLIED MATHEMATICS
July 22 – 26, 2002, Leuven, Belgium
pp. 1–10
NONLINEAR DYNAMICS IN QUANTUM PHYSICS –
QUANTUM CHAOS AND QUANTUM INSTANTONS
Helmut Kr¨oger
D´epartement de Physique
Universit´e Laval
Qu´ebec, Qu´ebec G1K 7P4, Canada
Abstract. We discuss the recently proposed quantum action - its interpretation, its moti-",N/A,N/A
"vation, its mathematical properties and its use in physics: quantum mechanical tunneling,
quantum instantons and quantum chaos.
1. Introduction. Modern physics returns to some of its origins dating back
to the ﬁrst part of the last century. Examples are entanglement, according to
Schr¨odinger the most peculiar property occuring in quantum mechanics, or the
condensation of very cold atoms predicted by Einstein and Bose (Bose-Einstein",N/A,N/A
"condensate). Another example is nonlinear dynamics and chaos, dating back
to the work of Poincar´e and others and its modern descendents - quantum
chaos. Entanglement plays a fundamental role in quantum optics, quantum
computing, quantum cryptography, and quantum teletransportation [1, 2].
The Bose-Einstein condensate is a new state of matter. Classical chaos plays an
important role in macroscopic physics, chemistry and biology. Quantum chaos",N/A,N/A
"may become quite important for example in semiconductor devices, when due
to decreasing size (from micron to Angstrom) atomic length scales are reached
and the laws of quantum mechanics apply. Like chaotic motion in a ﬂuid,
quantum chaos may cause a similar phenomenon for the ﬂux of the electric
current in a semiconductor.
What has the quantum action - the subject of this article - to do with the
above issues? The quantum action is a new concept concerning the foundations",N/A,N/A
"of quantum mechanics. Since de Broglie we know that the quantum world has
apparently a dual face - a particle picture and a wave picture. The quantum
action can be considered as a link between classical physics and quantum
physics. This may be interpreted as if the quantum world has a third face -
a classical picture with a new interaction. Consequently, the quantum action
may be expected to be useful to better understand the relation between and",N/A,N/A
"the transition from classical physics to quantum physics. In particular, there
are some very fruitful concepts in quantum physics, which are derived from
1991 Mathematics Subject Classiﬁcation. Primary: 81Q50, 37F25.
Key words and phrases. Nonlinear dynamics, quantum chaos.
1
2
H. KR ¨OGER
classical physics: One example is the instanton solution in a quantum ﬁeld
theory. Another example is quantum chaos.
On the other hand there are phenomena occuring in the quantum world",N/A,N/A
"which do not have a counter part in the classical world. A well known example
is tunneling: A double well potential with a barrier in the middle prohibits in
classical physics a transition from one minimum to the other if the energy is
too small to overcome the barrier. However, in quantum physics a transition
does occur with a certain probability. It is noteworthy that tunneling and
instantons are closely related [3]. There are other systems, where transitions",N/A,N/A
"are classically forbidden, due to some conserved quantity (other than energy),
but quantum mechanical transitions are possible. This is known as dynamical
tunneling [4].
It has recently been realized experimentally [5, 6].
It turns
out that quantum chaos seems to facilitate dynamical tunneling. We suggest
that the quantum action [7, 8, 9, 10, 11] is an appropriate tool to investigate
phenomena on the borderline between classical and quantum physics and to",N/A,N/A
"analyze quantum tunneling, quantum instantons and quantum chaos.
In the following we discuss the concept of the quantum action. In particular,
we discuss analytical properties of the quantum action in the limit when the
time of a quantum mechanical transition goes to inﬁnity. As an example of the
use of the quantum action we discuss quantum instantons from a double well
potential and quantum chaos from the 2-D anharmonic oscillator. Finally, we",N/A,N/A
"give an outlook on further use of the quantum action.
2. The problem of quantum chaos and quantum instantons. Chaos
is quite well understood in classical physics. Its origin in terms of nonlinear
dynamics has been investigated thoroughly in theoretical physics and math-
ematics.
If one considers nature at the level of atoms, where the laws of
quantum mechanics (Q.M.) hold, chaotic phenomena are by far less well un-
derstood than in classical (macroscopic) physics [12, 13, 14, 15, 16]. Quantum",N/A,N/A
"chaos is usually analyzed in terms of the level density of its energy spectrum.
This is based on a conjecure by Bohigas et al. [17] which states that the level
density distribution (Poissonian vs. Wignerian) corresponds to an integrable
(non-chaotic) vs.
chaotic quantum system.
In classically chaotic systems,
phase space portraits, Poincar´e sectioons, Lyapunov exponents and the KAM
theorem are very useful to analyze the chaotic behavior. However, those no-",N/A,N/A
"tions have no direct counterpart in quantum systems. The problem is due to
the fact that in quantum mechanics one can not specify with certainty position
and momentum at the same time (Heisenberg’s uncertainty relation). Hence
a sharp point in phase space has no meaning.
This is also the problem with the deﬁnition of quantum instantons. Recall
that in classical physics the instanton is a solution in imaginary time where
a particle moves in a potential with degenerate minima, such that it starts",N/A,N/A
"at one minimum (sharp position and velocity zero) and goes over to another
3
minimum (sharp position and velocity zero). Again boundary conditions are
sharp points in phase space with no direct analogon in Q.M.
Here we take the following approach: Via the quantum action one can pa-
rametrize quantum mechanical transition amplitudes (which contain all infor-
mation about the physics of the system). On the other hand, the quantum",N/A,N/A
"action has the same mathematical form as the classical action, a kinetic term
(proportional to velocity squared) and a local potential term. However, the
action parameters, like mass and potential are diﬀerent from the classical one,
in general.
Starting from such quantum action then allows to construct a
phase space portrait and hence reintroduce the tools of classical chaos theory
to the quantum world.
Let us come back to the problem of a point in phase space used as initial",N/A,N/A
"condition. Recall in classical mechanics that equations of motions are ﬁxed
by specifying the dynamics (usually in terms of a diﬀerential equation) and
by specifying initial conditions. Usually one speciﬁes position and velocity at
some initial time. A consequence of this type of boundary conditions is that
certain trajectories are forbidden. For example those where the energy is too
small to overcome a potential barrier. Moreover, this initial condition has no",N/A,N/A
"direct analogon in Q.M. However, there is a simple way out: Consider classical
mechanics with 2-point boundary conditions. I.e., one speciﬁes positions at
some initial and ﬁnal time. Then there are no classically forbidden trajecto-
ries (sometimes even inﬁnitely many trajectories are possible). In quantum
physics, there is a well deﬁned transition amplitude.
Below we deﬁne the
quantum action by use of two-point boundary conditions.",N/A,N/A
"3. Postulate of quantum action. The quantum action [7] is deﬁned by the
following requirements. For a given classical action
S[x] =
Z
dtm
2 ˙x2 −V (x) ,
(1)
there is a quantum action
˜S[x] =
Z
dt ˜m
2 ˙x2 −˜V (x) ,
(2)
which parametrizes the Q.M. transition amplitude
G(xf, tf; xi, ti) = ˜Z exp
 i
ℏ
˜Σ

xf,tf
xi,ti

,
˜Σ

xf,tf
xi,ti = ˜S[˜xcl]

xf,tf
xi,ti =
Z tf
ti
dt ˜m
2
˙˜x2
cl −˜V (˜xcl)

xf
xi
.
4
H. KR ¨OGER",N/A,N/A
"2
˙˜x2
cl −˜V (˜xcl)

xf
xi
.
4
H. KR ¨OGER
where ˜xcl denotes the classical path corresponding to the action ˜S. We require
2-point boundary conditions,
˜xcl(t = ti) = xi
˜xcl(t = tf) = xf .
˜Z stands for a dimensionful normalisation factor. Note: The parameters of
the quantum action (mass, potential) are independent of the boundary points
xf, xi, but depend on the transition time T = tf −ti. The same q-action
parametrizes all transition amplitudes for a given transition time.",N/A,N/A
"The postulate leads to the question: Does such quantum action exist? So far
we have no general proof. However, the answer is aﬃrmative in the following
cases:
(a) Harmonic oscillator. In this case the classical action satisﬁes the deﬁnition
of the quantum action [18, 7], hence both coincide.
(b) Arbitrary local potential, limit when transition time T →0: Then the
quantum action exists as it coincides with classical action.
(c) Arbitrary potential, imaginary time, limit when transition time T →∞",N/A,N/A
"(equivalent to temperature going to zero): Then the quantum actions exists,
being diﬀerent from the classical action, in general (a proof is given in Ref.[11]).
4. Analytical properties of the quantum action. In this limit of large
imaginary time, the quantum action has a number of remarkable properties:
(i) The WKB approximation for the ground state wave function becomes exact,
after replacing the classical action by the quantum action.",N/A,N/A
"(ii) There is an analytic expression for the ground state wave function in terms
of the quantum action.
(iii) The ground state energy coincides with the minimum of the quantum
potential.
(iv) The ground state wave function has a maximum exactly at the same
position, where the quantum potential has a minimum.
(v) The quantum action allows also to reproduce energies and wave functions
of excited states. Example: The spectrum of the hydrogen atom, considering",N/A,N/A
"the lowest energy states for given angular momentum.
Let us detail some of those results.
For physical and mathematical reasons, it is interesting to go from real time
over to imaganiary time. A mathematical reason is that the path integral for
the Q.M. transition amplitude then becomes well deﬁned (Wiener integral).
A physical reason is that the description of ﬁnite temperature physics requires
the use of imaginary time. Thus we make the following transition
t →−it .
5",N/A,N/A
"t →−it .
5
Then the action becomes the so-called Euclidean action
SE =
Z T
0
dtm
2 ˙x2 + V (x) ,
(3)
the transition amplitude becomes the Euclidean transition amplitude
GE(xf, T; xi, 0)
=
⟨xf| exp[−HT/ℏ]|xi⟩
=
Z
[dx] exp [−SE[x]/ℏ]

xf,T
xi,0
,
and the quantum action becomes the Euclidean quantum action
GE(xf, T; xi, 0) = ˜ZE exp

−1
ℏ
˜ΣE

xf,T
xi,0

.
(4)
Let us recall the Feynman-Kac formula, which makes a statement about the",N/A,N/A
"time evolution of the quantum system in the limit of large imaginary time.
In this limit the time evolution of a quantum system is determined by the
behavior of exp[−HT/ℏ] when T goes to ∞. In particular, one has
e−HT/ℏ−→T→∞|ψgr⟩e−EgrT/ℏ⟨ψgr| ,
where Egr and ψgr are the ground state energy and wave function, respectively.
Now let us consider the case of a potential V (x) having a unique minimum
and obeying V (x) →∞when x →±∞. We consider the Euclidean action",N/A,N/A
"in the limit of large time. The trajectory minimizes the action. Because the
kinitic term and the potential term (by assumption) are positive, this means
that the trajectory minimizes ﬂuctuations and stays as close as possible to the
bottom of the potential valley. This implies for T →∞,
˜V →˜Vmin , ˜Tkin →0 , ǫ = −˜Tkin + ˜V →˜Vmin ,
and
˜Σ ≡˜S[˜xcl]|
xf,T
xi,0 =
Z T
0
dt ˜Tkin+ ˜V = ˜v0T+
Z 0
xi
+
Z xf
0
dx ±
q
2 ˜m( ˜V (x) −˜Vmin)

,",N/A,N/A
"Z 0
xi
+
Z xf
0
dx ±
q
2 ˜m( ˜V (x) −˜Vmin)

,
where the sign depends on initial and ﬁnal data. The transition amplitude
then becomes
G(xf, T; xi, 0) = ˜Z exp[−˜Σ/ℏ]

xf ,T
xi,0
T→∞
−→˜Z0 exp[−˜v0T/ℏ]
× exp[−
Z xfi
0
dx
q
2 ˜m( ˜V (x) −˜Vmin)/ℏ] exp[−
Z 0
xin
dx
q
2 ˜m( ˜V (x) −˜Vmin)/ℏ] .
By comparison with the Feynman-Kac formula one obtains the following ana-
lytic expressions for the ground state energy and wave function, expressed in
terms of the quantum action,",N/A,N/A
"terms of the quantum action,
Egr = ˜Vmin , ψgr(x) = 1
N e−R |x|
0
dx′ √
2 ˜m( ˜V (x′)−˜Vmin)/ℏ.
(5)
6
H. KR ¨OGER
Combining this with the Schr¨odinger equation leads to the following transfor-
mation law
2m(V (x) −Egr) = 2 ˜m( ˜V (x) −˜Vmin) −ℏ
2
d
dx2 ˜m( ˜V (x) −˜Vmin)
q
2 ˜m( ˜V (x) −˜Vmin)
sgn(x) .
(6)
Although those results have been obtained in imaginary time, they hold also
in real time (ground state energy Egr and wave function ψgr(x) are the same
as in real time).",N/A,N/A
"as in real time).
Eq.(5) shows that the minimum of the quantum potential coincides with
the ground state energy. Second, the position of the minimum of the quantum
potential coincides with the position of the maximum of the ground state
wave function. This is shown in Fig.[1]. Hence the quantum potential gives a
much better picture of the behavior of the quantum system than the classical
potential, which does not share those properties.
0
2
0
2
4
Egr
Particle in the potential : V(x) = mω
2x",N/A,N/A
"2
4
Egr
Particle in the potential : V(x) = mω
2x
2/2+g/x
2
Wave function with classical and quantum  
                 potential for g=1/100                                 
 Classical potential
 Quantum potential
 ψ (x5)
X
Figure 1. Inverse square potential. Classical potential, quan-
tum potential and groundstate wave function.
7
The celebrated semi-classical WKB formula [Wentzel, Kramers and Bril-
louin (1926)] gives approximate solutions to wave function and tunneling am-",N/A,N/A
"plitude. As an example let us consider in 1-D a system with parity symmetric
”conﬁnement” potential (potential goes to +∞when |x| →∞). Assume that
the system is in the ground state. The WKB formula gives an approximate
expression for wave function at energy E = Egr
ψW KB(x) =
A
(2m[V (x) −Egr])1/4 exp

−1
ℏ
Z x
x0
dx′q
2m[V (x′) −Egr]

.
Comparing with the results from sect.4, we see that the WKB formula becomes
exact, when replacing parameters of classical action by those of the quantum",N/A,N/A
"action
m →˜m , V (x) →˜V (x) ,
and replacing the rational term in front by a constant (wave function normal-
isation).
5. Excited states of hydrogen atom. Can the quantum action also give
analytical results for excited states? The answer is yes, if we consider excited
states being lowest energy states of a conserved quantum number.
As an
example let us consider the radial motion of the hydrogen atom in a sector
of ﬁxed angular momentum l > 0.
The potential has a centrifugal plus a",N/A,N/A
"The potential has a centrifugal plus a
Coulomb term. Let us consider angular motion to be quantized. We keep the
angular momentum quantum number l ﬁxed. In the Feynman-Kac limit the
transition amplitude is projected onto the state of lowest energy compatible
with quantum number l. The states of the hydrogen atom are characterized by
the quantum numbers n (principal quantum number) l (angular momentum)
where n = l + 1. There is also the magnetic quantum number m. The radial
potential is given by",N/A,N/A
"potential is given by
Vl(r) = ℏ2l(l + 1)
2mr2
−e2
r .
The exact energy of the excited states is given by
El = −EI
n2 = −
EI
(l + 1)2 , EI = me4
2ℏ2 ≈13.6eV (ionisation energy) .
The corresponding wave function is given by
φl(r) = 1
Nl
 r
a0
l
exp

−
r
(l + 1)a0

, a0 = ℏ2
me2 (Bohr radius) .
For the quantum action we make an ansatz
˜m = m , ˜Vl(r) = µ/r2 −ν/r .
8
H. KR ¨OGER
A transformation law [similar to Eq.(6)] determines the parameters of the
q-action,
µ = ℏ2
2ml2 , ν = e2
l
l + 1 ,",N/A,N/A
"q-action,
µ = ℏ2
2ml2 , ν = e2
l
l + 1 ,
and the minimum of the quantum potential gives exactly the excitation ener-
gies
El = ˜V min
l
= −me4
2ℏ2
1
(l + 1)2 = −
EI
(l + 1)2 .
Again the wave function can be expressed in terms of the quantum action in a
way similar to Eq.(5), and reproduces the exact wave function φl. Moreover,
we observe that the excited state wave function φl(r) has its maximum where
the quantum potential ˜Vl has its minimum. The quantum action has the same",N/A,N/A
"structure as the classical action. Both, the centrifugal and the Coulomb term
get tuned.
6. Quantum instantons. We consider quantum mechanics in 1-D. A particle
of mass m moves in a quartic potential of double well shape given by
V (x) = 1
2 −x2 + 1
2x4 ,
and m = 1, ℏ= 1. The potential minima lie at a = ±1. The potential barrier
has the height B = 1/2. The double well potential has a classical instanton
solution. It is obtained by solving the Euler-Lagrange equations of motion of",N/A,N/A
"the Euclidean classical action, with the initial conditions x(t = −∞) = −a,
˙x(t = −∞) = 0,
xcl
inst(t) = a tanh[
p
2/m A a t],
where A = 1/
√
2. The classical instanton goes from x(t = −∞) = −a to
x(t = +∞) = +a (see Fig.[2]).
For the quantum action we make the following ansatz,
˜S =
Z
dt1
2 ˜m ˙x2 −
4
X
k=0
˜vkxk.
For example, at (imaginary) transition time T = 0.5 we ﬁnd the following
parameters for the quantum action ˜m = 0.9961(2), ˜v0 = 1.5710(17), ˜v1 =",N/A,N/A
"0.000(2), ˜v2 = −0.745(6), ˜v3 = 0.000(2), ˜v4 = 0.493(3). By adding a constant,
the quantum potential can be expressed as a positive double well with minima
located at ±˜a with ˜a = 0.869(6). It has a barrier height ˜B = 0.281. It displays
”degenerate vacua”. Compared with the classical potential it is softer, i.e. its
potential minima are closer to the origin and its barrier is also lower. The
quantum potential also has an instanton solution, corresponding to T = 0.5,
given by
xT=0.5",N/A,N/A
"given by
xT=0.5
inst (t) = ˜a tanh[
p
2/ ˜m ˜A ˜a t] ≈0.869 tanh[0.865 t].
9
Similarly, we ﬁnd an instanton solution for any larger value of T. The quan-
tum instanton is obtained in the asymptotic limit T →∞. The evolution of
the instantons under variation of T, i.e. under variation of the temperature,
is depicted in Fig.[2]. It shows the transition from the classical instanton (at
inﬁnite temperature) to the quantum instanton (at zero temperature). One",N/A,N/A
"observes that the quantum instanton is much softer than the classical instan-
ton.
−10
−5
0
5
10
t 
−1
−0.5
0
0.5
1
x(t)
 Quantum Instanton 
Double well potential 
T=0.0 (Classical Instanton)  
T=0.2 M.C.
T=0.4 M.C. 
T=0.6 M.C.
T=0.8 M.C.
T=1.0 S.E.
T=2.0 E.S.
T=3.0 E.S.
T=4.0 E.S.
T=5.0 E.S.
T=6.0 E.S.
T=7.0 E.S.
T=8.0 E.S. 
T=9.0 E.S.
Figure 2. Instantons in double well potential.
7. Quantum chaos. The hydrogen atom in the presence of strong magnetic",N/A,N/A
"ﬁelds has been explored experimentally and theoretically [17, 19, 20]. It dis-
plays quantum chaos via disorder in the spectrum. In the regime of high lying
excited states, where the system becomes semi-classical, Gutzwiller’s trace for-
mula has been applied successfully by Wintgen [20] to extract periodic orbit
information. Here we suggest to explore quantum chaos via the phase space
generated by the quantum action. As a prototype system, we consider a 2-dim",N/A,N/A
"non-integrable Hamiltonian, with a classically chaotic counter part.
Our deﬁnition of quantum chaos is based on the concept of ’some’ phase
space related to quantum mechanics. The novel idea is to introduce this phase
space via the quantum action. Second, the quantum action depends on the
transition time T, however, for large T it converges asymptotically. More-
over, in this regime the existence of the quantum action has been established
10
H. KR ¨OGER",N/A,N/A
"10
H. KR ¨OGER
rigorously. The regime of large T makes physical sense, because the proper def-
inition of Lyapunov exponents, one of the characteristics of chaotic dynamics,
involves the large time limit.
As an example, let us consider the following Hamiltonian
S =
Z T
0
dt 1
2m( ˙x2 + ˙y2) + V (x, y)
V (x, y) = v2(x2 + y2) + v22x2y2
m = 1 , v2 = 0.5 , v22 = 0.05 .
The parameter v22 controls the deviation from integrability. At v22 = 0 the",N/A,N/A
"system is integrable. The system corresponds to two uncoupled oscillators, the
corresponding quantum action then coincides with the classical action. One
expects that tuning the parameter v22, while keeping the other parameters
ﬁxed, the system will become more chaotic when increasing v22. It is interesting
to ask: Does the quantum system also become more chaotic?
For the quantum action, we have made the following ansatz: It reﬂects the",N/A,N/A
"time-reversal symmetry, parity conservation and symmetry under exchange
x ↔y:
˜S
=
Z T
0
dt 1
2 ˜m( ˙x2 + ˙y2) + ˜V (x, y),
˜V
=
˜v0 + ˜v2(x2 + y2) + ˜v22x2y2 + ˜v4(x4 + y4) .
We also have included in the quantum action terms like ˙x ˙y, xy, xy3 + x3y,
x2y4 + x4y2, x4y4.
Numerically, those coeﬃcients were found to be small
(compared to machine precision or zero within error bars).
An example of Poincar´e sections for the classical system and the quantum",N/A,N/A
"systen are shown in Fig.[3]. The quantum Poincar´e section corresponds to
transition time T = 4.5. The energy has been chosen to be E = 10. One
can observe some diﬀerences between the classical and the quantum system.
Further numerical studies [10] have shown the following behavior: For small
v22, Poincar´e sections of classical and quantum physics are quite similar. With
increase of energy, both display mixed dynamics and become more chaotic.",N/A,N/A
"Also, with increase of energy diﬀerences between classical and quantum phasse
space become more pronounced. Islands of regular behavior diﬀer in shape and
position. Quantitatively, one observes that the value of ˜v22 (quantum action)
is smaller than the corresponding value v22 of the classsical action. Because
this parametyers measures the deviation from integrability, this hints to the
possibility that the quantum system is ”less” chaotic than the classical system.",N/A,N/A
"A more detailed analysis is called for.
8. Outlook: Further use of quantum action. In cosmology, the inﬂation-
ary scenario describes the early universe. Inﬂation involves potentials with
11
Figure 3. 2-D anharmonic oscillator. Poincar´e section of clas-
sical action vs. quantum action.
several minima and instanton solutions. The instanton starts out as a quan-
tum instanton and eventually turns into a classical instanton. This has eﬀects",N/A,N/A
"on the subsequent formation of galaxies. The quantum action allows to search
for new minima in the quantum potential, which may be absent in the classical
potential.
In condensed matter physics, superconducting quantum interference devices
(SQUID) have been used by Friedman et al. to demonstrate experimentally the
phenomenon of quantum superposition in macroscopic states. This involves
12
H. KR ¨OGER
Josephson junctions. The SQUID potential has a double-well structure. The",N/A,N/A
"quantum action allows to construct a quantum potential and analyze quantum
superposition in terms of such quantum potential.
In atomic physics, Steck et al. and Hensinger et al. have demonstrated
experimentally the phenomenon of dynamical tunneling (where the classical
transition is forbidden due to some conserved quantity diﬀerent from energy).
It has been realized by arrays of cold atoms. It has been observed that the
presence of quantum chaos enhances the dynamical tunneling transition. It",N/A,N/A
"would be interesting to reexamine dynamical tunneling using the phase space
portrait constructed from the quantum action.
In chemistry, the process of chemical binding of macromolecules often in-
volves potentials of a double well structure. The quantum action can be used
to study the formation of such macromolecules.
Acknowledgements
H.K. is grateful for support by NSERC Canada.
REFERENCES
[1] C. Macchiavello, G.M. Palma and A. Zelinger, Quantum Computation and Quantum",N/A,N/A
"information Theory, World Scietiﬁc, Singapore (2000).
[2] D. Bouwmeester, A. Ekert and A. Zeilinger, The Physics of Quantum Information,
Springer, Berlin (2000).
[3] S. Coleman, Aspects of Symmetry, Cambridge University Press, Cambridge (1985),
p.265.
[4] B.P. Anderson and M.A. Kasevich, Macroscopic quantum interference from atomic
tunnel arrays, Science 282(1998)1686.
[5] D.A. Steck, W.H. Oskay and M.G. Raizen, Observation of chaos-assisted tunneling",N/A,N/A
"between islands of stability, Science 293(2001)274.
[6] W.K. Hensinger, H. H¨aﬀner, A. Browaeys, N.R. Heckenberg, K. Helmerson, C. McKen-
zie, G.J. Wilburn, W.D. Phillips, S.L. Roiston, H. Rubinsztein-Dunlop and B. Upcroft,
Dynamical tunneling of ultracold atoms, Nature 412(2001)52.
[7] H. Jirari, H. Kr¨oger, X.Q. Luo, K.J.M. Moriarty and S.G. Rubin, Closed path integrals
and the quantum action, Phys. Rev. Lett. 86(2001)187.",N/A,N/A
"[8] H. Jirari, H. Kr¨oger, X.Q. Luo, G. Melkonyan and K.J.M. Moriarty, Renormalisation
in quantum mechanics, hep-th/0103027.
[9] H. Jirari, H. Kr¨oger, X.Q. Luo, K.J.M. Moriarty and S.G. Rubin, Quantum instantons
and quantum chaos, Phys. Lett. A281(2001)1.
[10] L.A. Caron, H. Jirari, H. Kr¨oger, X.Q. Luo, G. Melkonyan, and K.J.M. Moriarty,
Quantum chaos at ﬁnite temperature, Phys. Lett. A288(2001)145.
[11] H. Kr¨oger, Existence of the quantum action, Phys. Rev. A65(2002)052118.",N/A,N/A
"[12] A. Bl¨umel and W.P. Reinhardt, Chaos in Atomic Physics, Cambridge Univ. Press,
Cambridge (1997).
[13] M.C. Gutzwiller, Chaos in Classical and Quantum Mechanics, Springer, Berlin (1990).
[14] F. Haake, Quantum Signatures of Chaos, Springer, Berlin (2001).
[15] K. Nakamura, Quantum Chaos - A New Paradigm of Nonlinear Science, Cambridge
Univ. Press, Cambridge (1993).
[16] H.J. St¨ockmann., Quantum Chaos, Cambridge Univ. Press, Cambridge (1999).
13",N/A,N/A
"13
[17] O. Bohigas, M.J. Giannoni and C. Schmit, Characterization of chaotic quantum spectra
and universality of level ﬂuctuation laws, Phys. Rev. Lett. 52(1984)1.
[18] L.S. Schulman, Techniques and Applications of Path Integration, John Wiley&Sons,
New York (1981).
[19] H. Friedrich and D. Wintgen, The hydrogen atom in a uniform magnetic ﬁeld: An
example of chaos, Phys. Repts. 183(1989)37.
[20] D. Wintgen, Semiclassical path-integral quantization of nonintegrable Hamiltonian sys-",N/A,N/A
"tems, Phys. Rev. Lett. 61(1988)1803.
E-mail address: hkroger@phy.ulaval.ca",N/A,N/A
"Matteo Carlesso
Lecture Notes on Quantum Algorithms in Open
Quantum Systems
Department of Physics, University of Trieste
Version 1.0 – June 2024
arXiv:2406.11613v1  [quant-ph]  17 Jun 2024
Preface
These lecture notes aim to provide a clear and comprehensive introduction to using open quantum system theory
for quantum algorithms. They are based on various sources, including research papers and textbooks, which can",N/A,N/A
"be found in literature. While I have focused on clarity and consistency, there is always space for improvement.
I will work on expanding these notes and welcome your constructive feedback and comments. Feel free to send
them to matteo.carlesso@units.it.
In the Suggested Bibliography reported below, the reader can find the list of references I considered to prepare
these notes. Some of these are unpublished (please contact me directly for more info). I apologise in advance",N/A,N/A
"to all the numerous authors whose contributions I did not cite. The field is vast and the intent of these notes is
not to serve as a comprehensive review article. I have certainly not done justice to the literature.
These notes will be used as a basis for some courses that I held at the Department of Physics of the University
of Trieste. Specifically, these are
• 357SM - Quantum Algorithms in Opens Quantum Systems (Spring 2024)
• 987DF - Quantum Computing Algorithms (Autumn 2024)",N/A,N/A
"Acknowledgments
For the preparation of these lecture notes, I am in great debt with several people. Among these Angelo Bassi,
Francesco Cesa, Giulio Crognaletti, Giovanni di Bartolomeo, Sandro Donadi and Michele Vischi for inputs,
discussion and support.
I also acknowledge the financial support from the National Quantum Science and Technology Institute
through the PNRR MUR project PE0000023-NQSTI, the University of Trieste and the Italian National In-
stitute for Nuclear Physics (INFN).",N/A,N/A
"stitute for Nuclear Physics (INFN).
©Matteo Carlesso1,2, June 2024, Trieste
1Department of Physics, University of Trieste, Strada Costiera 11, 34151 Trieste, Italy
2Istituto Nazionale di Fisica Nucleare, Trieste Section, Via Valerio 2, 34127 Trieste, Italy
i
Suggested Bibliography
Open Quantum Systems
Although not explicitly discussed in these notes, a part of the above mentioned courses regards the theory of",N/A,N/A
"open quantum systems. For this part of the courses, I suggest the following literature.
• Angelo Bassi. Lecture Notes on Advanced Quantum Mechanics. Unpublished.
• Heinz-Peter Breuer, Francesco Petruccione. The theory of open quantum systems. Oxford, 2022.
• Mahn-Soo Choi. A Quantum Computation Workbook. Springer, 2022.
• Roberto Floreanini. Lecture Notes on Quantum Information. Unpublished.
• Daniel A. Lidar. Lecture Notes on Theory of Open Quantum Systems. arXiv preprint arXiv:1902.00967.",N/A,N/A
"• Ahsan Nazir. Lecture notes on open quantum systems. https://www.yumpu.com/en/document/view/8219582/
lecture-notes-on-open-quantum-systems-workspace.
• Stefano Olivares. Lecture Notes on Quantum Computing. University of Milano, 2020.
Quantum Computation
• Giuliano Benenti, Giulio Casati, Davide Rossini, and Giuliano Strini. Principles of quantum computation
and information: a comprehensive textbook. World Scientific, 2019.
• Mahn-Soo Choi. A Quantum Computation Workbook. Springer, 2022.",N/A,N/A
"• Christoph Dittel. Lecture Notes on Quantum information theory. arXiv preprint arXiv:2311.12442.
• Ronald de Wolf. Lecture Notes on Quantum Computing. arXiv preprint arXiv:1907.09415.
• Aram W Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations.
Physical Review Letters 103, 150502, (2009).
• Anton Frisk Kockum, Ariadna Soro, Laura Garc´ıa-´Alvarez, Pontus Vikst˚al, Tom Douce, G¨oran Johansson,",N/A,N/A
"and Giulia Ferrini. Lecture Notes on Quantum Computing. arXiv preprint arXiv:2311.08445.
• Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv preprint arXiv:2201.08309.
• M. A. Nielsen and I. L. Chuang Quantum Computation and Quantum Information. Cambridge University
Press 2010.
• Stefano Olivares. Lecture Notes on Quantum Computing. University of Milano, 2020.",N/A,N/A
"• Oswaldo Zapata. A Short Introduction to Quantum Computing for Physicists. arXiv preprint arXiv:2306.09388.
ii
iii
Quantum Error Correction
• Giuliano Benenti, Giulio Casati, Davide Rossini, and Giuliano Strini. Principles of quantum computation
and information: a comprehensive textbook. World Scientific, 2019.
• Mahn-Soo Choi. A Quantum Computation Workbook. Springer, 2022.
• Andrew N. Cleland. An introduction to the surface code. SciPost Phys. Lect. Notes 49 (2022).",N/A,N/A
"• Ronald de Wolf. Lecture Notes on Quantum Computing. arXiv preprint arXiv:1907.09415.
• Sandro Donadi. Lecture Notes on Quantum Algorithms in Open Quantum Systems. Unpublished.
• Ekert, A and Hosgood, T and Kay, A and Macchiavello, C. Introduction to Quantum Information Science.
https://qubit.guide.
• Austin G. Fowler, Matteo Mariantoni, John M. Martinis, and Andrew N. Cleland. Surface codes: Towards
practical large-scale quantum computation. Phys. Rev. A, 86:032324, 2012.",N/A,N/A
"• Steven M. Girvin. Introduction to quantum error correction and fault tolerance. SciPost Phys. Lect. Notes
70 (2023).
• Stefano Olivares. Lecture Notes on Quantum Computing. University of Milano, 2020.
• Andrew M. Steane. A Tutorial on Quantum Error Correction. IOS Press 2006.
• Oswaldo Zapata. A Short Introduction to Quantum Computing for Physicists. arXiv preprint arXiv:2306.09388.
Dynamical Decoupling and Quantum Error Mitigation",N/A,N/A
"Dynamical Decoupling and Quantum Error Mitigation
• Zhenyu Cai, Ryan Babbush, Simon C. Benjamin, Suguru Endo, William J. Huggins, Ying Li, Jarrod R.
McClean, and Thomas E. O’Brien. Quantum error mitigation. Review Modern Physics 95,045005 (2023).
• Sandro Donadi. Lecture Notes on Quantum Algorithms in Open Quantum Systems. Unpublished.
• Tudor Giurgica-Tiron, Yousef Hindy, Ryan LaRose, Andrea Mari, and William J. Zeng. Digital zero noise",N/A,N/A
"extrapolation for quantum error mitigation. In 2020 IEEE International Conference on Quantum Computing
and Engineering (QCE). IEEE, 2020.
Contents
1
Circuit model for quantum computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Qubit gates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1.1",N/A,N/A
"1
1.1.1
Hadamard test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2
No-cloning theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.3
Dense coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.4",N/A,N/A
"5
1.4
Quantum teleportation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.5
Quantum Phase estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.5.1
Single-qubit quantum phase estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.5.2",N/A,N/A
"8
1.5.2
Kitaev’s method for single-qubit quantum phase estimation . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.5.3
n-qubit quantum phase estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.6
Harrow-Hassidim-Lloyd algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2",N/A,N/A
"11
2
Variational Quantum Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.1
The Ising model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.2
Mapping combinatorial optimisation problems into the Ising model . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.3",N/A,N/A
"16
2.3
Adiabatic Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.4
Quantum Annealing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.5
Quantum Approximate Optimisation Algorithm (QAOA) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.6",N/A,N/A
"20
2.6
Variational Quantum Eigensolver (VQE) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
3
Noisy Intermediate-Scale Quantum (NISQ) computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
3.1
Miscalibrated gates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.2",N/A,N/A
"25
3.2
Projection noise and sampling error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
3.3
Measurement error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
3.3.1
Environmental noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3.3.2",N/A,N/A
"30
3.3.2
Global noise action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
4
Quantum Error Correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
4.1
Quantum Error Correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
4.1.1",N/A,N/A
"33
4.1.1
Classical error correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
4.1.2
Quantum information context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
4.1.3
The 3-qubit bit-flip code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
4.1.4",N/A,N/A
"35
4.1.4
The 3-qubit phase-flip code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.1.5
The 9-qubit Shor code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
4.1.6
On the redundancy and threshold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
4.1.7",N/A,N/A
"41
4.1.7
More layers of encoding or only more qubits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
4.2
Stabiliser formalism. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
4.2.1
Inverting quantum channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
iv
Contents
v
4.2.2",N/A,N/A
"48
iv
Contents
v
4.2.2
Correctable errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
4.2.3
Stabilisers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.2.4
Normalisers and Centralisers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
4.2.5",N/A,N/A
"55
4.2.5
Stabiliser code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.3
Surface code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.3.1
Detecting errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
4.4",N/A,N/A
"60
4.4
Fault-tolerant computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
4.4.1
Stean code or 7-qubit code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
5
Dynamical Decoupling and Quantum Error Mitigation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
5.1",N/A,N/A
"70
5.1
Dynamical Decoupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
5.2
Quantum Error Mitigation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
5.2.1
Zero noise extrapolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
5.2.2",N/A,N/A
"80
5.2.2
Probabilistic error cancellation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
A
Solutions of the exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
A.1 Solution to Exercise 1.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88",N/A,N/A
"88
A.2 Solution to Exercise 1.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
A.3 Solution to Exercise 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
A.4 Solution to Exercise 1.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
Chapter 1",N/A,N/A
"90
Chapter 1
Circuit model for quantum computation
In quantum computation, the basic ingredients are qubits and gates. The composition of different gates acting
on a series of qubits is what we called an algorithm. Here we introduce quantum gates and some algorithms.
1.1 Qubit gates
The single qubit algebra can be described in terms of the identity ˆ1 and Pauli ˆσx, ˆσy and ˆσz operators. All",N/A,N/A
"single qubit gates are a linear composition of these. In particular, they can be visualised as rotations of the state
|ψ⟩on the Bloch sphere. The three elementary rotations by an angle θ around the Cartesian axes are defined
as ˆRj(θ) = e−iθˆσj/2 for j = x, y, z. In particular, in the computational basis, which is the one mainly used in
quantum computation, one has
Rx(θ) =

cos(θ/2)
−i sin(θ/2)
−i sin(θ/2)
cos(θ/2)

,
Ry(θ) =
cos(θ/2) −sin(θ/2)
sin(θ/2) cos(θ/2)

,
Rz(θ) =
exp(−iθ/2)
0
0",N/A,N/A
"sin(θ/2) cos(θ/2)

,
Rz(θ) =
exp(−iθ/2)
0
0
exp(iθ/2)

.
(1.1)
Then, the rotation of an angle θ around the unit axis n is given by
ˆRn(θ) = e−iθn·ˆσ/2 = cos(θ/2)ˆ1 −i sin (θ/2)n · ˆσ.
(1.2)
Beside the rotations, there are six important single-qubit gates that are standard. These are X, Y , Z and
H =
1
√
2
1 1
1 −1

,
S =
1 0
0 i

,
T =
1
0
0 eiπ/4

.
(1.3)
In particular, X, Y and Z are respectively the Pauli operators ˆσx, ˆσy and ˆσz represented in the computational",N/A,N/A
"basis, and H is known as the Hadamard gate.
Eventually, the state of the qubit is measured. In particular, this is always the measurement of ˆσz and one
always obtains one of the two discrete outcomes: “0” or “1”. Given the generic state |ψ⟩= α |0⟩+ β |1⟩, with
α and β being complex and |α|2 + |β|2 = 1, then one has a probability p0 = |α|2 to have the outcome “0” and
p1 = |β|2 to have the outcome “1”.
1
2
1 Circuit model for quantum computation
Example 1.1
The gate X flips states. Indeed,
X

α",N/A,N/A
"The gate X flips states. Indeed,
X

α
β

=
0 1
1 0
 α
β

=
β
α

.
(1.4)
Example 1.2
The Hadamard gate H generates uniform superpositions. In particular, one has
H
1
0

=
1
√
2
1 1
1 −1
 1
0

=
1
√
2
1
1

,
H
0
1

=
1
√
2
1 1
1 −1
 0
1

=
1
√
2
 1
−1

.
(1.5)
Namely, one has
ˆH |0⟩= |+⟩,
and
ˆH |0⟩= |−⟩,
(1.6)
where |±⟩= (|0⟩± |1⟩)/
√
2. Notably, the Hadamard gate maps the basis of ˆσz in that of ˆσx, and back.
Exercise 1.1
Express the Hadamard gate as a rotation.",N/A,N/A
"Express the Hadamard gate as a rotation.
Exercise 1.2
Prove that, given two fixed non-parallel normalised vectors n and m, any unitary single qubit gate ˆU can
be expressed as
ˆU = eiα ˆRn(β) ˆRm(γ) ˆRn(δ),
(1.7)
with α, β, γ, δ ∈R.
It is common to represent quantum circuits with diagrams with the time running from left to right, where
lines correspond to qubits and boxes to gates. For example, the following diagram
|0⟩
H
RZ(θ)
(1.8)
corresponds to the following logical consecutive operations",N/A,N/A
"0) Prepare the qubit in the ground state |0⟩.
1) Apply the Hadamard gate H.
2) Apply a rotation of an angle θ around the z axis.
3) Measure the state of the qubit.
When one is working with more than one qubit, there is the need to construct the representation of the states
the common computational basis. In the case of two qubits, the basis is given by { | 00⟩, | 01⟩, | 10⟩, | 11⟩},
whose representation in the common computational basis is
|00⟩∼




1
0
0
0



,
|01⟩∼




0
1
0
0
",N/A,N/A
"



1
0
0
0



,
|01⟩∼




0
1
0
0



,
|10⟩∼




0
0
1
0



,
|11⟩∼




0
0
0
1



,
(1.9)
where the symbol ∼indicates that the state |ψ⟩was represented on the computational basis. This is constructed
through the tensor product, i.e.
1.1 Qubit gates
3
|ψϕ⟩∼
ψ1
ψ2

⊗
ϕ1
ϕ2

=




ψ1ϕ1
ψ1ϕ2
ψ2ϕ1
ψ2ϕ2



.
(1.10)
Owning the computational representation, we can introduce some 2-qubit gates. One of the most useful",N/A,N/A
"among these gates is the CNOT or control-NOT gate:
CNOT =




1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0



,
(1.11)
and is represented as
or equivalentely as
X
(1.12)
It acts on a target qubit (qubit 1) in a way that depends on the state of a control qubit (qubit 0). Namely, it
applies an X gate to the qubit 1 if the state of qubit 0 is 1, otherwise it does not change the state:
CNOT |00⟩= |00⟩,
CNOT |01⟩= |01⟩,
CNOT |10⟩= |11⟩,
CNOT |11⟩= |10⟩.
(1.13)
Exercise 1.3",N/A,N/A
"CNOT |11⟩= |10⟩.
(1.13)
Exercise 1.3
Prove that CNOT can generate entanglement.
A second important 2-qubit gate is the SWAP, which swaps the state between two qubits. Namely
SWAP |a⟩⊗|b⟩= |b⟩⊗|a⟩.
(1.14)
A SWAP operation can be constructed using a concatenation of CNOT gates. In particular:
SWAP ∼
=
=
(1.15)
Similarly as the CNOT, one can construct a controlled unitary gate, where the state of the control qubit
determines if a unitary gate ˆU is applied to the target qubit:
C(U) ∼




1 0
0",N/A,N/A
"C(U) ∼




1 0
0
0
0 1
0
0
0 0 U00 U01
0 0 U10 U11



∼
U
(1.16)
where Uij are the matrix elements of ˆU.
4
1 Circuit model for quantum computation
1.1.1 Hadamard test
The Hadamard test is a useful tool for computing expectation values of a unitary, black-box operator ˆU with
respect to a state |ψ⟩, which can be in principle a multi-qubit state. Since in general ˆU is not Hermitian, one
measures independently the real and immaginary part of ⟨ψ| ˆU|ψ⟩.",N/A,N/A
"The circuit for the real Hadamard test is
|0⟩
|ψ⟩
H
H
U
(1.17)
and it performs as follows. The first step is to generate a superposition in the first qubit (qubit 0):
|0⟩|ψ⟩
ˆ
H⊗ˆ1
−−−→
1
√
2(|0⟩+ |1⟩) |ψ⟩.
(1.18)
Then, we entangle the qubits with the C(U) gate:
1
√
2(|0⟩+ |1⟩) |ψ⟩
C(U)
−−−→
1
√
2(|0⟩|ψ⟩+ |1⟩ˆU |ψ⟩),
(1.19)
and apply the Hadamard gate to qubit 0:
ˆ
H⊗ˆ1
−−−→1
2
h
(|0⟩+ |1⟩) |ψ⟩+ (|0⟩−|1⟩) ˆU |ψ⟩
i
= 1
2
h
|0⟩(ˆ1 + ˆU) |ψ⟩+ |1⟩(ˆ1 −ˆU) |ψ⟩
i
.
(1.20)",N/A,N/A
"2
h
|0⟩(ˆ1 + ˆU) |ψ⟩+ |1⟩(ˆ1 −ˆU) |ψ⟩
i
.
(1.20)
Finally, one measures qubit 0, and the probability of finding the qubit in |0⟩is
P(|0⟩) = 1
4 ⟨ψ|

ˆ1 + ˆU † 
ˆ1 + ˆU

|ψ⟩= 1
2

1 + ℜ⟨ψ| ˆU|ψ⟩

.
(1.21)
Thus, by measuring only one qubit (qubit 0) one has an indication of the real part of ⟨ψ| ˆU|ψ⟩. To estimate the
imaginary part, the circuit is modified as follows:
|0⟩
|ψ⟩
H
S†
H
U
(1.22)
Then, the state before the measurement is
1
2
h
|0⟩(ˆ1 −i ˆU) |ψ⟩+ |1⟩(ˆ1 + i ˆU) |ψ⟩
i
,
(1.23)",N/A,N/A
"|0⟩(ˆ1 −i ˆU) |ψ⟩+ |1⟩(ˆ1 + i ˆU) |ψ⟩
i
,
(1.23)
and correspondingly one has
˜P(|0⟩) = 1
2

1 + ℑ⟨ψ| ˆU|ψ⟩

.
(1.24)
Notably, to well characterise these probabilities, there is the need to run the protocol several times to construct
a statistics.
Exercise 1.4
Prove that the circuit in Eq. (1.22) provides the result in Eq. (1.24).
1.3 Dense coding
5
1.2 No-cloning theorem
For different computational reasons, one would like to create an independent and identical copy of an arbitrary",N/A,N/A
"state with a unitary operation. Nevertheless, the following theorem prevents it.
Theorem 1.1 (No-cloning).
Consider two quantum systems A and B with corresponding Hilbert spaces of the same dimensions HA and
HB. Then, it is not possible to construct a unitary operation ˆU acting on HA ⊗HB that copies an arbitrary state
of A over an initial, reference state of B. Namely, ∄ˆU such that
ˆU |ψ⟩|e⟩= |ψ⟩|ψ⟩,
(1.25)
where |ψ⟩is an arbitrary state and |e⟩is a reference state.",N/A,N/A
"Proof. A simple proof goes as follows. Suppose there exists ˆU such that described in Eq. (1.25). Then, one
considers the scalar product between the state |ψ, e⟩= |ψ⟩|e⟩and |ϕ, e⟩= |ϕ⟩|e⟩, where |ϕ⟩is a second arbitrary
state. This gives
⟨ϕ, e|ψ, e⟩= ⟨ϕ|ψ⟩⟨e|e⟩.
(1.26)
Exploiting the unitarity of ˆU we have
⟨ϕ, e|ψ, e⟩= ⟨ϕ, e| ˆU † ˆU|ψ, e⟩
(1.27)
Now, we apply Eq. (1.25) to both these states:
⟨ϕ, e| ˆU † ˆU|ψ, e⟩= ⟨ϕ, ϕ|ψ, ψ⟩= ⟨ϕ|ψ⟩2 .
(1.28)",N/A,N/A
"(1.28)
By putting together the last three expressions we find
⟨ϕ|ψ⟩⟨e|e⟩= ⟨ϕ|ψ⟩2 ,
(1.29)
which holds true only if ⟨ϕ|ψ⟩= 0 or |ϕ⟩= eiα(ϕ,ψ) |ψ⟩with α(ϕ, ψ) being a phase possibly depending on the two
input states. In both cases, one does not allow for full arbitrariness, thus proving the no-cloning theorem.
Importantly for the quantum computation field, the no-cloning theorem prevents the employment of classical",N/A,N/A
"error correction techniques on quantum states. One needs to employ quantum error corrections, which will be
subject of Chapter 4, that effectively circumvent the no-cloning theorem.
1.3 Dense coding
An interesting quantum algorithm is that of dense coding. Suppose Alice has two classical bits x and y that
wants to communicate (securely) to Bob, and can do it only via a single qubit. The following protocol allows
for it. It assumes to have two qubits on which six operations are performed:
|0⟩",N/A,N/A
"|0⟩
|0⟩
H
U
H
share
send
(1.30)
The first operation is to prepare an initial entangled state
6
1 Circuit model for quantum computation
|0⟩|0⟩
ˆ
H⊗ˆ1
−−−→
1
√
2(|0⟩+ |1⟩) |0⟩
CNOT
−−−−→
1
√
2(|0⟩|0⟩+ |1⟩|1⟩) = |ψ+⟩.
(1.31)
The second operation is to share the state among Alice (qubit 0) and Bob (qubit 1). Then, the third operation
is the encoding: Alice encodes the state of (x, y) in the operation performed with the gate ˆU:
x, y
ˆU
0, 0 ˆ1 ⊗ˆ1
0, 1 ˆσx ⊗ˆ1
1, 0 ˆσz ⊗ˆ1
1, 1 iˆσy ⊗ˆ1",N/A,N/A
"0, 1 ˆσx ⊗ˆ1
1, 0 ˆσz ⊗ˆ1
1, 1 iˆσy ⊗ˆ1
This leads to
|ψ+⟩
ˆU⊗ˆ1
−−−→











1
√
2(|0⟩|0⟩+ |1⟩|1⟩) = |ψ+⟩,
if (x, y) = (0, 0),
1
√
2(|1⟩|0⟩+ |0⟩|1⟩) = |ϕ+⟩,
if (x, y) = (0, 1),
1
√
2(|0⟩|0⟩−|1⟩|1⟩) = |ψ−⟩,
if (x, y) = (1, 0),
1
√
2(|0⟩|1⟩−|1⟩|0⟩) = |ϕ−⟩,
if (x, y) = (1, 1),
(1.32)
where |ψ±⟩and |ϕ±⟩are the four Bell states (fully entangled state, being a basis of the common Hilbert space).",N/A,N/A
"The fourth operation consists in Alice sending the qubit 0 to Bob. Any operation performed on the two qubits
by Bob is now fully local. The fifth operation is the decoding. Bob applies the last two operations (CNOT and
ˆH ⊗ˆ1) which together form the inverse operation of the encoding:
|ψ+⟩→|0⟩|0⟩,
|ϕ+⟩→|0⟩|1⟩,
|ψ−⟩→|1⟩|0⟩,
|ϕ−⟩→|1⟩|1⟩.
(1.33)
The last operation is to Bob to measure the state of both qubits, which will identify which bits Alice encoded
in her qubit.
1.4 Quantum teleportation",N/A,N/A
"in her qubit.
1.4 Quantum teleportation
An application of the dense coding protocol is the quantum teleportation, that allows for sending a generic state
|ψ⟩= α |0⟩+ β |1⟩from Alice to Bob without knowing a priory the state. The protocol is based on the use of
three qubits and six operations:
|ψ⟩
|0⟩
|1⟩
|ψ⟩
H
H
U
share
classical communication
(1.34)
The first operation is to prepare an entangled state between qubit 1 and 2 (similarly as in the dense coding
protocol):
|ψ01⟩
ˆ1⊗ˆ
H⊗ˆ1
−−−−−→|ψ⟩",N/A,N/A
"protocol):
|ψ01⟩
ˆ1⊗ˆ
H⊗ˆ1
−−−−−→|ψ⟩
1
√
2(|0⟩+ |1⟩) |1⟩
ˆ1⊗CNOT
−−−−−−→|ψ⟩
1
√
2(|01⟩+ |10⟩) = |ψ⟩|ϕ+⟩.
(1.35)
1.5 Quantum Phase estimation
7
Then, the second operation is to shared the qubits among Alice (qubit 0 and 1) and Bob (qubit 2). The third
operation consists in applying a decoding operation (see dense coding) to the first two qubits. Namely, the
decoding operation acts as in Eq. (1.33). Thus, owning that |ψ⟩= α |0⟩+ β |1⟩, one obtains
|ψ⟩|ϕ+⟩
CNOT ⊗ˆ1
−−−−−−→
1
√",N/A,N/A
"|ψ⟩|ϕ+⟩
CNOT ⊗ˆ1
−−−−−−→
1
√
2 [α |0⟩(|01⟩+ |10⟩) + β |1⟩(|11⟩+ |00⟩)]
ˆ
H⊗ˆ1⊗ˆ1
−−−−−→1
2 [|00⟩(α |1⟩+ β |0⟩) + |01⟩(α |0⟩+ β |1⟩) + |10⟩(α |1⟩−β |0⟩) + |11⟩(α |0⟩−β |1⟩)] .
(1.36)
The fourth operation consists in Alice measuring her qubits. There are 4 possible couples, and thus four possible
collapses (according to the measurement postulate of quantum mechanics). These are |00⟩, |01⟩, |10⟩and |11⟩",N/A,N/A
"with probability 1/4 each. The fundamental point of the protocol is that the collapse of the state of the first 2
qubit implies that of the last qubit, being in Bob’s hands. In particular, if Alice measures the couple (0, 0), then
qubit 2 collapses in α |1⟩+ β |0⟩; and similarly for the other three measurement outcomes. The fifth operation
is the classical communication of the outcomes of the measurement to Bob. Consequently, the sixth operation",N/A,N/A
"is a unitary operation ˆU on qubit 2 that depends on the outcomes (q0 and q1) of the measurement:
q0 q1
|q2⟩
ˆU
0 0 α |1⟩+ β |0⟩ˆσx
0 1 α |0⟩+ β |1⟩ˆ1
1 0 α |1⟩−β |0⟩iˆσy
1 1 α |0⟩−β |1⟩ˆσz
(1.37)
where |q2⟩is the state on which qubit 2 has collapsed after the measurement. By applying the unitary we obtain
α |1⟩+ β |0⟩
ˆσx
−−→|ψ⟩,
α |0⟩+ β |1⟩
ˆ1
−−→|ψ⟩,
α |1⟩−β |0⟩
iˆσy
−−→|ψ⟩,
α |0⟩−β |1⟩
ˆσz
−−→|ψ⟩.
(1.38)",N/A,N/A
"iˆσy
−−→|ψ⟩,
α |0⟩−β |1⟩
ˆσz
−−→|ψ⟩.
(1.38)
In such a way, Bob retrieves the state |ψ⟩without that neither Bob or Alice had measure it.
We notice that there is a strong difference with the case studied in the no cloning theorem. Here, one needs to
measure two qubits to perform the protocol: this a fundamentally different procedure with respect to a unitary
operation.
1.5 Quantum Phase estimation",N/A,N/A
"operation.
1.5 Quantum Phase estimation
The framework of quantum phase estimation (QPE) is the following. Consider a unitary operation ˆU where the
state |ψ⟩is one of its eigenstates. In particular, one has
ˆU |ψ⟩= e2πiφ |ψ⟩.
(1.39)
Then, the task is to determine the phase φ with a certain given precision.
8
1 Circuit model for quantum computation
1.5.1 Single-qubit quantum phase estimation",N/A,N/A
"1.5.1 Single-qubit quantum phase estimation
The Hadamard test described in Sec. 1.1.1 can be used to implement a single qubit phase estimation. Indeed,
from Eq. (1.39) one gets that
⟨ψ| ˆU|ψ⟩= e2πiφ.
(1.40)
Then, by merging with Eq. (1.21) one has
P(|0⟩) = 1
2(1 + cos(2πφ)),
(1.41)
which implies
φ = ±arccos (1 −2P(|0⟩))
2π
+ 2πk,
(1.42)
where k ∈N. Notice that such a circuit cannot distinguish the sign of φ. Conversely, using both Eq. (1.21) and
Eq. (1.24), one has
φ = arctan
1 −2P(|0⟩)",N/A,N/A
"Eq. (1.24), one has
φ = arctan
1 −2P(|0⟩)
1 −2 ˜P(|0⟩)

.
(1.43)
Now, for the sake of simplicity, let us restrict to the case of φ ∈[0, 1[. Suppose we would like to estimate
the value of φ with a single run of the circuit in Eq. (1.17). Then, if the outcome is +1 (i.e., the state collapses
on |0⟩), we have P(|0⟩) = 1. Conversely, with the outcome being −1 we have P(|0⟩) = 0. Then, by employing
Eq. (1.42) we obtain
outcome P(|0⟩)
¯φ
φv
+1
1
0
[0, 1/2[
−1
0
1/2 [1/2, 1[
(1.44)",N/A,N/A
"¯φ
φv
+1
1
0
[0, 1/2[
−1
0
1/2 [1/2, 1[
(1.44)
where ¯φ gives the best estimation for the real value of the phase φv. Since there are no other possible outcomes
with a single run, the phase is estimated with an error ϵ = 1/2, namely φv ∈[ ¯φ, ¯φ + ϵ[. This is a really low
accuracy for a deterministic algorithm. To improve this accuracy, one should run the algorithm several times
(namely, a number of times that scales as O(1/ϵ2), where ϵ is the target error bound), or consider alternative",N/A,N/A
"methods, as the N-qubit quantum phase estimation described below.
1.5.2 Kitaev’s method for single-qubit quantum phase estimation
In the fixed point representation, a natural number k can be represented with a real number φ ∈[0, 1[ by
employing d bits, i.e.
φ = (.φd−1 . . . φ0),
(1.45)
where φk ∈{0, 1}, as far as k ≤2d −1.
Example 1.3
To make an explicit example of the fixed point representation, the value of k = 41 corresponds to the d = 6",N/A,N/A
"bit’s string [101001] and can be represented with φ = 0.640625 being equivalent to (.101001). Indeed, by
employing the following expression with the string φ = (.φd−1 . . . φ0) = (.101001) one has
d−1
X
i=0
φi2i−d = φ52−1 + φ42−2 + φ32−3 + φ22−4 + φ12−5 + φ02−6 = 2−1 + 2−3 + 2−6 = 0.640625.
(1.46)
Such a value, when multiplied by 26 gives exactly 41.
In the simplest scenario of d = 1, one has φ = (.φ0) with φ0 ∈{0, 1}. Thus, when performing once the real",N/A,N/A
"Hadamard test, one has P(|0⟩) = 1 if φ0 = 0 (i.e., ¯φ = 0), and P(|0⟩) = 0 if φ0 = 1 (i.e., ¯φ = 1/2).
1.5 Quantum Phase estimation
9
Next, we consider the case of d bits, where φ = (.0 . . . 0φ0). Here, the first d bits are 0 and the last one is φ0.
To determined the value of φ0 one needs to reach a precision of ϵ < 2−d. This would require O(1/ϵ2) = O(22d)
repeated applications of the single-qubit quantum phase estimation, or number of queries to ˆU. The observation",N/A,N/A
"from Kitaev’s method is that if we can have access to ˆU j for a suitable power j, then the number of queries to
ˆU can be reduced. If one substitutes ˆU j to ˆU, with the corresponding circuit being
|0⟩
|ψ⟩
H
H
U j
(1.47)
then the probability changes in
P(|0⟩) = 1
2(1 + cos(2πjφ)).
(1.48)
Importantly, every time one multiplies a number by a factor 2, the bits in the fixed point representation are
shifted to the left. To make an example,
2 × (.00φ0) = (.0φ0).
(1.49)",N/A,N/A
"2 × (.00φ0) = (.0φ0).
(1.49)
Then, one has that 2d−1φ = 2d−1(.0 . . . 0φ0) = (.φ0). Thus, applying the circuit in Eq. (1.47) with j = d −1 to
estimate (.0 . . . 0φ0) is equivalent to apply the circuit in Eq. (1.17) to estimate (.φ0).
This idea can be extended to general phases with d bits, i.e. φ = (.φd−1 . . . φ0). Indeed, one has
ˆUe2πiφ |ψ⟩= ˆUe2πi(.φd−1...φ0) |ψ⟩= e2πi(φd−1.φd−2...φ0) |ψ⟩= e2πiφd−1e2πi(.φd−2...φ0) |ψ⟩,
(1.50)
but e2πiφd−1 = 1 independently from the value of φd−1. Thus",N/A,N/A
"ˆUe2πiφ |ψ⟩= e2πi(.φd−2...φ0) |ψ⟩,
(1.51)
i.e. the application of ˆU shifts the bits and allows the evaluation of the first bit after the decimal point.
1.5.3 n-qubit quantum phase estimation
Notably, both the previous algorithms necessitate an important classical post-processing. Employing n ancillary
qubits allow the reduction of such post-processing. This is based on the application of the Inverse Quantum
Fourier Transform ˆF †.
Recall 1.1 (Quantum Fourier transform)",N/A,N/A
"Recall 1.1 (Quantum Fourier transform)
The discrete Fourier transform of a N-component vector with complex components { f(0), . . . , f(N −1) }
is a new complex vector { ˜f(0), . . . , ˜f(N −1) }, defined as
F(f(j), k) = ˜f(k) =
1
√
N
N−1
X
j=0
e2πijk/Nf(j).
(1.52)
The Quantum Fourier transform (QFT) acts similarly: it acts as the unitary operator ˆF on a quantum
register of n qubits, where N = 2n, in the computational basis as
ˆF |j⟩=
1
√
2n
2n−1
X
k=0
e2πijk/2n |k⟩,
(1.53)
10",N/A,N/A
"1
√
2n
2n−1
X
k=0
e2πijk/2n |k⟩,
(1.53)
10
1 Circuit model for quantum computation
where |j⟩= |jn−1 . . . j0⟩and |k⟩= |kn−1 . . . k0⟩. Namely, the application of the quantum Fourier transform
ˆF to the state |j⟩= |jn−1 . . . j0⟩gives
ˆF |j⟩=
1
√
2n

|0⟩+ e2πi(0.j0) |1⟩
 
|0⟩+ e2πi(0.j1j0) |1⟩

. . .

|0⟩+ e2πi(0.jn−1...j0) |1⟩

.
(1.54)
In the case of a superposition |ψ⟩= P
j f(j) |j⟩, one has
| ˜ψ⟩= ˆF |ψ⟩=
2n−1
X
k=0
˜f(k) |k⟩,
(1.55)",N/A,N/A
"| ˜ψ⟩= ˆF |ψ⟩=
2n−1
X
k=0
˜f(k) |k⟩,
(1.55)
where the coefficients ˜f(k) are the discrete Fourier transform of the coeficients f(j).
The inverse quantum Fourier transform ˆF † acts as
ˆF † |j⟩=
1
√
2n
2n−1
X
j=0
e−2πijk/2n |k⟩,
(1.56)
in a completely similar way as Eq. (1.53) but with negative phases.
Example 1.4
The application of the quantum Fourier transform ˆF to the state |j⟩= |10⟩= |j1 = 1, j0 = 0⟩gives
ˆF |j⟩= 1
2

|0⟩+ e2πi(0.j0) |1⟩
 
|0⟩+ e2πi(0.j1j0) |1⟩

,
=
1
√
2(|0⟩+ |1⟩) 1
√",N/A,N/A
"|0⟩+ e2πi(0.j1j0) |1⟩

,
=
1
√
2(|0⟩+ |1⟩) 1
√
2(|0⟩−|1⟩).
(1.57)
The algorithm implementing the (standard) quantum phase estimation uses a first register of n ancillary
qubits and a second register of which we want to compute the phase. The first register is initially prepared in
the |0⟩state for all the qubits. The circuit implementing the algorithm is the following
|0⟩
. . .
...
|0⟩
. . .
|0⟩
. . .
|0⟩
. . .
|ψ⟩
. . .
|ψ⟩
First register,
n qubits
H
F †
H
H
H
Second register,
t qubits
U 20",N/A,N/A
"H
F †
H
H
H
Second register,
t qubits
U 20
U 21
U 22
U 2n−1
end first step
(1.58)
In particular, the state of the first register after the end of the first part of the algorithm (see red dashed line)
reads
1
√
2n

|0⟩+ e2πi(2n−1φ) |1⟩

. . .

|0⟩+ e2πi(20φ) |1⟩

.
(1.59)
Now, by considering the binary representation of φ = (φn−1 . . . φ0), the latter expression becomes
1.6 Harrow-Hassidim-Lloyd algorithm
11
1
√
2n

|0⟩+ e2πi(0.φ0) |1⟩
 
|0⟩+ e2πi(0.φ1φ0) |1⟩

. . .
",N/A,N/A
" 
|0⟩+ e2πi(0.φ1φ0) |1⟩

. . .

|0⟩+ e2πi(0.φn−1...φ0) |1⟩

,
(1.60)
which is exactly equal to ˆF |j⟩in Eq. (1.54) for |j⟩= |φ⟩. Thus, applying the inverse Fourier transform ˆF † one
gets |φ⟩, which is then measured.
1.6 Harrow-Hassidim-Lloyd algorithm
The Harrow-Hassidim-Lloyd (HHL) algorithm allows for the resolution of linear system problems on a quantum
computer. To be precise, the problem to be solved is described as finding the Nb complex entries of x that solve
the following problem",N/A,N/A
"the following problem
Ax = b,
(1.61)
where A is an hermitian and non-singular Nb × Nb matrix and b is a Nb vector, both defined on C. Classically,
the solution is given by
x = A−1b.
(1.62)
The question is then how one can implement this on a quantum computer.
First, let us assume that the entries of b are such that ||b|| = 1. Then, b can be stored in a nb-qubit state
|b⟩, through the following mapping:
b =



b0
...
bNb−1


↔b0 |0⟩+ · · · + bNb−1 |Nb −1⟩= |b⟩,
(1.63)",N/A,N/A
"

↔b0 |0⟩+ · · · + bNb−1 |Nb −1⟩= |b⟩,
(1.63)
where Nb = 2nb. For example, this can be done via a unitary operation ˆUb. Now, we define |x⟩= ˆA−1 |b⟩,
where ˆA in the computational representation gives the classical matrix A. Notably, the state |x⟩needs to be
normalised to be stored in a quantum register. Thus, one has
|x⟩=
ˆA−1 |b⟩
|| ˆA−1 |b⟩||
,
(1.64)
where the normalisation problem can be tackled in a second moment.
Consider the spectral decomposition of ˆA:
ˆA |vj⟩= λj |vj⟩,
(1.65)",N/A,N/A
"ˆA |vj⟩= λj |vj⟩,
(1.65)
where λj and |vj⟩are respectively the eigeinvalues and eigeinstates of ˆA. We also assume that the ordering of
the eigeinvalues is such that
0 < λ0 ≤· · · ≤λNb−1 < 1.
(1.66)
In general this will not be the case, but one can remap the problem in order to fall within this case. We also
assume that all the Nb eigeinvalues have an exact d-bit representation.
By applying what in Sec. 1.5, we can query ˆA via an unitary operation ˆU = e2πi ˆ
A using QPE. For example,",N/A,N/A
"A using QPE. For example,
suppose |b⟩= |vj⟩, then we have
ˆUQPE |0⟩⊗d |vj⟩= |λj⟩|vj⟩.
(1.67)
In particular, the (not-normalised) solution of the linear system problem would be
ˆA−1 |b⟩= ˆA−1 |vj⟩=
1
λj |vj⟩.
(1.68)
More generally, one can decompose the state |b⟩on the basis of ˆA, i.e.
12
1 Circuit model for quantum computation
|b⟩=
2nb−1
X
j=0
βj |vj⟩,
(1.69)
where βj are a linear combination of bj. Then the QPE procedure gives
ˆUQPE |0⟩⊗d |b⟩=
X
j
βj |λj⟩|vj⟩,
(1.70)",N/A,N/A
"ˆUQPE |0⟩⊗d |b⟩=
X
j
βj |λj⟩|vj⟩,
(1.70)
and the solution of the problem is given by
ˆA−1 |b⟩=
2nb−1
X
j=0
βj
λj
|vj⟩.
(1.71)
The aim of the HHL algorithm is to generate the normalised version of the state in Eq. (1.71) from the general
state |b⟩as shown in Eq. (1.69).
The algorithm works with three registers. The first one is an ancillary register made of a single qubit, the
second is also an ancillary register but made of d qubits, the third register is made of nb qubits and will encode",N/A,N/A
"the solution of the problem. The HHL circuit is the following
d
nb
|0⟩
|0⟩⊗d
|0⟩⊗d
|0⟩⊗nb
|x⟩
R
UQPE
U −1
QPE
ˆUb
|Ψ5⟩
|Ψ6⟩
|Ψ4⟩
|Ψ9⟩
|Ψ1⟩
(1.72)
The algorithm works as the following. Initially, all the qubits are prepared in |0⟩:
|Ψ0⟩= |0⟩|0⟩⊗d |0⟩⊗nb ,
(1.73)
then the information about b is encoded in the last register:
|Ψ1⟩= ˆ1 ⊗ˆ1⊗d ⊗ˆUb |Ψ0⟩= |0⟩|0⟩⊗d |b⟩.
(1.74)
We apply the QPE procedure, which is here broke down in the corresponding three steps. The first is the",N/A,N/A
"application of the Hadamard gate:
|Ψ2⟩= ˆ1 ⊗ˆH⊗d ⊗ˆ1 |Ψ1⟩= |0⟩
1
2d/2 (|0⟩+ |1⟩)⊗d |b⟩.
(1.75)
This is followed by the controlled unitary ˆU j:
|Ψ3⟩= ˆ1 ⊗C(U j) |Ψ2⟩= |0⟩
1
2d/2
2d−1
X
k=0
e2πikφ |k⟩|b⟩,
(1.76)
where ˆU |b⟩= e2πiφ |b⟩with φ ∈[0, 1[. Finally, we apply the inverse Fourier transform to the second register
1.6 Harrow-Hassidim-Lloyd algorithm
13
|Ψ4⟩= ˆ1 ⊗ˆF † ⊗ˆ1⊗nb |Ψ3⟩,
= |0⟩
1
2d/2
2d−1
X
k=0
e2πikφ ˆF † |k⟩|b⟩,
= |0⟩1
2d
2d−1
X
k=0
e2πikφ
2d−1
X
y=0
e−2πiyk/2d |y⟩|b⟩.
(1.77)",N/A,N/A
"X
k=0
e2πikφ
2d−1
X
y=0
e−2πiyk/2d |y⟩|b⟩.
(1.77)
However, one has that
2d−1
X
k=0
e2πik(φ−y/2d) =
(P2d−1
k=0 e0 = 2d,
if φ = y/2d,
0,
if φ ̸= y/2d,
(1.78)
meaning that the k sum selects the value of y = φ2d. Thus,
|Ψ4⟩= |0⟩|φ2d⟩|b⟩.
(1.79)
In general, |b⟩is in a superposition of |vj⟩, then
ˆU |vj⟩= e2πi ˆ
A |vj⟩= e2πiλj |vj⟩.
(1.80)
Then, the entire QPE gate maps
|Ψ1⟩= |0⟩|0⟩⊗d
2nb−1
X
j=0
βj |vj⟩
UQPE
−−−→|Ψ4⟩= |0⟩
2nb−1
X
j=0
βj |λj2d⟩|vj⟩.
(1.81)",N/A,N/A
"−−−→|Ψ4⟩= |0⟩
2nb−1
X
j=0
βj |λj2d⟩|vj⟩.
(1.81)
We apply a controlled rotation on the first register, such that
|Ψ5⟩= C(R) ⊗ˆ1⊗nb |Ψ4⟩=
2nb−1
X
j=0
βj
r
1 −C2
λ2
j |0⟩+ C
λj |1⟩

|λj2d⟩|vj⟩,
(1.82)
where C ∈R is an arbitrary constant. At this point we perform the measurement of the first register. If the
outcome is +1 and the state collapses in |0⟩then we discard the run; if the outcome is −1 with the state",N/A,N/A
"collapsed in |1⟩then we retain the run. To increase the probabilities of having the outcome −1, we make C as
large as possible. After the collapse of the first register in |1⟩, the state of the second and third register is
|Ψ6⟩=
1
P2nb−1
j=0
|βj/λj|2
1/2
2nb−1
X
j=0
βj
λj |λj2d⟩|vj⟩,
(1.83)
where we exploited that C ∈R. Now, we apply the inverse QPE, which has also three steps. The first is the
application of the QFT:
|Ψ7⟩= ˆF ⊗ˆ1⊗nb |Ψ6⟩,
=
1
P2nb−1
j=0
|βj/λj|2
1/2
2nb−1
X
j=0
βj",N/A,N/A
"=
1
P2nb−1
j=0
|βj/λj|2
1/2
2nb−1
X
j=0
βj
λj ˆF |λj2d⟩|vj⟩,
=
1
P2nb−1
j=0
|βj/λj|2
1/2
2nb−1
X
j=0
βj
λj
1
2d/2
2d−1
X
y=0
e2πiy(λj2d)/2d |y⟩|vj⟩.
(1.84)
Then, we apply the controlled unitary C(U −j), which gives
14
1 Circuit model for quantum computation
|Ψ8⟩= C(U −j) |Ψ7⟩,
=
1
P2nb−1
j=0
|βj/λj|2
1/2
2nb−1
X
j=0
βj
λj
1
2d/2
2d−1
X
y=0
e2πiyλj |y⟩e−2πiλjy |vj⟩,
(1.85)
where the two phases cancel and thus
|Ψ8⟩=
1
2d/2
2d−1
X
y=0
|y⟩
2nb−1
X
j=0
βj
λj
1
P2nb−1
j=0
|βj/λj|2
1/2 |vj⟩.",N/A,N/A
"X
j=0
βj
λj
1
P2nb−1
j=0
|βj/λj|2
1/2 |vj⟩.
(1.86)
Finally, the application of Hadamard’s gates on the second register gives
|Ψ9⟩= ˆH⊗d ⊗ˆ1⊗nb |Ψ8⟩= |0⟩⊗d
2nb−1
X
j=0
βj
λj
1
P2nb−1
j=0
|βj/λj|2
1/2 |vj⟩,
(1.87)
where the third register is exactly in the form in Eq. (1.71) after the proper normalisation. Thus,
|Ψ9⟩= |0⟩⊗d |x⟩,
(1.88)
embeds the solution of the linear system Ax = b.
Chapter 2
Variational Quantum Algorithms",N/A,N/A
"Chapter 2
Variational Quantum Algorithms
This class of algorithms employs a quantum and a classical computer to solve some optimisation problems.
The quantum computer performs the quantum evolution of a state with respect to an Hamiltonian that is
transformed, say from ˆH0 to ˆH1. The classical computer determines how such a transformation should take
place employing the variational principle. Typically, the problem is to map the state from the ground state of",N/A,N/A
"ˆH0 to that of ˆH1, whose ground state is unknown. Thus, one wants to have a well-known ˆH0. This is often
taken as that of the Ising model.
2.1 The Ising model
In a combinatorial optimisation problem, one has a string of n bits and wants to optimise a particular problem.
The problem is mapped in a minimisation (or maximisation) of a cost function C : { 0, 1 }n →R. Notably, the
maximisation problem can be obtained from the minimisation one buy a minus sign: C →−C.",N/A,N/A
"To solve a combinatorial optimisation problem via a quantum algorithm, one needs to encode the problem
onto a quantum system. In the following, we show how the Ising Hamiltonian can be used to embed such an
optimisation problem.
The Ising model was developed to study the phase transition in magnetic materials. It consists in n spins
that can be coupled via long-range interactions. The corresponding Hamiltonian is
ˆHC = −
n
X
i=1
hiˆσ(i)
z
−
X
1≤i<j≤n
Jijˆσ(i)
z ˆσ(j)
z ,
(2.1)",N/A,N/A
"hiˆσ(i)
z
−
X
1≤i<j≤n
Jijˆσ(i)
z ˆσ(j)
z ,
(2.1)
where hi are the single spin magnetic fields describing the single spin evolution and Jij the spin-spin couplings.
The choice of the latter encodes if the spins are encouraged to be aligned (ferromegnetic phase) or anti-aligned
(antiferromagnetic phase). Since only ˆσz are appearing in ˆHC, then its spectral decomposition can be expressed
in the computational basis:
ˆHC =
2n−1
X
z=0
C(z) |z⟩⟨z| ,
(2.2)",N/A,N/A
"ˆHC =
2n−1
X
z=0
C(z) |z⟩⟨z| ,
(2.2)
where C(z) is the energy of the specific spin configuration |z⟩. Then, by properly mapping a combinatorial
problem in the choice of { hi } and { Jij }, one can find the optimal solution by minimizing the energy, i.e. by
finding the configuration |z⟩that corresponds to minimal energy (or cost) C(z).
15
16
2 Variational Quantum Algorithms
2.2 Mapping combinatorial optimisation problems into the Ising model",N/A,N/A
"Many problems can be mapped in the form in Eq. (2.1), and hence solve with a quantum computer, by choosing
the appropriate values of { hi } and { Jij }. Here we consider some explicit examples.
Subset sum problem. Given an integer number m (total value) and a set of N positive and negative integers
n = { n1, . . . , nN }, which is the subset of the latter integers whose sum gives m?
Example 2.1",N/A,N/A
"Example 2.1
Consider the case of m = 7 and n = { −5, −3, 1, 4, 9 }. The subset { −3, 1, 9 } solves the problem: −3+1+9 =
7 = m.
Exercise 2.1
Consider the case of m = 13 and n = { −3, 2, 8, 4, 20 }. Show that the corresponding subset sum problem
has no solution.
The subset sum problem can be framed as an energy minimisation problem as follows. Consider the sum
PN
i=1 nizi −m, where ni are the elements of n and zi ∈{ 0, 1 } are weights that select or not the corresponding",N/A,N/A
"element ni in the sum (effectively, this is the way to select a specific subsection). We define E(z) as the square
of such a sum:
E(z) = E(z1, . . . , zN) =
 N
X
i=1
nizi −m
!2
.
(2.3)
Then, if there is a subset solving the problem, one has that exists a value of z = { z1, . . . , zN } such that E(z) = 0.
Conversely, if all the possible values of z give E(z) ̸= 0, then there is no subset that can solve the subset sum",N/A,N/A
"problem. One can already see that the z corresponding to the solution of the problem is the one minimising
E(z). We now show the connection with the Ising model. We introduce the classical spins si = ±1, which will
be employed in place of the weights zi. Namely, one uses
zi = 1
2(1 −si),
(2.4)
so that si = +1 (spin up) corresponds to zi = 0 and si = −1 (spin down) to zi = 1. We define the corresponding
classical Hamiltonian
H(s1, . . . , sN) =
 N
X
i=1
ni 1
2(1 −si) −m
!2
,
= 1
4
N
X
i,j=1",N/A,N/A
"N
X
i=1
ni 1
2(1 −si) −m
!2
,
= 1
4
N
X
i,j=1
ninjsisj −
N
X
i=1

1
2
N
X
j=1
nj −m

nisi +
 
1
2
N
X
i=1
ni −m
!2
,
(2.5)
where the last term is independent from si and thus is a negligible constant of the problem. After having defined
Jij = −ninj
4
,
and
hi =

1
2
N
X
j=1
nj −m

ni,
(2.6)
the Hamiltonian becomes
H(s1, . . . , sN) = −
X
1≤i<j≤n
Jijsisj −
n
X
i=1
hisi + const,
(2.7)
where
2.3 Adiabatic Theorem
17
const =
 
1
2
N
X
i=1
ni −m
!2
−
N
X
i=1
Jiis2
i ,
(2.8)",N/A,N/A
"1
2
N
X
i=1
ni −m
!2
−
N
X
i=1
Jiis2
i ,
(2.8)
is si independent since s2
i = 1 for any value of i. To solve the problem on a quantum computer, one quantises
the Hamiltonian in Eq. (2.7) by substituting si →ˆσ(i)
z
and gets Eq. (2.1).
Number partitioning problem. Another combinatory problem that can be mapped in an Ising Hamiltonian
is the number partitioning problem. It asks if a set of N integers { n1, . . . , nN } can be partitioned in two subsets",N/A,N/A
"such that the sum of the elements in the individual subsets is equal.
Example 2.2
Consider the set n = { 1, 2, 3, 4, 6, 10 }. In such a case, one can consider the case of { 1, 2, 4, 6 } and { 3, 10 },
whose individual sums are both equal to 13.
The classical Hamiltonian for this problem can be straightforwardly constructed as
H(s1, . . . , sN) =
 N
X
i=1
nisi
!2
,
(2.9)
with si = ±1. Clearly, the solution s = { s1, . . . , sN } is such that H(s) = 0. Expanding the square, we find
H(s) = −
X",N/A,N/A
"H(s) = −
X
1≤i<j≤N
Jijsisj −Tr [Jij] ,
(2.10)
where
Jij = −ninj
2
,
and
Tr [Jij] =
N
X
i=1
Jiis2
i .
(2.11)
The classical Hamiltonian in Eq. (2.10) can be quantised and one obtains that in Eq. (2.1) with no need to
introduce the magnetic fields, i.e. hi = 0.
2.3 Adiabatic Theorem
Adiabatic quantum computation is based on the adiabatic theorem. The latter considers the case of a time
dependent Hamiltonian, that changes from ˆH0 at time t = 0 to ˆH1 at time t = τ. We also assume that the",N/A,N/A
"two Hamiltonians do not commute, i.e.[ ˆH0, ˆH1] ̸= 0. The theorem states that a system prepared in the n-th
eigeinstate of ˆH0 goes in the n-th eigeinstate of ˆH1 if the transformation is made slowly enough, i.e. adiabatically.
The application to quantum computation then is to take an initial Hamiltonian with a ground state that can be
easily prepared and then adiabatically change the Hamiltonian to that of the problem one wants to optimise. If",N/A,N/A
"the system is initially in the ground state of ˆH0, then will remain in the ground state of the target Hamiltonian
ˆH1 and it will encode the solution of the optimisation problem.
The proof of the adiabatic theorem is the following. Consider the instantaneous spectralisation of a time-
dependent Hamiltonian ˆH(t), which is
ˆH(t) |n(t)⟩= En(t) |n(t)⟩,
(2.12)
where En(t) and |n(t)⟩are respectively the corresponding instantaneous eigeinvalues and eigeinstates. Given a",N/A,N/A
"state |ψ(t)⟩at time t, one can always express it as a superposition of the instantaneous eigeinstates as
|ψ(t)⟩=
X
n
cn(t) |n(t)⟩,
(2.13)
18
2 Variational Quantum Algorithms
where
cn(t) = ⟨n(t)|ψ(t)⟩,
(2.14)
determine the probabilities Pn(t) = |cn(t)|2 of being in |n(t)⟩at time t. The evolution of cn(t) can be determined
via
˙cn(t) = ⟨˙n(t)|ψ(t)⟩+ ⟨n(t)| ˙ψ(t)⟩,
= ⟨˙n(t)|ψ(t)⟩−i
ℏ⟨n(t)| ˆH(t)|ψ(t)⟩,
= ⟨˙n(t)|ψ(t)⟩−i
ℏEn(t) ⟨n(t)|ψ(t)⟩,
(2.15)
where we defined | ˙n(t)⟩=
d",N/A,N/A
"(2.15)
where we defined | ˙n(t)⟩=
d
dt |n(t)⟩, and we applied the Schr¨odinger equation and applied the Hamiltonian to
its eigeinstate. Then, the imposing Eq. (2.13), we get
˙cn(t) =
X
m
cm(t) ⟨˙n(t)|m(t)⟩−i
ℏEn(t)cn(t),
(2.16)
which determines a system of coupled differential equations. In complete generality, the evolution of cn(t)
depends on cm(t) for all values of m. To determine the first term of Eq. (2.16), we consider the time derivative",N/A,N/A
"of Eq. (2.12) with |n(t)⟩subsituted with |m(t)⟩and projecting it on ⟨n(t)|. This gives
⟨n(t)| d
dt ˆH(t)|m(t)⟩+ ⟨n(t)| ˆH| ˙m(t)⟩= ˙Em(t)δnm + Em(t) ⟨n(t)| ˙m(t)⟩,
(2.17)
which can be recasted as
(En(t) −Em(t)) ⟨n(t)| ˙m(t)⟩= ˙Em(t)δnm −⟨n(t)| d
dt ˆH(t)|m(t)⟩.
(2.18)
For m ̸= n, one then has
⟨˙n(t)|m(t)⟩= ⟨n(t)| d
dt ˆH(t)|m(t)⟩
(En(t) −Em(t)) ,
(2.19)
where we exploited that ⟨˙n(t)|m(t)⟩= −⟨n(t)| ˙m(t)⟩. Thus, by separating the case of m = n and m ̸= n in
Eq. (2.16), we have
˙cn(t) =",N/A,N/A
"Eq. (2.16), we have
˙cn(t) =
 ⟨˙n(t)|n(t)⟩−i
ℏEn(t)

cn(t) +
X
m̸=n
cm(t)⟨n(t)| d
dt ˆH(t)|m(t)⟩
(En(t) −Em(t)) .
(2.20)
In the limit where the Hamiltonian ˆH(t) changes slowly enough, i.e. for ⟨n(t)| d
dt ˆH(t)|m(t)⟩≪(En(t) −Em(t))
for all n and m, then one can neglect the last term in Eq. (2.20). This is the so-called adiabatic approximation,
which gives the following solutions
cn(t) = eiθn(t)eiγn(t)cn(0),
(2.21)
where we defined
θn(t) = −1
ℏ
Z t
0
ds En(s),
and
γn(t) = −i
Z t
0",N/A,N/A
"θn(t) = −1
ℏ
Z t
0
ds En(s),
and
γn(t) = −i
Z t
0
ds ⟨˙n(s)|n(s)⟩.
(2.22)
In particular, γn(t) ∈R is known as the Berry phase.
Importantly, under the adiabatic approximation, one has that the probabilities evolve as
Pn(t) = |cn(t)|2 = |cn(0)|2 = Pn(0),
(2.23)
which is the final proof of the theorem.
Remark 2.1. It is important to understand the limits in which the adiabatic approximation is valid. To prove it",N/A,N/A
"in complete generality, one should require that the time-scale τ of the transformation is such that
2.4 Quantum Annealing
19
τ ≫max
n̸=m max
0≤t≤τ

⟨n(t)| d
dt ˆH(t)|m(t)⟩
(En(t) −Em(t))
 .
(2.24)
For the perspective of quantum computation, one can restrict to the case of n = 0 and m = 1. This is the case
where the system is initially prepared in the ground state n = 0 and one does not want a jump in the first
excited state m = 1. In such a case, the approximation is valid if
τ ≫max",N/A,N/A
"τ ≫max
0≤t≤τ

⟨ψ0(t)| d
dt ˆH(t)|ψ1(t)⟩
(E0(t) −E1(t))
 .
(2.25)
Notably, the more the energy gap E1 −E0 closes, the larger value of τ one has to consider. In the case of a
linear transition between the initial ˆH0 and final Hamiltonian ˆH1 (i.e. ˆH(t) = (1−t/τ) ˆH0 +t/τ ˆH1), a necessary
condition for keeping the energy gap open is that [ ˆH0, ˆH1] ̸= 0. Figure 2.1 represents graphically how the gap",N/A,N/A
"should remain open during the Hamiltonian change so that the initial state being the ground state of ˆH0 is
mapped to the ground state of ˆH1, which encodes the solution of the problem.
E1(s)
E0(s)
0
1
S
S
DEmin
E0(1) ! |f0(1)i ⌘|Ypi
|y0i ⌘|f0(0)i ! E0(0)
E
E1(1) ! |f1(1)i
|f1(0)i ! E1(0)
Fig. 2.1: Graphical representation of how the energy levels of ˆH(t) change in time. As long as the minimum",N/A,N/A
"energy gap ∆Emin is finite, one can employ the adiabatic theorem to go from the ground state of ˆH0 (here
denoted as |ψ0⟩) to that of ˆH1 (|Ψp⟩). Here, we used the parameter s to parametrise the time flow: t = sτ.
2.4 Quantum Annealing
The quantum annealing is an heuristic quantum algorithm based on the adiabatic theorem. It aims at solving
hard combinatorial optimisation problems using the Ising Hamiltonian as a target Hamiltonian.",N/A,N/A
"The algorithm exploits an Hamiltonian transformation of the form
ˆH(t) = (1 −s(t)) ˆH0 + s(t) ˆHC,
(2.26)
where s(t) is a suitable smooth function of time with s(0) = 0 and s(τ) = 1, and ˆHC is the Ising Hamiltonian
in Eq. (2.1) whose ground state encodes the solution of the problem. Moreover, one requires that H0 has a
non-degenerate ground state that is easy to prepare and that [ ˆH0, ˆH1] ̸= 0. A simple choice is
ˆH0 = −
n
X
i=1
ˆσ(i)
x ,
(2.27)",N/A,N/A
"ˆH0 = −
n
X
i=1
ˆσ(i)
x ,
(2.27)
which has |+⟩⊗n as ground state. This can be easily prepared via Hadamard gates: |+⟩⊗n = ˆH⊗n |0⟩⊗n.
If the quantum annealing time τ is not sufficiently long (i.e. the transformation is not sufficiently adiabatic),
which is essentially always the case, then one reach a state |ψ(τ)⟩, which has a probability p of being the solution
20
2 Variational Quantum Algorithms",N/A,N/A
"20
2 Variational Quantum Algorithms
of the problem. Such a probability (of success) is given by p = | ⟨zsol|ψ(τ)⟩|2, where |zsol⟩is the state encoding
the exact solution. To obtain the solution with a 99% certainty, one has to repeat the annealing procedure m
times. Indeed,
P m
succ = 1 −(1 −p)m = 0.99.
(2.28)
The corresponding total time required is given by
T99% = mτ = ln(1 −0.99)
ln(1 −p) τ
(2.29)",N/A,N/A
"T99% = mτ = ln(1 −0.99)
ln(1 −p) τ
(2.29)
A strong challenge for the quantum annealing is the full connectivity of the qubits. Indeed, in a quantum
computer, the qubits interactions, which are parameterised by Jij, are typically null beyond nearest-neighbour
sites. This strongly limits the scaling of universally annealing where one can suitably tune all the values of Jij.
2.5 Quantum Approximate Optimisation Algorithm (QAOA)",N/A,N/A
"The Quantum Approximate Optimisation Algorithm (QAOA) is a hybrid quantum-classical algorithm that
allows for optimising a cost function and finding an approximated solution. It is an application of the adiabatic
theorem, similarly as the quantum annealing, which is run on a quantum computer, while a classical computer
optimises the cost function.
We start from a quantum annealing Hamiltonian of the form
ˆH(t) = (1 −s(t)) ˆHM + s(t) ˆHC,
(2.30)",N/A,N/A
"ˆH(t) = (1 −s(t)) ˆHM + s(t) ˆHC,
(2.30)
where s(t) is an arbitrary function such that s(0) = 0 and s(τ) = 1 with τ being the total time of the
algorithm. The initial Hamiltonian ˆHM is such that its ground state can be prepared easily. ˆHC is instead
the cost Hamiltonian whose ground state encodes the solution to the problem. The QAOA is based on the
observation that the best way to implement the annealing Hamiltonian in Eq. (2.30) is a Trotter procedure.",N/A,N/A
"Namely, this is to consider the unitary evolution with respect to ˆH(t) and decompose it in small time steps.
Then, we have
ˆU(τ) = T exp

−i
ℏ
Z τ
0
dt ˆH(t)

≃
p
Y
k=1
exp
h
−i
ℏˆH(k∆t)∆t
i
,
(2.31)
where T indicates the time ordering, one assumes a large number of steps p ≫1 of length ∆= τ/p. Owing that
for [ ˆA, ˆB] ̸= 0 one has
ei( ˆ
A+ ˆ
B)∆t = ei ˆ
A∆tei ˆ
B∆t + O((∆t)2),
(2.32)",N/A,N/A
"A+ ˆ
B)∆t = ei ˆ
A∆tei ˆ
B∆t + O((∆t)2),
(2.32)
and since we require that [ ˆHC, ˆHM] ̸= 0, one has that at each time step the following approximation is valid to
the order (∆t)2:
ˆU(τ) ≃
p
Y
k=1
exp
h
−i
ℏ(1 −s(k∆t)) ˆHM∆t
i
exp
h
−i
ℏs(k∆t) ˆHC∆t
i
.
(2.33)
Now, the key idea of QAOA is to redefine the time dependence in the following way:
1
ℏ(1 −s(k∆t)) ∆t →βk,
and
1
ℏs(k∆t)∆t →γk.
(2.34)
Thus, we have
ˆU(τ) ≃
p
Y
k=1
exp
h
−iβk ˆHM
i
exp
h
−iγk ˆHC
i
,
(2.35)",N/A,N/A
"Y
k=1
exp
h
−iβk ˆHM
i
exp
h
−iγk ˆHC
i
,
(2.35)
where the parameters β = (β1, . . . , βp) and γ = (γ1, . . . , γp) become the variational parameters to be optimised.
Crucial difference with respect to the quantum annealing case is that one optimises over a set of 2p parameters
2.5 Quantum Approximate Optimisation Algorithm (QAOA)
21
instead of a fixed time segments. Finally, one constructs the variational state
|γ, β⟩=
p
Y
k=1
e−iβk ˆ
HMe−iγk ˆ
HC |init⟩,
(2.36)",N/A,N/A
"p
Y
k=1
e−iβk ˆ
HMe−iγk ˆ
HC |init⟩,
(2.36)
where the initial state |init⟩is the ground state of ˆHM. In the case of ˆHM being equal to Eq. (2.27), one has
|init⟩= ˆH⊗n |0⟩⊗n .
(2.37)
In the computational basis, the variational state reads
|γ, β⟩=
2n−1
X
z=0
dz(γ, β) |z⟩,
(2.38)
where dz(γ, β) defines the superposition in the Z basis. Notably, since ˆHC encodes in its ground state the
solution of the problem, one needs to minimise the expectation value of ˆHC computed on the variational state.",N/A,N/A
"Namely
Ep(γ, β) = ⟨γ, β| ˆHC|γ, β⟩=
2n−1
X
z=0
Pz(γ, β)C(z),
(2.39)
where Pz(γ, β) = |dz(γ, β)|2 is the probability of having the |z⟩state and C(z) = ⟨z| ˆHC|z⟩is the corresponding
cost. The best (γ, β) are such that
(γ∗, β∗) = arg min
γ,β Ep(γ, β).
(2.40)
Such an optimisation is performed on classical computer (classical optimiser). The circuit representation of the
QAOA is
quantum computer
classical optimiser
n
|0⟩
. . .
. . .
. . .
H⊗n
e−iγ1HC
e−iβ1HM
e−iγpHC
e−iβpHM
Compute: Ep(γ, β)",N/A,N/A
"e−iγ1HC
e−iβ1HM
e−iγpHC
e−iβpHM
Compute: Ep(γ, β)
Gives the minimum?
Yes
Stop
No
New (γ, β)
(2.41)
Exercise 2.2
Derive the explicit expression of the cost fucntion C(z) in terms of the coefficients Jij and hi.
The single k step of the QAOA, when considering ˆHM as in Eq. (2.27) and ˆHC being the Ising Hamiltonian,
is implemented as the following. First we consider ˆHM,
ˆHM = −
n
X
i=1
ˆσ(i)
x .
(2.42)
Then, the corresponding unitary acts independently on each qubit
22",N/A,N/A
"22
2 Variational Quantum Algorithms
e−iβk ˆ
HM = eiβk
Pn
i=1 ˆσ(i)
x
=
n
Y
i=1
eiβkˆσ(i)
x .
(2.43)
Then, the corresponding action can be implemented with a rotation on the single i-th qubit. The circuit
implementing it is
RX(−2βk)
(2.44)
Indeed a rotation around n by an angle θ is defined a ˆRn(θ) = e−iθn·ˆσ/2. The implementation of the unitary
related to ˆHC can be divided in two steps, indeed the two terms of ˆHC in Eq. (2.1) commute. Then, one writes
e−iγk ˆ
HC = eiγk(
Pn
i=1 hiˆσ(i)
z +P",N/A,N/A
"e−iγk ˆ
HC = eiγk(
Pn
i=1 hiˆσ(i)
z +P
1≤i<j≤n Jij ˆσ(i)
z
ˆσ(j)
z ) =
Y
1≤i<j≤n
eiγkJij ˆσ(i)
z
ˆσ(j)
z
n
Y
i=1
eiγkhiˆσ(i)
z .
(2.45)
Here, the single qubits factors act as rotations, with a circuit being
RZ(−2γkhi)
(2.46)
On the other hand, the two qubits interactions are 2-local gates, which can be implemented via a rotation
between two CNOT gates. Namely, the corresponding circuit will read
RZ(−2γkJij)
(2.47)
thus becoming very easy to be implemented.",N/A,N/A
"(2.47)
thus becoming very easy to be implemented.
2.6 Variational Quantum Eigensolver (VQE)
Similarly as the QAOA, the Variational Quantum Eigeinsolver (VQE) is an heuristic approach to solve combi-
natorial optimisation problem that exploits a combination of quantum computation and classical optimisation.
In particular, the QAOA can be seen as a specific implementation of the VQE algorithm.",N/A,N/A
"The algorithm is designed to solve problems that can be stated as finding the ground state energy E0 of n
qubit Hamiltonian. Namely, to find the configuration corresponding to the state |Ψ0⟩that
ˆH |Ψ0⟩= E0 |Ψ0⟩.
(2.48)
The generality with respect to QAOA comes in the form of the cost Hamiltonian ˆHC. Indeed, one assumes for
it the most general form, which is
ˆHC =
X
α
hα ˆPα =
X
α
hα
n
O
j=1
ˆσ(j)
αj ,
(2.49)",N/A,N/A
"X
α
hα ˆPα =
X
α
hα
n
O
j=1
ˆσ(j)
αj ,
(2.49)
where hα are coefficients and the ˆPα are called Pauli strings. The latter are product of n single-qubit Pauli
matrices (including the identity). Thus, compared to QAOA (which exploits the Ising model), this Hamiltonian
is not limited to two qubit interactions only, but can consider n qubit interactions. This is particularly relevant
when considering more complex systems where the Ising model fails to describe the entire complexity of the
problem.",N/A,N/A
"problem.
Then, the steps of VQE are the following:
1. Map the problem in a cost Hamiltonian ˆHC so that the solution is embedded in its ground state.
2.6 Variational Quantum Eigensolver (VQE)
23
2. Prepare the initial state as the ground state of ˆH.
3. Generate the trial state |Ψ(θ)⟩, which is determined by a set of parameters θ.
4. Measure the expectation values of the Pauli strings in the Hamiltonian, i.e. ⟨Ψ(θ)| ˆPα|Ψ(θ)⟩. This is the end
of the computation on the quantum computer",N/A,N/A
"of the computation on the quantum computer
5. Compute the corresponding energy, i.e. E(θ) = P
α hα ⟨Ψ(θ)| ˆPα|Ψ(θ)⟩
6. Update or accept the values of θ based on the result.
7. If updated, one goes back to point 2.
Notably, when searching for the ground state energy of the cost Hamiltonian, there are several pitfalls that
the update step must deal with. For example, the parameter landscape may have local minima where one does
not want to remain stacked.
Chapter 3",N/A,N/A
"not want to remain stacked.
Chapter 3
Noisy Intermediate-Scale Quantum (NISQ) computation
For quantum algorithms to function properly, we need to ensure that the basic units of quantum information, the
qubits, are as reliable as the bits in classical computers. These qubits must be shielded from environmental noise
that can disrupt their states, while still have to be controlled by external agents. This control involves making",N/A,N/A
"the qubits entangle and eventually measuring their states to extract the outputs of the quantum computation.
Technically, it is feasible to minimise the impact of noise without compromising the quantum information
process through the development of Quantum Error Correction (QEC) and Quantum Error Mitigation (QEM)
protocols, see Chap. 4.
Many quantum algorithms that come with guaranteed performance need millions of physical qubits to effec-",N/A,N/A
"tively use QEC methods. It could take decades to build fault-tolerant quantum computers capable of reaching
this scale. Presently, quantum devices typically have around 100-1000 physical qubits, often referred to as noisy
intermediate-scale quantum (NISQ) devices. These devices lack error correction and are imperfect, yet in the
NISQ era, the aim is to maximize the quantum computational capabilities of current devices, while working on
techniques for fault-tolerant quantum computation.",N/A,N/A
"Here, we study how noises impact quantum circuits. The following circuit will be considered as a basis of the
study:
|0⟩
Xd
|ψ⟩
(3.1)
where the gate X is repeated d times. The value of d is also called the depth of the circuit. The state before the
measurement, when no noise is considered, is given by
|ψ⟩= (i ˆRx(θ = π))d |0⟩= id [cos(dπ/2) |0⟩−sin(dπ/2) |1⟩] ,
(3.2)
indeed one has that the X gate can be realised as a rotation of an angle π around the x axis: ˆσx = i ˆRx(π).",N/A,N/A
"Notably, the factor id is just a negligible global phase. The expectation value of the polarisation is
⟨Z⟩= ⟨ψ|ˆσz|ψ⟩= cos2(dπ/2) −sin2(dπ/2) = cos(dπ),
(3.3)
which is shown in the left panel of Fig. 3.1. Clearly, the value of ⟨Z⟩jumps from +1 to −1 depending on the
value of d. However, when we perform such a simple experiment the result is quite different due to the noises
and errors acting on the system. This is represented in the right panel Fig. 3.1. Such a result account for the",N/A,N/A
"presence of different noises and errors. These are listed and studied below.
24
3.1 Miscalibrated gates
25
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
Fig. 3.1: Expectation value of the polarisation ⟨Z⟩for the circuit in Eq. (3.1) with respect to the depth d of the
circuit: (left panel) in the case of no noises; (right panel) when noises are accounted.
3.1 Miscalibrated gates",N/A,N/A
"3.1 Miscalibrated gates
As we saw previously, the gate X can be performed as a rotation of an angle π around the x axis. Now, let us
suppose that the gate is systematic miscalibrated. Specifically, one performs a rotation of an angle of π + ϵ in
place of only π. Then, we have that the actual gate ˜X is given by
˜X
=
X
iRx(ϵ)
(3.4)
indeed one has that
Rx(π + ϵ) = Rx(π)Rx(ϵ).
(3.5)
Then, when running the circuit with d repetitions, one simply has
|0⟩
|0⟩
˜Xd
=
Xd
iRx(dϵ)
|ψ⟩
(3.6)
where
|ψ⟩= id h",N/A,N/A
"|0⟩
˜Xd
=
Xd
iRx(dϵ)
|ψ⟩
(3.6)
where
|ψ⟩= id h
cos

d (π+ϵ)
2

|0⟩−i sin

d (π+ϵ)
2

|1⟩
i
.
(3.7)
Correspondingly, one has that the expectation value for the polarisation is
⟨Z⟩= cos2 
d (π+ϵ)
2

−sin2 
d (π+ϵ)
2

= cos(d(π + ϵ)),
(3.8)
which is shown in the left panel of Fig. 3.2. For small values of ϵ and d, one performs an error of
| ⟨Z⟩noiseless −⟨Z⟩miscalibrated | ∼1
2d2ϵ2,
(3.9)",N/A,N/A
"2d2ϵ2,
(3.9)
which scales quadratically with the miscalibration ϵ. As it is shown in the right panel of Fig. 3.2, the difference
with respect to the noiseless result can be substantial. Indeed, for values of d such that dϵ ∼(2n + 1)π, with
n ∈N, we have that
⟨Z⟩miscalibrated = −⟨Z⟩noiseless .
(3.10)
This means that the error completely inverts the output signal.
26
3 Noisy Intermediate-Scale Quantum (NISQ) computation
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40",N/A,N/A
"0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40
60
80
100
0.0
0.5
1.0
1.5
2.0
circuit depth d
|<Z>noisless-<Z>miscalibrated|
Fig. 3.2: (Left panel) Expectation value (red dots) of the polarisation ⟨Z⟩for the circuit in Eq. (3.1) with respect
to the depth d of the circuit when miscalibrated gates are considered. (Right panel) Difference with respect to
the noiseless case (blue line) and the small ϵ and d expansion (red line). Here we considered ϵ = 0.1.
3.2 Projection noise and sampling error",N/A,N/A
"3.2 Projection noise and sampling error
Consider the following trivial circuit
|ψ⟩
(3.11)
whose possible values of the polarisation are z = +1, meaning that the state after the collapse is |0⟩, and z = −1,
with corresponding state |1⟩.
Let us define a measurement operator ˆ
M that indicates if the state of the qubit is in the |1⟩state. Such an
operator can be constructed as
ˆ
M = |1⟩⟨1| ,
= 1 |1⟩⟨1| + 0 |0⟩⟨0| ,
=
X
m=0,1
m ˆΠm,
(3.12)
where m are the eigeinvalues of ˆ",N/A,N/A
"m ˆΠm,
(3.12)
where m are the eigeinvalues of ˆ
M and ˆΠm = |m⟩⟨m|, with P
m ˆΠm = ˆ1. Namely, the expectation value of ˆ
M
indicates the probability p(m = 1) that the state |ψ⟩is equal to |1⟩:
⟨ψ| ˆ
M|ψ⟩= ⟨ψ|1⟩⟨1|ψ⟩= | ⟨1|ψ⟩|2 = p(m = 1).
(3.13)
Correspondingly, one has p(m = 0) = 1−p(m = 1). To ease the notation, in the following we use p = p(m = 1).
The outcomes of the operator ˆ
M are distributed via a binomial distribution B(p). To be more explicit, let us",N/A,N/A
"consider the repetition of the above circuit N times, meaning that we have N samplings of the protocol.
Then, we can construct a series of outputs: { mn }N
n=1 = { 0, 0, 1, 0, 1, 1, 0, . . . }, where each entry is a random
variable. This corresponds in a series of states into which the system has collapsed after the measurement:
{ | 0⟩, | 0⟩, | 1⟩, | 0⟩, | 1⟩, | 1⟩, | 0⟩, . . . }. Suppose we have N = 3, then we have a total of 2N = 23 outputs
(m1, m2, m3). Namely",N/A,N/A
"(m1, m2, m3). Namely
3.2 Projection noise and sampling error
27
(m1, m2, m3) (|m1⟩, |m2⟩, |m3⟩) S
(0, 0, 0)
(|0⟩, |0⟩, |0⟩)
0
(0, 0, 1)
(|0⟩, |0⟩, |1⟩)
1/3
(0, 1, 0)
(|0⟩, |1⟩, |0⟩)
1/3
(0, 1, 1)
(|0⟩, |1⟩, |1⟩)
2/3
(1, 0, 0)
(|1⟩, |0⟩, |0⟩)
1/3
(1, 0, 1)
(|1⟩, |0⟩, |1⟩)
2/3
(1, 1, 0)
(|1⟩, |1⟩, |0⟩)
2/3
(1, 1, 1)
(|1⟩, |1⟩, |1⟩)
1
(3.14)
where we also computed the corresponding sampling mean S, which is defined as
S = 1
N
N
X
n=1
mn.
(3.15)",N/A,N/A
"S = 1
N
N
X
n=1
mn.
(3.15)
The statement then is that the sampling mean S, which is also a random variable, is distributed as a binomial
distribution B(p), with mean E[S] = p and variance V[S] = p(1 −p)/N. Fig. 3.3 shows some examples. Now,
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.1
0.2
0.3
S
prob(S)
Fig. 3.3: Binomial distribution followed by the sampling mean S for N = 100 samplings with p = 0.2 (red plot)
and p = 0.5 (blue plot), and for N = 3 with p = 0.5 (green plot).",N/A,N/A
"by assuming that the state |ψ⟩in Eq. (3.11) is that one has before the measurement in Eq. (3.6), i.e.
|ψ⟩= id h
cos

d (π+ϵ)
2

|0⟩−i sin

d (π+ϵ)
2

|1⟩
i
,
(3.16)
then the corresponding distribution B(pd) depends on the probability of being in the state |1⟩after a depth d
of the circuit. This is given by
pd = sin2 
d (π+ϵ)
2

.
(3.17)
The corresponding expectation value of the polarisation is shown in Fig. 3.4, where we also report its difference",N/A,N/A
"with respect to the case shown in Fig. 3.2.
28
3 Noisy Intermediate-Scale Quantum (NISQ) computation
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40
60
80
100
0.00
0.02
0.04
0.06
0.08
circuit depth d
|<Z>miscalibrated-<Z>sampling|
Fig. 3.4: (Left panel) Expectation value (red dots) of the polarisation ⟨Z⟩for the circuit in Eq. (3.1) with
respect to the depth d of the circuit when miscalibrated gates and error sampling are considered. (Right panel)",N/A,N/A
"Difference with respect to the miscalibrated case. Here we considered ϵ = 0.1 and N = 10.
3.3 Measurement error
Another source of errors is related to the performance of the measurement apparatus. To be explicit, consider
the following trivial circuit
|0⟩
U
|ψ⟩
(3.18)
Suppose that is the state |ψ⟩= |0⟩to be fed to the measurement apparatus. Then, if the apparatus is perfectly
set, it will give as the polarisation value z = +1 corresponding to the output m = 0. However, there might be",N/A,N/A
"errors and there could be a non-null probability µ that the measurement apparatus gives as an output m = 1.
Similarly, if |ψ⟩= |1⟩, one could have a probability ν to have m = 0. The following scheme represents the
supposed outcome and the actual outcome with the corresponding probabilities:
supposed m =
µ
(1−ν)
ν
(1−µ)
0
0
1
1
= actual ˜m.
(3.19)
We can define the probability vectors for the supposed and actual outcomes, which respectively are
PM =
1 −p
p

and
P ˜
M =
1 −˜p
˜p

,
(3.20)",N/A,N/A
"PM =
1 −p
p

and
P ˜
M =
1 −˜p
˜p

,
(3.20)
where p = p(m = 1) and ˜p = ˜p( ˜m = 1) are the probability of having the outcome m = 1 in the supposed
and actual case respectively. Such vectors are related by the matrix A, which quantifies the performances of
measurement apparatus: P ˜
M = APM, where
A =
P( ˜m = 0|m = 0) P( ˜m = 0|m = 1)
P( ˜m = 1|m = 0) P( ˜m = 1|m = 1)

,
(3.21)
where P( ˜m|m) is the conditional probability of having the actual outcome ˜m given the supposed outcome m.",N/A,N/A
"The diagram in Eq. (3.19) sets the entries of A to
3.3 Measurement error
29
A =
1 −µ
ν
µ
1 −ν

.
(3.22)
By merging the latter and Eq. (3.20), we find
˜p = p + µ −(ν + µ)p,
(3.23)
which is represented in Fig.3.5. To recalibrate the measurement apparatus, i.e. to quantify experimentally the
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
p
p
(1 −𝜈−𝜇)
Ideal case
Measurement noise case
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40
60
80
100
0.00
0.02
0.04
0.06
0.08",N/A,N/A
"0
20
40
60
80
100
0.00
0.02
0.04
0.06
0.08
0.10
0.12
circuit depth d
|<Z>miscalibrated-<Z>measurement|
Fig. 3.5: (Top panel) Representation of Eq. (3.23). (Bottom left panel) Expectation value (red dots) of the
polarisation ⟨Z⟩for the circuit in Eq. (3.1) with respect to the depth d of the circuit when miscalibrated gates
and measurement errors are considered. (Bottom right panel) Difference with respect to the miscalibrated case.
Here we considered ϵ = 0.1, ν = 0.07 and µ = 0.03.",N/A,N/A
"values of µ and ν one would need to run the following two trivial circuits:
|0⟩
|1⟩
(3.24)
They should give 100% of the time the outcomes m = 0 and m = 1 respectively. Variations of such percentage
will characterise the values of µ and ν. The bottom panels in Fig. 3.5 show the corresponding polarisation and
difference with the miscalibrated case.
30
3 Noisy Intermediate-Scale Quantum (NISQ) computation
3.3.1 Environmental noise",N/A,N/A
"3.3.1 Environmental noise
We now dwell in the most interesting source of noise, which is the one due to the external environment. In a
circuit-based representation of the evolution, one now has
|0⟩
˜G
(3.25)
where ˜G represents the noisy version of the gate G. There are different possible ways how one can account for
the noise action. Here, we will consider the following way. Every gate G of the noiseless case is substituted by",N/A,N/A
"˜G, where an extra gate, say E, is added with a probability pE. Namely,
Case Probability
Effective circuit
A
1 −pE
˜GA
|0⟩
1
G
B
pE
˜GB
|0⟩
E
G
(3.26)
For the sake of simplicity, we will consider the case of E = X and G = X. With this choice, in the case A,
one has ˜G = 1X = X, and the gate is properly implemented. While the case B, one has ˜G = XX = 1, which
nullify the action of the original gate. Now, in the ideal case (E = 1 always), the state before the measurement",N/A,N/A
"is |ψ⟩= |1⟩, so the outcome is
⟨m⟩= Tr
h
ˆ
M ˆρ
i
= 1,
(3.27)
indeed, the probability of having m = 1 is p(m = 1) = 1. In the case with the environmental noise, one has
⟨m⟩=
X
m=0,1
m p(m),
= (1 −pE) + pE × 0,
= (1 −pE).
(3.28)
In particular, this result can be constructed as follows. Starting from the initial state |0⟩, we construct the
corresponding initial statistical operator ˆρ0. Then, with a probability pA = (1 −pE) evolves as in the case A,",N/A,N/A
"and with a probability pB = pE as in the case B. Namely, one has
ˆρ = pAˆρA + pBˆρB,
(3.29)
where
ˆρB = ˆσxˆρ0ˆσx,
and
ˆρB = ˆ1ˆρ0ˆ1.
(3.30)
This gives
ˆρ = (1 −pE) |1⟩⟨1| + pE |0⟩⟨0| ,
(3.31)
which, in the computational basis, is represented as
ρ =

pE
0
0 (1 −pE)

.
(3.32)
The corresponding expectation value of the measurement operator ˆ
M is
3.3 Measurement error
31
⟨m⟩= Tr
h
ˆ
M ˆρ
i
,
= Tr
0 0
0 1
 pE
0
0 (1 −pE)

,
= Tr

0
0
0 (1 −pE)

,
= (1 −pE),
(3.33)",N/A,N/A
"
,
= Tr

0
0
0 (1 −pE)

,
= (1 −pE),
(3.33)
as expected. Conversely, the polarisation is
⟨Z⟩= (2pE −1).
(3.34)
Applying the noisy gate d times, we find
⟨Z⟩= (2pE −1)d,
(3.35)
which is represented in Fig. 3.6.
Exercise 3.1
Verify the relation in Eq. (3.35).
0
20
40
60
80
100
-1.0
-0.5
0.0
0.5
1.0
circuit depth d
Measured <Z>
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
circuit depth d
|<Z>noisless-<Z>environment|",N/A,N/A
"0.8
circuit depth d
|<Z>noisless-<Z>environment|
Fig. 3.6: (Left panel) Expectation value (red dots) of the polarisation ⟨Z⟩for the circuit in Eq. (3.1) with respect
to the depth d of the circuit when the environment noise considered. (Right panel) Difference with respect to
the noiseless case. Here we considered pE = 0.007.
3.3.2 Global noise action
The last step of this section is to put together the different noises and errors discussed here. Namely, when one",N/A,N/A
"has a circuit, to account for the error, such a circuit needs to be substituted as represented
|0⟩
|0⟩

d
X
→
E
X
iRx(ϵ)
Sampling
Measurement
(3.36)
32
3 Noisy Intermediate-Scale Quantum (NISQ) computation
The action of the environment noise and miscalibration lead the qubit in the state
ˆρ = (1 −pE) |ψA⟩⟨ψA| + pE |ψB⟩⟨ψB| ,
(3.37)
where
|ψA⟩= cos

d (π+ϵ)
2

|0⟩−i sin

d (π+ϵ)
2

|1⟩,
|ψB⟩= cos
 d ϵ
2

|0⟩−i sin
 d ϵ
2

|1⟩.
(3.38)
Specifically, such a state can be rewritten as",N/A,N/A
"Specifically, such a state can be rewritten as
ˆρ = (ρ00 |0⟩⟨0| + ρ11 |1⟩⟨1| + ρ10 |1⟩⟨0| + ρ01 |0⟩⟨1|) ,
(3.39)
where the ρ00 and ρ11 populations are fundamental in computing the expectation value of the polarisation:
⟨Z⟩= ρ00 −ρ11,
= (1 −pE) cos (d(π + ϵ)) + pE cos (dϵ) .
(3.40)
On the other hand, to compute the effect of the sampling error, one needs only ρ11, which is equal to the
probability of having m = 1, i.e. of being in the state |1⟩. Thus, Eq. (3.17) becomes",N/A,N/A
"pd = (1 −pE)(1 −cos(d(π + ϵ)))
2
+ pE
(1 −cos(dϵ))
2
,
(3.41)
with respect to which one constructs the statistics of the outcomes that are distributed following a binomial
distribution B(pd).
Finally, the measurement error can be accounted by mapping the sampling means Sd in those accounting for
diagram in Eq. (3.19). This consists in
Sd →Sd + µ −(ν + µ)Sd.
(3.42)
The result of considering all the noises and errors is given by the right panel of Fig. 3.1.
Chapter 4
Quantum Error Correction",N/A,N/A
"Chapter 4
Quantum Error Correction
4.1 Quantum Error Correction
Several techniques have been developed to correct errors due to the presence of noise. This is not only a considered
issue in the quantum information context, but also in the classical one. In both cases, the key ingredient is the
redundancy.
Encoding
Recovery
Decoding
Errors
𝜓
0
{
0
0
0
𝜓
0
}
0
0
0
Fig. 4.1: Schematic representation of the Quantum Error Correcting approach.
4.1.1 Classical error correction",N/A,N/A
"4.1.1 Classical error correction
Consider the following example, that will make clear the usefulness of redundancies. We have Alice that wants
to send a single bit information to Bob. The communication channel is not perfect: a bit-flip error noise can act
on the bit with the following probabilities:
Alice sends the bit =
ϵ
(1−ϵ)
ϵ
(1−ϵ)
0
0
1
1
= is the bit the Bob receives.
(4.1)
With this scheme, the protocol has a probability of failing that is
Pfail = ϵ,
(4.2)
33
34",N/A,N/A
"Pfail = ϵ,
(4.2)
33
34
4 Quantum Error Correction
which is equal to the probability ϵ of the bit being flipped. The idea of error correction is to suitably modify
the protocol so one can recover the wanted information, with a failing probability being
Pfail < ϵ.
(4.3)
Specifically, what Alice does is to send the bit string 000 in place of only the single bit 0. This operation is
called encoding, and in this specific case, one encodes the classical information in the following way
0 →000,",N/A,N/A
"0 →000,
1 →111.
(4.4)
Then, Bob receives three bits and needs to decode the information. This is performed via a majority voting.
For example, let us assume the second bit is flipped while the other remain untouched: Bob receives 010, and
the majority voting gives
010 →0.
(4.5)
This is a decoding of the classical information. Considering all the possible three bits strings (A, B, C) that Bob
can receive if Alice sends 000, with the corresponding probabilities p(A, B, C), we have",N/A,N/A
"Alice encodes 0 in 000 →Bob receives
(A, B, C) p(A, B, C) decoded bit
(0, 0, 0)
(1 −ϵ)3
0
At most 1 error
(0, 0, 1)
ϵ(1 −ϵ)2
0
(0, 1, 0)
ϵ(1 −ϵ)2
0
Majority voting works
(1, 0, 0)
ϵ(1 −ϵ)2
0
(0, 1, 1)
ϵ2(1 −ϵ)
1
2 or more errors
(1, 0, 1)
ϵ2(1 −ϵ)
1
(1, 1, 0)
ϵ2(1 −ϵ)
1
Majority voting fails
(1, 1, 1)
ϵ3
1
(4.6)
The probability that the protocol fails is given by the sum of the probabilities of the failing cases:
Pfail = 3 × ϵ2(1 −ϵ) + e3 = 3ϵ2 −2ϵ3,
(4.7)
which is reported in Fig. 4.2.
0.0
0.2",N/A,N/A
"(4.7)
which is reported in Fig. 4.2.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
ϵ
Pfail
Fig. 4.2: Probability of failing Pfail for the single bit channel (dashed red line) and the three-bit classical
correcting code (blue line).
4.1 Quantum Error Correction
35
Specifically, for 0 ≤ϵ < 1/2, we have that Eq. (4.3) is satisfied. This means that by using this protocol one
has less probability to fail (pfail) rather than using a single bit (ϵ). Therefore, the redundancy is a good approach",N/A,N/A
"to reduce errors, as long as Eq. (4.3) is satisfied.
4.1.2 Quantum information context
The direct application of redundancy in the quantum information context encounters some important, although
not insurmountable, difficulties.
-
The no-cloning theorem (see Sec. 1.1) does not allow to create copies of an unknown quantum state. This
means that Alice cannot generate |ψ⟩|ψ⟩|ψ⟩to protect an unknown state |ψ⟩.
-",N/A,N/A
"-
The second difficulty comes in how the classical error correcting code operates: one measures the state of the
bit and applies a correcting operation accordingly. In the quantum case, the measurement operation would
destroy the coherence of the state and thus the information encoded in the state. To be more quantitative,
take the generic state |ψ⟩= α |0⟩+ β |1⟩. After the measurement, the state collapses in |0⟩or in |1⟩with the",N/A,N/A
"respective probabilities. However, one cannot reconstruct the coherence of the state after its collapse.
-
In classical information, the only possible error is a bit-flip: 0 →1 and 1 →0. Conversely, in quantum
information the class of possible noises is far wider. For example, the phase-flip maps α |0⟩+ β |1⟩→α |0⟩−
β |1⟩, and this does not have a classical counterpart. Moreover, in the quantum context, one can also have",N/A,N/A
"infinitesimal errors that can accumulate as the depth of the algorithm increases. An example can be α |0⟩+
β |1⟩→α |0⟩+ ˆRx(ϵ)β |1⟩, where ˆRx(ϵ) is a rotation of an infinitesimal angle ϵ around the x axis.
4.1.3 The 3-qubit bit-flip code
The first Quantum Error Correction (QEC) code we see is that correcting bit-flip errors. This is the counterpart
of that seen in the classical information context.",N/A,N/A
"Suppose Alice wants to send the generic state |ψ⟩= α |0⟩+β |1⟩to Bob via a bit-flip noisy channel. We assume
that the noise acts independently on each of the qubits that Alice sends. This is an important assumption for
the QEC codes we will see here. We assume that the noise leaves the qubit untouched with a probability (1−ϵ),
while it applies ˆσx with a probability ϵ. Indeed, ˆσx |0⟩= |1⟩and ˆσx |1⟩= |0⟩. This is essentially the quantum
version of what shown in Eq. (4.1).",N/A,N/A
"version of what shown in Eq. (4.1).
To protect the information from bit-flip errors, Alice employs the following encoding:
|0⟩→|0L⟩= |0⟩|0⟩|0⟩,
|1⟩→|1L⟩= |1⟩|1⟩|1⟩,
(4.8)
where |0⟩and |1⟩are physical qubits, while |0L⟩and |1L⟩are logical qubits. Then, the generic state |ψ⟩is
encoded in
|ψ⟩= α |0⟩+ β |1⟩→α |0L⟩+ β |1L⟩= α |000⟩+ β |111⟩,
(4.9)
with the notation |q1q2q3⟩= |q1⟩|q2⟩|q3⟩. This encoding can be implemented via the following circuit
|ψ⟩
|0⟩
|0⟩
|Ψ1⟩
(4.10)
Indeed, we have
36",N/A,N/A
"|ψ⟩
|0⟩
|0⟩
|Ψ1⟩
(4.10)
Indeed, we have
36
4 Quantum Error Correction
|ψ00⟩= α |000⟩+ β |100⟩
CNOT ⊗ˆ1
−−−−−−→α |000⟩+ β |110⟩
ˆ1⊗CNOT
−−−−−−→α |000⟩+ β |111⟩= |Ψ1⟩.
(4.11)
We underline that the entangled state |Ψ1⟩is not equal to |ψ⟩|ψ⟩|ψ⟩, so the no-cloning theorem is not violated.
Now, the state |Ψ1⟩is sent to Bob via the noisy channel. Bob receives one of the following states |Ψ2⟩with
the respective probabilities p(|Ψ2⟩):
Alice encodes |ψ⟩in |Ψ1⟩→Bob receives
|Ψ2⟩
p(|Ψ2⟩)",N/A,N/A
"|Ψ2⟩
p(|Ψ2⟩)
α |000⟩+ β |111⟩(1 −ϵ)3
At most 1 error
α |001⟩+ β |110⟩ϵ(1 −ϵ)2
α |010⟩+ β |101⟩ϵ(1 −ϵ)2
α |100⟩+ β |011⟩ϵ(1 −ϵ)2
α |011⟩+ β |100⟩ϵ2(1 −ϵ)
2 or more errors
α |101⟩+ β |010⟩ϵ2(1 −ϵ)
α |110⟩+ β |001⟩ϵ2(1 −ϵ)
α |111⟩+ β |000⟩
ϵ3
(4.12)
Let us suppose that Bob receives the state |Ψ2⟩= α |100⟩+ β |011⟩. To correct the bit-flip, Bob would be
tempted to perform a simultaneous measurement of the spin of the three qubits, i.e. ˆσ(1)
z ˆσ(2)
z ˆσ(3)
z . Such an",N/A,N/A
"z ˆσ(2)
z ˆσ(3)
z . Such an
operation would give as an outcome 100 with probability |α|2 and 011 with probability |β|2. Then, by applying
a majority voting, Bob would understand that the first qubit is flipped. However, the coherence of the state is
lost. Indeed, the measurement of the spin of the qubits collapses the state. To solve the problem, one needs to
perform the so-called error syndrome. In particular, Bob employs two ancillary qubits that are prepared in the",N/A,N/A
"|0⟩state and coupled to the qubits carrying the encoded state. The circuit implementing the correction then is
x0
x1
|0⟩
|0⟩
|Ψ2⟩
ˆU
(4.13)
To be quantitative, starting from |Ψ2⟩= α |100⟩+ β |011⟩, we have
|Ψ2⟩|00⟩= α |10000⟩+ β |01100⟩
CNOT1,4
−−−−−−→α |10010⟩+ β |01100⟩,
CNOT2,4
−−−−−−→α |10010⟩+ β |01110⟩,
CNOT1,5
−−−−−−→α |10011⟩+ β |01110⟩,
CNOT3,4
−−−−−−→α |10010⟩+ β |01111⟩,
= (α |100⟩+ β |011⟩) |11⟩.
(4.14)",N/A,N/A
"= (α |100⟩+ β |011⟩) |11⟩.
(4.14)
Fundamentally, the last two qubits are not entangled with the first three. Thus, the measurement on the last
two qubits does not impose the collapse of the first three. After such a measurement, Bob has the outcomes
x0 = 1 and x1 = 1. In particular, x0 = 1 indicates that one among the first and the second qubit has flipped.
Similarly, x1 = 1 indicates that one among the first and the third qubit has flipped. Then, Bob knows, under",N/A,N/A
"the assumption of single qubit errors, that the first qubit has flipped and can apply ˆU = ˆσ(1)
x
to flip it back.
In general, Bob will apply the following unitary operations to correct the errors:
4.1 Quantum Error Correction
37
x0 x1
ˆU
0
0
ˆ1
0
1 ˆσ(3)
x
1
0 ˆσ(2)
x
1
1 ˆσ(1)
x
(4.15)
After having applied the correction, Bob gets the state |Ψ3⟩with the following probabilities
|Ψ2⟩
|Ψ3⟩
p(|Ψ3⟩)
α |000⟩+ β |111⟩α |000⟩+ β |111⟩(1 −ϵ)3
α |001⟩+ β |110⟩α |000⟩+ β |111⟩ϵ(1 −ϵ)2",N/A,N/A
"α |001⟩+ β |110⟩α |000⟩+ β |111⟩ϵ(1 −ϵ)2
α |010⟩+ β |101⟩α |000⟩+ β |111⟩ϵ(1 −ϵ)2
α |100⟩+ β |011⟩α |000⟩+ β |111⟩ϵ(1 −ϵ)2
α |011⟩+ β |100⟩α |111⟩+ β |000⟩ϵ2(1 −ϵ)
α |101⟩+ β |010⟩α |111⟩+ β |000⟩ϵ2(1 −ϵ)
α |110⟩+ β |001⟩α |111⟩+ β |000⟩ϵ2(1 −ϵ)
α |111⟩+ β |000⟩α |111⟩+ β |000⟩
ϵ3
(4.16)
Finally, Bob applies the following decoding circuit
|ϕ⟩
|0⟩
|0⟩
|Ψ2⟩
(4.17)
which is the inverse of the circuit in Eq. (4.10). The final state |ϕ⟩is
|ϕ⟩= α |0⟩+ β |1⟩= |ψ⟩,
with probability",N/A,N/A
"|ϕ⟩= α |0⟩+ β |1⟩= |ψ⟩,
with probability
p = (1 −ϵ)3 + 3ϵ(1 −ϵ)2,
|ϕ⟩= α |1⟩+ β |0⟩= ˆσx |ψ⟩,
with probability
p = 3ϵ2(1 −ϵ) + ϵ3.
(4.18)
Thus, the failing probability of this QEC code is
Pfail = 3ϵ2 −2ϵ3,
(4.19)
which is the same as in the classical correcting algorithm seen previously and it is plotted in Fig. 4.2. Notably,
Bob does not learn anything about the weights α and β thought this QEC code. The coherence of the state
remains intact.
4.1.4 The 3-qubit phase-flip code",N/A,N/A
"remains intact.
4.1.4 The 3-qubit phase-flip code
Let us consider the case of the phase-flip noise, where the following error generates with a probability ϵ:
|0⟩→ˆσz |0⟩= |0⟩,
|1⟩→ˆσz |1⟩= −|1⟩.
(4.20)
Consequently, one has
|ψ⟩= α |0⟩+ β |1⟩→α |0⟩−β |1⟩.
(4.21)
38
4 Quantum Error Correction
Notably, this noise does not have a classical counterpart. Since the error is imprinted in the relative phase",N/A,N/A
"between |0⟩and |1⟩, the bit-flip QEC code developed in Sec. 4.1.3 does not correct this type of errors. However,
a phase-flip error in the computational basis { | 0⟩, | 1⟩} corresponds to a bit-flip error in the { | +⟩, | −⟩}
basis. Indeed,
ˆσz |+⟩= |−⟩,
ˆσz |−⟩= |+⟩.
(4.22)
Then, by simply adding a Hadamard gate, one changes basis and thus is able to employ the bit-flip QEC code
to correct phase-flip errors. This is done both in the encoding and the decoding parts of the code. The encoding",N/A,N/A
"circuit is then
|ψ⟩
|0⟩
|0⟩
H
|Ψ1⟩
H
H
(4.23)
while the deconding becomes
|ϕ⟩
|0⟩
|0⟩
|Ψ2⟩
H
H
H
(4.24)
The remaining parts of the code remain identical.
4.1.5 The 9-qubit Shor code
We saw how the 3-qubit bit-flip and phase flip QEC codes can correct respectively bit-flip and phase flip
errors. Here, we show that concatenating these two codes, one can protects for generic single qubit errors.",N/A,N/A
"Indeed, consider the situation of a single qubit initially prepared in the state |ψ⟩. Suppose it is coupled to
the surrounding enviroment, whose state is initially |e⟩, and that the latter entangles with the system. Such a
transformation is described as
|ψ⟩|e⟩→c0ˆ1 |ψ⟩|e0⟩+ c1ˆσx |ψ⟩|e1⟩+ c2ˆσy |ψ⟩|e2⟩+ c3ˆσz |ψ⟩|e3⟩,
(4.25)
where ci are suitable constants, and |ei⟩are states of the environment. Then, the state of the system is trans-",N/A,N/A
"formed via the application of the four Pauli operators. Here, ˆσ0 = ˆ1 does not imply any change in the state, so
no error needs to be corrected. The errors due to ˆσx and ˆσz are respectively corrected via bit-flip and phase-flip
QEC codes. It remains that due to ˆσy. However, one can notice that, since the Pauli matrices form a Lie algebra,
one can express ˆσy in terms of ˆσx and ˆσz. Namely, ˆσy = iˆσxˆσz. Then, one needs only to correct two consecutive",N/A,N/A
"errors (phase-flip and then bit-flip) to correct a bit-phase flip. The following QEC code is sufficient to perform
such a correction.
The encoding of the 9-qubit Shore code is given by
|0⟩→|0L⟩=
1
√
8 (|000⟩+ |111⟩) (|000⟩+ |111⟩) (|000⟩+ |111⟩) ,
|1⟩→|1L⟩=
1
√
8 (|000⟩−|111⟩) (|000⟩−|111⟩) (|000⟩−|111⟩) .
(4.26)
4.1 Quantum Error Correction
39
This implies the following encoding for a generic state |ψ⟩
|ψ⟩→α
√
8 (|000⟩+ |111⟩) (|000⟩+ |111⟩) (|000⟩+ |111⟩) + β
√",N/A,N/A
"√
8 (|000⟩−|111⟩) (|000⟩−|111⟩) (|000⟩−|111⟩) .
(4.27)
The encoding is implemented via the following circuit
|ψ⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
H
H
H
(4.28)
The action of the first two CNOT gates and three Hadamard in Eq. (4.28) is to map the qubits 1, 4 and 7
as follows:
|ψ00⟩= α |000⟩+ β |100⟩,
→α |000⟩+ β |110⟩,
→α |000⟩+ β |111⟩,
→α |+ + +⟩+ β |−−−⟩.
(4.29)
Namely, they perform the encoding for the phase-flip QEC code:
|0⟩→|+ + +⟩,
|1⟩→|−−−⟩.
(4.30)",N/A,N/A
"|0⟩→|+ + +⟩,
|1⟩→|−−−⟩.
(4.30)
Then, every |+⟩and |−⟩state in these qubits is further encoded with the last CNOT gates. Specifically, one has
|+00⟩=
1
√
2 (|000⟩+ |100⟩) ,
→
1
√
2 (|000⟩+ |110⟩) ,
→
1
√
2 (|000⟩+ |111⟩) ,
(4.31)
and
40
4 Quantum Error Correction
|−00⟩=
1
√
2 (|000⟩−|100⟩) ,
→
1
√
2 (|000⟩−|110⟩) ,
→
1
√
2 (|000⟩−|111⟩) .
(4.32)
These, effectively perform the encoding for the bit-flip QEC code. Such an encoding combines the phase-flip
and the bit-flip encoding.",N/A,N/A
"and the bit-flip encoding.
To extract the error syndrome, one employs a collective measurement, similarly as for the bit-flip. In partic-
ular, 8 ancillary qubits are employed to construct the following circuit
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
|0⟩
H
H
H
H
H
H
d0
d1
H
H
H
H
H
H
d2
d3
H
H
H
H
H
H
d4
d5
d6
d7
(4.33)
4.1 Quantum Error Correction
41
Here, the outcomes (d0, d1), (d2, d3) and (d4, d5) respectively indicate bit-flip errors within the first, second",N/A,N/A
"and third block of three physical qubits. Specifically, for the first block, one employs exactly what described in
Sec. 4.1.3.
The outcomes (d6, d7) are instead used to detect phase-flip errors of the logical state encoded with the three
blocks. The collective measurements to do this are
ˆσ(1)
x ˆσ(2)
x ˆσ(3)
x ˆσ(4)
x ˆσ(5)
x ˆσ(6)
x ,
ˆσ(1)
x ˆσ(2)
x ˆσ(3)
x ˆσ(7)
x ˆσ(8)
x ˆσ(9)
x ,
(4.34)",N/A,N/A
"x ˆσ(3)
x ˆσ(7)
x ˆσ(8)
x ˆσ(9)
x ,
(4.34)
which provide d6 and d7 respectively. If one gets, for example, (d6 = −1, d7 = −1), then a phase flip occurred
in the first block.
4.1.6 On the redundancy and threshold
As we saw, a fundamental step in the QEC codes is the redundancy of the state. Notably, there is no need in
having exactly 3 copies. It can be extended to any k copies, as long as k > 1 is an odd number. What one wants",N/A,N/A
"is that the probability Pfail that the QEC code fails is smaller than the probability ϵ of an error occurring on a
single physical qubit: Pfail < ϵ.
Consider the case of k physical qubits encoding a single logical qubit. Given the probability ϵ of having an
error on one of these qubits, that of having j qubits with errors is given by
p(j) = ϵj(1 −ϵ)k−j,
(4.35)
and there are
k
j

=
k!
(k −j)!j!,
(4.36)",N/A,N/A
"and there are
k
j

=
k!
(k −j)!j!,
(4.36)
different possible combinations. Then, Pfail is given by the sum over these when the faulty qubits are at least
half of the total. This is
Pfail =
k
X
j= (k+1)
2
k
j

ϵj(1 −ϵ)k−j.
(4.37)
Namely, for k = 3, one has
Pfail =
3
X
j= (3+1)
2
3
j

ϵj(1 −ϵ)3−j = 3ϵ2(1 −ϵ) + ϵ3.
(4.38)
The behaviour of Pfail for different values of k is shown in Fig. 4.3.",N/A,N/A
"However, one can consider an alternative approach. Instead of encoding a logical qubit just once in a large
number of physical qubits, one can concatenate encodings. One encodes the logical qubit in different levels,
where each level employs a small numeber of qubits. To be more explict, the following is the encoding of a single
physical qubit in a 2 level encoding with three qubits each:
|0⟩
first encoding
−−−−−−−−→|000⟩
second encoding
−−−−−−−−−−→|000⟩|000⟩|000⟩,
(4.39)",N/A,N/A
"−−−−−−−−−−→|000⟩|000⟩|000⟩,
(4.39)
and similarly for |1⟩. Now, with this encoding, the actual physical qubit is that in the highest level of encoding,
and this is that directly suffering from the noise. Suppose there is a probability ϵ that an error occurs on this
physical qubit. Then, at the level 1, the probability of failing, for example for the bit-flip QEC code, is
Pfail,1 = 3ϵ2 −2ϵ3.
(4.40)
42
4 Quantum Error Correction
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
ϵ
Pfail
ϵ
k=3
k=7",N/A,N/A
"0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
ϵ
Pfail
ϵ
k=3
k=7
k=11
k=15
k=19
Fig. 4.3: Probability of failing Pfail for the single bit channel (dashed red line) with respect to a redundant
encoding with k physical qubits (continuous lines).
This quantity is the probability that the noise corrupts a qubit at the level 1. Thus, when computing the
probability of failing for the qubit at level 0, the actual logical qubit, Pfail,1 needs to be interpreted as the",N/A,N/A
"probability ϵ1 that an error occurs on the qubit at the level 1. Then, at level 0, one has that the failing
probability is
Pfail,0 = 3P 2
fail,1 −2P 3
fail,1,
= 3[3ϵ2 −2ϵ3]2 −2[3ϵ2 −2ϵ3]3,
= 27ϵ4 −36ϵ5 −42ϵ6 + 108ϵ7 −72ϵ8 + 16ϵ9.
(4.41)
The question is then which is the best encoding. Figure 4.4 compares the failing probabilities Pfail for a single
level encoding with 9 physical qubits (blue line), where Eq. (4.37) gives
Pfail = 126ϵ5 −420ϵ6 + 540ϵ7 −315ϵ8 + 70ϵ9,
(4.42)",N/A,N/A
"(4.42)
and that for a 2 level encoding each with 3 qubits (red line). This is a fair comparison, as both the approaches
are employing the same number of physical qubits, i.e. n = 9.
To keep the discussion more general, suppose p is the probability of failing for a qubit with no encoding (this
is what we called ϵ until now). Then, the failing probability is
P (0)
fail = p.
(4.43)
Suppose that after one encoding the failing probability is
P (1)
fail = cp2,
(4.44)",N/A,N/A
"P (1)
fail = cp2,
(4.44)
where c is some suitable constant. In the case of the 3-qubit encoding, one had
Pfail = 3p2 −2p3 ∼3p2,
(4.45)
for small values of p. After 2 encodings, one has
P (2)
fail = c(cp2)2 = 1
c (cp)22.
(4.46)
After k encodings, one has
4.1 Quantum Error Correction
43
0.00
0.02
0.04
0.06
0.08
0.10
10-8
10-5
ϵ
Pfail
Fig. 4.4: Comparison of the failing probabilities Pfail for a single level encoding with 9 physical qubits (blue",N/A,N/A
"line) and that for a 2 level encoding each with 3 qubits (red line).
P (k)
fail = pth
 p
pth
2k
,
(4.47)
where we defined the threshold probability as
pth = 1
c .
(4.48)
Such a probability depends on varius parameters, among which the QEC code used, the physical components,
the experimental implementation of the QEC protocol etc.
The threshold probability pth is fundamental due to the following theorem.",N/A,N/A
"Theorem 4.1 (Threshold theorem). If a threshold probability pth exists, then it is always possible to correct
errors at a faster than they are created. It is sufficient to increase the level k of encoding.
Proof. The proof is trivial. As long as the the occurrence of an error on the physical qubit p = ϵ is smaller
than the threshold probability pth, then the ratio
p
pth
< 1,
(4.49)
and thus the quantity
 p
pth
2k
,
(4.50)
can be made suitably small by simply increasing k.",N/A,N/A
"The beauty of the threshold theorem is its simplicity. However, it also highlights a non-trivial problem, which
is the necessity of employing a very large number of physical qubits. It naturally follows the question: How
many physical qubits are necessary to quantum error correcting a faulty circuit?
Suppose we have N components (this is the number of qubits times the number of gates). Suppose for each",N/A,N/A
"of these components one needs R physical qubit accounting for QEC at the 1 level of encoding. Then, after k
levels of encoding there is a total of NRk qubits. Suppose we want that the entire circuit works with a failing
probability Pfail, circuit < ϵ, where ϵ is a given probability. Then, per component, we have
Pfail = pth
 p
pth
2k
< ϵ
N .
(4.51)
44
4 Quantum Error Correction
The question is then how many levels k of encoding are necessary? Or equivalently, how many physical qubits",N/A,N/A
"Rk per components are required? From the previous expression we obtain
2k ∼
log2

Npth
ϵ

log2

pth
p
 ,
(4.52)
which implies
Rk ∼


log2

Npth
ϵ

log2

pth
p



log2 R
.
(4.53)
Thus, the size of the full circuit scales as
NRk ∼poly

log Npth
ϵ

.
(4.54)
This is the quantitative result of the threshold theorem.
4.1.7 More layers of encoding or only more qubits
Until now, we worked under the assumption of having only noises that act independently on the physical qubits.",N/A,N/A
"Let us suppose now a different kind of noise map, that correlates the noise on different qubits. Specifically, we
consider a Kraus map acting on N qubits, that reads
T [ˆρ] =
1
N(N −1)
N
X
i̸=j
h
(1 −p)ˆρ + pˆσ(i)
x ˆσ(j)
x ˆρˆσ(j)
x ˆσ(i)
x
i
,
(4.55)
where there is a probability p that the noise acts on the qubits and the prefactor is required to properly nor-
malise the state.
First of all, let us introduce a graphical notation. Suppose we have three physical qubits, and the noise has",N/A,N/A
"acted on the first and second. Then, we denote this with the following scheme
Before the noise
After the noise
XX
(4.56)
Now, suppose we are performing the encoding with N = 3 qubits and k = 1 layer of encoding. If there are
no errors — this happens with probability (1 −p) — then physical qubits are
and correspond to a logical qubit
(4.57)
which is untouched by the noise. If there is one error, which corresponds to two qubits being affected with a",N/A,N/A
"probability p, then the physical qubits are in one of the following three states
XX
XX
X
X
X
(4.58)
that correspond to a logical qubit that is affected to the noise. Here, we denote decodings with horizontal arrows.
Thus, the protocol fails. These states contribute to the failing probability:
4.1 Quantum Error Correction
45
Pfail ∼3p,
(4.59)
where the factor 3 is given by the number of equivalent states at the physical level, namely those represented
graphically in the left side of Eq. (4.58).",N/A,N/A
"graphically in the left side of Eq. (4.58).
If there are two errors, which is a process involving a probability p2 and four qubits, one has the following 9
states:
XX XX
XX X
X
XX XX
X
X
X
X
X X
X X
X
X
X
X
X
X
XX
XX
XX
X
X
XX
(4.60)
which correspond to
X X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
(4.61)
as the application of an bit-flip error twice on the same qubit correspond to not having an error, i.e. ˆσ2
x = ˆ1.",N/A,N/A
"x = ˆ1.
In such a case, only some combination are faulty, while in others the errors have cancelled. Here, we denote
equivalence with vertical arrows. These states will contribute to Pfail with +6p2. Thus, one gets
Pfail = 3p + 6p2 + · · · ∼3p,
(4.62)
where the . . . indicate higher order errors. Nevertheless, is the lowest order term in p that is the most significant,
under the hypothesis of small error probabilities.",N/A,N/A
"Consider now a double encoding k = 2 with a total of N = 32 = 9 qubits. In case of no errors, prob = (1−p),
we have
layer 2
layer 1
layer 0
(4.63)
which do not contribute to Pfail. If there is one error, prob = p, we have
 9
2

= 36 states. Some states display
two affected physical qubits in different layer-1 logical qubit,
layer 2
layer 1
layer 0
X
X
(4.64)
Some have two physical qubits in the same layer-1 logical qubit. Thus, the corresponding layer-1 logical qubit",N/A,N/A
"fails, but the layer-0 logical qubit is still protected
46
4 Quantum Error Correction
layer 2
layer 1
layer 0
X
X
X
(4.65)
This is the worst-case scenario with one error. If there are two errors, prob = p2, the states that are relevant are
those that have 2 layer-1 logical qubits affected. Namely, they reproduce the same graph as that in Eq. (4.58).
For example, of the form
layer 2
layer 1
layer 0
X
X
X
XX
X
X
(4.66)",N/A,N/A
"layer 2
layer 1
layer 0
X
X
X
XX
X
X
(4.66)
At the layer-1, this correspond to a probability being 3p. For each of the layer-1 affected logical qubits, one
needs 2 layer-2 affected physical qubits, with associated a probability 3p. Thus, one has
Pfail = (3p)2 + · · · ∼9p2.
(4.67)
With generic k layers of encoding, one has
Pfail = (3p)k + . . . ,
(4.68)
which is graphically represented in Fig. 4.5, where the lines are listed at increasing values of k and condense
towards the value of pth = 1/3.",N/A,N/A
"towards the value of pth = 1/3.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
p
Pfail
k
pth
Fig. 4.5: Comparison of the failing probabilities Pfail for different k layers of encoding with 3 qubits each. The
arrow indicates the direction of increasing values of k, while the vertical black line indicates the threshold
probability pth.
4.2 Stabiliser formalism
47
Let us now consider the alternative. Instead of taking a large number of layers of encoding with just a few",N/A,N/A
"qubits per layer, we consider a large number of qubits on a single encoding layer.
For N = 3, a single error, i.e. having two physical qubits affected, is sufficient to make the encoding fail:
No error
1 error
X
X
X
(4.69)
where there are three different combinations (see Eq. (4.58)) that count. Thus, we have
Pfail ∼3p
(4.70)
For N = 5, one requires two errors, with four qubits affected, to make the encoding fail. Indeed,
No error
1 error
X
X
2 errors
X
XXX
X
(4.71)",N/A,N/A
"No error
1 error
X
X
2 errors
X
XXX
X
(4.71)
In such a case, the failing probability is given by
Pfail = 1
2
5
2
3
2

p2 + · · · ∼15p2,
(4.72)
where the first binomial chooses 2 qubits to affect among the available 5, the second binomial chooses 2 qubits
among the remaining 3. The factor one-half acconts for the simmetry between the first error and the second
one, i.e. between the first couple of affected qubits and the second one.",N/A,N/A
"Also for N = 7, one requires 2 errors, i.e. four affected qubits. Indeed
No error
1 error
X
X
2 errors
X
XXX
X
(4.73)
In such a case, we get
Pfail = 1
2
7
2
5
2

p2 + · · · ∼105p2.
(4.74)
Figure 4.6 compares failing probabilities of the encodings with different values of N. As one can see the knee of
the curves moves towards zero, meaning that the threshold does not exist.
Thus, for the error defined in Eq. (4.55), employing several layers of encoding can allow for a fault-tolerant",N/A,N/A
"quantum computing, while employing only a single layer encoding with more qubits has strong limits.
4.2 Stabiliser formalism
The stabiliser formalism exploits the fact that there exist operations, namely stabilisers, that can be used to
detect errors without changing the state of the logical qubit. While the single stabiliser can only tell if there
48
4 Quantum Error Correction
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
p
Pfail
N
pth",N/A,N/A
"0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
p
Pfail
N
pth
Fig. 4.6: Comparison of the failing probabilities Pfail for different values N of the qubits with a single layer
of encoding. The arrow indicates the direction of increasing values of N, while the vertical black dashed lines
indicate how the curves cannot define a threshold probability.
was an error, without establishing which error, a specific set of stabilisers can identify the specific errors that",N/A,N/A
"occurred, and thus providing the information to correct it.
4.2.1 Inverting quantum channels
The following scheme summarises the QEC philosophy. Given a qubit, this is encoded in a logical qubit made
of a set of physical qubits. The interaction with the surrounding environment (or other faulty components of
the physical circuit) leads to errors in the state. The action of these errors can be described in terms of a CPTP",N/A,N/A
"map. The QEC code applies a recovery CPTP map, which — up to a certain probability — gives back the same
initial state, as there were no errors, cf. Fig. 4.7.
Encoded 
information
Faulty 
information
Corrected 
information
Noises
CPTP map
QEC
Recovery
CPTP map
Fig. 4.7: Schematic representation of the QEC scheme, where a recovery CPTP map is applied to recover the
information as there were no errors.
The question is: when is this possible?",N/A,N/A
"The question is: when is this possible?
Consider two CPTP maps E and R, which describe respectively the occurrence of environmental errors and
the recovery map. Their action is
B(H)
E−→B(H′)
R
−→B(H′′),
(4.75)
where B(H) is the space of all the linear operators acting on H. We want to have no effects of the errors,
i.e. R ◦E = id.
4.2 Stabiliser formalism
49
Now, we show that the following two statements are equivalent:
1) Given a CPTP map E, it exists another CPTP map R such that R ◦E = id.",N/A,N/A
"2) For any Kraus representation of E, which is defined through the set of Kraus operators ˆEi, then one has that
ˆE†
i ˆEj = µijˆ1,
(4.76)
where µij ∈C are the coefficients of the density matrix of the environment imposing the map E. Namely,
ˆµ =
X
ij
µij |ei⟩⟨ej| .
(4.77)
First, we prove that 1) implies 2). Consider |ψ⟩∈H, to which we apply the map E. This gives
|ψ⟩
E−→
X
j
ˆEj |ψ⟩|ej⟩,
(4.78)",N/A,N/A
"|ψ⟩
E−→
X
j
ˆEj |ψ⟩|ej⟩,
(4.78)
where |ej⟩is the state of the environment with which the system is entangling. Now, we apply the map R:
R
−→
X
jk
ˆRk ˆEj |ψ⟩|ej⟩|ak⟩,
(4.79)
where |ak⟩is the state of an ancilla, whose interaction defines the map R. Since we want that the map R works
as a recovery map for the map E, we have to impose that
X
jk
ˆRk ˆEj |ψ⟩|ej⟩|ak⟩= |ψ⟩⊗(. . . ),
(4.80)
where (. . . ) is a suitable state of the environment and the ancilla. In this way, the entanglement between the",N/A,N/A
"system and the environment is transferred to the environment and the ancilla, with no correlation to the state
of the system. This is possible only if
ˆRk ˆEj = αkjˆ1.
(4.81)
In such a case, one has that (. . . ) = P
jk αkj |ej⟩|ak⟩and
ˆE†
i ˆEj =
X
k
ˆE†
i ˆR†
k ˆRk ˆEj,
=
X
k
α∗
kiαkjˆ1,
(4.82)
where we used that
X
k
ˆR†
k ˆRk = ˆ1.
(4.83)
Then, we can define
µij =
X
k
α∗
kiαkj.
(4.84)
Notably, we have that µ∗
ji = µij, indeed
µ∗
jiˆ1 = (µijˆ1)† = ( ˆE†
i ˆEj)† = ˆE†
j ˆEi = µijˆ1.
(4.85)",N/A,N/A
"i ˆEj)† = ˆE†
j ˆEi = µijˆ1.
(4.85)
Moreover, we have that
X
i
µiiˆ1 =
X
i
ˆE†
i ˆEi = ˆ1,
(4.86)
50
4 Quantum Error Correction
and that
µiiˆ1 = ˆE†
i ˆEi,
(4.87)
is a positive operator, which implies that µii > 0. Thus, { µij }ij have all the properties to be the coefficients of
a density matrix, and this proves that 1) implies 2).
We now prove that 2) implies 1). We start from
ˆE†
i ˆEj = µijˆ1,
(4.88)",N/A,N/A
"ˆE†
i ˆEj = µijˆ1,
(4.88)
and we diagonalise µij. This implies a change the Kraus operators according to ˆEi →ˆFi such that
ˆF †
i ˆFj = δijpiˆ1,
(4.89)
where pi > 0 by definition. We then introduce the isometries ˆVi that are related to ˆFi via
ˆFi = √pi ˆVi.
(4.90)
Then, as represented in Fig. 4.8, the map E is mapping H to different subspaces H′
i of H′. Each of these
ℍ
ℍ’
𝑝! ""𝑉!
𝑝"" ""𝑉""
𝑝# ""𝑉#
𝑝$ ""𝑉$
ℍ!
ℍ""
ℍ#
ℍ$
Fig. 4.8: Graphical representation of the mapping between H and H′.",N/A,N/A
"mapping is performed with a probability pi by the operator ˆVi ∝ˆFi. Notably, since we diagonalised µij, the
different operators ˆVi are orthogonal, and thus are also the subspaces H′
i. Now, given this set of isometries, we
can construct the recovery Kraus operators as
ˆRi = ˆV †
i ,
(4.91)
which will act only on the corresponding subspace H′
i, leaving the rest of Hilbert space H′ untouched: indeed,
for i ̸= j we have ˆV †
j Fj ∝ˆV †
j Vj = 0. Finally, we compose the maps E and R:
ˆρ",N/A,N/A
"ˆρ
E−→E(ˆρ) =
X
i
pi ˆViˆρ ˆV †
i ,
R
−→R(E(ˆρ)) =
X
j
ˆV †
j
 X
i
pi ˆViˆρ ˆV †
i
!
ˆVj,
=
X
ij
pi ˆV †
j ˆViˆρ ˆV †
i ˆVj,
=
X
i
piˆρ = ˆρ,
(4.92)
4.2 Stabiliser formalism
51
where we used that ˆV †
j ˆVi = δijˆ1.
4.2.2 Correctable errors
The generic scheme for QEC is the following. We are given k qubits in an unknown state |ψ⟩∈H. We encode
|ψ⟩in a larger number n > k of qubits. These n qubits are subject to errors, which are described in terms of",N/A,N/A
"a Kraus map E with the Kraus operators being ˆEi or equivalently ˆVi, see Eq. (4.90). The recovery protocol
employs some extra n′ ancillary qubits to apply the QEC, which inverts the error Kraus map under certain
conditions.
After the encoding, the relevant state will be |ψ′⟩∈HC, which is a subspace of H′ and it is called code space.
In particular, the entire Hilbert space H′ is the union of the code space HC with the ⊗iH′
i. Here, the basis of
each H′",N/A,N/A
"i. Here, the basis of
each H′
i is obtained by applying the corresponding ˆVi to the basis of HC. Under this perspective, one can say
that also the basis of HC is generated in the same way, where the corresponding error operator is ˆVC = ˆ1. Now,
since the subspace H′
i so constructed is orthogonal to HC, then the error can be recovered. What is needed is
a error syndrome measurement that identifies the subspace H′
i in which the state |ψ′⟩has been mapped. Given",N/A,N/A
"i in which the state |ψ′⟩has been mapped. Given
such a measurement, one can apply the corresponding Kraus recovery operator. This is graphically represented
in Fig. 4.9
ℍ
ℍ’
Encoding
ℍ!
!𝑉!
ℍ""
!𝑉""
ℍ#
ℍ$
ℍ%
ℍ&
ℍ'
ℍ(
ℍ…
Fig. 4.9: Graphical representation of the division of the Hilbert space H′ in the code space H and error spaces
Hi, which are linked by the operators ˆVi.
One can invert the error map if the corresponding operators ˆEi satisfy
ˆP ˆE†
i ˆEj ˆP = µij ˆP,
(4.93)",N/A,N/A
"ˆP ˆE†
i ˆEj ˆP = µij ˆP,
(4.93)
where ˆP is a projector on the code space HC.
Notably, ˆP acts as an identity operator if restricted on HC. This also implies that there exists a special set
of Kraus operators, which allow to rewrite the error map, and thus also the recovery map, as a mixture of
isometries. These are induced by a set of unitary operators ˆUi on the code space:
ˆVi = ˆUi ˆP,
(4.94)
such that
ˆP ˆU †
i ˆUj ˆP = δij ˆP.
(4.95)
52
4 Quantum Error Correction",N/A,N/A
"(4.95)
52
4 Quantum Error Correction
Then, one can map the state ˆVi |ψ′⟩back to HC by selecting the corresponding recovery Kraus operator ˆRi = ˆV †
i .
An important note is the following. Let be R the recovery map for E. Then, one has
E(ˆρ) =
X
i
ˆEiˆρ ˆE†
i ,
R(ˆρ) =
X
k
ˆRk ˆρ ˆR†
k,
(4.96)
such that ˆRk ˆEi = αkiˆ1. We define the map D as
D(ˆρ) =
X
i
ˆDiˆρ ˆD†
i ,
(4.97)
with ˆDi appertaining to the span of { ˆEi }i, i.e. ˆDi = P
j cij ˆEj. Then, the map D can be recovered with the",N/A,N/A
"same recovery map R.
Consider the case of n qubits . We want to construct the recovery map for errors due to the application of
the Pauli operators. These are { ˆ1, ˆσx, ˆσy, ˆσz }
⊗n, and they form the basis of B(H⊗n). The operator ˆ1 is the
identity, so is not associated to any error. The operator ˆσy = iˆσxˆσz. So, one needs to construct the recovery
map R that corrects only errors due to ˆσx and ˆσz. Now, for every Pauli operator different from the identity, we",N/A,N/A
"have two important properties: Tr [ˆσi] = 0 and ˆσ2
i = ˆ1. They imply that their eigenvalues are ±1. Thus, one can
divide the full Hilbert space H′ = H, with dim(H) = 2n, in two subspaces (of the same dimension), which are
associated to the corresponding eigeinvalues, see Fig. 4.10. Namely, given ˆσi we have Hσi=1 and Hσi=−1, with
dim(Hi) = 2n−1, whose union gives H′. Suppose the code space HC is defined in terms of the operators ˆE1 and
ˆE2 as it follows: ∀|ψ⟩∈HC, one has
ˆE1 |ψ⟩= +1 |ψ⟩,
and",N/A,N/A
"ˆE1 |ψ⟩= +1 |ψ⟩,
and
ˆE2 |ψ⟩= +1 |ψ⟩.
(4.98)
Any other combination identifies an error subspace H′
i.
ℍ’
ℍ!
ℍ""
ℍ#
ℍ$
!𝐸!
!𝐸""
+1
−1
+1
−1
(+1, +1)
(−1, +1)
(+1, −1)
(−1, −1)
Fig. 4.10: Division of the Hilbert space H′ with respect to the subspaces defined by the eigeinvalues of ˆE1 and
ˆE2.
More in general, given the operators in B(H), they are part of one of the following families:
-
They specify the subspaces we are going to divide H′.
4.2 Stabiliser formalism
53
-",N/A,N/A
"4.2 Stabiliser formalism
53
-
They are responsible for errors. So they describe how a state moves from HC to H′
i.
-
They are responsible for logical operations within the individual subspaces HC and Hi.
4.2.3 Stabilisers
For n qubits, one has 4 × 4n Pauli operators. The first factor 4 accounts for the four relevant phases
{ +1, −1, +i, −i }, while the rest count the operators being the basis of the operators acting on a 2n dimensional",N/A,N/A
"space. We define as stabilisers the elements of an abelian subgroup which is responsible of the division of H′ in
subspaces. Namely, there will be one code space HC and the other are the error spaces.
Example 4.1
Consider the case of n = 3. The stabilisers are
(Stabilisers for n = 3) = { ˆ1ˆ1ˆ1, ˆσzˆσzˆ1, ˆ1ˆσzˆσz, ˆσzˆ1ˆσz } .
(4.99)
Consider ˆσzˆσzˆ1. It determines the parity of the first and the second qubit. Thus, it divides the Hilbert space",N/A,N/A
"H′ in two parts, one associated to its +1 eigeinvalue and to its −1 eigeinvalue:
+1
−1
|000⟩|100⟩
|111⟩|011⟩
|001⟩|010⟩
|110⟩|101⟩
(4.100)
A similar division can be done considering the operator ˆ1ˆσzˆσz, for which we have
+1
−1
|000⟩|001⟩
|111⟩|110⟩
|100⟩|010⟩
|011⟩|101⟩
(4.101)
We notice that there are no other possible partitions of H′. Indeed, the last non-trivial stabilisers is ˆσzˆ1ˆσz
can be expressed as the product of the other two:
ˆσzˆ1ˆσz = (ˆσzˆ1ˆσz)(ˆσzˆσzˆ1).
(4.102)",N/A,N/A
"ˆσzˆ1ˆσz = (ˆσzˆ1ˆσz)(ˆσzˆσzˆ1).
(4.102)
To be specific, the operators ˆσzˆ1ˆσz and ˆσzˆσzˆ1 are the generators of the abelian subgroup of the stabilisers.
Now, we can define the code space HC as that associated to the +1 eigeinvalues for all the stabilisers.
Namely, this is the subspace of H′ which is spanned by the +1 eigeinstates of all the generators of the
abelian subgroup:
HC = span(|000⟩, |111⟩).
(4.103)
The partitioning of H′ is represented graphically in Fig. 4.11.",N/A,N/A
"Now, consider ˆEi being one of the 4 × 4n Pauli operators not being one of the stabilisers Sk. Now, since it
is constructed as the product of single qubit Pauli operators, ˆEi can only commute or anticommute with the
stabilisers Sk.
• Assume that it commutes:
h
ˆEi, ˆSk
i
= 0. Then, we have that for any |ψ⟩∈HC, it holds
54
4 Quantum Error Correction
ℍ’
ℍ!
ℍ""
ℍ#
ℍ$
!𝑍!𝑍!𝐼
+1
−1
+1
−1
000
|111⟩
100
|011⟩
001
|110⟩
010
|101⟩
!𝐼!𝑍!𝑍",N/A,N/A
"−1
000
|111⟩
100
|011⟩
001
|110⟩
010
|101⟩
!𝐼!𝑍!𝑍
Fig. 4.11: Division of the Hilbert space H′ with respect to the subspaces defined by the eigeinvalues of ˆσzˆσzˆ1
and ˆ1ˆσzˆσz.
ˆSk ˆEi |ψ⟩= ˆEi ˆSk |ψ⟩= ˆEi |ψ⟩,
(4.104)
where the last equality follows from the fact that Sk is a stabiliser and thus acts as an identity on HC. Then, if
ˆEi commutes stabiliser ˆSk, it is associated to the eigeinvalue +1 of the latter. Indeed, the state |ϕi⟩= ˆEi |ψ⟩
is associated to the +1 eigeinvalue of ˆSk.",N/A,N/A
"is associated to the +1 eigeinvalue of ˆSk.
• Conversely, if it anticommutes:
n
ˆEi, ˆSk
o
= 0, then
ˆSk ˆEi |ψ⟩= −ˆEi ˆSk |ψ⟩= −ˆEi |ψ⟩.
(4.105)
In such a case, one says that ˆEi is associated to the -1 eigeinvalue of Sk.
Example 4.2
In the case of n = 3 one has that the operators ˆσxˆ1ˆ1 and ˆσxˆσxˆσx are associated to the eigenvalues of ˆσzˆσzˆ1
and ˆ1ˆσzˆσz as
ˆσzˆσzˆ1 ˆ1ˆσzˆσz
ˆσxˆ1ˆ1
−1
+1
ˆσxˆσxˆσx
+1
+1
(4.106)",N/A,N/A
"ˆσxˆ1ˆ1
−1
+1
ˆσxˆσxˆσx
+1
+1
(4.106)
Now, ˆσxˆσxˆσx commutes with both the (generators of the subgroup of) stabilisers. Thus, it means that if
|ψ⟩∈HC,
then
ˆσxˆσxˆσx |ψ⟩∈HC.
(4.107)
Namely, it is a normaliser (see below) and it acts as a logical ˆσx.
Conversely, ˆσxˆ1ˆ1 anticommutes with ˆσzˆσzˆ1. This means that given a state
|ψ⟩∈HC,
then
ˆσxˆ1ˆ1 |ψ⟩∈H′
1 ∪H′
3,
(4.108)
where H′
1 and H′
3 are respectively associated to the eigeinvalues (−1, +1) and (−1, −1) of (ˆσzˆσzˆ1, ˆ1ˆσzˆσz).",N/A,N/A
"However, since ˆσxˆ1ˆ1 commutes with ˆ1ˆσzˆσz, then ˆσxˆ1ˆ1 |ψ⟩∈H′
1.
Namely, the operator ˆσxˆ1ˆ1 is one of the ˆVi errors that maps the states from the code space to the
corresponding H′
i.
4.2 Stabiliser formalism
55
If we have k qubits that are encoded in n qubits, with n > k, then we need (n −k) generators from the
stabilisers to define the partitions. By starting with dim(H′) = 2n, since each generator divides the Hilbert space",N/A,N/A
"in two parts, we have 2n−k different subspaces of dimension 2k.
4.2.4 Normalisers and Centralisers
There are Pauli operators that commute with all the elements of the stabilisers, but do not appartain to the
stabilisers subgroup. These are the normalisers ˆNk. They respect the partition of H, meaning that they do not
map states from the code space HC to an error space H′
i, and act non-trivially in the code space. They are
defined via
ˆNk ˆSi ˆN †
k = ˆSj,
(4.109)",N/A,N/A
"defined via
ˆNk ˆSi ˆN †
k = ˆSj,
(4.109)
where ˆSi are the stabilisers. If i = j they are called centralisers, while for i ̸= j they are normalisers. In the
particular case of the Pauli algebra, meaning that all the operators are generated by the product of Pauli
operators, one has that the normalisers are centralisers. Indeed,
ˆNk ˆSi ˆN †
k = ± ˆNk ˆN †
k ˆSi = ± ˆSi,
(4.110)
since Pauli operators can only commute or anticommute. However, given the stabilisers ˆSi, the operator −ˆSi",N/A,N/A
"does not stabilise the code space. Thus, the −sign cannot be accepted and one gets
ˆNk ˆSi ˆN †
k = ˆSi = ˆSj.
(4.111)
Thus, they are all centralisers.
Example 4.3
Consider the case of n = 3. The operator ˆσxˆσxˆσx acts as follows:
|000⟩
ˆσx
−→|111⟩,
|111⟩
ˆσx
−→|000⟩.
(4.112)
Thus, it acts as a logical ˆσx. The same happens for ˆσxˆσxˆσx ˆSk for any stabiliser ˆSk. Indeed, for |ψ⟩∈HC,
we have that
ˆσxˆσxˆσx ˆSk |ψ⟩= ˆσxˆσxˆσx |ψ⟩,
(4.113)",N/A,N/A
"ˆσxˆσxˆσx ˆSk |ψ⟩= ˆσxˆσxˆσx |ψ⟩,
(4.113)
since ˆSk acts as a logical identity on HC. Suppose we take the stabiliser ˆSk = ˆσzˆσzˆ1, then
(ˆσxˆσxˆσx)(ˆσzˆσzˆ1) = −ˆσyˆσyˆσx,
(4.114)
which also acts as a logical ˆσx.
The normalisers contain ˆσxˆσxˆσx, −ˆσyˆσyˆσy, ˆσzˆσzˆσz, and all the products of these with all the stabilisers
ˆSk, which act as a logical identity.
56
4 Quantum Error Correction
Physical operation Logical operation
ˆ1ˆ1ˆ1
ˆ1
ˆσzˆσzˆ1
ˆ1
ˆσzˆ1ˆσz
ˆ1
ˆ1ˆσzˆσz
ˆ1
ˆσxˆσxˆσx
ˆσx",N/A,N/A
"ˆσzˆσzˆ1
ˆ1
ˆσzˆ1ˆσz
ˆ1
ˆ1ˆσzˆσz
ˆ1
ˆσxˆσxˆσx
ˆσx
ˆσxˆσxˆσx ˆSk
ˆσx
−ˆσyˆσyˆσy
ˆσy
−ˆσyˆσyˆσy ˆSk
ˆσy
ˆσzˆσzˆσz
ˆσz
ˆσzˆσzˆσz ˆSk
ˆσz
(4.115)
4.2.5 Stabiliser code
Consider the three qubits encoding a single logical qubit. The stabilisers are:
ˆ1ˆ1ˆ1,
ˆσzˆσzˆ1,
ˆσzˆ1ˆσz,
ˆ1ˆσzˆσz.
(4.116)
Among the possible errors, there are some that are more and less likely to occur. Under the assumption of errors",N/A,N/A
"that act independently on the qubits, the error ˆ1ˆσxˆ1 is more likely to occur than ˆσxˆσxˆσx. The first has weight
1 (only one operator different from the identity), while the second has weight 3.
Now, the question is which are the errors that can be corrected, and eventually how they can be corrected.
As we already saw, the errors where only one of the qubits is modified can be corrected (see bit-flip, phase-flip",N/A,N/A
"and 9-qubit Shor QEC codes). These can be corrected via the application of the recovery operator ˆRk = ˆV †
k , so
that
ˆRk ˆVk = ˆV †
k ˆVk = ˆ1.
(4.117)
However, the operator ˆRk can correct for a much wider class of operators. Indeed, given a state |ψ⟩∈HC and
a stabiliser ˆSi, one has
ˆRk( ˆVk ˆSi) |ψ⟩= ˆRk ˆVk |ψ⟩= |ψ⟩.
(4.118)
Thus, ˆRk can correct also errors of the form of a correctable error multiplied by a stabiliser, i.e. ˆVk ˆSi.",N/A,N/A
"Conversely, an error in the class of normalisers which is not a stabiliser is a non-correctable error. Indeed, it
acts non-trivially on the code space.
4.3 Surface code
The surface code is a QEC code that is related to topology. The idea is that a logical qubit is encoded in L × L
physical qubits as in the layout presented in Fig. 4.12. The array they construct has to be considered with
periodic boundary conditions. The L2 qubits are divided in two classes:",N/A,N/A
"• Half of the physical qubits are used as data qubits: they store quantum states |ψL⟩that will be used for
computation. They are represented with open circles .
• Half of the physical qubits are called measurement qubits and they are employed as error detecting qubits.
They are represented with full circles . There are two type of measurement qubits:
– Measure Z or Z-syndrome qubits, which are represented in green,
– Measure X or X-syndrome qubits, which are represented in yellow.",N/A,N/A
"4.3 Surface code
57
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
Z
X
Fig. 4.12: Graphical representation of the L2 physical qubits (full and open circles) in the array generating the
surface code through their interaction (green and yellow connections).",N/A,N/A
"Each data qubit is coupled to two X-syndrome and two Z-syndrome qubits. Each measurement qubit is coupled
to four data qubits. These couplings are describe as the following. For the green block, i.e. the Z-syndrome, we
have
a
b
c
d
Z
Z
Z
Z
=
|0 ⟩
|ψabcd⟩
(4.119)
where |0 ⟩indicates that the qubit
has been initiallised in |0⟩. Similarly, for the yellow block one has
X
X
X
X
a
b
d
c
=
|0 ⟩
|ψabcd⟩
H
H
(4.120)",N/A,N/A
"X
X
X
X
a
b
d
c
=
|0 ⟩
|ψabcd⟩
H
H
(4.120)
In such a way, the measurement qubits are coupled to the data qubits. These circuits are run in cycles, between
one logical operation and the following one, so to keep track of the errors that occur in between.
To understand the logic of the surface code, let us focus on the case where one has only four physical qubits:
2 are data qubits and 2 are measurement qubits (one in X and one in Z). The generators of the stabilisers are
58",N/A,N/A
"58
4 Quantum Error Correction
the operators ˆXa ˆXb and ˆZa ˆZb. Here, we employ the notation ˆZi to identify the ˆσ(i)
z
Pauli operator acting on
the i-th physical qubit. One can easily show that these operators commute, i.e.
h
ˆXa ˆXb, ˆZa ˆZb
i
= 0, although
they do not at the level of single qubit, i.e.
h
ˆXi, ˆZi
i
̸= 0. Thus, they have common eigeinstates, which identify
the division of the Hilbert space H′ in the code and error subspaces (for the sake of simplicity, we will drop all",N/A,N/A
"the normalisation constants):
|ψ⟩
ˆXa ˆXb ˆZa ˆZb
|00⟩+ |11⟩
+1
+1
|00⟩−|11⟩
−1
+1
|01⟩+ |10⟩
+1
−1
|01⟩−|10⟩
−1
−1
(4.121)
The circuit that applies these two stabilisers is
a
b
Z
Z
X
X
Z
X
=
|0 ⟩
|0 ⟩
X
H
H
a
|ψab⟩
|ψ′
ab⟩
b
Z
(4.122)
where the first qubit is the X-syndrome and the last is the Z-syndrome. Considering the generic state |ψab⟩for
the qubits a and b being
|ψab⟩= A |00⟩+ B |01⟩+ C |10⟩+ D |11⟩,
(4.123)",N/A,N/A
"|ψab⟩= A |00⟩+ B |01⟩+ C |10⟩+ D |11⟩,
(4.123)
one can input this state in the circuit in Eq. (4.122) and, before the measurements, obtains that the total state
reads
|ΨXabZ⟩= (A + D) |0⟩(|00⟩+ |11⟩) |0⟩
+ (A −D) |1⟩(|00⟩−|11⟩) |0⟩
+ (B + C) |0⟩(|01⟩+ |10⟩) |1⟩
+ (B −C) |1⟩(|01⟩−|10⟩) |1⟩.
(4.124)
It follows that, after the measurement of the X and Z-syndrome qubits, one obtains — depending on the
outcomes { MX, MZ } — the following states with the corresponding probabilities P|ψ′
ab⟩:",N/A,N/A
"ab⟩:
{ MX, MZ }
|ψ′
ab⟩
P|ψ′
ab⟩
{ +1, +1 } |00⟩+ |11⟩|A + D|2
{ −1, +1 } |00⟩−|11⟩|A −D|2
{ +1, −1 } |01⟩+ |10⟩|B + C|2
{ −1, −1 } |01⟩−|10⟩|B −C|2
(4.125)
After the collapse on one of these common eigenstates of ˆXa ˆXb and ˆZa ˆZb, subsequent applications of the circuit
in Eq. (4.122) will provide always — in the assumption of no noise — the same state.
Example 4.4
Consider the state in Eq. (4.124) and suppose the first cycle (which acts effectively as an encoding) provides",N/A,N/A
"the measurements { MX = −1, MZ = −1 } and |ψ′
ab⟩= |01⟩−|10⟩. Now, |ψ′
ab⟩is equal to |ψab⟩in Eq. (4.123)
when setting A = D = 0 and B = −C = 1. The corresponding output state at the end of the second cycle
before the measurement will be |ΨXabZ⟩= |1⟩(|01⟩−|10⟩) |1⟩. This has two important implications: 1) the
4.3 Surface code
59
state |ψ′
ab⟩remains untouched by the circuit, which is the implementation of the stabilisers: ˆS2 ˆS1 |ψ′
ab⟩=
|ψ′",N/A,N/A
"ab⟩=
|ψ′
ab⟩; 2) also the output of the measurement { MX = −1, MZ = −1 } remains the same.
This example shows that, without measuring directly |ψ′
ab⟩, one can use the output of the measurements to
infer the state of the data qubits. Turning the argument upside-down, an error occuring in the data qubits will
be identified by the change in the outcomes of the measurements.
We notice that, in the case of 2 data qubits and 2 measurement qubits, one has",N/A,N/A
"• 4 degrees of freedom where to encode a logical state: there are 2 physical qubits having 2 dimensions. The
total Hilbert space H′ has 2 × 2 dimensions.
• 4 constrains from the stabilisers: we have 2 stabilisers and each divides H′ in 2 subspaces.
Then, there are no free degrees of freedom where one can perform logical operations. In order to do that, one
needs to impose the length of the array of physical qubits L being an odd number > 1. In such a way, one has",N/A,N/A
"2 free degrees of freedom that can be employed. The minimal array is that having L = 3 with 5 data qubits
and 4 measurement qubits. Such an array in shown in Fig. 4.13. The circuit corresponding to the stabilisers
Fig. 4.13: Graphical representation of the surface code with 5 data qubits and 4 measurement qubits.
application is given by
|0 ⟩
|0 ⟩
|0 ⟩
|0 ⟩
a
|ψacegi⟩
|ψ′
acegi⟩
c
e
g
i
b,Z
d,X
H
H
f,X
H
H
h,Z
(4.126)",N/A,N/A
"acegi⟩
c
e
g
i
b,Z
d,X
H
H
f,X
H
H
h,Z
(4.126)
Suppose we input the state |ψacegi⟩= |00000⟩. Then, the action of this circuit before the measurement is given
by
60
4 Quantum Error Correction
|00000, 0000⟩
circuit in Eq. (4.126)
−−−−−−−−−−−−−→
(|00000⟩+ |10110⟩+ |01101⟩+ |11011⟩) |0000⟩
+(|00000⟩−|10110⟩+ |01101⟩−|11011⟩) |0100⟩
+(|00000⟩−|10110⟩−|01101⟩+ |11011⟩) |0010⟩
+(|00000⟩−|10110⟩−|01101⟩+ |11011⟩) |0110⟩,
(4.127)",N/A,N/A
"(4.127)
where we expressed the states in the form |ψacegi, ϕbdfh⟩. Suppose the measurement results in { Mb, Md, Mf, Mh } =
{ +1, +1, −1, +1 }, which corresponds to the measurement state |ϕbdfh⟩= |0010⟩. Then, the data state is given
by
|data⟩= |ψ′
acegi⟩= |00000⟩−|10110⟩−|01101⟩+ |11011⟩,
(4.128)
which remains untouched by subsequent applications of the circuit in Eq. (4.126). This is an easy but lengthy",N/A,N/A
"computation if performed in terms of states. However, it becomes trivial and immediate if considering that the
circuit corresponds to the application of the stabilisers ˆS4 ˆS3 ˆS2 ˆS1 on the state |data⟩, which has been already
stabilised by the same circuit. Thus, ˆS4 ˆS3 ˆS2 ˆS1 |data⟩= |data⟩.
4.3.1 Detecting errors
There are several kinds of errors that can be detected with surface code. For the sake of simplicity, we consider",N/A,N/A
"the case of the array with 5 data and 4 measurement qubits, and that the logical state is encoded in |data⟩
shown in Eq. (4.128). The latter corresponds to the measurement state |0010⟩, i.e. to the measurement outcomes
{ Mb, Md, Mf, Mh } = { +1, +1, −1, +1 }. We construct the table of outcomes with respect to the number of
cycles that are performed. In the case of no errors and no logical operations, such table reads
# cycles Mb Md Mf Mh
1
+1 +1 −1 +1
2
+1 +1 −1 +1
3
+1 +1 −1 +1
4
+1 +1 −1 +1
5",N/A,N/A
"2
+1 +1 −1 +1
3
+1 +1 −1 +1
4
+1 +1 −1 +1
5
+1 +1 −1 +1
...
...
...
...
...
(4.129)
We now introduce errors, that will appear exactly at the third cycle. There are also other relevant errors,
but we only focuses on the following two kinds.
1) Errors on the measurement or on the syndrome qubits;
These are the errors due to the erroneous output of a measurement Mi, or errors that are applied to the",N/A,N/A
"syndrome qubit. The latter will appear as the former. Suppose we have an error on the measurement of the
f qubit. Then, the above table becomes
# cycles Mb Md Mf Mh
1
+1 +1 −1 +1
2
+1 +1 −1 +1
3
+1 +1 +1 +1
4
+1 +1 −1 +1
5
+1 +1 −1 +1
...
...
...
...
...
(4.130)
where we highlighted the difference between the two tables. The error is only momentaneous. Later appli-
cations of the cycle will erase the action of these kind of errors. Indeed, if the error is due to the random",N/A,N/A
"erroneous measurement outcome, then the following cycle will (most probably) provide the exact outcome.
4.3 Surface code
61
This will not be the case if there is a systematic error in the measurement process, which cannot be corrected.
Conversely, if the error is caused by the application of an external action on the measurement qubit (say the
surrounding environment acts with ˆZ on the f qubit), then the error vanishes in the next cycle since the",N/A,N/A
"qubit’s state is initialised at the beginning of each cycle.
2) Errors on the data qubits. These are the errors on the data qubits that can be, for example, due to the
surrounding environment, and that can corrupt the information encoded in the data state. It becomes then
fundamental to being able to detect and account for such errors for the sake of computation.
Suppose we have a phase-flip error on the e qubit. The state is then transformed as
|ψ′
acegi⟩
phase-flip error on qubit e",N/A,N/A
"|ψ′
acegi⟩
phase-flip error on qubit e
−−−−−−−−−−−−−−−−→ˆZe |ψ′
acegi⟩.
(4.131)
Then, the Z-syndrome qubits will be unable to detect it. However, X-syndrome qubits d and f will detect
the error: their coupling to the data qubit e imposes the action of ˆXe, which do not commute with ˆZe. Then,
what happens is that the state of the X-syndrome qubits will flip. By supposing that the error occurs at the
third cycle. Then, the table of outcomes becomes
# cycles Mb Md Mf Mh
1
+1 +1 −1 +1
2",N/A,N/A
"# cycles Mb Md Mf Mh
1
+1 +1 −1 +1
2
+1 +1 −1 +1
3
+1 −1 +1 +1
4
+1 −1 +1 +1
5
+1 −1 +1 +1
...
...
...
...
...
(4.132)
Importantly, the outcomes Md and Mf change sign for any subsequent cycle (if no other errors or logical
operations take place). This is how one can distinguish an error on the measurement and on the data qubits.
The best way to account for this error is to employ a classical control software that will changes the sign of",N/A,N/A
"every subsequent measurement of that data qubit’s two adjacent X-syndrome qubits.
When one has an array of larger dimensions, then the situation is more complicated. For example, one might
have that several data errors that form paths on the array. If this happens, the errors will be highlighted only
by two syndrome qubits at the ends of the error path. An example is shown in Fig. 4.14, where the X-syndrome",N/A,N/A
"qubits a and f indicate that an error occurred. However, there is no indication about which path between a
and f the Z-errors are covering.
a
b
c
e
d
f
A
B
C
D
E
F
G
Fig. 4.14: Graphical representation of Z noises detected by the measurement qubits a and f. Different paths
(blue, purple and orange) can produce this error syndrome.
62
4 Quantum Error Correction
This could be one among ABE (blue path), ADG (purpkle path) or CFG (orange path). When accounting",N/A,N/A
"via classical control software for the errors, one needs to select one of these paths. The question is what happens
if one selects the wrong path? The beauty of the surface code kicks in: as long as the error path and the selected
one form a closed loop, the error is well accounted. This is shown with the following argument. Suppose the error
path is ABE, which is produced by ˆZA ˆZB ˆZE, and we select the path CFG to be corrected, whose correction",N/A,N/A
"is given by ˆZC ˆZF ˆZG. This is however not a problem, indeed we have that
( ˆZA ˆZB ˆZE) = ( ˆZC ˆZF ˆZG) ˆSe ˆSd,
(4.133)
where we defined the stabilisers
ˆSe = ˆZB ˆZE ˆZD ˆZG,
and
ˆSd = ˆZA ˆZC ˆZD ˆZF .
(4.134)
Therefore, the two errors are related by two stabilisers. This means, that recovery operator ˆRk that corrects
ˆZA ˆZB ˆZE can correct also for ˆZC ˆZF ˆZG. This has been discussed in Sec. 4.2.5. Thus, every time we can form",N/A,N/A
"closed loops, the error can be accounted properly. These are harmless errors.
Conversely, consider now the case shown in Fig. 4.15. Here the error path (shown in orange) crosses the
boundary of the array, and due to the periodic boundary conditions only two syndrome qubits highlight the
error path. In such a case, one would still be tempted to connect directly the syndrome qubits with a path",N/A,N/A
"fully in the array (shown in purple). However, such a correction is not the proper one. Indeed, the two paths
would form a logical operation. To visualise harmless and harmful paths, one maps the array on a torus. If the
Fig. 4.15: Graphical representation of an error path that crosses the boundary of the array (orange path). If
corrected with the purple path, it leads to a logical operation, thus not correcting for the error.",N/A,N/A
"path can be closed, then it is harmless. If the path cannot be closed, then it is harmful. Figure 4.16 shows the
mapping between the array and the torus, and highlights the harmless and harmful paths.
4.4 Fault-tolerant computation
Let us suppose we want to implement the following logical circuit
|0⟩
|0⟩
H
(4.135)
4.4 Fault-tolerant computation
63
Fig. 4.16: Graphical representation of the mapping of the array on a torus surface. The red path corresponds to",N/A,N/A
"a logical X, while the blue path to a logical Z operation. These are harmful error. The purple path is an error
that can be corrected.
so that if an error occurs it can be successfully corrected via a QEC code. The error can essentially occur in
any of the components of the circuit. Namely,
-
in the state preparation,
-
in the logic quantum gates,
-
in the measurement,
-
in the simple transition of the quantum information along the quantum wires.",N/A,N/A
"To combat the effect of the noise, one encodes the logical qubits in blocks of physical ones, using QEC codes.
However, one needs also to replace the logical operations with encoded gates. Performing QEC periodically on
the encoded states prevents the accumulation of errors in the state. However, it is not sufficient to prevent the
build-up of errors, even if QEC is applied after each encoded gate.
There are two main reasons:
1) The encoded gates can cause the propagation of errors.",N/A,N/A
"Let us consider a specific example, where two qubits are connected by a CNOT gate and a X error occurs on
the control qubit before the CNOT. Then, the error propagates also to the target qubit. This can be easily
computed by considering that the CNOT is implemented by the unitary operator ˆUCNOT. Then, one has
ˆUCNOTˆσ(1)
x
= ˆUCNOTˆσ(1)
x
ˆU †
CNOT ˆUCNOT = ˆσ(1)
x ˆσ(2)
x
ˆUCNOT,
(4.136)
which can be graphically represented with
X
→
X
X
(4.137)",N/A,N/A
"X
→
X
X
(4.137)
Then, one needs to design the encoded gates carefully, so that errors do not propagate on the entire block,
but are limited to some physical qubits. In such a case the QEC code can remove these errors.
Performing encoded gates in such a way is a fault-tollerant (FT) procedure.
2) Also QEC can introduce errors.
An example is that graphically represented in Fig. 4.15, where an error is not correctly recovered.
To showcase the FT procedure, we introduce the Steane code.
64",N/A,N/A
"64
4 Quantum Error Correction
4.4.1 Stean code or 7-qubit code
The Steane code is a stabiliser code employing 7 data qubit and 6 syndrome qubits for each logical qubit. The
total Hilbert space H′ has 128 dimensions that are divided in 64 subspaces of two dimensions. The graphical
representation is given in Fig. 4.17. The generators of the stabilisers are
1
3
2
7
6
5
4
!𝑆!
"" = $𝑋# $𝑋"" $𝑋$ $𝑋%
!𝑆&
"" = !𝑍# !𝑍"" !𝑍$ !𝑍%
!𝑆!
' = $𝑋' $𝑋"" $𝑋( $𝑋%
!𝑆&
' = !𝑍' !𝑍"" !𝑍( !𝑍%
!𝑆!
# = $𝑋) $𝑋$ $𝑋( $𝑋%
!𝑆&",N/A,N/A
"' = !𝑍' !𝑍"" !𝑍( !𝑍%
!𝑆!
# = $𝑋) $𝑋$ $𝑋( $𝑋%
!𝑆&
# = !𝑍) !𝑍$ !𝑍( !𝑍%
Fig. 4.17: Graphical representation of the Steane code with the data qubit represented as open circles and the
corresponding stabilisers.
{ ˆSk }
6
k=1 =

















ˆ1 ˆ1 ˆ1 ˆX ˆX ˆX ˆX,
ˆ1 ˆX ˆX ˆ1 ˆ1 ˆX ˆX,
ˆX ˆ1 ˆX ˆ1 ˆX ˆ1 ˆX,
ˆ1 ˆ1 ˆ1 ˆZ ˆZ ˆZ ˆZ,
ˆ1 ˆZ ˆZ ˆ1 ˆ1 ˆZ ˆZ,
ˆZ ˆ1 ˆZ ˆ1 ˆZ ˆ1
ˆZ

















=

















ˆX4 ˆX5 ˆX6 ˆX7,
ˆX2 ˆX3 ˆX6 ˆX7,",N/A,N/A
"







ˆX4 ˆX5 ˆX6 ˆX7,
ˆX2 ˆX3 ˆX6 ˆX7,
ˆX1 ˆX3 ˆX5 ˆX7,
ˆZ4 ˆZ5 ˆZ6 ˆZ7,
ˆZ2 ˆZ3 ˆZ6 ˆZ7,
ˆZ1 ˆZ3 ˆZ5 ˆZ7,

















.
(4.138)
With the Steane code, any single-qubit error can be correctly recovered as it send the code space HC in one of
the other subspaces Hi. Specifically, the code space HC is given by the span of two logical states { | 0L⟩, | 1L⟩}.
These are encoded as
|0L⟩= 1
√",N/A,N/A
"These are encoded as
|0L⟩= 1
√
8 [|0000000⟩+ |1010101⟩+ |0110011⟩+ |1100110⟩+ |0001111⟩+ |1011010⟩+ |0111100⟩+ |1101001⟩] ,
|1L⟩= 1
√
8 [|1111111⟩+ |0101010⟩+ |1001100⟩+ |0011001⟩+ |1110000⟩+ |0100101⟩+ |1000011⟩+ |0010110⟩] .
(4.139)
The logical operations are given by the normalisers. In the Pauli group, we have the logical X-gate and the
logical Z-gate. These are constructed by applying the corresponding single qubit operators to each physical
qubit. Namely,",N/A,N/A
"qubit. Namely,
ˆXL = ˆX1 ˆX2 ˆX3 ˆX4 ˆX5 ˆX6 ˆX7,
ˆZL = ˆZ1 ˆZ2 ˆZ3 ˆZ4 ˆZ5 ˆZ6 ˆZ7.
(4.140)
These operations are allowed, as there are still two free degrees of freedom. There are also other logical operations
that one can construct. These are normalisers that do not appartain to the Pauli group. An example is the
Hadamard gate, which can be also implemented as the application of single qubit Hadamards:
ˆHL = ˆH1 ˆH2 ˆH3 ˆH4 ˆH5 ˆH6 ˆH7.
(4.141)
4.4 Fault-tolerant computation
65",N/A,N/A
"(4.141)
4.4 Fault-tolerant computation
65
At this point, one would naively extrapolate that any logical operation can be constructed via the application
of the corresponding gate on the single data qubits where the logical state is encoded. However, this is not the
case. An example is the phase gate ˆS, whose representation in the computation basis reads
S =
1 0
0 i

.
(4.142)
The corresponding logical gate is constructed as
ˆSL = ˆS†
1 ˆS†
2 ˆS†
3 ˆS†
4 ˆS†
5 ˆS†
6 ˆS†
7.
(4.143)",N/A,N/A
"1 ˆS†
2 ˆS†
3 ˆS†
4 ˆS†
5 ˆS†
6 ˆS†
7.
(4.143)
Indeed, when applied to the logical computational basis we find
ˆSL |0L⟩= |0L⟩,
ˆSL |1L⟩= i |1L⟩.
(4.144)
Conversely, if one would have defined a ˆS′
L as just simply applying the S-gate to each physical qubit, one would
have obtained
ˆS′
L |0L⟩= |0L⟩,
ˆS′
L |1L⟩= −i |1L⟩.
(4.145)
Thus, the construction of logical gates needs to be done with care and it depends on the QEC code that one is
employing.",N/A,N/A
"employing.
Let us consider the case of a CNOT gate. Here, we have two logical qubits, each corresponding to 7 data and
6 syndrome qubits. One can see that the logical CNOT gate can be implemented pairwise as described by the
following ciurcuit
(4.146)
66
4 Quantum Error Correction
It follows that one can implement the logical circuit
H
(4.147)
as
H
H
H
H
H
H
H
(4.148)
This way of implementing logical gates is called transversal construction. This is a really easy and straightforward",N/A,N/A
"construction, but most importantly allows to confine errors, as they are unable to propagate. Let us take as an
example the circuit in Eq. (4.148) and suppose we have initially a X error on the first qubit of the first block.
In such a case, the error propagates accordingly to
4.4 Fault-tolerant computation
67
X
H
H
H
H
H
H
H
→
H
X
H
H
H
H
H
H
X
(4.149)
Thus, the error has been copied to the first qubit of the second block, but all the other qubits are not affected.",N/A,N/A
"The Steane code can correct for such an error. This holds true for any transverse construction.
Till now, we have covered the case for the normalisers { ˆXL, ˆZL, ˆHL, ˆSL, CNOTL }, which is the so-called
Clifford group. Notably, the Gottesman-Knill theorem indicates that operations performed using only elements
of this group can be simulated classically. Thus, one cannot have a real quantum advantage over a classical",N/A,N/A
"computer. Moreover, the Clifford group is not universal, meaning that the composition of elements of this group
is not sufficient to implement any arbitrary gate. This is essentially the argument of the Solovay-Kitaev theorem.
One needs to extend the Clifford group with the addition of at least an extra gate not appartaining to the group.
This can be the T-gate or the Toffoli gate.
Unfortunately, one does not know how to implement through unitary operations the T-gate in a transversal",N/A,N/A
"way using the Steane code. This is a code-related problem. One could consider a different QEC code and im-
plement the T-gate, but they will have problems with another gate, e.g. the Hadarmard gate. The Eastin-Knill
theorem indicates that it is not possible to construct a fault-tolerant universal set with unitary operations.
Notably, the latter theorem applies only to unitary operations. One can still have the entire universal set",N/A,N/A
"by substituting the problematic gate with an effective implementation. Below, we focus on the derivation of an
effective T-gate for the Steane code.
68
4 Quantum Error Correction
Consider the following circuit
|ψ⟩
|0⟩
|φ⟩
H
y
H
(4.150)
where one obtains that the state |φ⟩is given by
|φ⟩= ˆXy ˆH |ψ⟩,
(4.151)
with y = 0, 1. Notably, the three operations performed here, the two Hadamards and the control-Z gates, are
all fault-tolerant.",N/A,N/A
"all fault-tolerant.
Suppose we slightly modify the circuit by adding a T-gate on the second qubit as follows
|ψ⟩
|0⟩
|φ′⟩
H
y
H
T
(4.152)
where the representation of the T-gate on the computational basis reads
T =
 
1
0
0 e−i π
4
!
(4.153)
and the final state of the second qubit now is
|φ′⟩= ˆT ˆXy ˆH |ψ⟩.
(4.154)
Since, a part from a total phase, the T-gate can be written as
ˆT = ei π
8 ˆ
Z,
(4.155)
one obtains
|φ′⟩= ˆXy ˆT (1−2y) ˆH |ψ⟩.
(4.156)
But, ˆT (1−2y) can be expressed as",N/A,N/A
"(4.156)
But, ˆT (1−2y) can be expressed as
ˆT (1−2y) = ˆTe−i πy
4 ˆ
Z = e−i πy
4 ˆSy ˆT,
(4.157)
where we can safely omit the phase in the last expression. Thus, we get
|φ′⟩= ˆXy ˆSy ˆT ˆH |ψ⟩= ( ˆX ˆS)y ˆT ˆH |ψ⟩.
(4.158)
Here, the last equality holds since the value of y can be only 0 or 1. Moreover, we also find that the T-gate
commutes with the control-Z, since it commutes with ˆZ. Thus, by adding an extra Hadamard gate on the first
qubit, we obtain
|ψ⟩
|0⟩
|φ′′⟩
H
H
y
H
T
(4.159)
where",N/A,N/A
"|ψ⟩
|0⟩
|φ′′⟩
H
H
y
H
T
(4.159)
where
4.4 Fault-tolerant computation
69
|φ′′⟩= ( ˆX ˆS)y ˆT |ψ⟩.
(4.160)
Specifically, the latter implies the following one
|ψ⟩
|ϕ⟩
|χ⟩
H
H
y
( ˆS† ˆX)y
(4.161)
where
|χ⟩= ˆT |ψ⟩,
|ϕ⟩= ˆT ˆH |0⟩.
(4.162)
This means that, if one is able to prepare the second qubit in the state |ϕ⟩, then they also can apply the T-gate
to an arbitrary state |ψ⟩that was initially embedded in the first qubit. This is an effective application of the",N/A,N/A
"T-gate. Clearly, it requires the preparation of |ϕ⟩. Specifically, this is given by
|ϕ⟩= ˆT ˆH |0⟩= e−i π
8 ˆ
Z |+⟩.
(4.163)
Now, the state |+⟩is eigeinstate of ˆX with eigeinvalue (+1), and in the same way |ϕ⟩is eigeinstate of the
operator
e−i π
8 ˆ
Z ˆXei π
8 ˆ
Z = e−i π
4 ˆ
Z ˆX = ˆS ˆX,
(4.164)
with the eigeinvalue (+1). Here, the last two equalities follow from the commutaion of ˆT and ˆX and the",N/A,N/A
"definition of the S-gate. Thus, |ϕ⟩is eigeinstate of ˆS ˆX with eigeinvalue (+1). Similarly, the ortogonal state
|ϕ⊥⟩is associated to the eigenvalue (−1). Now, this implies that given an arbitrary state |ν⟩by measuring the
operator ˆS ˆX, the state will collapse in |ϕ⟩or |ϕ⊥⟩with corresponding outcomes respectively given by (+1) and
(−1).
The complete circuit thus becomes
|ψ⟩
|ν⟩
|ϕ⟩
|χ⟩
discarded
H
H
y
ˆS ˆX
( ˆS† ˆX)y
+1
−1
(4.165)",N/A,N/A
"discarded
H
H
y
ˆS ˆX
( ˆS† ˆX)y
+1
−1
(4.165)
and effectively applies the T-gate to an arbitrary state |ψ⟩. If the measurement is also FT (this can be proven,
but it will not be tackled here), then one has that the entire circuit is FT.
Chapter 5
Dynamical Decoupling and Quantum Error Mitigation
The greatest problem in the development of quantum computers are the presence of errors and noises. QEC",N/A,N/A
"works in theory: the threshold theorem guarantees it. However, it requires a number of physical qubits (∼103
to ∼106) that is often beyond what possible with the current technology. In this chapter, we introduce two
possible routes to tackle the problem. These are the Dynamical Decoupling and the Quantum Error Mitigation.
5.1 Dynamical Decoupling
The dynamical decoupling (DD) approach leverage on averaging out the unwanted effects of the surrounding",N/A,N/A
"environment by applying a control on the system.
Two introduce the idea, we focus on the specific model of a qubit coupled to a thermal bath of harmonic
oscillators, with ˆbk being the annihilation operator of the k oscillator. The total Hamiltonian reads
ˆH0 = ˆHS + ˆHB + ˆHSB = 1
2ℏω0ˆσz +
X
k
ℏωkˆb†
kˆbk +
X
k
ℏˆσz(gkˆb†
k + g∗
kˆbk),
(5.1)
where the first and second contributions are the free Hamiltonian of the qubit system and thermal bath re-",N/A,N/A
"spectively, while the last term describes their interaction being weighted by the constants gk. Eventually, one
focuses on the dynamics of the qubit alone. Thus, the state of interest is the reduced density matrix, which is
obtained via
ˆρS(t) = Tr
(B) h
e−i ˆ
H0t/ℏˆρT(0)ei ˆ
H0t/ℏi
,
(5.2)
where ˆρT(0) is the total state at time t = 0. The latter can be decomposed on the computational basis
{ | 0⟩, | 1⟩} as
ˆρS(t) =
X
i,j=0,1
ρij(t) |i⟩⟨j| .
(5.3)",N/A,N/A
"ˆρS(t) =
X
i,j=0,1
ρij(t) |i⟩⟨j| .
(5.3)
Now, given the total Hamiltonian ˆH0, one finds that the populations ρii are conserved. Indeed,
h
ˆσz, ˆH0
i
= 0
and thus the model describes a purely decohering mechanism, where no energy exchange between the system
and the bath is present. Specifically, one can focus on the dynamics of the coherences ρ01(t) alone, and we do
it in the interaction picture. Thus, we have that the total state is given by
ˆρ
(I)
T (t) = ei( ˆ
HS+ ˆ
HB)t/ℏˆρT(t)e−i( ˆ
HS+ ˆ",N/A,N/A
"(I)
T (t) = ei( ˆ
HS+ ˆ
HB)t/ℏˆρT(t)e−i( ˆ
HS+ ˆ
HB)t/ℏ,
(5.4)
with the effective Hamiltonian reading
70
5.1 Dynamical Decoupling
71
ˆH
(I)
0 (t) = ℏˆσz
X
k

gkˆb†
keiωkt + g∗
kˆbke−iωkt
.
(5.5)
Correspondingly, the unitary operator determining the time evolution in the interaction picture from time t0 to
t is
ˆU
(I)(t0, t) = T exp

−i
ℏ
Z t
t0
ds ˆH
(I)
0 (s)

,
(5.6)
where T indicates the time-ordering operator. The corresponding Dyson expansion, which is effectively a Taylor",N/A,N/A
"expansion accounting also for the time-ordering, reads
ˆU
(I)(t0, t) = ˆ1 −i
ℏ
Z t
t0
dt1 ˆH
(I)
0 (t1) −1
ℏ2
Z t
t0
dt2
Z t2
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) + . . .
(5.7)
Let us focus on the second order term, which can be rewritten in term of the integral from t0 to t for both
variables as
Z t
t0
dt2
Z t2
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) =
Z t
t0
dt2
Z t
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) −
Z t
t0
dt2
Z t
t2
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1).
(5.8)",N/A,N/A
"dt2
Z t
t2
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1).
(5.8)
The last term corresponds to the integral over the area highlighted by the blue lines in Fig. 5.1: for each value
of t2 ∈[t0, t], the t1 integral runs from t2 to t. Equivalently, this area can be described by the red lines: for each
value of t1 ∈[t0, t], one performs the t2 integral from t0 to t1.
𝑡!
𝑡""
𝑡! = 𝑡""
𝑡!
𝑡""
𝑡! = 𝑡""
Fig. 5.1: Representation of different but equivalent ways of how to perform the integral in Eq. (5.9).",N/A,N/A
"Mathematically, this implies that the following equality holds
Z t
t0
dt2
Z t
t2
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) =
Z t
t0
dt1
Z t1
t0
dt2 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1).
(5.9)
Moreover, we can recast the right-hand-side of the latter equation as
Z t
t0
dt1
Z t1
t0
dt2 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) =
Z t
t0
dt1
Z t1
t0
dt2
h
ˆH
(I)
0 (t2), ˆH
(I)
0 (t1)
i
+
Z t
t0
dt1
Z t1
t0
dt2 ˆH
(I)
0 (t1) ˆH
(I)
0 (t2),
=
Z t
t0
dt1
Z t1
t0
dt2
h
ˆH
(I)
0 (t2), ˆH
(I)
0 (t1)
i
+
Z t
t0
dt2
Z t2
t0
dt1 ˆH
(I)",N/A,N/A
"(I)
0 (t1)
i
+
Z t
t0
dt2
Z t2
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1),
(5.10)
where we swapped the variables t1 ↔t2 in the second term. Namely, such second term is identical to that in
the left-hand-side of Eq. (5.8). Here, the non-equal time Hamiltonians do not commute, but give
72
5 Dynamical Decoupling and Quantum Error Mitigation
h
ˆH
(I)
0 (t2), ˆH
(I)
0 (t1)
i
= ℏ2ˆσ2
z
X
kk′

gkg∗
k′eiωkt2−iωk′t1 h
ˆb†
k,ˆbk′
i
+ g∗
kgk′e−iωkt2+iωk′t1 h
ˆbk,ˆb†
k′
i
,
= −2iℏ2 X
k
|gk|2 sin[ωk(t2 −t1)],",N/A,N/A
"k′
i
,
= −2iℏ2 X
k
|gk|2 sin[ωk(t2 −t1)],
(5.11)
which is an imaginary number. Now, by merging the last four equations, we find
Z t
t0
dt2
Z t2
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) = 1
2
Z t
t0
dt2
Z t
t0
dt1 ˆH
(I)
0 (t2) ˆH
(I)
0 (t1) −1
2
Z t
t0
dt1
Z t1
t0
dt2
h
ˆH
(I)
0 (t2), ˆH
(I)
0 (t1)
i
,
= 1
2
Z t
t0
dt1 ˆH
(I)
0 (t1)
2
+ iℏ2
Z t
t0
dt1
Z t1
t0
dt2
X
k
|gk|2 sin[ωk(t2 −t1)].
(5.12)
This allows to recast the Dyson expansion as
ˆU
(I)(t0, t) = ˆ1 −i
ℏ
Z t
t0
dt1 ˆH
(I)
0 (t1) + 1
2
",N/A,N/A
"ℏ
Z t
t0
dt1 ˆH
(I)
0 (t1) + 1
2

−i
ℏ
Z t
t0
dt1 ˆH
(I)
0 (t1)
2
−iϕ(t0, t) + . . . ,
(5.13)
where
ϕ(t0, t) = 1
2
Z t
t0
dt1
Z t1
t0
dt2
X
k
|gk|2 sin[ωk(t2 −t1)].
(5.14)
By summing all the terms, one gets
ˆU
(I)(t0, t) = e−iφ(t0,t) exp

−i
ℏ
Z t
t0
ds ˆH
(I)
0 (s)

,
(5.15)
where one has an extra global phase, which is hiowever unimportant since
ˆU
(I)(t0, t)ˆρ
h
ˆU
(I)(t0, t)
i†
= exp

−i
ℏ
Z t
t0
ds ˆH
(I)
0 (s)

ˆρ exp
 i
ℏ
Z t
t0
ds ˆH
(I)
0 (s)

,
(5.16)",N/A,N/A
"
ˆρ exp
 i
ℏ
Z t
t0
ds ˆH
(I)
0 (s)

,
(5.16)
and there is not time-ordering operator.
Specifically, one can perform explicitly the time integral in the exponential of ˆU (I)(t0, t), which reads
−i
ℏ
Z t
t0
ds ˆH
(I)
0 (s) = 1
2 ˆσz
X
k

ˆb†
keiωkt0ξk(t −t0) −ˆbke−iωkt0ξ∗
k(t −t0)

,
(5.17)
where
ξk(t −t0) = 2gk
ωk
(1 −eiωk(t−t0)).
(5.18)
Now, the quantity of interest is the coherence, which in the interaction picture is given by
ρ
(I)
01(t) = ⟨0|ˆρ
(I)
S (t)|1⟩= ⟨0| Tr
(B)

ˆU",N/A,N/A
"ρ
(I)
01(t) = ⟨0|ˆρ
(I)
S (t)|1⟩= ⟨0| Tr
(B)

ˆU
(I)(t0, t)ˆρT(t0)

ˆU
(I)(t0, t)
†
|1⟩,
(5.19)
and it can be computed analytically under the following assumptions:
1) The total initial state is separable, namely
ˆρT(t0) = ˆρS(t0) ⊗ˆρB(t0);
(5.20)
2) The initial state of the bath is a thermal state of the form
5.1 Dynamical Decoupling
73
ˆρB(t0) =
Y
k
(1 −e−βℏωk) exp

−βℏωkˆb†
kˆbk

,
(5.21)
with β = (kBT)−1 being the inverse temperature.",N/A,N/A
"with β = (kBT)−1 being the inverse temperature.
By going back to the Schr¨odinger picture, Eq. (5.19) reads
ρ01(t) = e−iω0(t−t0)ρ
(I)
01(t),
= e−iω0(t−t0) ⟨0| Tr
(B)
""
exp
""
1
2 ˆσz
X
k

ˆb†
keiωkt0ξk(t −t0) −ˆbke−iωkt0ξ∗
k(t −t0)
#
ˆρT(t0)
× exp
""
−1
2 ˆσz
X
k

ˆb†
keiωkt0ξk(t −t0) −ˆbke−iωkt0ξ∗
k(t −t0)
##
|1⟩.
(5.22)
By applying with ˆσz on the ⟨0| and |1⟩states, we get
ρ01(t) = e−iω0(t−t0) Tr
(B)
""
exp
""X
k

ckˆb†
k −c∗
kˆbk
#
ˆρB(t0)
#
ρ01(t0),
(5.23)",N/A,N/A
"k

ckˆb†
k −c∗
kˆbk
#
ˆρB(t0)
#
ρ01(t0),
(5.23)
where we exploited the cyclicity of the partial trace with respect to the bath operators, the assumption of
separability of the initial state, the definition of the initial coherence ρ01(t0) = ⟨0|ˆρS(t0)|1⟩, and defined
ck = ck(t0, t) = eiωkt0ξk(t −t0).
(5.24)
In Eq. (5.23), one can recognise the displacement operator. Namely, the latter equation can be recasted as
ρ01(t) = e−iω0(t−t0) Tr
(B)
""Y
k
ˆDk(ck)ˆρB(t0)
#
ρ01(t0),
(5.25)
where",N/A,N/A
"(B)
""Y
k
ˆDk(ck)ˆρB(t0)
#
ρ01(t0),
(5.25)
where
ˆD(β) = exp(βˆb†
k −β∗ˆb)
(5.26)
is the displacement operator.
Recall 5.1 (Coherent states)
Given the ground state |0⟩, one can construct a coherent state via the application of a displacement operator
to |0⟩. Namely,
ˆD(β) |0⟩= |β⟩,
(5.27)
where β ∈C. The coherent states form an overcomplete basis of the Hilbert space H, for which one has
ˆ1 =
Z d2z
π |z⟩⟨z| ,
(5.28)",N/A,N/A
"ˆ1 =
Z d2z
π |z⟩⟨z| ,
(5.28)
where d2z = d(ℜz)d(ℑz). The combination of two displacement operators is governed by
ˆD(α) ˆD(β) = e
1
2 (αβ∗−βα∗) ˆD(α + β).
(5.29)
Finally, one can express the coherent states in terms of the Fock basis { | n⟩}, where
⟨n|z⟩= zn
√
n!
e−|z|2/2,
(5.30)
74
5 Dynamical Decoupling and Quantum Error Mitigation
determines the weights between the two basis.
Let us then consider the partial trace over the k-th mode of the displacement operator and the thermal state,",N/A,N/A
"which explicitly reads
Tr
(B) h
ˆDk(ck)ˆρBk(t0)
i
= (1 −e−βℏωk) Tr
(B) h
ˆDk(ck)e−βℏωkˆb†
kˆbk
i
,
= (1 −e−βℏωk)
Z d2z
π ⟨z|e−βℏωkˆb†
kˆbk ˆDk(ck)|z⟩,
(5.31)
where we exploited the coherent basis to compute the partial trace and exploit its cyclicity. By applying the
composition of displacement opertors (namely, Eq. (5.29) merged with Eq. (5.27)), and introducing an identity
in the Fock basis, i.e. ˆ1 = P+∞
n=0 |n⟩⟨n|, we get
Tr
(B) h
ˆDk(ck)ˆρBk(t0)
i
= (1 −e−βℏωk)
Z d2z
π
X
n
⟨z|n⟩e−βℏωkne
1",N/A,N/A
"i
= (1 −e−βℏωk)
Z d2z
π
X
n
⟨z|n⟩e−βℏωkne
1
2 (ckz∗−zc∗
k) ⟨n|z + ck⟩,
= (1 −e−βℏωk)
Z d2z
π
X
n
e−βℏωkne
1
2 (ckz∗−zc∗
k) (z∗)n
√
n!
e−|z|2/2 (z + ck)n
√
n!
e−|z+ck|2/2,
(5.32)
where we applied Eq. (5.30). By putting together the exponentials, we obtain
Tr
(B) h
ˆDk(ck)ˆρBk(t0)
i
= (1 −e−βℏωk)
Z d2z
π e−|z|2e−|ck|2/2e−zc∗
kS(z, ck)
(5.33)
where
S(z, ck) =
X
n
e−βℏωkn (z∗)n
√
n!
(z + ck)n
√
n!
,
=
X
n
1
n!

e−βℏωk(|z|2 + ckz∗)
n ,
= exp

e−βℏωk(|z|2 + ckz∗)

.
(5.34)
Thus,
Tr
(B) h",N/A,N/A
"
e−βℏωk(|z|2 + ckz∗)

.
(5.34)
Thus,
Tr
(B) h
ˆDk(ck)ˆρBk(t0)
i
= (1 −e−βℏωk)
Z d2z
π e−|z|2αke−|ck|2/2e−zc∗
k exp[ckz∗e−βℏωk],
(5.35)
where
αk = 1 −e−βℏωk,
(5.36)
is a positive quantity. Then, the Gaussian integral in Eq. (5.35) can be safely implemented and gives
Tr
(B) h
ˆDk(ck)ˆρBk(t0)
i
= (1 −e−βℏωk) 1
αk
exp

−|ck|2
αk
e−βℏωk

e−|ck|2/2,
= exp

−|ck|2
1
2 +
e−βℏωk
(1 −e−βℏωk)

,
= exp

−|ck|2
2
coth
βℏωk
2

.
(5.37)",N/A,N/A
"
,
= exp

−|ck|2
2
coth
βℏωk
2

.
(5.37)
Finally, by merging together the latter equation with Eq. (5.25), we obtain
ρ01(t) = e−iω0(t−t0)e−Γ (t0,t)ρ01(t0),
(5.38)
where we defined
5.1 Dynamical Decoupling
75
Γ(t0, t) =
X
k
|c2
k|
2 coth
βℏωk
2

,
=
X
k
|eiωkt0ξk(t −t0)|2
2
coth
βℏωk
2

,
=
X
k
| 2gk
ωk (1 −eiωk(t−t0))|2
2
coth
βℏωk
2

,
=
X
k
4|gk|2
ω2
k
(1 −cos[ωk(t −t0)]) coth
βℏωk
2

(5.39)",N/A,N/A
"ω2
k
(1 −cos[ωk(t −t0)]) coth
βℏωk
2

(5.39)
where we simply substituted the definitions of ck and ξk(t −t0). Now, by introducing the spectral density I(ω)
as
I(ω) =
X
k
δ(ω −ωk)|gk|2,
(5.40)
which determines the strength of the coupling between the system and each bath’s modes, we can rewrite Γ(t0, t)
as
Γ(t0, t) = 4
Z +∞
0
dω I(ω) coth
βℏω
2
 (1 −cos[ω(t −t0)])
ω2
,
= 4
Z +∞
0
dω I(ω) (2¯n(ω, T) + 1) (1 −cos[ω(t −t0)])
ω2
,
(5.41)",N/A,N/A
"ω2
,
(5.41)
where ¯n(ω, T) is the mean number of excitations of the mode ω at the temperature T = (kBβ)−1. Notably,
Γ(t0, t) is positive. This can be seen explicitly from the first line of Eq. (5.39). This means, that — as expected
— the interaction with the environment reduces the coherences [cf. Eq. (5.38)].
Suppose now that we want to perturb the system so the induce a spin-flip transition. Physically, since the",N/A,N/A
"interaction Hamiltonian ˆHSB is proportional to ˆσz, then opposite contributions arise when the system is in |0⟩
and |1⟩. Thus, by making the system change fast between |0⟩and |1⟩, one can average out the contributions
from ˆHSB, effectively decoupling the system from the environment.
Specifically, we will consider a modified Hamiltonian reading
ˆH0 →ˆH(t) = ˆH0 + ˆHP(t),
(5.42)
where the Hamiltonian perturbation ˆHP(t) can be implemented via a monocromatic alternating magnetic field",N/A,N/A
"applied at the resonance. Its explicit form we consider is
ˆHP(t) =
nP
X
n=1
V (n)(t)
n
ˆσx cos[ω0(t −t(n)
P )] + ˆσy sin[ω0(t −t(n)
P )]
o
,
=
nP
X
n=1
V (n)(t)

ˆσ+eiω0(t−t(n)
P
) + ˆσ−e−iω0(t−t(n)
P
)
,
(5.43)
with nP being the number of pulses, t(n)
P
is the time at which the pulse is switched on every ∆t, namely
t(n)
P
= t0 + n∆t,
with
n ∈{ 1, . . . , nP } .
(5.44)
Finally, the switch of the impulse is determined by V (n)(t), which is defined as
V (n)(t) =
(
V,
for t ∈[t(n)
P , t(n)
P",N/A,N/A
"V (n)(t) =
(
V,
for t ∈[t(n)
P , t(n)
P
+ τP],
0,
otherwise,
(5.45)
76
5 Dynamical Decoupling and Quantum Error Mitigation
where τP is the duration time of the pulses.
The exact dynamics with respect to the modified Hamiltonian ˆH(t) cannot be solved. However, we can
assume that during the pulses the contribution of ˆHSB is negligible and we completely neglect it. Then, the
dynamics becomes piecewise, alternating ˆHSB to ˆHP.",N/A,N/A
"As for the unperturbed case, we tackle the problem in the interaction picture. Namely, the effective Hamil-
tonian becomes
ˆH
(I)(t) = ˆH
(I)
0 (t) + ˆH
(I)
P (t),
(5.46)
where ˆH
(I)
0 (t) is shown in (5.5) and
ˆH
(I)
P (t) = exp
 i
ℏ

ˆHS + ˆHB

ˆHP(t) exp

−i
ℏ

ˆHS + ˆHB

,
= eiω0ˆσzt/2
nP
X
n=1
V (n)(t)

ˆσ+eiω0(t−t(n)
P
) + ˆσ−e−iω0(t−t(n)
P
)
e−iω0ˆσzt/2.
(5.47)
However, one has that
eiω0ˆσzt/2ˆσ−e−iω0ˆσzt/2 = eiω0ˆσzt/2 |0⟩⟨1| e−iω0ˆσzt/2,
= eiω0t |0⟩⟨1| ,
= eiω0tˆσ−,
(5.48)",N/A,N/A
"= eiω0t |0⟩⟨1| ,
= eiω0tˆσ−,
(5.48)
and similarly
eiω0ˆσzt/2ˆσ+e−iω0ˆσzt/2 = e−iω0tˆσ+.
(5.49)
Then, we obtain
ˆH
(I)
P (t) =
nP
X
n=1
V (n)(t)

ˆσ+e−iω0t(n)
P
+ ˆσ−eiω0t(n)
P

,
=
nP
X
n=1
V (n)(t)eiω0ˆσzt(n)
P
/2ˆσxe−iω0ˆσzt(n)
P
/2,
(5.50)
where we exploited that ˆσ+ + ˆσ−= ˆσx. Notably, the only time dependence is in V (n)(t), but it is only formal
as one can see from Eq. (5.45). Then, when considering the corresponding unitary, we have
ˆV
(I)
n (τP) = exp
 
−i
ℏ
Z t(n)
P
+τP
t(n)
P
ds ˆH",N/A,N/A
"(I)
n (τP) = exp
 
−i
ℏ
Z t(n)
P
+τP
t(n)
P
ds ˆH
(I)
P (s)
!
,
= exp

−i
ℏV eiω0ˆσzt(n)
P
/2ˆσxe−iω0ˆσzt(n)
P
/2τP

.
(5.51)
By Taylor expanding
ˆV
(I)
n (τP) =
X
k
1
k!

−i
ℏV eiω0ˆσzt(n)
P
/2ˆσxe−iω0ˆσzt(n)
P
/2τP
k
,
= eiω0ˆσzt(n)
P
/2 X
k
1
k!

−i
ℏV ˆσxτP
k
e−iω0ˆσzt(n)
P
/2,
= eiω0ˆσzt(n)
P
/2e−i
ℏV ˆσxτPe−iω0ˆσzt(n)
P
/2.
(5.52)
We finally fix V and τP so to have an actual bit-flip. This is provided by setting
V τP
ℏ
= π
2 ,
(5.53)
5.1 Dynamical Decoupling
77
which gives
e−i",N/A,N/A
"5.1 Dynamical Decoupling
77
which gives
e−i
ℏV ˆσxτP = e−i π
2 ˆσx = −iˆσx.
(5.54)
Notably, we can consider the limit of the time pulses that go to zero, i.e. τP →0, as long as V →∞and
Eq. (5.53) holds. Since from here V does not appear explicitly, this will only simplify the calculations.
Then, we have that
ˆV
(I)
n (τP) = ˆV
(I)
n = −ieiω0ˆσzt(n)
P
/2ˆσxe−iω0ˆσzt(n)
P
/2.
(5.55)
By considering that the following relation holds
e−iω0ˆσzt/2 = cos(ω0t/2)ˆ1 −i sin(ω0t/2)ˆσz,
(5.56)",N/A,N/A
"(5.56)
and the anticommutation relation {ˆσx, ˆσz} = 0, we have that
ˆσxe−iω0ˆσzt/2 = eiω0ˆσzt/2ˆσx.
(5.57)
It follows that one can write the operator ˆV (I)
n in two equivalent ways:
ˆV
(I)
n = −ieiω0ˆσzt(n)
P ˆσx = −iˆσxe−iω0ˆσzt(n)
P .
(5.58)
Let us now consider the time evolution of the first entire cycle of spin-flips: this is from time t0 through
time t(1)
P
when the spin flips the first time, to time t(2)
P
when the spin flips back to the original spin state. In",N/A,N/A
"particular, we define this latter time as t1 = t0 + 2∆t. The unitary dynamics from t0 to t1 is given by
ˆU
(I)
P (t0, t1) = ˆV
(I)
2 ˆU
(I)(t(1)
P , t(2)
P )ˆV
(I)
1 ˆU
(I)(t0, t(1)
P ),
=
h
ˆV
(I)
2 ˆV
(I)
1
i 
ˆV
(I)
1
−1 ˆU
(I)(t(1)
P , t(2)
P )ˆV
(I)
1

ˆU
(I)(t0, t(1)
P ),
(5.59)
where
ˆU
(I)(tα, tβ) = exp
""
1
2 ˆσz
X
k

ˆb†
keiωktαξk(tβ −tα) −ˆbke−iωktαξ∗
k(tβ −tα)
#
.
(5.60)
The first square parenthesis in the last line of Eq. (5.59) is given by
ˆV
(I)
2 ˆV
(I)
1 =

−ieiω0ˆσzt(2)",N/A,N/A
"ˆV
(I)
2 ˆV
(I)
1 =

−ieiω0ˆσzt(2)
P ˆσx
 
−iˆσxe−iω0ˆσzt(1)
P

,
= −eiω0ˆσz(t(2)
P −t(1)
P ).
(5.61)
Similarly, the second square parenthesis in the last line of Eq. (5.59) can be rewritten as

ˆV
(I)
1
−1 ˆU
(I)(t(1)
P , t(2)
P )ˆV
(I)
1 = eiω0ˆσzt(1)
P ˆσx exp
1
2 ˆσz ˆB(t(1)
P , t(2)
P )

ˆσxe−iω0ˆσzt(1)
P
(5.62)
where B(t(1)
P , t(2)
P ) = P
k

ˆb†
keiωkt(1)
P ξk(∆t) −ˆbke−iωkt(1)
P ξ∗
k(∆t)

. Here, we Taylor expand the central exponential,
which gives
exp
1
2 ˆσz ˆB(t(1)",N/A,N/A
"which gives
exp
1
2 ˆσz ˆB(t(1)
P , t(2)
P )

=
X
l
1
l!
1
2 ˆσz ˆB(t(1)
P , t(2)
P )
l
.
(5.63)
We divide the contributions to the sum in those with even and odd values of l. For even values, we have ˆσl
z = ˆσ2l′
z ,
where l = 2l′; then ˆσl
z = ˆ1 = (−ˆσz)l. For odd values of l, we have ˆσl
z = ˆσ2l′+1
z
, where l = 2l′ + 1; then ˆσl
z = ˆσz.
But more specifically, we also have that ˆσxˆσl
zˆσx = ˆσxˆσzˆσx = −ˆσz = −ˆσl
z. Thus, it follows that
78",N/A,N/A
"z. Thus, it follows that
78
5 Dynamical Decoupling and Quantum Error Mitigation

ˆV
(I)
1
−1 ˆU
(I)(t(1)
P , t(2)
P )ˆV
(I)
1 = exp

−1
2 ˆσz ˆB(t(1)
P , t(2)
P )

.
(5.64)
Thus, we have that Eq. (5.59) reads
ˆU
(I)
P (t0, t1) = −eiω0ˆσz(t(2)
P −t(1)
P ) exp

−1
2 ˆσz ˆB(t(1)
P , t(2)
P )

exp
1
2 ˆσz ˆB(t0, t(1)
P )

,
(5.65)
and can be recasted as
ˆU
(I)
P (t0, t1) = exp
""
iω0ˆσz(t(2)
P
−t(1)
P ) + 1
2 ˆσz
X
k

ˆb†
keiωkt0ηk(∆t) −ˆbke−iωkt0η∗
k(∆t)
#
,
(5.66)",N/A,N/A
"ˆb†
keiωkt0ηk(∆t) −ˆbke−iωkt0η∗
k(∆t)
#
,
(5.66)
where we neglected the overall unimportant phase and we defined
ηk(∆t) = ξ(∆t)
 1 −eiωk∆t
.
(5.67)
Now, the full evolution from time t0 to time tN after N entire cycles of spin-flip is simply given by
N
Y
n=1
ˆU
(I)
P (tn−1, tn) = exp
""
iω0ˆσz(tN −t0) + 1
2 ˆσz
X
k
 
ˆb†
k
X
n
eiωkt0ηk(N, ∆t) −ˆbk
X
n
e−iωkt0η∗
k(N, ∆t)
!#
,
(5.68)
where we introduced
ηk(N, ∆t) = e−iωkt0 X
n
eiωktn−1ηk(∆t),
= ηk(∆t)
N
X
n=1
e2iωk∆t(n−1).
(5.69)",N/A,N/A
"= ηk(∆t)
N
X
n=1
e2iωk∆t(n−1).
(5.69)
Such an evolution is to be compared to that with no pulses on the same time period. This is given by Eq. (5.60)
where one substitutes tα →t0 and tβ →tN. Then, since tN −t0 = 2N∆t, we have
ˆU
(I)(t0, tN) = exp
""
1
2 ˆσz
X
k

ˆb†
keiωkt0ξk(2N∆t) −ˆbke−iωkt0ξ∗
k(2N∆t)
#
.
(5.70)
Notably, the expressions in Eq. (5.68) and Eq. (5.70) have a similar structure, with the important difference",N/A,N/A
"being the factor ηk(N, ∆t) substituted with ξk(2N∆t). Thus, the decohering factor Γ(t0, tN) will take a suitably
modified expression as that in Eq. (5.39), namely
Γ(t0, tN) =
X
k
|eiωkt0ηk(N, ∆t)|2
2
coth
βℏωk
2

.
(5.71)
We now compare the difference between these two factors:
ηk(N, ∆t) −ξk(2N∆t) = ηk(∆t)
N
X
n=1
e2iωk∆t(n−1) −ξk(2∆t)
N
X
n=1
e2iωk∆t(n−1),
(5.72)
where we exploited the composition of the ξk terms. Then, by considering that
5.2 Quantum Error Mitigation
79",N/A,N/A
"5.2 Quantum Error Mitigation
79
ξk(∆t)(1 + eiωk∆t) = 2gk
ωk
(1 −eiωk∆t)(1 + eiωk∆t),
= 2gk
ωk
(1 −e2iωk∆t),
= ξk(2∆t),
(5.73)
and the definition of ηk(∆t) in Eq. (5.67), we obtain
ηk(N, ∆t) −ξk(2N∆t) = −2ξk(∆t)eiωk∆t X
n=1
e2iωk∆t(n−1).
(5.74)
Equivalently, we have
ηk(N, ∆t) = ξk(2N∆t) (1 −fk(N, ∆t)) ,
(5.75)
where
fk(N, ∆t) = 2
ξk(∆t)
ξk(2N∆t)eiωk∆t X
n=1
e2iωk∆t(n−1).
(5.76)
By exploiting the geometric series and the definition of ξk, we get
fk(N, ∆t) = 2 (1 −eiωk∆t)",N/A,N/A
"fk(N, ∆t) = 2 (1 −eiωk∆t)
(1 −e2iωkN∆t)eiωk∆t (1 −e2iωkN∆t)
(1 −e2iωk∆t) ,
= 2 (1 −eiωk∆t)
(1 −e2iωk∆t)eiωk∆t.
(5.77)
Finally, by taking the limit of dense pulses, i.e. ∆t →0, we obtain
lim
∆t→0 fk(N, ∆t) = 1,
(5.78)
which means that under the same limit we have
lim
∆t→0 ηk(N, ∆t) = 0.
(5.79)
As a consequence, the decoherence factor vanishes: Γ(t0, tN) →0. Namely, the decohering effect of the en-",N/A,N/A
"vironment on the system is cancelled. Effectively, one has a (dynamical) decoupling of the system from its
environment.
5.2 Quantum Error Mitigation
Quantum Error Mitigation (QEM) wants to translate the improvements of quantum hardware in those of
quantum information and computation. Namely, it is an algorithmic scheme that reduces noise-induced bias in
the expectation value of an observable of interest by post-processing outputs from an ensemble of circuit runs.",N/A,N/A
"To do this, it employs circuits at the same depth as the original unmitigated circuit or above. QEM applies
post-processing directly from the hardware outputs. Thus, if the circuit size, being the product of the circuit
depth times the number of qubits, becomes too large then QEM loses its usefulness.
A good QEM approach should employ a limited number of qubits, while still providing a guaranteed accu-",N/A,N/A
"racy. This converts in a formal error bound, which indicates how well the QEM code works. Moreover, it should
employ only a few (or better none) assumptions about the final state. For example, assuming that the final state
is factorised is not a good assumption. Indeed, it would strongly limit the applicability of the corresponding
QEM algorithm.
80
5 Dynamical Decoupling and Quantum Error Mitigation",N/A,N/A
"Before dwelling in two, among various, algorithms in the QEM context, we provide the general idea of the
QEM approach. We defined the primary circuit as that process that would ideally produce the perfect output
state ˆρ0. Due to the presence of noises, the primary circuit produces the noisy state ˆρ. To account how a circuit
works, we consider an observable of interests ˆO whose expectation value is the output information we seek.",N/A,N/A
"To compute this, we will run the circuit Nsample times, which is the number of circuit executions. Also in the
noiseless case, a finite value of Nsample implies a finite inaccuracy of the estimated average. This is the so-called
shot noise. However, in such a case, there will be no systematic shift, i.e. bias, in the expectation value of ˆO
due to the noise. QEM aims to reduce such a bias. Often, this implies that the corresponding variace increases.",N/A,N/A
"Then, one needs to increase the number of circuit runs N > Nsample to compensate. The sampling overhead is
the cost, in terms of number of repetitions, of the QEM method when compared to the noiseless circuit.
We underline that, conversely to QEC, in QEM there is no monitoring of the errors occurring during the run
of the circuit.
5.2.1 Zero noise extrapolation
The Zero noise extrapolation (ZNE) method extracts the zero-noise expectations from a fitting of the circuit",N/A,N/A
"ran at different values of the noise. We define a time dependent Hamiltonian ˆH(t) that embeds action of the
noiseless circuit. It can be written as
ˆH(t) =
X
α
Jα(t) ˆPα,
(5.80)
where Jα(t) are some time dependent couplings that switch on and off the gates of the circuit, which are
implemented by the corresponding N-qubit Pauli operators ˆPα. The full dynamics, including the action of the
noise, is given by the following master equation
dˆρλ(t)
dt
= −i
ℏ
h
ˆH(t), ˆρλ(t)
i
+ λL[ˆρλ(t)],
(5.81)",N/A,N/A
"dt
= −i
ℏ
h
ˆH(t), ˆρλ(t)
i
+ λL[ˆρλ(t)],
(5.81)
where t ∈[0, T], with T being the time at which the circuit ends. We assume here that the noise coupling λ is
small. Moreover, we assume that the noise dissipator L is invariant under time rescaling and it is independent
from ˆJα(t).
Now, given the observable of interest ˆA, we compute the corresponding expectation value on the noisy circuit
as E(λ) = Tr
h
ˆAˆρλ(T)
i",N/A,N/A
"as E(λ) = Tr
h
ˆAˆρλ(T)
i
, where ˆρλ(T) is the solution of Eq. (5.81). What we want to do is to estimate E(λ) for
λ →0. Since one cannot reduce the value of λ, to construct a series of measurement from where extrapolate the
estimate E(0), we increase the value of λ. This can be done by considering the following rescaling. We dilate
the time T at which the circuit is ran and, due to the time invariance of L, this is equivalent to let the noise",N/A,N/A
"act more on the circuit. Then, one applies this idea with different values of λ and can perform a fit and deduce
the value of E for λ →0. Practically, we perform the circuit Ncir times, at different values of the noise rate
λj = cjλ, j = 0, . . . , Ncir −1 with c0 = 1 < c1 < · · · < cNcir−1. For each value of λj, we run the circuit with the
following rescaled Hamiltonian
ˆH(j)(t) =
X
α
J(j)
α (t) ˆPα,
where
J(j)
α (t) = c−1
j Jα(c−1
j t),
(5.82)
for a time Tj = cjT. The rescaled dynamics gives",N/A,N/A
"for a time Tj = cjT. The rescaled dynamics gives
dˆρ(j)
λ (t)
dt
= −i
ℏ
h
ˆH(j)(t), ˆρ(j)
λ (t)
i
+ λL[ˆρ(j)
λ (t)].
(5.83)
By merging the latter with Eq. (5.82), we obtain
5.2 Quantum Error Mitigation
81
dˆρ(j)
λ (t)
dt
= −i
ℏ
X
α
c−1
j Jα(c−1
j t)
h
ˆPα, ˆρ(j)
λ (t)
i
+ λL[ˆρ(j)
λ (t)].
(5.84)
By defining s = c−1
j t, which runs in the interval s ∈[0, T] since t ∈[0, Tj], we rewrite the above master equation
as
dˆρ(j)
λ (t)
dt
= dˆρ(j)
λ (cjs)
cjds
= −i
ℏ
X
α
c−1
j Jα(s)
h
ˆPα, ˆρ(j)
λ (cjs)",N/A,N/A
"cjds
= −i
ℏ
X
α
c−1
j Jα(s)
h
ˆPα, ˆρ(j)
λ (cjs)
i
+ λL[ˆρ(j)
λ (cjs)].
(5.85)
By multiplying the left and right hand side by cj we obtain
dˆρ(j)
λ (cjs)
ds
= −i
ℏ
h
ˆH(s), ˆρ(j)
λ (cjs)
i
+ cjλL[ˆρ(j)
λ (cjs)],
(5.86)
which is Eq. (5.81) with λ substituted with cjλ. Its solution at time s = T is given by ˆρcjλ(T) = ˆρ(j)
λ (Tj).
Correspondingly, we compute the expectation value E(λj) = Tr
h
ˆAˆρ(j)
λ (Tj)
i
= Tr
h
ˆAˆρcjλ(T)
i
. Experimentally,",N/A,N/A
"λ (Tj)
i
= Tr
h
ˆAˆρcjλ(T)
i
. Experimentally,
for each cj, one performs Nsample runs of the circuit and obtains an estimator ˜E(λj), which converges to the
true value E(λj) only in the asymptotic limit Nsample →∞. Specifically, one has
˜E(λj) = E(λj) + ˜δ,
(5.87)
where ˜δ is a random variable with zero mean and variance E[˜δ2] = σ2
0/Nsample, with σ2
0 corresponding to the
single-shot variance. Here, E is to the mean over the sampling.",N/A,N/A
"Now, the ZNE problem is to construct a good estimator ˜E(0) for the expectation value E(λ = 0) =
Tr
h
ˆAˆρ0(T)
i
from the set of estimators ˜E(λj). Figure 5.2 represents the problem. To be a good estimator,
𝜆
1
2
3
1.5
2.5
3.5
!𝐸(0)
!𝐸(𝜆)
!𝐸(1.5𝜆)
!𝐸(2𝜆)
!𝐸(2.5𝜆)
!𝐸(3𝜆)
!𝐸(3.5𝜆)
Fig. 5.2: Graphical representation of the Zero Error Extrapolation. Given the set of estimators ˜E(λ) at different",N/A,N/A
"values of the noise (black and blue dots and error bars), one performs a fit assuming a specific model (gray
dashed line) with corresponding confidence region (light blue region). In such a way, one extrapolates the value
of ˜E(0) with its corresponding error bar (red point and error bar).
we want that its bias
Bias( ˜E(0)) = E[ ˜E(0) −E(0)],
(5.88)
82
5 Dynamical Decoupling and Quantum Error Mitigation
and its variance
Var( ˜E(0)) = E[ ˜E(0)2] −E[ ˜E(0)]2,
(5.89)",N/A,N/A
"Var( ˜E(0)) = E[ ˜E(0)2] −E[ ˜E(0)]2,
(5.89)
are both small. We employ the mean squared error (MSE) are a figure of merit with respect to the true unknown
parameter
MSE( ˜E(0)) = E[( ˜E(0) −E(0))2],
= Var( ˜E(0)) + (Bias( ˜E(0)))2.
(5.90)
If the expectation value E(λ) can be an arbitrary function of λ without any regularity assumption, then ZNE
is impossible. However, from physical considerations, it is reasonable to have a model for it, for example we can",N/A,N/A
"assume a linear, a polynomial or an exponential dependence with respect to λ.
1 If we assume a linear dependence on λ, the corresponding linear model is given by
Elinear(λ) = a0 + a1λ.
(5.91)
In such a case, a simple analytic solution exists, which is that of the ordinary least squared estimator of the
intercept parameter. Namely, we have
˜Elinear(0) = ¯E(λ) −SλE
Sλλ
¯λ,
(5.92)
where
¯λ =
1
Ncir
Ncir−1
X
j=0
λj,
¯E(λ) =
1
Ncir
Ncir−1
X
j=0
˜E(λj),
SλE =
Ncir−1
X
j=0
(λj −¯λ)( ˜E(λj) −¯E(λ)),",N/A,N/A
"SλE =
Ncir−1
X
j=0
(λj −¯λ)( ˜E(λj) −¯E(λ)),
Sλλ =
Ncir−1
X
j=0
(λj −¯λ)2.
(5.93)
With respect to the zero noise value Elinear(0), the estimator ˜Elinear(0) is unbiased. Its variance, under the
assumption that the statistical uncertainty is the same for each λj, reads
Var( ˜Elinear(0)) =
σ2
0
Nsample
 1
Ncir
+
¯λ2
Sλλ

.
(5.94)
2 The Richardson’s extrapolation is a special case of the polynomial extrapolation, which is limited at order
Ncir −1. The corresponding model is given by",N/A,N/A
"Ncir −1. The corresponding model is given by
ERich(λ) = a0 + a1λ + · · · + cNcir−1λNcir−1.
(5.95)
This is the only case in which the fitted polynomial perfectly interpolates the Ncir data points such that, in
the ideal limit of an infinite number of samples Nsample →∞, the error with respect to the true expectation
value is by construction O(Ncir). Using the Lagrange polynomial, the estimator can be expressed explicitly
as
˜ERich(0) =
Ncir−1
X
j=0
˜E(λj)γj,
(5.96)
where",N/A,N/A
"˜ERich(0) =
Ncir−1
X
j=0
˜E(λj)γj,
(5.96)
where
5.2 Quantum Error Mitigation
83
γj =
Y
m̸=j
cm
cj −cm
.
(5.97)
The error of the estimator is O(Ncir) only in the asymptotic limit Nsample →∞. In other words, O(Ncir)
corresponds to the bias term in Eq. (5.88). In a real scenario, Nsample is finite, and the variance term in
Eq. (5.88) grows exponentially as we increase Ncir.
5.2.2 Probabilistic error cancellation",N/A,N/A
"5.2.2 Probabilistic error cancellation
The Probabilistic error cancellation (PEC) method cancels the effects of the noise employing a map that acts
as the inverse of the noise map under suitable average.
Suppose the ideal circuit is performed by a unitary CPTP map U being the consecutive application of unitary
gates: ˆUcircuit = ˆUd . . . ˆU1, where d id the depth of the circuit. One can represent the corresponding noisy circuit",N/A,N/A
"by substituting each unitary operation with its noisy counterpart, namely ˆUiˆρ ˆU †
i →ˆUiΛi[ˆρ] ˆU †
i , where Λi is a
CPTP noisy map and ˆρ is the N-qubit state. If we focus on a single gate ˆUi, the two corresponding circuits are
represented as
Ui
→
Λi
Ui
(5.98)
Now, the point is if we can invert the CPTP map Λi via the application of its inverse Λ−1
i . In general, this is
not possible. Indeed, typically, Λ−1
i
is not a CPTP map and thus such an inverse operation of the noise cannot",N/A,N/A
"be implemented. Nevertheless, such an operation can be implemented on average.
Consider the toy model of a single qubit, where the unitary noiseless operation is the identity: ˆU = ˆ1, and
the noise channel is the bit-flip with a probability p. Thus, the corresponding map is
Λ(ˆρ) = (1 −p)ˆ1ˆρˆ1 + pˆσxˆρˆσx.
(5.99)
This map corresponds to the unravelling with two components: with a probability p one applies an extra gate X,",N/A,N/A
"and with probability (1−p) one does nothing, i.e. applies the gate 1. Notably, both these gates have an inverse.
Indeed, ˆ1−1 = ˆ1 and ˆσ−1
x
= ˆσx. Then, we construct the inverse noise map Λ−1 as having two components: with
a probability q we apply an X gate, and with a probability (1 −q) we apply an 1 gate. The corresponding total
circuit can be then decomposed in the four components:
Λ−1
Λ
1
=

























1
1
1
a), with prob = (1 −p)(1 −q),
X
1
1",N/A,N/A
"



1
1
1
a), with prob = (1 −p)(1 −q),
X
1
1
b), with prob = (1 −p)q,
1
X
1
c), with prob = p(1 −q),
X
X
1
d), with prob = pq.
(5.100)
Now, we want to fix q such that, under the ensemble average, the circuit b) occurs with a probability being the
opposite value of that of circuit c) occuring, and that the sum of the probabilities of having the circuit a) and
d) gives 1. This implies the following system of equations
84
5 Dynamical Decoupling and Quantum Error Mitigation",N/A,N/A
"PaPd = (1 −p)(1 −q) + pq = 1,
and
PbPc = (1 −p)q + p(1 −q) = 0.
(5.101)
The solution is given by
q =
−p
1 −2p,
(5.102)
which is a quasi-probability, since it can take negative values, and it is shown in the left panel of Fig. 5.3. Now,
0.0
0.2
0.4
0.6
0.8
1.0
-4
-2
0
2
4
p
q
0.0
0.2
0.4
0.6
0.8
1.0
2
4
6
8
10
12
p
γ
Fig. 5.3: Quasi-probability q (left panel) and renormalisation constant γ (right panel) as a function of the
probability p of having an error.
the inverse noise map Λ−1 is given by",N/A,N/A
"the inverse noise map Λ−1 is given by
Λ−1(ˆρ) = (1 −q)ˆ1ˆρˆ1 + qˆσxˆρˆσx,
= sgn(1 −q)|1 −q|ˆ1ˆρˆ1 + sgn(q)|q|ˆσxˆρˆσx,
= γ

S1P1ˆ1ˆρˆ1 + SXPX ˆσxˆρˆσx

,
(5.103)
where in the first line we used x = sgn(x)|x|, with sgn indicating the sign function, and in the second line we
introduced
γ = |1 −q| + |q|,
(5.104)
which is represented in the right panel of Fig. 5.3. Finally, we defined
S1 = sgn(1 −q),
P1 = |1 −q|
γ
,
SX = sgn(q),
PX = |q|
γ .
(5.105)",N/A,N/A
"P1 = |1 −q|
γ
,
SX = sgn(q),
PX = |q|
γ .
(5.105)
Thus, independently from the unravelling of the noise map, i.e. without knowing if the bit-flip noise is applied
or not, we apply the map Λ−1 in the last line of Eq. (5.103). This can be implemented with the following circuit:
Λ−1
Λ
1
⟨M⟩
CPP
=













1
Λ
1
M1
S1
a), with prob = P1,
X
Λ
1
MX
SX
b), with prob = PX.
(5.106)
5.2 Quantum Error Mitigation
85",N/A,N/A
"(5.106)
5.2 Quantum Error Mitigation
85
A classical post-processing (CPP) is applied to multiplicate the outcome of the result by the proper sign factor.
Eventually, the mitigated result is given by
⟨M⟩= γ (S1P1M1 + SXPXMX) .
(5.107)
This is an unbiased estimator. The cost of the mitigation procedure goes in the variance, which grows by a
factor γ2 compared to the unmitigated one.
Consider a more general case of the noise map Λ acting on a single qubit, which reads",N/A,N/A
"Λ(ˆρ) = λ0ˆρ + λ1ˆσxˆρˆσx + λ2ˆσy ˆρˆσy + λ3ˆσz ˆρˆσz,
(5.108)
where
λα ≥0,
and
3
X
α=0
λα = 1.
(5.109)
Such a map is a CPTP map. Similarly as done above, we construct the inverse map Λ−1 as
Λ−1(ˆρ) = q0ˆρ + q1ˆσxˆρˆσx + q2ˆσy ˆρˆσy + q3ˆσz ˆρˆσz,
(5.110)
where we require that
3
X
α=0
qα = 1,
(5.111)
but we do not add any restriction on the sign of qα. Then, in terms of unravellings, we have 4 possible evolutions",N/A,N/A
"provided by Λ and 4 by Λ−1 for a total of 16 possible mappings. Explicitly they give
Λ Λ−1
ˆρ →ˆρ′
probability Pαβ
ˆ1
ˆ1
ˆρ
λ0q0
ˆ1
ˆσx
ˆσxˆρˆσx
λ0q1
ˆ1
ˆσy
ˆσy ˆρˆσy
λ0q2
ˆ1
ˆσz
ˆσz ˆρˆσz
λ0q3
ˆσx
ˆ1
ˆσxˆρˆσx
λ1q0
ˆσx ˆσx
ˆσ2
xˆρˆσ2
x
λ1q1
ˆσx ˆσy ˆσxˆσy ˆρˆσyˆσx
λ1q2
ˆσx ˆσz
ˆσxˆσz ˆρˆσzˆσx
λ1q3
ˆσy
ˆ1
ˆσy ˆρˆσy
λ2q0
ˆσy ˆσx ˆσyˆσxˆρˆσxˆσy
λ2q1
ˆσy ˆσy
ˆσ2
y ˆρˆσ2
y
λ2q2
ˆσy
ˆσz
ˆσyˆσz ˆρˆσzˆσy
λ2q3
ˆσz
ˆ1
ˆσz ˆρˆσz
λ3q0
ˆσz
ˆσx ˆσzˆσxˆρˆσxˆσz
λ3q1
ˆσz
ˆσy
ˆσzˆσy ˆρˆσyˆσz
λ3q2
ˆσz
ˆσz
ˆσ2",N/A,N/A
"λ3q1
ˆσz
ˆσy
ˆσzˆσy ˆρˆσyˆσz
λ3q2
ˆσz
ˆσz
ˆσ2
z ˆρˆσ2
z
λ3q3
(5.112)
However, we can exploit that ˆσ2
α = ˆ1 and that ˆσiˆσj = iϵijkˆσk. Thus, the above table becomes
86
5 Dynamical Decoupling and Quantum Error Mitigation
Λ Λ−1 ˆρ →ˆρ′ probability Pαβ
ˆ1
ˆ1
ˆρ
λ0q0
ˆ1
ˆσx
ˆσxˆρˆσx
λ0q1
ˆ1
ˆσy
ˆσy ˆρˆσy
λ0q2
ˆ1
ˆσz
ˆσz ˆρˆσz
λ0q3
ˆσx
ˆ1
ˆσxˆρˆσx
λ1q0
ˆσx ˆσx
ˆρ
λ1q1
ˆσx ˆσy
ˆσz ˆρˆσz
λ1q2
ˆσx ˆσz
ˆσy ˆρˆσy
λ1q3
ˆσy
ˆ1
ˆσy ˆρˆσy
λ2q0
ˆσy ˆσx
ˆσz ˆρˆσz
λ2q1
ˆσy ˆσy
ˆρ
λ2q2
ˆσy
ˆσz
ˆσxˆρˆσx
λ2q3",N/A,N/A
"λ2q1
ˆσy ˆσy
ˆρ
λ2q2
ˆσy
ˆσz
ˆσxˆρˆσx
λ2q3
ˆσz
ˆ1
ˆσz ˆρˆσz
λ3q0
ˆσz
ˆσx
ˆσy ˆρˆσy
λ3q1
ˆσz
ˆσy
ˆσxˆρˆσx
λ3q2
ˆσz
ˆσz
ˆρ
λ3q3
(5.113)
Finally, we impose that the sum of the probabilities of getting ˆρ′ = ˆρ should be 1, and those such ˆρ′ ̸= ˆρ should
be 0. Namely
P00 + P11 + P22 + P33 = λ0q0 + λ1q1 + λ2q2 + λ3q3 = 1,
P01 + P10 + P23 + P32 = λ0q1 + λ1q0 + λ2q3 + λ3q2 = 0,
P02 + P20 + P13 + P31 = λ0q2 + λ2q0 + λ1q3 + λ3q1 = 0,
P03 + P30 + P12 + P21 = λ0q3 + λ3q0 + λ1q2 + λ2q1 = 0.
(5.114)",N/A,N/A
"(5.114)
The solution to this system of linear equations gives
q0 = 1
4

1 +
1
1 −2λ1 −2λ2
+
1
1 −2λ1 −2λ3
+
1
1 −2λ2 −2λ2

,
q1 = 1
4

1 −
1
1 −2λ1 −2λ2
−
1
1 −2λ1 −2λ3
+
1
1 −2λ2 −2λ2

,
q2 = 1
4

1 −
1
1 −2λ1 −2λ2
+
1
1 −2λ1 −2λ3
−
1
1 −2λ2 −2λ2

,
q3 = 1
4

1 +
1
1 −2λ1 −2λ2
−
1
1 −2λ1 −2λ3
−
1
1 −2λ2 −2λ2

.
(5.115)
The inverse map can be rewritten as
Λ−1(ˆρ) =
3
X
α=0
qαˆσαˆρˆσα,
=
3
X
α=0
sgn(qα)|qα|ˆσαˆρˆσα,
= γ
3
X
α=0
SαPαˆσαˆρˆσα,
(5.116)
where
γ =
3
X
α=0
|qα|,
Sα = sgn(qα),",N/A,N/A
"(5.116)
where
γ =
3
X
α=0
|qα|,
Sα = sgn(qα),
and
Pα = |qα|
γ .
(5.117)
5.2 Quantum Error Mitigation
87
Then, the mitigated result is given by
⟨M⟩= γ
3
X
α=0
SαPαMα,
(5.118)
where Mα is the outcome obtained from the measurement at the end of the circuit at whose beginning we
applied ˆσα.
The application of PEC mitigation works if one has an almost perfect knowledge of the noise. However, for",N/A,N/A
"such a characterisation for N qubits, one needs to quantify 4N −1 parameters, where 4 is the dimensions of the
single-qubit algebra and 1 degree of freedom is fixed as it corresponds to the map given by ˆ1⊗N whose associated
probability is given by the unity minus the sum of all the other probabilities. To be quantitative, for 2 qubits
one needs 15 parameters, for 10 qubits these become ∼106, and for 50 qubits we have ∼1030 parameters.",N/A,N/A
"Therefore, it is an approach that requires too many classical processing to be used for a large number of qubits.
Appendix A
Solutions of the exercises
A.1 Solution to Exercise 1.1
To express the Hadamard gate H as a rotation, we proceed as follows. We consider the general rotation
ˆRn(θ) = cos(θ/2)ˆ1 −i sin (θ/2)n · ˆσ,
(A.1)
of an angle θ around n, where the Pauli matrices are
X =
0 1
1 0

,
Y =
0 −i
i 0

,
Z =
1 0
0 −1

.
(A.2)
From such a rotation, we want to obtain
H =
1
√
2
1 1",N/A,N/A
"H =
1
√
2
1 1
1 −1

.
(A.3)
First thing, we highlight that the sum X + Z gives
X + Z =
1 1
1 −1

,
(A.4)
then it follows that
H = X + Z
√
2
= { 1
√
2, 0,
1
√
2} · ˆσ.
(A.5)
Such an expression recalls the last term in Eq. (A.1). Finally, we need to set the angle θ so that the first term
in Eq. (A.1) vanishes. This is θ = π. Then
H = i ˆRn(π),
where
n = { 1
√
2, 0,
1
√
2},
(A.6)
gives the solution.
A.2 Solution to Exercise 1.2",N/A,N/A
"gives the solution.
A.2 Solution to Exercise 1.2
To prove that, given two fixed non-parallel normalised vectors n and m, any unitary ˆU can be expressed as
ˆU = eiα ˆRn(β) ˆRm(γ) ˆRn(δ),
(A.7)
with α, β, γ, δ ∈R, then one needs to recast ˆU in the form
88
A.3 Solution to Exercise 1.3
89
ˆU = eiα ˆRt(ω),
(A.8)
with α ∈R and t ∈R3 suitably chosen.
The first step of the proof is to write (m · ˆσ)(n · ˆσ) in terms of a single Pauli matrix vector ˆσ. We have",N/A,N/A
"(m · ˆσ)(n · ˆσ) = (m1ˆσx + m2ˆσy + m3ˆσz)(n1ˆσx + n2ˆσy + n3ˆσz),
= m · n + m1n2ˆσxˆσy + m1n3ˆσxˆσz + m2n1ˆσyˆσx + m2n3ˆσyˆσz + m3n1ˆσzˆσx + m3n2ˆσzˆσy.
(A.9)
By applying
ˆσiˆσj = δijˆ1 + iϵijkˆσk,
(A.10)
we have that Eq. (A.9) becomes
(m · ˆσ)(n · ˆσ) = (m · n)ˆ1 + i(m × n) · ˆσ.
(A.11)
The second step is to consider the composition of two rotations:
ˆRm(γ) ˆRn(δ) =
 cos(γ/2)ˆ1 −i sin (γ/2)m · ˆσ
  cos(δ/2)ˆ1 −i sin (δ/2)n · ˆσ

,",N/A,N/A
"  cos(δ/2)ˆ1 −i sin (δ/2)n · ˆσ

,
= cos(γ/2) cos(δ/2)ˆ1 −i cos(γ/2) sin (δ/2)n · ˆσ −i cos(δ/2) sin (γ/2)m · ˆσ
−sin (γ/2) sin (δ/2)(m · ˆσ)(n · ˆσ).
(A.12)
Substituting Eq. (A.11) in the last expression, we find that
ˆRm(γ) ˆRn(δ) = ˆRh(ϵ) = cos(ϵ/2)ˆ1 −i sin (ϵ/2)h · ˆσ,
(A.13)
where ϵ and h are taken such that
cos(ϵ/2) = cos(γ/2) cos(δ/2) −sin (γ/2) sin (δ/2)m · n,
sin(ϵ/2)h = cos(γ/2) sin (δ/2)n + cos(δ/2) sin (γ/2)m + sin (γ/2) sin (δ/2)(m × n).
(A.14)
Then, we have",N/A,N/A
"(A.14)
Then, we have
ˆRn(β) ˆRm(γ) ˆRn(δ) = ˆRn(β) ˆRh(ϵ) = ˆRt(ω),
(A.15)
where we applied again the composition of two rotations, which ends the proof.
A.3 Solution to Exercise 1.3
Consider two qubits, where the first is prepared in the superposition
|ψ1⟩= |0⟩+ |1⟩
√
2
,
(A.16)
while the second is initialised in the ground state |ψ2⟩= |0⟩. The total state is
|ψ12⟩= |0⟩+ |1⟩
√
2
|0⟩= |00⟩+ |10⟩
√
2
.
(A.17)",N/A,N/A
"|ψ12⟩= |0⟩+ |1⟩
√
2
|0⟩= |00⟩+ |10⟩
√
2
.
(A.17)
From the first expression, one clearly sees that the state is separable. By appling the CNOT gate, we find that
the state becomes
|ψ12⟩= |00⟩+ |11⟩
√
2
,
(A.18)
which is a fully entangled state.
90
A Solutions of the exercises
A.4 Solution to Exercise 1.4
Consider the circuit
|0⟩
|ψ⟩
H
S†
H
U
(A.19)
Its action is the following
|0⟩|ψ⟩
ˆ
H⊗ˆ1
−−−→
1
√
2(|0⟩+ |1⟩) |ψ⟩
ˆS†⊗ˆ1
−−−→
1
√
2(|0⟩−i |1⟩) |ψ⟩
C(U)
−−−→
1
√
2(|0⟩|ψ⟩−i |1⟩ˆU |ψ⟩)
ˆ
H⊗ˆ1
−−−→1",N/A,N/A
"C(U)
−−−→
1
√
2(|0⟩|ψ⟩−i |1⟩ˆU |ψ⟩)
ˆ
H⊗ˆ1
−−−→1
2
h
(|0⟩+ |1⟩) |ψ⟩−i(|0⟩−|1⟩) ˆU |ψ⟩
i
= 1
2
h
|0⟩(ˆ1 −i ˆU) |ψ⟩+ |1⟩(ˆ1 + i ˆU) |ψ⟩
i
.
(A.20)
Finally, one measures qubit 0, and the probability of finding the qubit in |0⟩is
P(|0⟩) = 1
4 ⟨ψ|

ˆ1 + i ˆU † 
ˆ1 −i ˆU

|ψ⟩= 1
2

1 + ℑ⟨ψ| ˆU|ψ⟩

,
(A.21)
which ends the exercise.",N/A,N/A
"arXiv:1212.4177v1  [math-ph]  17 Dec 2012
A “quantum spherical model” with transverse
magnetic ﬁeld.
I. Lyberg
School of Theoretical Physics, Dublin Institute for Advanced Studies
ilyberg@stp.dias.ie
September 10, 2018
1
Introduction
The Quantum Ising Model with a transverse magnetic ﬁeld is well known [1]
[2]. In one dimension it has the Hamiltonian
HN = −J
N
X
n=1
σx
nσx
n+1 + B
N
X
n=1
σz
n + H
N
X
n=1
σx
n,
(1)
where J > 0 is the coupling constant and σx =
 0
1
1
0

, σy =
 0
−i
i
0
",N/A,N/A
" 0
1
1
0

, σy =
 0
−i
i
0

and σz =
 1
0
0
−1

are the Pauli matrices. B and H are transverse and
longitudinal magnetic ﬁelds, respectively. The partition function is
ZN = tr e−βHN
(2)
where β is the inverse temperature. In the case where H = 0 this model has
been exactly solved [1] [3]. The free energy is [2]
f(β, J, B)
=
−lim
N→∞
1
βN log ZN
=
−1
2πβ
Z 2π
0
log 2 cosh β∆(x) dx
(3)
where
∆(x) =
√
J2 + B2 −2BJ cos x.
(4)
1
In particular the ground state energy is given by
f∞(J, B) = lim",N/A,N/A
"f∞(J, B) = lim
β→∞f(β, J, B) = −1
2π
Z 2π
0
∆(x) dx.
(5)
In this limit there is a critical point in B at B = J. The correlation function
⟨σx
j σx
k⟩= lim
N→∞
tr σx
j σx
ke−βHN
ZN
(6)
can be written as a Toeplitz determinant of size |j −k| just as the corre-
lation function of the two dimensional classical Ising model [4], but only in
the limit β →∞. In fact the correlation function limβ→∞⟨σx
j σx
k⟩is the same
as the diagonal correlation function ⟨σjjσkk⟩of the two dimensioanl classi-",N/A,N/A
"cal Ising lattice for T < Tc, the ratio B/J in the one dimensional quantum
model corresponding to (sinh 2E1/kBT sinh 2E2/kBT)−1 in the two dimen-
sional classical model. (Here E1 and E2 are the coupling constants in the
horizontal and vertical directions, respectively). In particular the limit of
inﬁnite separation is given by [3]
lim
|j−k|→∞lim
β→∞⟨σx
j σx
k⟩=
(
{1 −(B/J)2}1/4
if B < J,
0
if B ≥J,
(7)
which is most easily proved using Szeg¨o’s theorem [5] [6].
2
The quantum spherical model",N/A,N/A
"2
The quantum spherical model
In analogy with (1) we deﬁne a partition function of a (d-dimensional)
isotropic quantum spherical model on a lattice Λ as follows:
ZN
=
Z
[0,∞)N
Z
[0,2π)N
Z
[0,π]N e
P
j,k∈Λ : ⟨jk⟩βJrj cos θjrk cos θk
e
P
j∈Λ β(Brj sin θj cos ϕj+Hrj cos θj)
N
Y
l=1
r2
l sin θl dNθ dNϕ δ

N
X
m=1
r2
m −N

dNr
=
Z
R3N e
P
⟨jk⟩βJzjzk+P
j β(Bxj+Hzj)δ

N
X
k=1
(x2
k + y2
k + z2
k) −N

d3Nx.(8)
Here J > 0, B ≥0 and H > 0. δ signiﬁes the Dirac distribution. The",N/A,N/A
"notation ⟨jk⟩means that j and k are nearest neighbors on Λ. Unlike the
2
Quantum Ising Model with H = 0, in this model the critical point is B = 2Jd
(in the limit H →0). In fact, it will be shown that in this limit the ground
state free energy fH,∞:= −limβ→∞limN→∞(Nβ)−1 log ZN is given by
f0,∞= lim
H→0 fH,∞= −
(
Jd + B2/4Jd
if B ≤2Jd,
B
if B > 2Jd.
(9)
We shall now give a proof of (9).
2.1
The case B > 2Jd
We use the method of steepest descent to prove this result, following the",N/A,N/A
"calculation by Baxter [7]. We let H = 0 in (8). Clearly the integrand in
(8) may be multiplied by a factor exp a(PN
k=1(x2
k + y2
k + z2
k) −N) without
changing the partition function ZN. Using the identity
δ(x) = 1
2π
Z ∞
−∞
eisxds,
(10)
together with (8) and letting a > 0, we get
ZN = πN−1
2
Z
RN
Z ∞
−∞

1
a + is
N
exp N(βB)2
4(a + is)
exp [
X
⟨jk⟩
βJzjzk +
X
j
(a + is)(1 −z2
j )] ds dNz
(11)
after integrating over x and y. Let V be the symmetric matrix such that
zTVz = (a + is)
N
X
j=1
z2",N/A,N/A
"zTVz = (a + is)
N
X
j=1
z2
j −βJ
N
X
⟨jk⟩
zjzk.
(12)
In this way (11) can be written as
ZN = πN−1
2
Z
RN
Z ∞
−∞

1
a + is
N
exp N(βB)2
4(a + is)
exp [−zTVz + N(a + is)] ds dNz.
(13)
We now choose the constant a so large that all the eigenvalues of V have
positive real part. This allows us to change the order of integration, and we
may now write (13) as
ZN = π3N/2−1
2
Z ∞
−∞

1
a + is
N
(det V)−1/2
exp
 N(βB)2
4(a + is) + N(a + is)

ds.
(14)
3",N/A,N/A
"exp
 N(βB)2
4(a + is) + N(a + is)

ds.
(14)
3
We need to calculate the eigenvalues of V. Since V is cyclic, this is easily
done. We let the lattice be d-dimensional hypercubic, so that
N = Ld
(15)
for some positive integer L. It now follows from (12) that the eigenvalues are
λ(ω1, ..., ωd) = a + is −βJ
d
X
j=1
cos ωj
(16)
where each ωj takes the values {2πk/L}L−1
k=0, and a > βJd. The determinant
of V is the product of its eigenvalues, so
log det V =
X
ωj : 1≤j≤d
log λ(ω1, ..., ωd).
(17)",N/A,N/A
"log det V =
X
ωj : 1≤j≤d
log λ(ω1, ..., ωd).
(17)
Clearly
ZN = βJ
2πi
 π
βJ
3N/2 Z c+i∞
c−i∞
eNφ(w)dw,
(18)
where
φ(w) = βJw −1
2g(w) + (βB)2/4βJw,
(19)
c = (a −βJd)/βJ and
g(z) = 2 log w + 1
N
X
ωj
log (w −
X
j
cos ωj).
(20)
Since φ approaches +∞as w approaches 0 or +∞along the real line, φ has
a minumum at some w0, 0 < w0 < ∞. Thus ℜφ has a maximum at w0 along
the line (w0 −i∞, w0 +i∞). Since B > 2Jd, we may choose c = w0. We now",N/A,N/A
"use the method of steepest descent (see for instance Murray [8]), by letting
N approach inﬁnity. In this way, the free energy is
f
=
−β−1 lim
N→∞N−1 log ZN
=
−3
2β ln (π/βJ) −β−1φ(w0).
(21)
Now
lim
β→∞w0 = B/2J,
(22)
and thus the ground state energy is
lim
β→∞f
=
−lim
β→∞β−1φ(w0)
=
−B.
(23)
4
2.2
The case B ≤2Jd
In this case we let H > 0, so instead of (13) we have
ZN = πN/2−1
2
Z
RN
Z ∞
−∞

1
a + is
N
exp N(βB)2
4(a + is)
exp [−zTVz + hTz + N(a + is)] ds dNz,
(24)",N/A,N/A
"exp [−zTVz + hTz + N(a + is)] ds dNz,
(24)
where h = βH(1, ..., 1). We change variables to t = z −1
2V−1h, and rotate
the axes in (t1, ..., tN) to make V diagonal. Thus we get
ZN = πN/2−1
2
Z ∞
−∞

1
a + is
N
(det V)−1/2 exp N(βB)2
4(a + is)
exp [hTV−1h/4 + N(a + is)] ds.
(25)
Thus
ZN = πN/2
2πi
Z c+i∞
c−i∞
eNφ(w) dw,
(26)
where a + is −βJd = βJw and
φ(w)
=
βJ(w + d) + (βH)2
4βJw +
(βB)2
4βJ(w + d)
−
log βJ(w + d) −1
2
X
ωj
log (βJ(w + d) −βJ
X
j
cos ωj). (27)",N/A,N/A
"2
X
ωj
log (βJ(w + d) −βJ
X
j
cos ωj). (27)
We proceed in the same way as before, taking the limit N →∞and then
β →∞. In this case w0 →0 as H →0. The free energy is thus
f = −Jd −B2
4Jd.
(28)
This ends the proof.
3
Discussion
Comparison of (5) and (9) shows that the susceptibilites of the two mod-
els at B = 0 are equal when d = 1; that is −∂2f∞/∂B2|B=0 = 1/2J and
−∂2f0,∞/∂B2|B=0 = 1/2Jd. While the Quantum Ising Model has only been",N/A,N/A
"exactly solved in the one dimensional case, the quantum spherical modelcan
be solved in any ﬁnite dimension.
Acknowledgements The authour would like to thank Prof. T. Dorlas for
many discussions.
5
References
[1] E. Lieb, T. Schultz and D. Mattis. Two Soluble Models of an Antiferro-
magnetic Chain. Ann. Phys., 16, 407 (1961).
[2] D. C. Mattis. The theory of magnetism made simple. World Scientiﬁc,
New Jersey (2006).
[3] B. M. McCoy. Spin Correlation Functions of the X-Y Model. Phys. Rev.,",N/A,N/A
"173, 531 (1968).
[4] B. Kaufman and L. Onsager. Crystal statistics. III. Short-range order
in a binary Ising model. Phys. Rev. 76, 1244 (1949).
[5] E. W. Montroll, R. B. Potts and J. C. Ward. Correlations and sponta-
neous magnetization of the two dimensional Ising model. J. Math. Phys.,
4, 308 (1963).
[6] U. Grenander and G. Szeg¨o. Toeplitz Forms and Their Applications.
University of California Press. Berkeley (1958).
[7] R. J. Baxter. Exactly solved models in statistical mechanics. Academic",N/A,N/A
"Press, London (1982).
[8] J. D. Murray. Asymptotic Analysis. Springer-Verlag, New York (1984).
6",N/A,N/A
"The Governance of Physical Artiﬁcial Intelligence
Yingbo Li*1,*, Anamaria-Beatrice Spulber2, and Yucong Duan*3,*
1Hainan University
2Visionogy
3Hainan University
*Corresponding author: xslwen@outlook.com, duanyucong@hotmail.com
ABSTRACT
Physical artiﬁcial intelligence can prove to be one of the most important challenges of the artiﬁcial intelligence. The governance
of physical artiﬁcial intelligence would deﬁne its responsible intelligent application in the society.
Introduction",N/A,N/A
"Introduction
Artiﬁcial Intelligence (AI) has grown to be the fundamental technology in today’s world. Over the last few years, not only has
AI been popularly applied in typical AI applications of information and signal processing such as Natural Language Processing
(NLP), but it has also empowered all the other industries such as healthcare and robotics. Miriyev and Kovac1 proposed to",N/A,N/A
"deﬁne the AI used in Robotics as Physical Artiﬁcial Intelligence (PAI) because PAI interacts with the physical world, contrary
to the notion of traditional Digital Artiﬁcial Intelligence (DAI) applied in digital information processing. From this perspective,
we propose to extend the notion of PAI to a much wider domain to also include Internet of Things (IoT), or automatic driving",N/A,N/A
"cars. To the best of our knowledge, most research on AI governance is limited to the domain of DAI, so in the present paper we
propose to outline the governance framework of PAI.
The application of PAI
In the proposed concept of PAI by Miriyev and Mirko 1, PAI refers to the typical robot system. While, we propose to extend the
concept of PAI to cover all potential applications with the built-in AI perceiving and interacting between the cyberspace and the",N/A,N/A
"physical world. Besides the robot system with the AI working in an integrated and limit physical environment, the distributed
intelligent system with AI capability is the typical Distributed PAI. As shown in Fig. 1, PAI could be applied in and include
multiple distributed industries, such as IoT, self-driving cars, agriculture, healthcare and logistics.
We propose to classify PAI into two overlapped kinds as shown in Fig. 1: Independent PAI and Distributed PAI. Independent",N/A,N/A
"PAI refers to the intelligent device and the robot1. Distributed PAI becomes more and more popular when the edge computing2
is mature and every device is connected to the network in the wider space. IoT and edge computing are typical Distributed PAI
subdomains. Since it is popular for every intelligent system to be online and individual units in Distributed PAI have strong
computing capabilities now, Independent PAI and Distributed PAI will overlap in multiple applications3.",N/A,N/A
"The IoT is a typical distributed system with a spatial distribution that ranges from a small space such as a room to a wider
area such as a city. The IoT is formed of various sensors that capture the signals and changes in the physical world. Its AI
power could happen in both server side and the edge side. Based on the AI analysis, IoT could directly or indirectly make
predictions in the cyberspace to inﬂuence the physical world. For example, a self-driving car needs to ﬁrst perceive real time",N/A,N/A
"road situations and connect to the Internet for navigation, then adjust the driving behavior. The agriculture is one of the most
successful PAI applications. The sensors in the agriculture including cameras, temperature meter, hygrometer, etc, monitor the
growth of the plant and predict, for example, the optimal pesticide intervention and the best harvesting time. In the healthcare",N/A,N/A
"industry, families, nursing homes or hospitals could use the biological sensors and the chemical sensors to monitor a patient
and predict potential risks such as falling or unstable situations through a monitoring center. The ""last mile"" is the expensive
and hard problem in the logistic industry. A typical distributed AI application could help with delivery tasks through delivery",N/A,N/A
"robots and drones connected to and commanded by the center server. Another example is the automatic sorting robot that has
been used in the sorting center of the logistics. The general framework of Distributed PAI is described in Fig. 2.
DAI mimics the brain capability of logical thinking and induction in human brain, to process the data and signals perceived
by human eyes and ears. The human brain is only responsible for processing the signals and transmitting commands to other",N/A,N/A
"parts of the body such as movement, vision perception, sound perception, digestion and etc. By comparison, Individual PAI is
like an individual human body, while Distributed PAI further extends the AI capabilities just like the human society is composed
1
arXiv:2304.02924v1  [cs.AI]  6 Apr 2023
Figure 1. The applications of Distributed PAI
of multiple humans.
Due to the probabilistic data processing of the current DAI, decisions from DAI are unsubstantial, not being able to reduce",N/A,N/A
"the uncertainty of applications. On the other side of promoting the application of DAI, the explainable property of current DAI
poses increasing governance challenges against negative and malicious practice of DAI, including data biases and AI frauds,
etc. Explainable AI tries to explain and understand the internal operating mechanism of AI. Distributed PAI interacts with the
physical world with a much larger spatial area and consequently accumulates Big Data AI footprints which includes much",N/A,N/A
"longer interaction trajectories crossing cyberspace and physical world. So explainable AI applied in Distributed PAI has the
advantage to reveal the internal mechanism of DAI and the integrated human-cyber-physical social phenomena.
PAI needs to combine multiple streams of information including materials, temperature, vision, sound, etc, crossing multiple
modals from multiple sensors as shown in Fig. 1. Through the mix of the multimodal information, PAI builds competitive",N/A,N/A
"capability that uses multiple types of information which allows it to make better decision and better precision, in the context
of imprecise data collection, inconsistent information and incomplete knowledge scattering over various abstraction levels.
The various sources of data and information bring multiple kinds of data, which outperform a single source of data, to make
real-time decisions and predictions. This is a signiﬁcant feature of PAI.
The governance of PAI",N/A,N/A
"The governance of PAI
The governance of DAI has been challenged by researchers from a fairness to social impact perspective. DAI has been facing
the challenges of risk and governance4 from, but not limited to, the following aspects: 1) The storage and transfer security; 2)
The fake data; 3) The social privacy; 4) The bias of the sex, gender, and race because of the limited training datasets.",N/A,N/A
"As a consequence to the multi-source perception and multi-dimension interaction in a much larger space, PAI, especially
Distributed PAI, brings more uncertainty and risk from the social impact to the technology inﬂuence:
• The existence problem. PAI especially Distributed PAI such as IoT needs multiple kinds of sensors to interact with the
physical world. If PAI is distributed in a limited space such as a factory, it will not encounter challenging regulation",N/A,N/A
"problems because it is in an internal space. However, if the space is extended to a larger space such as a city which is not
under one unique regulation, PAI will face problems of social regulations.
• The data organization problem. The multiple sources of data from the physical world of a wider space will increase
the structural construction and integration complexity of the data and information. The Knowledge Graph could be the",N/A,N/A
"potential solution for the information organization in the hierarchical structure.
2/4
Figure 2. Distributed PAI
• Cannikin Law. The development of PAI depends on at least 5 disciplines of materials science, mechanical engineering,
chemistry, biology and computer science. Therefore, the slower development of one discipline will cause the problem of
Cannikin law and prohibit the development of PAI.",N/A,N/A
"Cannikin law and prohibit the development of PAI.
• The social acceptance. Similar to the dilemma of DAI, the ubiquitous application of PAI will cause the worry of the
society regarding the increase of unemployment, broadening of the gap in income, the shrinking of privacy space, etc.
The acceptance from multiple aspects of the law and society will inﬂuence the application of PAI in the research, the",N/A,N/A
"industry and the society. So, the acceptance of the society and the corresponding legislation is a potential factor for PAI.
We illustrates above governance problems of PAI in Figure 3. The development of PAI has to resolve these four problems.
Conclusion
We have suggested extending the notion of PAI to a larger physical space with the distributed applications with the notion of",N/A,N/A
"Distributed PAI. The spatial variety of Distributed PAI could vary from a room space to a city space, while its applications
include IoT, agriculture, and so forth. Since PAI, especially Distributed PAI, perceives and interacts with different physical
entities in different spaces, the governance issues including the existence problem has been challenged. We have put forward a
3/4
Figure 3. PAI governance problems",N/A,N/A
"3/4
Figure 3. PAI governance problems
framework of governance problems of PAI however this is open to further discussions since it is a research topic applying not
only to the research but also the development of the whole human society.
References
1. Miriyev, Aslan, and Mirko Kovaˇc. ""Skills for physical artiﬁcial intelligence."" Nature Machine Intelligence 2.11 (2020):
658-660.
2. Satyanarayanan, Mahadev. ""How we created edge computing."" Nature Electronics 2.1 (2019): 42-42.",N/A,N/A
"3. Vinuesa, Ricardo, et al. ""The role of artiﬁcial intelligence in achieving the Sustainable Development Goals."" Nature
communications 11.1 (2020): 1-10.
4. Margetts, Helen, and Cosmina Dorobantu. ""Rethink government with AI."" Nature (2019): 163-165.
4/4",N/A,N/A
"Does an artiﬁcial intelligence perform market
manipulation with its own discretion?
– A genetic algorithm learns in an artiﬁcial
market simulation –
Takanobu Mizuta∗
SPARX Asset Management Co. Ltd., Tokyo, Japan
Abstract
Who should be charged with responsibility for an ar-
tiﬁcial intelligence performing market manipulation
have been discussed. In this study, I constructed an
artiﬁcial intelligence using a genetic algorithm that
learns in an artiﬁcial market simulation, and investi-",N/A,N/A
"gated whether the artiﬁcial intelligence discovers mar-
ket manipulation through learning with an artiﬁcial
market simulation despite a builder of artiﬁcial intel-
ligence has no intention of market manipulation. As
a result, the artiﬁcial intelligence discovered market
manipulation as an optimal investment strategy. This
result suggests necessity of regulation, such as obligat-
ing builders of artiﬁcial intelligence to prevent artiﬁcial
intelligence from performing market manipulation.
1",N/A,N/A
"1
Introduction
Who should be charged with responsibility for an arti-
ﬁcial intelligence (AI) having an accident and/or per-
forming an illegal action have been discussed. In ﬁnan-
cial sector, who should be charged with responsibility
for an AI performing market manipulation have been
discussed. Market manipulation is that some traders
artiﬁcially increase or decrease market prices to gain
their proﬁts, and is prohibited in many countries as
unfair trades.",N/A,N/A
"unfair trades.
Scopino indicated that when a human has built an
AI trader without intention to perform market manip-
ulation and the AI trader has actually performed mar-
ket manipulation with its own discretion, the human
may not be charged with responsibility in the present
regulation of the united states [1]. This means that
even though market prices are manipulated no one is
charged with responsibility. This is a big problem to
∗mizutata@gmail.com, https://mizutatakanobu.com",N/A,N/A
"∗mizutata@gmail.com, https://mizutatakanobu.com
prevent keeping quality of markets.
An AI trader must automatically learn impacts of its
trades to market prices in order to discover that mar-
ket manipulation earns proﬁt because own trades must
increase or decrease market prices to perform market
manipulation. An AI trader is usually evaluated by
backtesting, in which the proﬁt is estimated if the AI
trader were trading at some time using historical real",N/A,N/A
"data of market prices. An AI trader cannot learn im-
pacts of its trades to market prices because market
prices are ﬁxed as real historical data in the backtest-
ing.
Therefore, an AI trader will not discover that
market manipulation earns proﬁt when the AI trader
use backtesting as learning process. Then, we do not
have to worry that an AI trader performs market ma-
nipulation with its own discretion without the human’s
intention as long as using backtesting.",N/A,N/A
"intention as long as using backtesting.
In contrast, an artiﬁcial market simulation using a
kind of agent-based model [2] allows an AI trader to
be able to automatically learn impacts of its trades to
market prices because in the simulation market prices
are changed by trades of an AI trader.
In this study, as Fig. 1 shown, I constructed an AI
trader using a genetic algorithm 1 that learns in an
artiﬁcial market simulation, and investigated whether",N/A,N/A
"the AI trader discovers market manipulation through
learning despite a builder of the AI trader has no in-
tention of market manipulation.
1A genetic algorithm is a calculation method approximately
searching an optimal solution inspired by the evolution of life
by the force of natural selection. Input values are represent as
genes, and surviving a gene that has higher adaptability (output
value) leads to obtain an optimal solution, that is the input value",N/A,N/A
"that emerges the highest output value. Goldberg wrote the great
text book [3]
1
arXiv:2005.10488v1  [q-fin.TR]  21 May 2020
Order
Exchange
Artificial Market
Simulation
Actions
By a Gene
Gene
Genetic
Algorithm
All Actions
Profit=Evaluation
AI agent
(AIA)
Gene
Artificial Market
All Actions
Evaluation
Gene
Gene
・
・
・
・
・
・
・
・
・
・
・
・
・
・
・
・
B
S
S
・・・・・
B
B
S
S
・・・・・
S
S
S
S
・・・・・
B
B
B
B
・・・・・
S
Nt Actions(Buy(B), Sell(S), No action(null))
Ng
Genes",N/A,N/A
"Ng
Genes
Inherit to new Generation after Crossover and Mutation
Repeat Ne generations
・
・
・
・
・
・
・
・
Normal
Agent (NA)
Artificial Market
Artificial Market
All Actions
Evaluation
All Actions
Evaluation
Fig. 1: My model
2
Model
A human building an AI trader (builder) gives the
AI trader candidates of trading strategies, and makes
the AI trader to learn which strategies and parameters
earn more. This study focuses whether an AI trader
can discover market manipulation through learning de-",N/A,N/A
"spite the builder has no intention of market manipula-
tion2.
Fig. 1 schematically shows a model of this study. An
AI trader that the builder intents no trading strategy
is modeled using a genetic algorithm in which a gene
includes all trades. Each gene is evaluated in the artiﬁ-
cial market simulation. The artiﬁcial market includes
an AI agent (AIA) that trades exactly same as one
gene indicating. The gene is evaluated by AIA’s proﬁt",N/A,N/A
"2In reality, the builder always intents some kinds of strate-
gies in the process of picking up and modeling candidates of
strategies. In contrast, it is very important for this study that
the builder has no intention of any strategies including market
manipulation. Therefore, I do not intentionally modeled trad-
ing strategies and my model directly searches for all the best
trades in an artiﬁcial market environment. Due to no models
of trading strategies my model can not make any outputs in an",N/A,N/A
"out-sample, then no one can test my model in an out-sample. I
argue, however, that this study needs no evaluations in an out-
sample because this study focuses whether an AI trader can dis-
cover market manipulation through learning despite the builder
has no intention of market manipulation. This study does not
aim to use my model in actual ﬁnancial markets that are in an
out-sample environment.
in the artiﬁcial market simulation. The genetic algo-",N/A,N/A
"rithm search the gene most earns proﬁt. This searching
corresponds with what the AI trader learns how trades
earns proﬁt.
Of course, trades of the AIA impact market prices
in the artiﬁcial market, but for the purpose of compar-
ison, I also investigated the case without the impacts
to market prices (backtesting).
In the following, at ﬁrst I explain the artiﬁcial mar-
ket simulation evaluating each gene and then, I explain
the genetic algorithm searching the gene most earns
proﬁt.
2.1",N/A,N/A
"proﬁt.
2.1
Artiﬁcial Market Simulation
In this study, I built an artiﬁcial market model added
an AIA to the artiﬁcial market model of Mizuta [2]
In the model here, there is one stock.
The stock
exchange adopts a continuous double auction to de-
termine the market price. In this auction mechanism,
multiple buyers and sellers compete to buy and sell
ﬁnancial assets in the market, and transactions can
occur at any time whenever an oﬀer to buy and an of-",N/A,N/A
"fer to sell match. The minimum unit of price change is
δP. The buy-order price is rounded oﬀto the nearest
fraction, and the sell-order price is rounded up to the
nearest fraction.
The model includes n normal agents (NAs) and an
AIA. Agents can short sell freely. The quantity of hold-
2
ing positions is not limited, so agents can take any
shares for both long and short positions to inﬁnity.
Agents always places an order for only one share. I
employed “tick time” t that increase by one when an",N/A,N/A
"agent orders.
2.1.1
Normal Agent (NA)
To replicate the nature of price formation in actual
ﬁnancial markets, I introduced the NA to model a very
general investor. The number of NAs is n. First, at
time t = 1, NA No. 1 places an order to buy or sell
its risk asset; then, at t = 2, 3, , , n, NAs No. 2, 3, , , n
respectively place buy or sell orders. At t = n + 1, the
model returns to the ﬁrst NA and repeats this cycle.
An NA determines an order price and buys or sells as",N/A,N/A
"follows. It uses a combination of a fundamental value
and technical rules to form an expectation on a risk
asset’s return. The expected return of agent j for each
risk asset is
rt
e,j = (w1,j log Pf
P t−1 +w2,j log
P t−1
P t−τj−1 +w3,jϵt
j)/Σ3
i wi,j
(1)
where wi,j is the weight of term i for agent j and is
independently determined by random variables uni-
formly distributed on the interval (0, wi,max) at the
start of the simulation for each agent. log is natural",N/A,N/A
"logarithm. Pf is a fundamental value and is a con-
stant. P t is a market price that is the mid price (the
average price of the highest buy order price and the
lowest sell order price), and ϵt
j is determined by ran-
dom variables from a normal distribution with average
0 and variance σϵ. Finally, τj is independently deter-
mined by random variables uniformly distributed on
the interval (1, τmax) at the start of the simulation for
each agent3.
The ﬁrst term of Eq. (1) represents a fundamental",N/A,N/A
"The ﬁrst term of Eq. (1) represents a fundamental
strategy: the NA expects a positive return when the
market price is lower than the fundamental value, and
vice versa. The second term of Eq. (1) represents a
technical strategy using a historical return: the NA
expects a positive return when the historical market
return is positive, and vice versa. The third term of
Eq. (1) represents noise.
After the expected return has been determined, the
expected price is
P t
e,j = P t exp (rt
e,j).
(2)",N/A,N/A
"expected price is
P t
e,j = P t exp (rt
e,j).
(2)
An order price P t
o,j is determined by random vari-
ables uniformly distributed on the interval (P t
e,j −
Pd, P t
e,j + Pd) where Pd is a constant.
Whether to
buy or sell is determined by the magnitude relation-
ship between P t
e,j and P t
o,j:
3When t < τj, however, the second term of Eq. (1) is zero.
when P t
e,j > P t
o,j, the NA places an order to buy one
share, but
when P t
e,j < P t
o,j, the NA places an order to sell one",N/A,N/A
"e,j < P t
o,j, the NA places an order to sell one
share4. The remaining order is canceled after tc from
the order time.
2.1.2
AI Agent (AIA)
Every δt tick time the AIA takes one of three actions
that are buy one share (at the lowest sell order price
on the order book), sell one share (at the highest buy
order price on the order book) and no action5. The
AIA takes actions Nt = (te −tc)/δt times through
the whole one artiﬁcial market simulation, where one
simulation runs until tick time te.",N/A,N/A
"simulation runs until tick time te.
The actions are
given by one gene in the genetic algorithm as following
I will mention.
2.2
Genetic Algorithm
2.2.1
Genes and Artiﬁcial Market
Fig. 1 schematically shows a model of this study. An
AI trader that the builder intents no trading strategy
is modeled using a genetic algorithm. The number of
genes is Ng. One gene has information of actions and
the number of actions that one gene has is Nt. Each
action is one of three actions that are buy one share,",N/A,N/A
"sell one share and no action. Each gene is evaluated
by proﬁt of the AIA in an artiﬁcial market, in where
the AIA trades every δt tick time same as Nt actions
one gene indicating. When the AIA holds stocks at
the end of a simulation, the stocks are evaluated as
Pf. All artiﬁcial markets has exactly same NAs using
same random numbers. Therefore, if the AIA trades
same, the artiﬁcial markets output same market prices
and same NAs’ trades.
2.2.2
Inheritance to Next Generation",N/A,N/A
"2.2.2
Inheritance to Next Generation
The top Nge genes that earned most are not changed
and inherited to the next generation.
Non top Nge genes are, with a probability of Rc, re-
placed to the crossed-over gene with two genes g0 and
g1 that are randomly selected from the top Nge genes.
In the crossover, ﬁrst, all actions are replace with those
of the gene g0, and then from i0th to i1th actions (i0
and i1 are randomly determined) are replaced with",N/A,N/A
"and i1 are randomly determined) are replaced with
those of the gene g1. After crossovers, each action of
4When t < tc, however, to generate enough waiting orders,
the agent places an order to buy one share when Pf > P t
o,j, or
to sell one share when Pf < P t
o,j.
5But, the AIA dose not take any action before tick time tc
to stabilize the simulations. As I mentioned at *4, the period
before tc is aimed to generate enough waiting orders.
3
9800
10000
10200
10400
10600
0
1000
2000
3000
4000
5000",N/A,N/A
"10200
10400
10600
0
1000
2000
3000
4000
5000
6000
7000
Price
Tick Time
with AIA
without AIA
Fig. 2: Time evolution of market prices (mid prices)
in the case with the AI agent (AIA) and without the
AIA
all the non top Nge genes is mutated with a probabil-
ity of Rm. The mutated action is changed with same
probability to buy, sell or no action.
This inheritance to the next generation is repeated
Ne times.
At the ﬁrst generation, all actions of all genes are",N/A,N/A
"determined with same probability to buy, sell or no
action.
3
Simulation Result
In this study, I set parameters for the artiﬁcial market
with n = 900, w1,max = 1, w2,max = 100, w3,max =
1, τmax = 1000, σϵ = 0.03, Pd = 1000, tc = 2000, δP =
0.01, Pf = 10000, δt = 10. I ran simulations to t =
te = 10000. I set parameters for the genetic algorithm
with Nt = (te −tc)/δt = 800, Ng = 10000, Nge =
400, Rc = 0.65, Rm = 0.2, Ne = 1500.
These lead
Ng × Ne = 1.5 × 107, this means that I have executed",N/A,N/A
"15 million simulation runs of the artiﬁcial market. In
the following result, I used the AIA of the best gene
at the ﬁnal generation.
3.1
Result of First Simulation Run
Fig. 2 shows the time evolution of market prices (mid
prices) in the case with the AIA and without the AIA.
The AIA ampliﬁed variation of market prices.
Fig.
3 shows the time evolution of market prices
with the AIA and trading volume (positive and neg-
ative number show buy and sell, respectively) aggre-",N/A,N/A
"gated within each 200 tick time.
Around 2000 tick
time, the AIA bought many stocks, and this buying
leads to the market prices increasing.
Around 3000
tick time, the market prices continued to increase even
though the AIA did not bought so many stocks. Here,
the fundamental strategy of normal agents in the ﬁrst
term of Eq. (1) expected negative return because the
market prices are over the fundamental price. On the
other hand, the technical strategy in the second term of",N/A,N/A
"Eq. (1) expected larger positive return due to the his-
torical positive return around 2000 tick time where the
AIA had increased market prices by itself. Therefore,
the market prices were able to increase even though
the AIA did not bought so many stocks. After then,
from around 4000 tick time to around 6000 tick time,
the AIA was able to sell stocks with higher prices than
the prices bought them around 2000 tick time thanks
to increasing market prices around 3000 tick time.",N/A,N/A
"These trades of the AIA are nothing but market ma-
nipulation. This indicates that an artiﬁcial intelligence
can discover market manipulation as an optimal in-
vestment strategy through learning with an artiﬁcial
market simulation.
Fig.
4 shows the time evolution of market prices
and trading volume in the case without the impacts to
market prices (backtesting) like Fig. 3. Note that Fig.
4 has diﬀerent scale for the vertical axis from those in",N/A,N/A
"Fig. 2 and Fig. 3. The time evolution of market prices
is exactly same as the case without the AIA because
the trades of the AIA never impact market prices in
Fig. 2. Due to lower market prices from the funda-
mental price, the AIA tended to buy stocks. These
trades of the AIA corresponds to fundamental strat-
egy. Thus, in the case of backtesting, the AIA cannot
discover market manipulation as trading strategy.
This indicates possibility that an artiﬁcial intelli-",N/A,N/A
"gence cannot discover market manipulation through
learning with backtesting.
4
Summary and Future Works
In this study, as Fig. 1 shown, I constructed an AI
trader using a genetic algorithm that learns in an ar-
tiﬁcial market simulation, and investigated whether
the AI trader discovers market manipulation through
learning despite a builder of the AI trader has no in-
tention of market manipulation.
As a result, the AI trader discovered market ma-
nipulation as an optimal investment strategy.",N/A,N/A
"nipulation as an optimal investment strategy.
This
indicates that despite a builder of the AI trader has
no intention of market manipulation, the AI trader
can discover market manipulation as an optimal in-
vestment strategy through learning with an artiﬁcial
market simulation in which the AI trader to be able
to automatically learn impacts of its trades to market
prices. On the other hand, this also indicates possi-
bility that an AI trader cannot discover market ma-",N/A,N/A
"nipulation through learning with backtesting in which
there are no impacts to market prices.
4
-20
0
20
40
60
9800
10000
10200
10400
10600
0
1000
2000
3000
4000
5000
6000
7000
Trading Volume
Price
Tick Time
Trading Volume of AIA (right)
Market Price (left)
Fundamental Price (left)
Fig. 3: Time evolution of market prices with the AIA and trading volume (positive and negative number show
buy and sell, respectively) aggregated within each 200 tick time
-20
0
20
40
60
9980
10000
10020
10040
10060
0",N/A,N/A
"-20
0
20
40
60
9980
10000
10020
10040
10060
0
1000
2000
3000
4000
5000
6000
7000
Trading Volume
Price
Tick Time
Trading Volume of AIA (right)
Market Price (left)
Fundamental Price (left)
Fig. 4: Case without the impacts to market prices
(backtesting)
This result suggests necessity of regulation, such as
obligating builders of artiﬁcial intelligence to prevent
artiﬁcial intelligence from performing market manipu-
lation.
Of course, future works exist. In this study, I sim-",N/A,N/A
"ulated eleven situations by one data set of normal
agents. In short, I simulated whole my model showed
Table 1: Statistics for Returns in the Artiﬁcial Market
standard deviation of returns
0.0103%
kurtosis of returns
11.54
lag
1
0.081
auto-correlation
2
0.041
coeﬃcient of
3
0.032
square returns
4
0.047
5
0.018
by Fig. 1 only one time. Because this study aimed to
investigate whether possibility that an artiﬁcial intel-
ligence discovers market manipulation exists or does",N/A,N/A
"not, the only one simulation run indicating the pos-
sibility is enough for the aim of this study. On the
discussing necessity of regulation, whether there is the
possibility or not is very important.
On the other
hand, how easily an artiﬁcial intelligence can discover
market manipulation may also interested. To answer
the question, whole my model should be simulated
more times. The many runs needs very faster com-
puters. This is one of future works.
5
Appendix
4.1",N/A,N/A
"5
Appendix
4.1
Veriﬁcation of the Artiﬁcial Mar-
ket Model
In many previous artiﬁcial market studies, the mod-
els were veriﬁed to see whether they could explain
stylized facts, such as a fat-tail or volatility-clustering
[2, 4, 5].
A fat-tail means that the kurtosis of price
returns is positive.
Volatility-clustering means that
square returns have a positive auto-correlation, and
this auto-correlation slowly decays as its lag becomes
longer.
Many empirical studies, e.g., that of Sewell",N/A,N/A
"Many empirical studies, e.g., that of Sewell
[6], have shown that both stylized facts (fat-tail and
volatility-clustering) exist statistically in almost all ﬁ-
nancial markets.
Conversely, they also have shown
that only the fat-tail and volatility-clustering are sta-
bly observed for any asset and in any period because
ﬁnancial markets are generally unstable.
Indeed, the kurtosis of price returns and the auto-
correlation of square returns are stably and signiﬁ-",N/A,N/A
"cantly positive, but the magnitudes of these values
are unstable and very diﬀerent depending on the as-
set and/or period. The kurtosis of price returns and
the auto-correlation of square returns were observed
to have very broad magnitudes of about 1 ∼100 and
about 0 ∼0.2, respectively [6].
For the above reasons, an artiﬁcial market model
should replicate these values as signiﬁcantly positive
and within a reasonable range as I mentioned. It is",N/A,N/A
"not essential for the model to replicate speciﬁc values
of stylized facts because the values of these facts are
unstable in actual ﬁnancial markets.
Table 1 lists the statistics, standard deviation of re-
turns, kurtosis of price returns, and auto-correlation
coeﬃcient of square returns, where the returns are
measured within 100 time steps and the statistics are
averaged values of the 100 simulation runs. This table
shows that this model replicated the statistical char-",N/A,N/A
"acteristics, fat-tails, and volatility-clustering observed
in real ﬁnancial markets.
Disclaimer
Note that the opinions contained herein are solely those of the
authors and do not necessarily reﬂect those of SPARX Asset
Management Co., Ltd.
Reference
[1] G. Scopino,
“Do automated trading systems dream of
manipulating the price of futures contracts?
policing
markets for improper trading practices by algorithmic
robots,” Florida Law Review, vol. 67, p. 221, 2016. [Online].",N/A,N/A
"Available: https://scholarship.law.uﬂ.edu/ﬂr/vol67/iss1/5
[2] T. Mizuta, “An agent-based model for designing a ﬁnancial
market that works well,” arXiv, 2019. [Online]. Available:
https://arxiv.org/abs/1906.06000
[3] D. E. Goldberg, Genetic Algorithms in Search, Optimiza-
tion, and Machine Learning.
Addison-Wesley Professional,
1989.
[4] B. LeBaron, “Agent-based computational ﬁnance,” Hand-
book
of
computational
economics,
vol.
2,
pp.
1187–
1233, 2006. [Online]. Available:",N/A,N/A
"2,
pp.
1187–
1233, 2006. [Online]. Available:
https://doi.org/10.1016/
S1574-0021(05)02024-1
[5] S.-H. Chen, C.-L. Chang, and Y.-R. Du, “Agent-based
economic models and econometrics,” Knowledge Engineer-
ing Review, vol. 27, no. 2, pp. 187–219, 2012. [Online].
Available: https://doi.org/10.1017/S0269888912000136
[6] M. Sewell,
“Characterization of ﬁnancial time series,”
Research Note, University College London, Department of
Computer Science, no. RN/11/01, 2011. [Online]. Available:",N/A,N/A
"https://ﬁnance.martinsewell.com/stylized-facts/
6",N/A,N/A
"Impact of Artificial Intelligence on Economic Theory 
Tshilidzi Marwala 
University of Johannesburg 
Abstract 
Artificial intelligence has impacted many aspects of human life. This paper studies the impact of artificial 
intelligence on economic theory. In particular we study the impact of artificial intelligence on the theory 
of bounded rationality, efficient market hypothesis and prospect theory. 
 
Introduction",N/A,N/A
"Introduction 
Artificial intelligence is a paradigm where computers or machines are designed to perform tasks that 
require high level cognition. This is normally achieved by looking at nature and designing machines that 
are inspired by objects or systems from nature that have been perfected over a long period of time. For 
example, one can look at how a colony of ants find a shortest distance from its home and the food source",N/A,N/A
"and use this to design routing algorithms that are essential for our GPS guides in our cars. The impact of 
artificial intelligence on major areas of economic sectors is extensive. In the manufacturing industry the 
application of artificial intelligence to perform tasks that used to be performed by humans will result in 
extensive job losses. Artificial intelligence has found applications in complex areas in the social, political",N/A,N/A
"and economic spaces. For example, Marwala and Lagazio (2011) applied artificial intelligence extensively 
to model militarized interstate conflict. In this regard the problem of conflict resolution which traditionally 
required human intuition now involves using computers empowered with artificial intelligence to secure 
peace. Another application of artificial is the application of artificial intelligence to better design complex",N/A,N/A
"structures such as aircrafts. In this regard Marwala et. al. (2015a) and Marwala (2010) were able to use 
artificial intelligence to create models that are essential to the design of complex systems such as aircraft. 
In decision making one essential aspect is to be able to secure all information required to make a rational 
decision. Artificial intelligence has been applied successfully to fill in the gaps that exist in information",N/A,N/A
"required to make informed decision. Marwala (2009) applied artificial intelligence to fill in missing 
information and applied this to decision making in assessing the risks associated with making decisions 
with incomplete information. Monitoring the conditions of structures such as bridges is essential for 
securing safe utilization of essential public goods such as bridges. In this regard Marwala (2012) applied",N/A,N/A
"artificial intelligence to monitor the conditions of essential mechanical and electrical engineering 
structures essential in the electricity industry.  
Bounded Rationality 
One aspect of the artificial intelligence is how this technology changes economic theories. Marwala (2013) 
applied artificial intelligence to model economic and financial instruments such as the stock markets, 
derivatives and options. How then does artificial intelligence changes economic theory? For example,",N/A,N/A
"Economics Nobel Laureate Herbert Simon (1991) observed that on making decisions rationally one does 
not have the perfect and complete information to make a fully rational decision. Moreover, one does not 
have the perfect brain to process such information timely and efficiently and the human brain is not 
consistent and thus decisions made by a human brain are thus inconsistent as they change depending on",N/A,N/A
"other factors such as moods swings. Simon termed decision making under such circumstances bounded 
rationally. With the advent of artificial intelligence one is able to access information that was hidden and 
thus not accessible, and is able to use such information consistently by the use of artificial intelligence for 
decision making and is able to increasingly make such decisions more timely and efficiently due to Moore’s",N/A,N/A
"Law which states that the processing power of machines is always increasing (Moore, 2006).   What does 
this advent of artificial intelligence mean for the theory of bounded rationality? It means that the bounds 
in Simon’s theory of bounded rationality are in effect flexible due to Moore’s Law, advanced signal 
processing and artificial intelligence and more information on this can be studies in the books by Marwala 
(2014 and 2015b). 
Efficient Market Hypothesis",N/A,N/A
"(2014 and 2015b). 
Efficient Market Hypothesis  
Another economic theory which is influenced by the advent of artificial intelligence is the theory of the 
efficient market hypothesis developed by Nobel Laureate Eugene Fama (1965). This hypothesis states that 
it is often difficult to beat the markets because the markets are efficient. The problem, is that because the 
traders in the market are often not perfect and the information they have is imperfect and incomplete",N/A,N/A
"the markets are not efficient. Now what happens to the efficient market theory if the traders in the market 
are not just people but are a combination of people and artificial intelligence infused computer trader? 
The more artificial intelligence empowered computer traders we have in the markets the more efficient 
the markets become and therefore the degree at which markets are efficient depends on the amount of 
artificial intelligent traders we have in the markets.    
Prospect Theory",N/A,N/A
"Prospect Theory 
Nobel Laureate Daniel Kahneman and Amos Tversky (1979) proposed the prospect theory that states that 
when people make decisions with the probability of outcomes known they weigh potential losses against 
potential gains to make such decisions. The impact of this theory on the markets is extensive. However, it 
rests on the fact that the decision maker is just a person. What happens to this theory if the decision",N/A,N/A
"maker is not just a person but a person who is using an artificial intelligent decision machine? How about 
if the decision maker is wholly an artificial intelligent machine? The applicability of Prospect Theory solely 
depends on how much artificial intelligent machine is used to make such a decision. 
Conclusion 
Decision making is more and more involving artificial intelligent machine. This paper described how three",N/A,N/A
"economic theories are impacted by the application of artificial intelligent machine in the decision making 
process. It is found that the use of artificial intelligent machine changes the degrees in which the theory 
of bounded rationality, efficient market hypothesis and prospect theories are applicable.     
Reference: 
1. Fama, Eugene (1965). ""The Behavior of Stock Market Prices"". Journal of Business 38: 34–105.",N/A,N/A
"doi:10.1086/294743.Kahneman, Daniel; Tversky, Amos (1979). ""Prospect Theory: An Analysis of Decision 
under Risk"" (PDF). Econometrica 47 (2): 263. doi:10.2307/1914185. ISSN 0012-9682. 
2. Marwala, Tshilidzi, Boulkaibet, Ilyes, and Adhikari Sondipon. (2015a). Probabilistic Finite Element Model 
Updating Using Bayesian Statistics: Applications to aeronautical and mechanical engineering. John Wiley and 
Sons  ISBN: 978-1-119-15303-0 (in press).",N/A,N/A
"Sons  ISBN: 978-1-119-15303-0 (in press). 
3. Marwala, Tshilidzi (2015b). Causality, Correlation, and Artificial Intelligence for Rational Decision Making. 
Singapore: World Scientific. ISBN 978-9-814-63086-3. 
4. Marwala, 
Tshilidzi 
(2014). 
Artificial 
Intelligence 
Techniques 
for 
Rational 
Decision 
Making. 
Heidelberg: Springer. ISBN 978-3-319-11423-1. 
5. Marwala, 
Tshilidzi 
(2013). 
Economic 
Modeling 
Using 
Artificial 
Intelligence 
Methods.",N/A,N/A
"Using 
Artificial 
Intelligence 
Methods. 
Heidelberg: Springer. ISBN 978-1-84996-323-7. 
6. Marwala, 
Tshilidzi 
(2012). 
Condition 
Monitoring 
Using 
Computational 
Intelligence 
Methods. 
Heidelberg: Springer. ISBN 978-1-4471-2380-4. 
7. Marwala, Tshilidzi; Lagazio, Monica (2011). Militarized Conflict Modeling Using Computational Intelligence. 
Heidelberg: Springer. ISBN 978-0-85729-789-1.",N/A,N/A
"Heidelberg: Springer. ISBN 978-0-85729-789-1. 
8. Marwala, Tshilidzi (2010). Finite Element Model Updating Using Computational Intelligence Techniques: 
Applications to Structural Dynamics. Heidelberg: Springer. ISBN 978-1-84996-322-0. 
9. Marwala, Tshilidzi (2009). Computational Intelligence for Missing Data Imputation, Estimation, and 
Management: Knowledge Optimization Techniques. Pennsylvania: IGI Global. ISBN 978-1-60566-336-4.",N/A,N/A
"10. Moore, Gordon (2006). ""Chapter 7: Moore's law at 40"". In Brock, David. Understanding Moore’s Law: Four 
Decades of Innovation (PDF). Chemical Heritage Foundation. pp. 67–84. ISBN 0-941901-41-6.  
11. Simon, Herbert (1991). ""Bounded Rationality and Organizational Learning"". Organization Science 2 (1): 125–
134. doi:10.1287/orsc.2.1.125",N/A,N/A
